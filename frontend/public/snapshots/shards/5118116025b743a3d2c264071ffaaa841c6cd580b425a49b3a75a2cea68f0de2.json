{"version":"v1","hackathon_url":"https://cal-hacks-12-0.devpost.com","generated_at":"2026-02-17T18:22:27.964251Z","result":{"hackathon":{"name":"Cal Hacks 12.0","url":"https://cal-hacks-12-0.devpost.com","gallery_url":"https://cal-hacks-12-0.devpost.com/project-gallery","scanned_pages":30,"scanned_projects":699,"winner_count":102},"winners":[{"project_title":"Ted.AI","project_url":"https://devpost.com/software/ted-ai-x8537t","tagline":"A multimodal AI companion that fuses emotion sensing, language understanding, and real-time biofeedback to support children‚Äôs mental wellness.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/898/779/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"LiveKit: Most Creative Project"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: 2nd Overall"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"fetchai","url":null},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"neurolinq","url":"https://devpost.com/software/built-with/neurolinq"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Every day, millions of children grow up battling unseen struggles ‚Äî anxiety, ADHD, loneliness, and emotional overwhelm ‚Äî in a world moving too fast to listen. We wanted to create something that not only hears them but feels with them. A companion that bridges empathy and intelligence to help them regulate emotions and feel understood."},{"heading":"What it does","content":"Ted.AI is an emotionally intelligent teddy bear powered by multimodal AI. It senses hugs, movement, and heart rate using embedded sensors and responds with empathy through a conversational LLM. It guides children through breathing exercises, focus routines, and calming interactions while analyzing tone, language, and gestures to adapt its responses in real time. A connected dashboard visualizes emotional states, sentiment trends, and simulated brain-region activations for parents, educators, and clinicians."},{"heading":"How we built it","content":"Ted.AI integrates:\n\nHardware: ESP32 microcontroller, HW-502 pulse sensor, capacitive touch sensors, and MPU6050 accelerometer. Software: OpenAI Whisper for speech-to-text, RoBERTa for emotion detection, and GPT-powered dialogue through LangChain orchestration. Data Pipeline: Real-time sensor fusion via MQTT, edge inference using TensorFlow Lite Micro, and backend storage with Flask, MongoDB, and InfluxDB. Dashboard: Built with React, Flask, and D3.js to visualize emotion timelines and neural activation maps."},{"heading":"Challenges we ran into","content":"Synchronizing real-time audio, motion, and biosensor inputs required complex sensor fusion and filtering. Integrating emotion classification with low-latency on-device inference was another major challenge. We also spent time designing dialogue flows that felt emotionally natural rather than robotic, balancing empathy with accuracy."},{"heading":"Accomplishments that we're proud of","content":"We successfully built a fully functional prototype that detects emotion through physical and verbal cues, reacts in real time, and displays a live dashboard of emotional analytics. The seamless blend of hardware sensing, multimodal AI, and affective computing exceeded our expectations in both complexity and impact."},{"heading":"What we learned","content":"We learned how to merge disciplines ‚Äî embedded systems, AI, psychology, and human-centered design ‚Äî to create technology that genuinely connects with people. Building Ted.AI taught us the importance of empathy in engineering and how emotional design can make AI feel human."},{"heading":"What's next for Ted.AI","content":"We plan to integrate EEG-based emotional tracking, cloud-based analytics for therapists, and reinforcement learning for adaptive empathy. Our vision is to expand Ted.AI into classrooms and therapy settings to support children worldwide through emotionally aware technology."},{"heading":"Built With","content":"amazon-web-services arduino docker fetchai firebase flask gemini neurolinq openai python react"}]},{"project_title":"Project No Cap","project_url":"https://devpost.com/software/project-no-cap","tagline":"Project NoCap: Bringing clarity to the chaos of misinformation through real-time AI verification.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/889/470/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: 3rd Overall"}],"team_members":[],"built_with":[{"name":"brightdata","url":null},{"name":"chroma","url":"https://devpost.com/software/built-with/chroma"},{"name":"claude","url":null},{"name":"creao","url":null},{"name":"fetch.ai","url":null},{"name":"fishaudio","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"janitorai","url":null},{"name":"lava","url":null},{"name":"vapi","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/aditya-nandyal1/nocaprepo"}],"description_sections":[{"heading":"Inspiration","content":"Our team sees a significant issue in the increasing polarization of the United States populace and common media consumption. In hopes of tackling this problem, our team decided to explore the impacts of misinformation on these growing dynamics and find a means to mitigate any potential spread of false information. Throughout our research and personal experiences, we uncovered that misinformation is often being spread through biased/false publications and mismanaged word of mouth. From here, we determined that it would be far too difficult to ensure perfect accuracy on the publishing end so we settled for the next best thing which was a consumer centric implementation. Employing an AI-centered approach to information assurance, we were able to develop a convenient product that provides an additional layer of verification to any online readings or conversations. By creating an application that is multi-faceted and easy to apply, we‚Äôve provided a new avenue by which individuals can access material on the internet without fear of misinformation or bias."},{"heading":"What it does","content":"This innovative project uses a three part solution to combat misinformation by checking for written bias, ensuring verbal accuracy, and providing a medium for productive debates. When the application is active on any website or article, any declarative statements are cross referenced with any other similar publications and any potential biases/incorrect information are listed to provide the reader more context on any content. Another use case of our project is when the user needs to verify information of a call/meeting in which case our tool will transform any speech into text to be analyzed and cross checked by various AI agents to determine how factual any declarative statements are. Finally, the application provides a medium by which individuals can engage in an AI moderated debate which can help people communicate their ideas effectively and without misleading or confusing others through false statements. In our unique combination of various future-forward technologies, users can be more confident of any information they receive regardless of the medium."},{"heading":"How we built it","content":"Our project required a diverse blend of different AI agents and tools to completely cover the complete breadth of different cases that we wanted to include. Our first task was to dissect the various technologies available and ensure that we could effectively fit together each piece of the puzzle without sacrificing efficiency or complexity of the solution. In order to organize our large tech stack, we spent a lot of time diagraming the interactions between different technologies and procuring necessary API credits or subscriptions. With the background work complete, we were able to begin leveraging Creao to put together a working back end and front end shell which were used to house all of our additional APIs and AI Agents. At this point we configured a speech to text then text to AI search agent pipeline which handled our entire fact checking work flow. At this point we spent some time maximizing efficiency with speech sensitivity and statement identification. Working with a large number of different implementation, we also had to split our program into a web app and phone application piece in order to create a fully comprehensive application from both mediums."},{"heading":"Challenges we ran into","content":"Our project was initially extremely ambitious and technically challenging which meant that we were plagued with various difficulties throughout the entire process. Since our project relied on the combined implementation of various different AI agents, we had to precisely navigate many different unique API‚Äôs and documentation which took a large amount of time. We originally found many of the technologies that we intended to implement were difficult to utilize in combination with other key technologies which led to many significant changes early on. Another difficulty that we had was ensuring a positive user experience while still maintaining reasonable computational complexity and effectively building out an MVP that still stayed true to our original expectations. With so many different moving parts in this project, we were working right up to the deadline and had to strategically cut some features in order to ensure that our product was reliable and consistent which led to various technical compromises. By making these decisions to cut back on certain technical aspects, we slightly decreased our project‚Äôs initial scope in exchange for time to further polishing our current application and ensure that all key features were sound. Another key component that we found difficult was our importance on underutilized and irregular applications of the various APIs and AI Agents which added further complexity to the final product. Regardless of all these hardships, we were able to persevere and achieve a satisfactory result."},{"heading":"Accomplishments that we're proud of","content":"We are proud that throughout the competition we stayed well organized and maintained a solid work flow in spite of unexpected circumstances. Our team came into the competition with very ambitious expectations and we were able to adapt to new technologies while working under a severe time crunch. Throughout the entire event, our team communicated effectively and was able to make use of each member‚Äôs unique skills. At the end of the day, we stayed upbeat and effectively managed our time and energy to complete a technically complex product that upheld our original intentions."},{"heading":"What we learned","content":"Thanks to the incredible variety of innovative sponsors and the prominence of various emerging AI frameworks, our team gained hands-on experience with cutting-edge technologies and AI workflows. Due to strict time constraints, we needed to organize our thinking and leverage various generative AI agents while efficiently cutting unnecessary components in order to complete a fully integrated product. Additionally, we explored the various benefits of simultaneous use of different AI products to increase redundancy and accuracy through cross-examination. In the future we intend to expand upon these newfound skills that we acquired at Cal Hacks 12.0, growing into more complete engineers."},{"heading":"What's next for Project No Cap","content":"In the future we would like to begin expanding our product to synthesize multiple different sources that the user is hoping to compare and allow for summarizing capabilities. Another feature that we believe could be practical is something along the lines of measuring confidence in a certain assurance and to potentially provide context for any situations with lower confidence. There are additionally many interesting avenues with regards to providing a backlog of alternate options of articles to expand the user‚Äôs perspective or background knowledge on a topic. In terms of technical refinements, we hope to expand to as many different platforms as possible to align with that goal of easy accessibility and to hopefully decrease the latency on some of the voice features."},{"heading":"Built With","content":"brightdata chroma claude creao fetch.ai fishaudio gemini groq janitorai lava vapi"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Hardware Context Protocol (MCP for Hardware)","project_url":"https://devpost.com/software/hardware-context-protocol","tagline":"Giving AI a physical embodiment for the world. Control multiple hardware platforms cooperatively via LLM prompts. Deployed with a custom voice-activated autonomous chef robot.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/897/419/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Crater: Play-Do Prize"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: Best Hardware Hack"}],"team_members":[],"built_with":[{"name":"asi:one","url":null},{"name":"cv","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"inverse-kinematics","url":null},{"name":"json","url":"https://devpost.com/software/built-with/json"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tcp","url":"https://devpost.com/software/built-with/tcp"}],"external_links":[{"label":"github.com","url":"https://github.com/danielzyy/calhacks2025"}],"description_sections":[{"heading":"What it does","content":"We created an SDK that allows the user to create a minimal JSON-based definition of a certain hardware node and what actions it exposes to the LLM. This then bootstraps a custom TCP networking layer deployable on the hardware node compliant with our novel HCP interaction layer. The LLM goes through an initial discovery period where any HCP-bootstrapped TCP nodes are able to subscribe to it and pass relevant context in the HCP-defined schema. Sensors, like a camera, can detect the locations of objects and items of interest within their sensing frame, exposing them to the model; these can then be used to inform control actions orchestrated by the HCP."},{"heading":"Challenges we ran into","content":"Architecting HCP to be a scalable architecture that would cleanly integrate a fully in-software LLM to real-life hardware. Exposing generic hardware interfaces on actuator interfaces (such as the demo'd SOARM101) to be controllable by the LLM, developing inverse kinematics and smooth path planning for safe operation of the robot arm as well."},{"heading":"Accomplishments that we're proud of","content":"Creating a fully-fledged SDK that we were able to use to bootstrap demo hardware nodes at near-zero ramp-up or integration cost. Creating a fully custom TCP networking stack under a publish/subscribe model that was HCP-compatible and allowed seamless multi-node orchestration. Creating a seamless agentic loop between pure-software LLMs and distributed hardware nodes, both for sensing and environment manipulation."},{"heading":"What we learned","content":"Building HCP taught us that bridging the digital reasoning power of LLMs with the physical world requires both a solid networking backbone and a thoughtful interface abstraction. We learned how critical it is to design schemas that balance simplicity with extensibility. This enables both small embedded devices and complex robotic systems to integrate seamlessly. We also realized that context management is the heart of intelligent automation: giving LLMs structured, real-time situational awareness unlocks emergent problem-solving behaviours that feel almost human.\n\nSOARM-101 Integration\n\nThe goal of the SOARM-101 integration is to provide an actuation platform that can be controlled by the HCP SDK. While the HCP SDK provides an authoritative interface for exposing a hardware node's capabilities, integrating a robotic arm required significant effort.\n\nThe robotic arm provides control functionality to move to a desired position and grab and move objects. LLM interprets the user‚Äôs prompt about what they want to eat and moves the arm to pick up the desired ingredients to make a suitable dish."},{"heading":"3DOF End-Effector Commanding","content":"In robotic manipulation challenges, the goal is typically to track an end-effector position in the world. However, the SOARM-100 only exposed an API to command joint angles, requiring us to develop our own single-link-chain inverse kinematics model . The solver can solve for multiple manipulator configurations (elbow up/down). The advantage of this approach is that it generalizes the HCP's interaction with the arm (fully in world-frame space), thereby enhancing the control system's generalizability.\n\nThe development of the model required implementing a custom simulator to validate that null-space solutions are rejected, as well as to provide a sanity check that the forward and inverse kinematics models yield sane results. A figure of the simulator is shown below and has proved to be helpful in debugging and iterating off-target."},{"heading":"Camera and Vision Detection","content":"A camera was used to identify the locations of each object for the robot to interact with, using AprilTags and OpenCV. It exposes each object's type and position to the HCP layer so the LLM can guide the robot to interact with them. This approach of publishing generic data can be easily expanded to any type of sensor in the future, to help the model gain a better understanding of its environment."},{"heading":"What's next for Hardware Context Protocol","content":"Our next step is to expand the HCP SDK into a fully modular ecosystem that supports standardized drivers, cloud-based orchestration, and real-time safety supervision layers. We hope to release open-source tools, including the ones developed at this very hackathon, for rapidly bootstrapping HCP-compatible nodes across a variety of microcontrollers. In the long term, we envision HCP serving as the foundation for a universal hardware abstraction layer for AI agents, enabling LLMs to intuitively control everything from IoT devices to full-scale industrial robotics, bringing physical intelligence to any environment."},{"heading":"Built With","content":"asi:one cv flask inverse-kinematics json python tcp"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"FaceTimeOS: AI Mac Agent","project_url":"https://devpost.com/software/facetime-macos-ai-agent","tagline":"FaceTime to talk, see, and control your Macbook with AI Agents","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/901/909/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: 1st Overall"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"electron","url":"https://devpost.com/software/built-with/electron"},{"name":"fetch.ai","url":null},{"name":"fishaudio","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"huggingface","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"rest","url":null},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ThePickleGawd/calhacks-25"}],"description_sections":[{"heading":"Inspiration","content":"Have you ever gone to the gym and forgotten to train your Hugging Face model? Have you ever wanted to show a friend your most recent Fortnite clip, but the file was stuck on your Mac?\n\nWe've all been there. In today's remote-first world, we're often physically separated from our most powerful tool: our personal computer. We're stuck on the go, desperately needing a local file, a specific app, or the ability to run a complex script that only exists on our Mac. Current remote desktop solutions are clunky, slow, and built for visual control, not quick, conversational commands. We were inspired to bridge this gap. What if you could control your computer as easily as you call a friend? We envisioned a world where you could just FaceTime or iMessage your Mac and tell it exactly what you need."},{"heading":"What it does","content":"FaceTimeOS turns your Mac into a personal assistant you can call or text from anywhere.\n\nRemote Control via FaceTime & iMessage: You can place a FaceTime call or send an iMessage to your Mac, and our AI agent answers. You can speak or type natural language commands, like \"Find the screen recording I made yesterday about the product demo and upload it to Google Drive,\" or \"Re-run my training script and let me know if it fails.\" Intelligent Task Automation: The agent doesn't just execute simple commands; it can handle complex, multi-step tasks. It can monitor scripts, identify errors, and even attempt to resolve them based on your instructions. Natural Language & Visual Feedback: The agent keeps you updated through natural speech in the FaceTime call (or via text). It summarizes its actions, so you're not left guessing. Critically, after completing a task, it sends a screenshot to your phone via iMessage to visually confirm the job is done."},{"heading":"How we built it","content":"Our system is a multi-agent architecture orchestrated to create a seamless conversational experience.\n\nCore Orchestrator: We use Claude as the central orchestrator. It understands the user's high-level intent from the conversation and determines what actions to take. FaceTime Audio Integration: This was the core of our hack. We used Fish Audio to create a virtual microphone and speaker on the Mac. When a FaceTime call comes in, Fish Audio pipes the incoming audio to a speech-to-text service. This text is sent to our Claude agent, which processes the request and generates a text response. This response is then synthesized into speech and played back into the call through the virtual speaker. Task Execution & Summarization: To understand what the computer is doing and report back, we integrated fetch.ai. This agent monitors the \"computer-use trajectory\" (e.g., file access, app usage, script logs). When the user asks for an update, fetch.ai uses a model running on Groq to instantly summarize these complex actions into a concise, natural-speech update. Application & Backend: The agent itself is a desktop application built with Electron, React, and Tailwind CSS. The backend logic, REST API integrations, and agent coordination are handled by a Python and Flask server."},{"heading":"Challenges we ran into","content":"Smoothly Integrating Everything: Our biggest challenge was getting all the moving parts to talk to each other reliably. We had to create a robust system where the Fish Audio stream, the Claude orchestrator, the fetch.ai summarizer, and the Flask backend all communicated in real-time without dropping requests or getting out of sync. Real-time Audio Hijacking: Getting audio in and out of a closed system like FaceTime was extremely difficult. Configuring Fish Audio's virtual devices to intercept and inject audio in real-time‚Äîwithout creating echoes, feedback loops, or massive latency‚Äîtook significant trial and error. Multi-Agent Orchestration: Teaching Claude how to be an effective \"orchestrator\" was difficult. We had to carefully craft our prompts to ensure it knew when to handle a request itself versus when to delegate to fetch.ai for a summary or to the Flask backend for a system action."},{"heading":"Accomplishments that we're proud of","content":"Implementing Voice (It Talks Back!): Our biggest \"wow\" moment. Successfully using Fish Audio to pipe audio from a live FaceTime call, get a response from our AI, and speak it back into the call felt like magic. We turned a simple video call into a powerful C&C interface. Native macOS Integration: This isn't just a web app. By using Electron and integrating directly with system audio via Fish Audio, our agent feels like a native part of the macOS ecosystem, answering FaceTime calls just like a real person. A True Multi-Agent System: We've built a pipeline where Fetch AI orchestrates multiple specialized models (Claude for reasoning, Groq for speed) to fulfill a single, complex user request. The Screenshot Confirmation: Getting the final screenshot sent back to iMessage was a key feature. It provides total peace of mind that the requested task was actually completed correctly, which is critical for a remote tool."},{"heading":"What we learned","content":"Specialized Agents Win: The \"agent-of-agents\" model is highly effective. Using Groq for its sheer speed in summarization, Fetch AI for orchestration, and Claude for its powerful reasoning allowed us to build a more robust system than one single model could provide. The Future is Conversational: Interfacing with complex systems via natural language (and getting visual feedback) is far more intuitive than traditional UIs for many tasks. Virtual Devices are a Superpower: Tools like Fish Audio are incredibly powerful. They let you integrate AI into existing, closed platforms (like FaceTime) without needing an official API."},{"heading":"What's next for FaceTimeOS: AI Mac Agent","content":"Proactive Assistance: We want the agent to be proactive. It could monitor your computer and ping you‚Äîfor example, \"I see that your training script just failed with the same CUDA error. Would you like me to try and fix it?\""},{"heading":"Built With","content":"claude electron fetch.ai fishaudio flask groq huggingface python react rest tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Physical Digital Darts (Wii Darts)","project_url":"https://devpost.com/software/digital-physical-darts-wii-darts","tagline":"\"Playing a game,\" involving a computer usually means using a keyboard and mouse. Through affordable and open-source design, we're here to change that by providing a customizable alternative.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/887/567/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: Best Beginner Hack"}],"team_members":[],"built_with":[{"name":"pygame","url":"https://devpost.com/software/built-with/pygame"},{"name":"pyserial","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"rust","url":"https://devpost.com/software/built-with/rust"}],"external_links":[{"label":"github.com","url":"https://github.com/commonkestrel/physical-digital-darts"}],"description_sections":[{"heading":"üí° Inspiration","content":"As a team who values accessible and immersive gaming experiences, we wanted to create a hack that embodied both of these ideas across software, hardware, and design. Taking inspiration from the Nintendo Wii and Switch consoles, we choose to create a Physical Digital Dart which allows the user to perform throwing motions as they would in real life, captures that motion with an accelerometer, and simulates the result on a digital dartboard."},{"heading":"üéØ What It Does","content":"After the MPU6050 accelerometer reads its current angles, those angles are filtered for noise on the Arduino Nano which then transmits the button state, roll, pitch, and yaw of the Physical Digital Dart via serial monitor to our Python dartboard simulator which launches a dart in the correct direction on the button‚Äôs release at the angle given by the MPU6050.\n\nTo account for drift, a double tap of the button re-calibrates the dart‚Äôs orientation to a standardized orientation."},{"heading":"üõ†Ô∏è How We Built It","content":"To optimize space and keep the dart as small as possible, we utilized small gauge wires for connections and assembled them to minimize wire overlap. The dart-like 3D printed casing contains an Arduino nano which is connected to a MPU6050 accelerometer via perfboard Along the side of the Physical Digital Dart is one button to keep track of the start (when pressed) and end of the throw (when released)."},{"heading":"üß± Challenges We Ran Into","content":"The accelerometer we were provided is an MPU6050 accelerometer and gyroscope. This type of small MEMS sensor is great for finding orientation, but velocity and position are far out of reach for the level of inaccuracy and drift found in the sensor. In order to fix this, we developed a specialized filtering algorithm for our application that was able to combat these issues and keep the drift in check.\n\nAdditionally, as we sought to use the 3D printers on the first day of the hackathon, we found that 3/4 were malfunctioning. In order to print our design and let others print theirs we worked through the night to fix the Prusa I3 Mark 2, the Ender 3, and the Ender 3 V2 SE, ultimately getting all 3 printers into a functioning state."},{"heading":"üèÜ Accomplishments That We're Proud Of","content":"Combining software, hardware, AND 3D design into a working product with very limited time Creating a product which can be adjusted in shape to meet the needs of its users Creating a product which combines the physical and digital worlds, redefining what it means to ‚Äúplay a game.\""},{"heading":"üìö What We Learned","content":"For our future hackathons, we noted that it would be best to bring as much personal hardware as needed, considering that there may not be a sufficient amount of hardware available to borrow from the venue."},{"heading":"üöÄ What's Next for Digital Physical Darts (Wii Darts)","content":"2D ‚Üí 3D\n\nSince our current version is 2D, we would like to implement a 3D version with better visuals and more character. Some additional features include:\n\nPlayer-versus-player gameplay A Wii Sports-like aesthetics\n\nFix Accelerometer Drift\n\nOriginally, our team wanted to track the position of the dart at all times but found that the drift of the MPU6050 made the double integration necessary to find that position highly accurate. A more precise accelerometer combined with a more intense filtering algorithm such as a Kalman filter would yield better results."},{"heading":"Built With","content":"pygame pyserial python rust"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Bob","project_url":"https://devpost.com/software/bob-vj43mq","tagline":"AR glasses for physical work. It sees what you see, hears what you hear, and gives real-time responses to help you build anything.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/889/853/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: Most Creative Hack"}],"team_members":[],"built_with":[{"name":"agent","url":null},{"name":"ar","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"spectacles","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"},{"name":"yoloe","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/raghavrajsah/tethyr/"}],"description_sections":[{"heading":"Inspiration","content":"Last year, the US had a shortage of 70,000 electricians and 642,000 mechanics. With one in five of these tradespeople over the age of 55 and growing demand in data centers and electric vehicles, this gap is only getting bigger. But what if everyone could become a skilled technician in under 5 minutes?\n\nThis is why we built Bob. By using this AI+AR assistant, homeowners could handle simple repairs, vocational schools could train workers more efficiently, and professionals could work faster, safer, and more collaboratively."},{"heading":"What it does","content":"Bob is a pair of agentic AR glasses that automatically watches over your actions, listens to your questions, and responds to your needs in real time. This could be instructions for your next steps, object-specific details (like a resistor's resistance), or warnings before you do something dangerous. For complex, collaborative tasks, it can also contact your teammates or highlight selected objects (in case you don't know what a ‚ÄúKellum grip‚Äù is).\n\nWhile existing smart glasses focus on specific workflows like trivia or design, we built Bob to be a generalist from the outset. It can help you build electrical circuits, repair cars, and assemble furniture. With more tools, the variety of tasks Bob can do would be even greater."},{"heading":"How we built it","content":"We‚Äôre using Snapchat Spectacles as our hardware and Gemini Live as our base model: the Spectacles stream video and audio data to a Python-built WebSocket server. On initial connection, we establish a new WebSocket connection to Gemini Live and store all subsequent audio and video frames in the session. Asynchronous workers handle buffering uploads, processing responses, executing tool calls, and resuming Gemini Live sessions efficiently.\n\nFor tools, we used SMTP to integrate Gmail, YOLOE-11 for object detection via text prompts, the Python Slack SDK to integrate Slack, and Google Generative AI SDK for Google Search and Google Map. When voice activation detects that the user has stopped speaking, Gemini Live returns text and tool calls. These get executed and sent back to the Spectacles to update the overlay and bounding box highlights, guiding users through their project. Finally, we would like to note that all WebSockets connections are reused, minimizing the latency between Spectacles and the server."},{"heading":"Challenges we ran into","content":"Messaging with Gemini Live over WebSocket turned out to be particularly challenging, with bugs in the asynchronous context manager and a demanding manual implementation of retry and bidirectional socket management. In addition, projecting pixel coordinates from the camera frame to the Snap Spectacle for object detection required debugging complex coordinate transformations. We solved these issues through test-driven development, A/B testing, and binary search."},{"heading":"Accomplishments that we're proud of","content":"As far as we know, we made the first pair of AR glasses with a multimodal AI agent that can talk back and forth with the user and instruct them in completing physical tasks.\n\nAlthough smart glasses exist, they are incapable of maintaining coherence over a physical task while accepting real-time input, often relying on obtrusive UI like buttons. By integrating live, multimodal agent and object detection into Snap Spectacles, we turned AR glasses into an agent with memory that helps anyone build whatever they want.\n\nWe‚Äôre especially proud of getting the Spectacles to work since none of us had touched AR glasses before this project."},{"heading":"What we learned","content":"Developing AR applications with Lens Studio Working with live instead of turn-based agents State management for WebSocket"},{"heading":"What's next for Bob","content":"When we interviewed our users about what else they would like to do with Bob, they gave really creative answers: cooking, first aid, martial arts‚Ä¶While these tasks are far from our original goal, Bob can quickly adapt to them because of its agentic framework. Every new tool can unlock a new field for Bob. For example, if we had added Composio‚Äôs toolset, Bob would be able to manage your calendar, send Slack messages, and read Notion pages. We could even link Bob to a humanoid robot that collaborates with the user on physical tasks.\n\nThe future path for Bob is to become the orchestrator directing tens, hundreds or even thousands of humans at a time concurrently on large projects. Managing and monitoring all of them towards common goals while maintaining a common state across workers which would allow for effective collaboration.\n\nIn addition, Bob is limited by its base models. If we had the hardware, we would run Qwen 2.5-Omni locally to reduce latency and use GroundingDINO to detect objects with greater accuracy."},{"heading":"Built With","content":"agent ar gemini python spectacles typescript websockets yoloe"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Elda AI","project_url":"https://devpost.com/software/elda-ai","tagline":"EldaAI listens, learns, and detects, transforming eldercare with AI that monitors behavior, prevents medication mistakes, and empowers caregivers through real-time insights.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/901/004/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Claude: Best Use of Claude"}],"team_members":[],"built_with":[{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"java","url":"https://devpost.com/software/built-with/java"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"shell","url":"https://devpost.com/software/built-with/shell"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/Gaurav890/Elda.git"}],"description_sections":[{"heading":"Inspiration","content":"When my grandmother was diagnosed with dementia, we watched her memory fade and her independence slowly disappear. Simple routines like taking medicine or remembering meals became daily struggles. That experience made us realize how deeply technology fails the people who need it most. EldaAI was born from the desire to build an AI that could understand, care, and detect before things get worse."},{"heading":"What it does","content":"EldaAI is an AI-powered eldercare platform that transforms caregiving from reminders to real-time intelligence. It listens, learns, and detects using Claude to understand speech and emotion, Letta to learn daily behavior patterns, and Chroma to detect changes over time. EldaAI automatically generates daily and monthly health summaries for doctors and caregivers, highlighting medication compliance, mood shifts, and potential cognitive decline."},{"heading":"How we built it","content":"Backend: FastAPI with PostgreSQL, JWT authentication, and APScheduler for smart reminders.\n\nAI Layer: Claude for intent and sentiment analysis, Letta for behavioral memory, Chroma for semantic pattern detection.\n\nMobile App: Built with React Native + Expo for voice-first interaction.\n\nCaregiver Dashboard: Built with Next.js + Tailwind for real-time monitoring, insights, and alerts.\n\nCommunication: Twilio for voice calls, Firebase for push notifications.\n\nDeployment: Railway (backend), Vercel (dashboard)."},{"heading":"Challenges we ran into","content":"Making voice-based AI interactions natural for elderly users with limited tech familiarity.\n\nTraining Claude to detect subtle emotional cues and health-related intent.\n\nIntegrating multiple AI services (Claude, Letta, Chroma) seamlessly while staying within API limits.\n\nDesigning a UI that feels simple enough for 80-year-olds but powerful enough for doctors."},{"heading":"Accomplishments that we're proud of","content":"Built a fully functional prototype Mobile App for Elder People and Care Giver web app in 2 days that integrates Claude, Letta, and Chroma.\n\nSuccessfully generated real-time AI health summaries from daily conversations.\n\nDesigned a caregiver dashboard that visualizes daily mood and medication adherence.\n\nCreated a system that bridges empathy, AI, and healthcare ‚Äî something our team truly believes in.\n\nWhat we learned\n\nBuilding human-centric AI means designing for emotion, not just accuracy.\n\nSimplicity in UX is more powerful than complexity in features ‚Äî especially for elders.\n\nPrompt engineering and data context are key to getting reliable results from LLMs like Claude.\n\nCollaboration across AI, design, and healthcare perspectives can create deeply impactful solutions."},{"heading":"What‚Äôs next for EldaAI","content":"Integrate with wearable health data (heart rate, sleep, activity) for early disease detection.\n\nEnable multi-language and cultural personalization for global accessibility.\n\nExpand caregiver tools to include doctor collaboration and long-term pattern analytics.\n\nLong-term vision: Let people ‚Äútrain‚Äù their AI throughout their lives so when they age, their AI already knows them deeply, acting as a personal caregiver and memory companion."},{"heading":"Built With","content":"html5 java javascript python shell typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Expungo","project_url":"https://devpost.com/software/clearpathai","tagline":"Making expungement simple and accessible for all.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Promise: Public Impact Prize (sponsored by Promise)"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Cal Hacks: Greatest Social Impact"}],"team_members":[],"built_with":[{"name":"chromadb","url":null},{"name":"fastapi","url":null},{"name":"google-gemini-api","url":null},{"name":"httpx","url":null},{"name":"lang-chain","url":null},{"name":"live-kit-sdk","url":null},{"name":"next.js","url":null},{"name":"open-ai-gpt-4-api","url":null},{"name":"pydantic","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Our inspiration behind our idea was to make expungement (the process of dismissing an old conviction) easier for people to access. It can be incredibly hard to find information, know what you need, and successfully go through the long official process. Our website asks the user a few simple questions and looks at their court documents to determine if they are eligible for expungement. If they aren't, it suggests next steps for the user to become eligible. If they are, it fills out the forms for them, simple as that."},{"heading":"What it does","content":"Expungo is an AI-powered platform that simplifies and automates the criminal record expungement process by analyzing uploaded documents to determine eligibility.\n\nUsers simply upload their court or RAP sheet and review their case directly with Expungo‚Äôs live voice agent for personalized, step-by-step guidance. All data is processed entirely in memory ‚Äî ensuring that sensitive user information remains secure and confidential."},{"heading":"How we built it","content":"‚Ä¢ Frontend: Developed with Next.js 15, TypeScript, and Tailwind CSS for a fast, accessible interface. The design includes a guided multi-step form and responsive layout for both desktop and mobile users. ‚Ä¢ Backend: Powered by FastAPI with asynchronous endpoints for high-performance handling of PDF uploads, RAG queries, and voice session tokens. Each microservice communicates via HTTPX and uses Pydantic for validation. ‚Ä¢ Document Intelligence: Implemented Google Gemini (via google-genai) for advanced PDF parsing -- It extracts structured legal data‚Äîcase numbers, conviction codes, and court details‚Äîfrom scanned RAP sheets. ‚Ä¢ Legal Reasoning (RAG System): Built with LangChain and ChromaDB , which stores vector embeddings of expungement laws from all 50 states. We use GPT-4 for natural-language reasoning over retrieved statutes to generate personalized eligibility results. ‚Ä¢ Voice Agent: Created with LiveKit Agents SDK, integrating WebRTC, Silero VAD, and real-time conversation management. This enables users to speak with Expungo‚Äôs AI assistant for hands-free legal guidance. ‚Ä¢ Privacy & Security: All data is processed in-memory only‚Äînothing is stored in external databases. Environment variables manage all API keys, and JWT authentication secures LiveKit sessions."},{"heading":"Challenges we ran into","content":"‚Ä¢ Integrating state-specific expungement laws was difficult. Each state‚Äôs statutes, eligibility criteria, and form formats are very different. Making sure our model pulled accurate and recent information from government sources required careful validation. ‚Ä¢ We had to be precise when extracting legal and government data, and found that even small extraction errors affected eligibility outcomes. ‚Ä¢ We ran into quite a few technical challenges regarding latency and reliability when we were combining voice input, document OCR, and NLP pipelines."},{"heading":"Accomplishments that we're proud of","content":"‚Ä¢ Successfully built a voice-enabled AI legal assistant that is able to guide users through expungement eligibility checks and generate completed court forms. ‚Ä¢ Designed a memory system that values privacy, where user data is stored locally in memory instead of databases or external APIs for confidentiality and control. ‚Ä¢ Integrated multi-state legal logic and document parsing that scales to various expungement statutes."},{"heading":"What we learned","content":"‚Ä¢ This was our first time developing a fully voice-driven agent, and we learned how to manage conversational state, speech-to-text accuracy, and intent recognition. ‚Ä¢ We gained experience in combining LLM based reasoning with structured legal rules. ‚Ä¢ We learned a lot about user trust and ethical AI design, especially when working with personal and legal data."},{"heading":"What's next for Expungo","content":"‚Ä¢ Expanding to support additional government and legal services like housing forms, voter registration, and professional licensing reinstatement. ‚Ä¢ Transitioning from third party LLM APIs to fully self-hosted or open source models for further data privacy. ‚Ä¢ Partnering with legal aid nonprofits and public defenders to test Expungo in real expungement clinics. ‚Ä¢ Continuing to refine our voice interface and eligibility logic for more inclusive, multilingual support."},{"heading":"Built With","content":"chromadb fastapi google-gemini-api httpx lang-chain live-kit-sdk next.js open-ai-gpt-4-api pydantic python tailwindcss typescript"}]},{"project_title":"Haven","project_url":"https://devpost.com/software/haven-536r1q","tagline":"Hospital command center powered by context-aware agentic AI that alerts nurses, unifies EHR data, and answers patient questions, improving understanding and reducing response delays and clinical error","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/892/299/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Fetch AI: Best Use of Fetch AI"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Y Combinator: Build an Iconic YC Company - 1st Place"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"LiveKit: Best Start-up Idea"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"fetch.ai","url":null},{"name":"grok","url":null},{"name":"livekit","url":null},{"name":"openai","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"photoplethsymography","url":null},{"name":"websocket","url":null},{"name":"whisper","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/scrappydevs/haven"}],"description_sections":[{"heading":"Inspiration","content":"David's great-uncle was in the hospital this year. He noticed that his great uncle often waited over an hour to find a nurse to answer his questions due to understaffing. When someone finally arrived, they had to bounce across multiple systems to refamiliarize themselves. It felt like the information was there, just not there when we needed.\n\nHospitals have more data than ever, yet nurses spend up to 50% of their shift on documentation instead of patient care. What if the moment a patient calls, an intelligent system helps manage nurse distribution throughout the hospital and flags concerning patterns and prepares exactly what the nurse needs to attend to their patient right away?\n\nThat's why we built Haven."},{"heading":"What it does","content":"Haven is a multi-agent hospital command center that transforms how nurses access critical patient information. Instead of hunting through fragmented systems, Haven provides three integrated intelligence layers:\n\n1. HavenAI Voice Assistant via LiveKit Patients and families speak naturally to Haven using LiveKit and OpenAI's realtime voice API. Haven asks clarifying follow-up questions, pulls validated EHR data, and delivers nurse-ready summaries and action items‚Äîturning a 20-minute wait into an instant, documented interaction.\n\n2. Autonomous Monitoring Dashboard via fetch.ai agents Fetch.ai agents continuously monitor patient vitals, detect concerning patterns, and coordinate with alert-response agents to flag issues before they escalate. Our computer vision pipeline uses facial photoplethysmography (FPPG) to non-invasively track heart rate and stress indicators, feeding real-time data to the monitoring network.\n\n3. Live 3D Hospital Map via Claude agents Powered by an Anthropic Claude chain-tool-calling agent, nurses see a spatial view of the entire floor with real-time alert-based room coloring. They can ask natural language questions like \"Tell me about Dheeraj's alerts and questions from the last 6 hours\" and instantly understand which patients need attention and why‚Äîno system-hopping required.\n\nIn addition, nurses can generate summary reports from their patients' discussions with Haven AI, so they do not need to turn to fragmented sources to familiarize themselves with the patients' current situation.\n\nTogether, these agents create a cohesive intelligence network where information flows to the right person at the right time, automatically."},{"heading":"How we built it","content":"Haven is a multi-agent hospital intelligence platform built on three core systems using LiveKit, Fetch.ai, and Claude agents :\n\nVoice Interface: HavenAI uses LiveKit for WebRTC streaming, OpenAI Whisper for speech-to-text, and OpenAI Realtime API for fully duplex conversation. The agent streams transcriptions and responses simultaneously, automatically triggering structured prompts to fill missing clinical details and pushing validated data to our backend.\n\nMonitoring & Alerts: Fetch.ai agents handle autonomous patient monitoring‚Äîa vitals-tracking agent communicates with an alert-response agent to raise or dismiss issues based on real-time thresholds and historical patterns. We also built a computer vision pipeline using OpenCV and facial photoplethysmography (FPPG) to extract heart rate and stress indicators from live video, feeding results directly into the Fetch agent network.\n\nSpatial Intelligence: Our live 3D hospital map is powered by an Anthropic Claude chain-tool-calling agent. It interprets natural language commands (\"Show me which rooms have active alerts\"), autonomously executes multiple tools to query patient data, and dynamically updates room colors and overlays in real-time based on the agent network's events."},{"heading":"Challenges we ran into","content":"Natural voice interaction: Fine-tuning turn-taking, silence detection, and handling dropped connections to make conversations feel human, not robotic. Multi-stream synchronization: Coordinating concurrent WebSockets from LiveKit, Fetch agents, and Claude while running computer vision without blocking the UI. Context management: Long patient conversations exceeded LLM limits. Built a summarization pipeline to compress transcripts while preserving critical clinical details."},{"heading":"Accomplishments","content":"Built a cohesive multi-agent ecosystem where Fetch.ai, LiveKit, and Claude agents autonomously coordinate. Implemented Claude's multi-tool-calling to interpret natural language and update the 3D hospital map in real-time. Created a facial photoplethysmography (FPPG) pipeline for non-invasive heart rate monitoring integrated with voice and spatial intelligence."},{"heading":"What we learned","content":"Specialized agents outperform monolithic systems‚Äîfocused tasks are more scalable despite coordination complexity. Low-latency architecture requires deep system design when streaming video, analyzing behavior, and raising real-time alerts."},{"heading":"Next Steps","content":"New Agents: Medication Reconciliation: Prevent dangerous drug interactions Discharge Planning: Coordinate patient transitions Resource Allocation: Optimize room and staff assignments Technical Improvements:\n\nReinforcement learning from nurse feedback Computer vision for fall detection and behavioral monitoring Federated learning across hospitals while preserving privacy"},{"heading":"Built With","content":"claude fetch.ai grok livekit openai opencv photoplethsymography websocket whisper"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Duck Duck Goose","project_url":"https://devpost.com/software/duck-duck-goose-jelxr9","tagline":"A fast, intelligent query engine built on DuckDB.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/895/526/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"AppLovin: Query Planner Challenge"}],"team_members":[],"built_with":[{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/KevinL10/applovin-query"}],"description_sections":[{"heading":"Built With","content":"python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Orbit","project_url":"https://devpost.com/software/orbit-n97hqz","tagline":"From ‚ÄúI should‚Äù to ‚ÄúI did.‚ÄùOur workflow listens, understands, and drives real progress from every conversation.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/897/285/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Fetch AI: Best Use of Fetch AI"}],"team_members":[],"built_with":[{"name":"agents","url":null},{"name":"ai","url":null},{"name":"composio","url":null},{"name":"fetch.ai","url":null},{"name":"mcp","url":null},{"name":"omi","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sim.ai","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Ganeshmohank/orbit.git"},{"label":"drive.google.com","url":"https://drive.google.com/drive/folders/1bx7zZMYRjNHUiyFbiJHbxRaMBweDjGtI?usp=drive_link"}],"description_sections":[{"heading":"The Problem","content":"Every meeting ends with a list of things to do, but most of them never get done.\n\nProfessionals spend an average of 11.3 hours per week in meetings, and nearly 57% of their workweek goes into communication instead of creation. This inefficiency costs companies over $29,000 per employee annually.\n\nExisting tools like Fellow and Tactiq only capture notes or action items - they ‚Äúrecord‚Äù work, but they don‚Äôt move it forward. Teams need automation that goes beyond transcription - one that truly acts."},{"heading":"Our Solution","content":"Orbit is an AI-powered productivity agent that listens to meetings, understands context, and executes real actions across your workflow tools - automatically. It connects your conversations with your workflows , transforming talk into tangible results.\n\nHow it works:\n\nListens to meetings (Zoom, Google Meet) and identifies key tasks, deadlines, and owners. Extracts and executes actions: creates Jira tickets, sends follow-up emails, and schedules events. Supports voice-triggered commands via the Omi Mic e.g., ‚ÄúBook a cab to SFO‚Äù or ‚ÄúRemind the team about the release.‚Äù Powered by a multi-agent (We call it NeXus) system using Sim.ai , Composio MCP , and Fetch.ai Agentverse .\n\nOrbit doesn‚Äôt just summarize your meetings, it gets things done."},{"heading":"How We Built It","content":"Sim.ai - reasoning and intent extraction from raw meeting transcripts, with multiple triggers Composio MCP Integrations - automation for Jira, Gmail, Calendar, and more. Omi Mic - enables natural, voice-triggered automation. Fetch.ai Agentverse - gives Orbit autonomy, persistence, and collaboration across agents.\n\nUnder the hood, Orbit transforms unstructured dialogue into structured JSON actions, validates them with Sim.ai, and triggers automation sequences through Composio MCP - with full transparency and user review."},{"heading":"Challenges We Ran Into","content":"Combining multiple inputs (Zoom + Voice + Email) into a single cohesive workflow. Translating ambiguous natural language into clear, executable tasks. Handling authentication, API rate limits, and user trust. Balancing autonomy with control - ensuring Orbit acts responsibly."},{"heading":"Accomplishments We‚Äôre Proud Of","content":"Built a full end-to-end AI workflow that connects meeting transcripts to task automation. Successfully hosted the autonomous agent on Fetch.ai Agentverse . Enabled real-time voice control with Omi Mic , Did any app can book a ride for you from voice command Designed a unified brand identity - Orbit: your AI orbit that keeps life in motion."},{"heading":"Market Insight","content":"Every employee loses nearly one-third of their week to communication overhead. Automation of post-meeting tasks shows clear ROI and faster adoption. Competitors like Fellow and Tactiq stop at transcription - Orbit extends into execution . Our middleware, Nexus , integrates with any MCP, expanding Orbit‚Äôs reach into scheduling, logistics, and enterprise automation."},{"heading":"Go-To-Market Strategy","content":"Inbound content: Blog posts & case studies on ‚Äúlost meeting actions,‚Äù ‚Äúvoice command productivity,‚Äù and ‚Äúmeeting-to-execution automation.‚Äù Demo-led sales: Live demo showing post-meeting automation in real time. Partner integrations: Zoom, Jira, Slack, and hardware partnerships with Omi Mic . Pricing model: Freemium: Basic meeting summaries + limited integrations. Team/SMB ($20‚Äì30/user/month): Full automation suite + Nexus integration."},{"heading":"What‚Äôs Next","content":"Expand to Microsoft Teams, Slack, and Notion integrations. Introduce contextual memory for ongoing projects. Enable multi-agent collaboration between team members. Launch as a desktop widget and browser extension for instant accessibility.\n\nOrbit - Turning every conversation into measurable progress. From ‚ÄúI should‚Äù ‚Üí ‚ÄúI did.‚Äù\n\nLinks\n\nReview more about our NeXes here GitHub Repository Contact Us"},{"heading":"Built With","content":"agents ai composio fetch.ai mcp omi python sim.ai"},{"heading":"Try it out","content":"github.com drive.google.com"}]},{"project_title":"ADLOVIN","project_url":"https://devpost.com/software/adlovin-media-intelligence","tagline":"An AI prototype that processes ad creatives, both images and videos, to extract rich visual, textual, and audio insights that reveal brand intent and power next-generation recommendation engines.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/898/243/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"AppLovin: Ad Intelligence Challenge"}],"team_members":[],"built_with":[{"name":"chromadb","url":null},{"name":"claude","url":null},{"name":"clip","url":null},{"name":"easyocr","url":null},{"name":"hugging-face","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"scikit-learn","url":"https://devpost.com/software/built-with/scikit-learn"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/SisuKah/calhacks2"},{"label":"github.com","url":"https://github.com/abtonmoy/calhacks12"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration came from real-world ad recommendation systems like AppLovin‚Äôs Axon, which rely on large datasets of ad creatives to predict performance. We wanted to explore how far we could push multimodal intelligence by building a system that understands ad content visually, textually, and acoustically. Our goal was to make ad data more insightful and useful for smarter recommendation models."},{"heading":"What it does","content":"ADLOVIN Media Intelligence processes ad creatives, both images and videos, and extracts high-value multimodal features such as visual composition, text sentiment, and audio mood. These embeddings can then be used to generate creative performance insights or power downstream machine learning models for recommendation and ranking."},{"heading":"How we built it","content":"We built a modular feature extraction pipeline in Python. For video ads, we used FFmpeg to extract keyframes and Librosa for audio signal analysis. Each frame was embedded using a pretrained vision transformer, and text elements were captured through EasyOCR and language models. We used ChromaDB to store and query embeddings at scale, and FastAPI to provide an interface for experimentation and testing."},{"heading":"Challenges we ran into","content":"One major challenge was optimizing feature extraction for large videos while maintaining temporal coherence between visual and audio signals. Another was ensuring meaningful clustering in the vector database without redundant representations, especially after removing the deduplication algorithm. Balancing efficiency and fidelity across multiple modalities required careful design and parameter tuning. One of the major issues faced was the wifi. It made our life really hard. We had to find place to work outside of the venue."},{"heading":"Accomplishments that we're proud of","content":"We successfully built an end-to-end multimodal intelligence pipeline that can process a wide range of ad creatives and output interpretable embeddings. The system achieved reliable text and sentiment extraction from frames and robust feature representation using transformer-based models."},{"heading":"What we learned","content":"We learned how to align multimodal embeddings for recommendation tasks, fine-tune vector similarity searches for creative clustering, and manage large-scale ad processing efficiently. We also gained experience combining computer vision, audio analysis, and natural language understanding into one cohesive system."},{"heading":"What's next for ADLOVIN Media Intelligence","content":"Next, we plan to add a lightweight deduplication model, connect the embeddings to a performance dataset for supervised learning, and build an interactive dashboard to visualize ad intelligence insights in real time. We also aim to explore generative tools that can use embeddings to suggest creative improvements."},{"heading":"Built With","content":"chromadb claude clip easyocr hugging-face numpy python react scikit-learn tailwind typescript"},{"heading":"Try it out","content":"github.com github.com"}]},{"project_title":"EDFlow AI","project_url":"https://devpost.com/software/edflowai","tagline":"EDFlow AI: A Mixture of Expert AI Agents auto-coordinate ER emergencies in <30s. Each specialist agent‚Äîbeds, labs, pharmacy‚Äîworks in parallel to save lives.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/897/217/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Fetch AI: Best Deployment of Agentverse"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"uagent","url":null}],"external_links":[{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qwy3cayvacfc0lrlmaa3tlqs30tqvvl78lnlc2ja7ff8pkmey863venry0q/profile"},{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qd6j2swdef06tgl4ly66r65c4vz6rcggt7rm89udnuvmn8n2y90myq46rfl/profile"},{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qfx6rpglgl86s8072ja8y7fkk9pfg5csa2jg7h2vgkl2nztt2fctye7wngx/profile"},{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qw4g3efd5t7ve83gmq3yp7dkzzmg7g4z480cunk8rru4yhw5x2k979ddxgk/profile"},{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qff3y8ry6jew53lgc5gxzg8cqc3cc505c5n0rwcntpwe2ydvz23gxc36xh4/profile"},{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qdvph9h02dhvs4vfk032hmpuaz3tm65p6n3ksgd9q5d22xyln3vqgkp2str/profile"},{"label":"agentverse.ai","url":"https://agentverse.ai/agents/details/agent1qdentzr0unjc5t8sylsha2ugv5yecpf80jw67qwwu4glgc84rr9u6w98f0c/profile"},{"label":"asi1.ai","url":"https://asi1.ai/shared-chat/daffc07c-0098-4800-9400-76a8f5734fdd"}],"description_sections":[{"heading":"The Problem That Inspired Us","content":"At 3:15 AM, a 69-year-old male arrives by ambulance with severe chest pain radiating to his left arm. His ECG shows ST elevation‚Äîa STEMI heart attack. For every minute of delay, 1.2 million cardiac cells die.\n\nIn traditional emergency departments, coordinating the response requires multiple phone calls: checking ICU beds, paging cardiology, ordering STAT labs, preparing medications, alerting staff. This manual coordination takes 3-5 minutes of precious time.\n\nThe bottleneck isn't medical expertise‚Äîit's coordination.\n\nWhat if autonomous AI agents could handle all this coordination simultaneously, reducing response time from minutes to seconds? EDFlow AI makes this reality."},{"heading":"What It Does","content":"EDFlow AI is an autonomous multi-agent system that coordinates emergency department preparation in under 10 seconds using Fetch.ai's uAgents framework and Claude AI.\n\nTraditional Coordination (Sequential): Nurse calls lab ‚Üí calls pharmacy ‚Üí pages doctor ‚Üí reserves bed ‚Üí 180+ seconds\n\nEDFlow AI (Parallel): Seven autonomous agents work simultaneously ‚Üí <10 seconds\n\nThe Agent Team:\n\nED Coordinator (Claude Sonnet 4): Receives ambulance reports, analyzes patient condition, detects protocols (STEMI/Stroke/Trauma), orchestrates all agents Resource Manager : Allocates trauma bays, assigns nursing staff, stages emergency equipment Bed Management : Reserves appropriate ICU/cardiac beds, verifies equipment functionality Lab Service : Orders protocol-specific STAT tests (troponin, CBC, coags), alerts lab technicians Pharmacy : Prepares time-critical medication kits (antiplatelet, anticoagulation protocols) Specialist Coordinator : Pages relevant specialists (cardiologist, neurologist), activates cath lab teams WhatsApp Notification : Sends real-time alerts to medical staff phones with patient details and ETA\n\nReal-World Scenario:\n\nAmbulance sends: \"69yo male, severe chest pain, ST elevation on ECG, HR 110, BP 160/95, SpO2 94%, ETA 5 minutes\"\n\nWithin 10 seconds:\n\nClaude AI identifies STEMI protocol, urgency level 1 Trauma Bay 1 cleared and staffed Cardiac ICU Bed 3 reserved STAT troponin and cardiac panel ordered Aspirin, heparin, and nitroglycerin staged at bedside Cardiologist paged (ETA 15 min), cath lab team mobilizing WhatsApp alert sent: \"üö® STEMI ALERT - Patient arriving in 5 min, cath lab activation required\"\n\nImpact: For STEMI patients, reducing door-to-balloon time by 3 minutes saves ~3.6 million cardiac cells per patient. For a hospital handling 200 STEMI cases annually, that's 720 million cells saved‚Äîtranslating to improved survival rates and reduced long-term cardiac damage."},{"heading":"How We Built It","content":"Agent Framework: Built on Fetch.ai's uAgents framework for native agent-to-agent communication, deployed all 7 agents on Agentverse with Chat Protocol enabled, integrated with ASI:One for discoverability, and registered agents on Almanac Contract.\n\nIntelligence Layer: Claude Sonnet 4 powers the ED Coordinator's decision-making:\n\nAnalyzes unstructured ambulance reports with medical context Accesses real-time hospital status (current capacity, staff availability, protocol performance) Determines protocol type and urgency level Generates clinical recommendations (door-to-balloon targets, resource allocation) Provides sub-5-second response times\n\nArchitecture: Hub-and-spoke coordination model where ED Coordinator broadcasts emergencies to all 6 specialized agents simultaneously, each agent independently fetches data from shared JSONBin database, agents respond with detailed preparation reports, and ED Coordinator aggregates responses with 10-second timeout.\n\nData Layer: JSONBin serves as shared hospital database storing real-time ED status (patient count, capacity, wait times), bed availability (ICU, regular, equipment status), medication inventory, specialist rosters, and protocol performance metrics.\n\nCommunication: Twilio WhatsApp API integration for instant medical staff notifications with rich context (patient vitals, protocol type, ETA, required actions), delivery confirmation tracking, and protocol-specific message templates.\n\nDeployment: All agents deployed on Agentverse with unique addresses, health checks every 2 minutes, persistent agent mailboxes, and environment-based configuration (API keys, database credentials)."},{"heading":"Challenges We Faced","content":"Agent Coordination Reliability:\n\nProblem: How to ensure all 6 agents respond reliably? What if one agent fails? Solution: Implemented polling mechanism with 10-second timeout. ED Coordinator checks every 3 seconds if all responses collected. System proceeds with partial responses if timeout reached. Result: 95%+ agent response rate.\n\nDatabase Race Conditions:\n\nProblem: Multiple agents reading/writing simultaneously could cause conflicts (e.g., two agents reserving same bed). Solution: Used JSONBin's versioning system for optimistic locking. Critical operations (bed reservations) include version checks. Failed updates trigger automatic retry with fresh data.\n\nReal-Time WhatsApp Delivery:\n\nProblem: Twilio requires phone number verification, has rate limits, and delivery isn't guaranteed. Solution: Pre-verified all medical staff numbers, implemented exponential backoff for rate limits, added delivery status tracking, and created fallback notification queue.\n\nClaude AI Context Management:\n\nProblem: How to provide Claude with enough context without exceeding token limits? Solution: Structured prompts with hierarchical information (critical vitals first, then hospital status, then protocol history). Used Claude's 200K context window efficiently. Result: Consistent high-quality analysis.\n\nAgentverse Deployment:\n\nProblem: Managing secrets (API keys, phone numbers) across 7 agents securely. Solution: Created standardized deployment scripts, used environment variables for sensitive data, implemented secret rotation mechanism, and added deployment validation checks.\n\nPerformance Optimization:\n\nProblem: Initial coordination took 15-20 seconds due to sequential database calls. Solution: Implemented async/await patterns throughout, used connection pooling for database access, parallelized agent broadcasts, and optimized Claude API calls. Result: Consistent <10-second performance."},{"heading":"What's Next for EDFlow AI","content":"Immediate (Next 3 Months):\n\nExpand protocol coverage: Sepsis, Cardiac Arrest, Massive Transfusion, Pediatric Emergencies Add predictive analytics: 4-hour ED capacity forecasting using historical patterns Multi-language support: Spanish, Mandarin for diverse patient populations Enhanced metrics: Real-time dashboard showing protocol performance trends\n\nMedium-Term (6-12 Months):\n\nMulti-hospital coordination: Regional networks for capacity sharing and patient transfers EHR integration: Automatic patient history retrieval and documentation Advanced AI features: 100K+ token patient history analysis, drug interaction checking Mobile app: Direct ambulance crew interface for report submission\n\nLong-Term (1-2 Years):\n\nAI-human collaboration: Suggested decision support with human override Clinical validation: Multi-center trials to measure mortality impact FDA clearance: Pursue approval as clinical decision support system Global deployment: Scale to 5,000+ emergency departments worldwide\n\nVision: Transform emergency departments into precision coordination systems where AI agents handle routine logistics, allowing medical staff to focus entirely on patient care. Every emergency department operating with Formula 1 pit crew efficiency‚Äîfast, coordinated, error-free."},{"heading":"Built With","content":"Fetch.ai Ecosystem:\n\nuAgents Framework (v1.0.5) - Multi-agent orchestration Agentverse - Cloud deployment platform Chat Protocol - Agent-to-agent messaging ASI:One - Agent discoverability Almanac Contract - Agent registration\n\nAnthropic:\n\nClaude Sonnet 4 - Medical reasoning and protocol detection Claude API - Real-time patient analysis\n\nInfrastructure:\n\nPython 3.10+ with AsyncIO for concurrent operations HTTPx for async HTTP requests Pydantic for data validation JSONBin.io for shared hospital database Twilio WhatsApp API for staff notifications"},{"heading":"Try It Out","content":"Live Demo on ASI:One:\n\nVisit app.fetch.ai Search for \"ED Coordinator Agent\" Send this ambulance report: ``` üöë AMBULANCE REPORT\n\nPatient: 69yo male Chief Complaint: Severe chest pain radiating to left arm Vitals: HR 110, BP 160/95, SpO2 94% EMS Report: ST elevation on ECG, suspected STEMI ETA: 5 minutes\n\n4. Watch autonomous coordination happen in real-time (<10 seconds) 5. See detailed responses from all 6 specialized agents 6. View WhatsApp notification sent to cardiologist **Live Agents on Agentverse:** @ed-coordinator-agent @bed-management-agent @pharmacy-agent @lab-service-agent @resource-manager-agent @whatsapp-notification-agent @specialist-coordinator-agent **Performance Metrics:** - STEMI Protocol: <10 seconds (Target: <10s) ‚úÖ - Stroke Protocol: <10 seconds (Target: <10s) ‚úÖ - Trauma Protocol: <10 seconds (Target: <10s) ‚úÖ - Agent Response Rate: 95%+ - System Uptime: 99.2% - WhatsApp Delivery: 98%+ --- **EDFlow AI: Where autonomous agents meet emergency medicine. Coordinating care at the speed of thought.** *Built with ‚ù§Ô∏è using Fetch.ai uAgents & Claude AI*"},{"heading":"Built With","content":"claude langchain langgraph python uagent"},{"heading":"Try it out","content":"agentverse.ai agentverse.ai agentverse.ai agentverse.ai agentverse.ai agentverse.ai agentverse.ai asi1.ai"}]},{"project_title":"Brydge","project_url":"https://devpost.com/software/brydge","tagline":"Presenting Brydge: the AI orchestration platform that turns scattered engineering knowledge into automated workflows, transforming hours of context-switching into just minutes of autonomous execution","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/893/019/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Y Combinator: Build an Iconic YC Company - 1st Place"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"confluence","url":"https://devpost.com/software/built-with/confluence"},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"jira","url":"https://devpost.com/software/built-with/jira"},{"name":"nemotron","url":null},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"oauth","url":"https://devpost.com/software/built-with/oauth"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"slack","url":"https://devpost.com/software/built-with/slack"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"weaviate","url":null}],"external_links":[{"label":"youtu.be","url":"https://youtu.be/I7pkua3iYAs"},{"label":"github.com","url":"https://github.com/aprabu/BrydgeCalhacks"},{"label":"brydge-7f8336bfba05.herokuapp.com","url":"https://brydge-7f8336bfba05.herokuapp.com/"}],"description_sections":[{"heading":"The Problem I Witnessed","content":"During my internship at NVIDIA, I was surrounded by cutting-edge AI tools: ChatGPT for brainstorming, Cursor for coding, Confluence for documentation, Jira for tracking, Slack for communication. Every tool was powerful individually, but my day became an endless cycle of context-switching: copy error logs from Datadog, paste into ChatGPT, get suggestions, search Confluence for architecture docs, check Jira for related tickets, update GitHub, notify the team in Slack. A simple bug fix that should take just minutes stretched into 2+ hours...not because of coding complexity, but because of coordination overhead.\n\nI realized the problem wasn't the tools themselves. It was that they existed in isolation. Each one held a piece of the puzzle, but no one was connecting them. Engineers were spending 50-60% of their time being \"human middleware, \"manually shuttling information between systems."},{"heading":"The Insight","content":"What if AI agents could do the context-switching for us? Not just answer questions, but actively orchestrate workflows across tools. Not just search documentation, but pull relevant context from everywhere, synthesize it, and take action. The key was multi-agent orchestration: specialized agents that understood each tool deeply (GitHub, Jira, Slack, Confluence) coordinated by a reasoning agent that understood the bigger picture."},{"heading":"The Project","content":"Brydge is an AI orchestration platform where one command triggers a cascade of intelligent agents working in parallel:\n\nThe Architecture:\n\nOrchestrator Agent (NVIDIA llama Nemotron reasoning model): Plans multi-step workflows, coordinates sub-agents, handles failures Tool-Specific Agents : GitHub Agent (code analysis + PR creation), Jira Agent (ticket context), Confluence Agent (docs), Slack Agent (notifications), Weaviate Query Agent (semantic search across all sources) Specialized Agents : Analysis Agent (root cause identification), Code Generation Agent (fixes via Claude Code SDK) Human-in-the-Loop Gates : Approval checkpoints before any write action\n\nSample Flow:\n\nManager pings in Slack: \"Checkout flow is broken for mobile users\" Orchestrator creates execution plan, shows it for approval Agents fan out in parallel: fetch Jira ticket, analyze recent commits, search Confluence docs, semantic search across codebase Analysis Agent synthesizes root cause from all sources Code Generation Agent writes fix using Claude Code SDK User reviews diff ‚Üí approves GitHub Agent creates PR Confluence Agent updates docs ‚Üí user approves Slack Agent notifies manager ‚Üí user approves\n\nWhat took 2 hours manually now takes 3 minutes of orchestrated agent work + 2 minutes of human review."},{"heading":"Technical Challenges","content":"1. Multi-Agent Coordination The hardest part was getting agents to work together without stepping on each other. For this, a DAG-based execution model where the Orchestrator determines dependencies (e.g., Code Generation can't start until Analysis completes) and runs independent tasks in parallel. Used asyncio for concurrent execution and Redis for inter-agent communication.\n\n2. Real-Time Streaming Users needed to see what agents were thinking in real-time (chain-of-thought transparency). Implemented WebSocket streaming where each agent broadcasts thoughts, actions, and results. The Claude Agent SDK's built-in streaming callbacks ( on_thought , on_tool_use ) made this much cleaner than expected.\n\n3. Context Window Management Claude's context limits were a big issue when processing large codebases. Solution: Weaviate Query Agent with semantic search to intelligently retrieve only relevant documents (solving the \"retrieve top 25 docs\" limitation by using Weaviate's agentic search modes that auto-refine queries).\n\n4. Approval Gate Design Needed human approval before any write action (code changes, PRs, notifications) without blocking the entire workflow. Implemented async approval gates: agent pauses execution, creates approval record in PostgreSQL, sends preview via WebSocket, waits for user decision, then continues or rolls back. The Claude Agent SDK's on_approval_needed hook was perfect for this.\n\n5. Error Handling Across Distributed Agents When one agent fails mid-workflow, how do you recover gracefully? Implemented checkpoint system: each agent step is logged to agent_steps table with status. If Analysis Agent fails, Orchestrator retries up to 3 times. If Code Generation fails, repo clone is cleaned up. If user rejects at any gate, all downstream steps are cancelled and changes are rolled back."},{"heading":"Learnings","content":"Technical:\n\nMulti-agent systems require different architecture than single-agent systems (stateful orchestration, not stateless requests) Real-time streaming is non-negotiable for transparency in agentic systems Human-in-the-loop is essential for trust (fully autonomous is scary, fully manual defeats the purpose) Vector databases (Weaviate) are crucial for context retrieval at scale Sub-agent delegation (Claude Code SDK's feature) mirrors how humans delegate tasks to specialists\n\nProduct:\n\nEngineers don't want \"AI magic\" they want transparent, controllable automation The value isn't eliminating human judgment, it's eliminating human busywork Showing the agent's reasoning (\"chain-of-thought\") builds trust Approval gates feel slow but are necessary for adoption"},{"heading":"What's Next","content":"Short-term (next 3 months):\n\nAdd Datadog and PagerDuty agents for incident response workflows Implement scheduled agent runs (e.g., weekly digest of PR activity) Build admin dashboard for monitoring agent performance across teams\n\nLong-term vision:\n\nMarketplace for custom agents (let companies build tool-specific agents for internal systems) Agent learning from feedback (when users reject changes, agents learn what patterns to avoid) Proactive agents (not just reactive to user commands, but monitoring for issues and suggesting fixes)\n\nThe future of engineering isn't replacing developers with AI; it's giving developers AI teammates that handle the coordination busywork so they can focus on creative problem-solving. Brydge is the operating system for that future."},{"heading":"Built With","content":"claude confluence github jira nemotron nvidia oauth python slack typescript weaviate"},{"heading":"Try it out","content":"youtu.be github.com brydge-7f8336bfba05.herokuapp.com"}]},{"project_title":"Agent Santa","project_url":"https://devpost.com/software/agent-santa","tagline":"Agent Santa is a multi-agent system where personality-based agents connect, understand relationships, and deliver perfect personalized gifts end-to-end with payments, intelligently and effortlessly.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/833/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Fetch AI: Best Use of ASI:One"}],"team_members":[],"built_with":[{"name":"fetchai","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"vercel","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ParthPatel00/SantAI"}],"description_sections":[{"heading":"Inspiration","content":"We realized how often people struggle with gifting ‚Äî not because they lack affection, but because they lack understanding of what would genuinely delight someone. Remembering birthdays, choosing meaningful gifts, and keeping surprises intact can become overwhelming. That‚Äôs what inspired Agent Santa ‚Äî an autonomous gifting ecosystem where agents know you, understand you, and gift like you would.\n\nOur idea began with a simple thought:\n\n‚ÄúWhat if your AI could talk to your friend‚Äôs AI and decide the perfect gift ‚Äî all by itself?‚Äù\n\nThis curiosity led us into the world of multi-agent systems, Fetch.ai‚Äôs Agentverse, and ASI.one, where we turned that thought into a working system."},{"heading":"What it does","content":"Agent Santa consists of four main components:\n\nPersonality Agents ‚Äì autonomous representations of each user, powered by Grok-LLaMA. These agents store our interests, preferences, and traits, and can communicate with each other.\n\nAgent Santa (Gifting Agent) ‚Äì the core orchestrator deployed on Agentverse. It queries personality agents, understands who the recipient is, and suggests personalized gifts.\n\nShopping & Comparison Engine ‚Äì built into the gifting agent to evaluate multiple options, compare prices, and pick the best choice.\n\nPayment Layer ‚Äì simulates secure transactions to complete the gifting process end-to-end.\n\nA typical interaction looks like this: User Request on ASI.one‚ÜíAgent Santa‚ÜíRecipient Personality Agent‚ÜíGift Suggestion + Payment"},{"heading":"How we built it","content":"Framework: uAgents on Fetch.ai\n\nDeployment: Fully on Agentverse with seamless integration via ASI.one\n\nLLM Backbone: Grok-LLaMA, for reasoning and contextual understanding\n\nArchitecture: Event-driven, asynchronous message passing between agents using defined protocols\n\nWorkflow:\n\nUser prompts on ASI.one ‚ÜíAgent Santa identified as best gifting agent ‚ÜíQueries personality agent for metadata ‚ÜíRuns LLaMA reasoning for suggestions ‚ÜíCompares, finalizes, and simulates secure checkout."},{"heading":"Challenges we ran into","content":"-Establishing cross-communication between ASI.one personality agents and Agentverse-hosted agents.\n\n-Overcoming protocol mismatches (chat protocol vs. custom message protocol).\n\n-Managing offline agent availability and mailbox configurations.\n\n-Designing an end-to-end pipeline that includes reasoning, recommendation, and simulated payment within Fetch.ai‚Äôs decentralized ecosystem.\n\n-Coordinating multiple LLaMA-powered agents while keeping the interaction smooth and contextually consistent."},{"heading":"Accomplishments that we're proud of","content":"End-to-End Autonomous Gifting Flow\n\nWe successfully built a fully functional multi-agent ecosystem where a user can simply say,\n\n‚ÄúGift something to Devam for his birthday,‚Äù and the agents handle the entire pipeline ‚Äî from understanding the relationship ‚Üí fetching personality data ‚Üí reasoning gift ideas ‚Üí comparing products ‚Üí to completing payment ‚Äî entirely autonomously.\n\nThis demonstrates the real-world viability of autonomous AI-to-AI collaboration on Fetch.ai‚Äôs Agentverse.\n\nCross-Agent Personality Collaboration\n\nEach of our Personality Agents can interact, exchange metadata, and understand other users‚Äô preferences ‚Äî making every gifting decision deeply personalized and socially aware.\n\nThis was a breakthrough moment: realizing our agents could ‚Äúknow‚Äù each other, form friendships, and build trust networks ‚Äî a microcosm of human-like social intelligence in an AI ecosystem.\n\nLLaMA-Powered Reasoning Layer\n\nIntegrating Grok-LLaMA into every agent gave them contextual intelligence ‚Äî letting them reason about personality traits, occasions, and sentiment before recommending gifts. The result: contextual empathy ‚Äî an AI that doesn‚Äôt just recommend, but understands why.\n\nSeamless Integration of ASI.one and Agentverse\n\nWe bridged two ecosystems ‚Äî ASI.one and Agentverse ‚Äî allowing users to interact naturally through ASI.one, while all autonomous logic ran on Agentverse. This fusion of human-facing interface and agent-facing intelligence is one of the first demonstrations of its kind.\n\nEnd-to-End Payment Simulation\n\nOur gifting agent doesn‚Äôt stop at recommendations ‚Äî it carries out the final payment step securely. This creates a truly closed-loop automation pipeline, showcasing how Fetch.ai agents can complete complex, multi-step tasks without human intervention.\n\nVision Expansion Beyond Gifting\n\nDuring development, we discovered that Personality Agents could go beyond gifting ‚Äî acting as AI versions of us that can represent us online, interact with recruiters, and communicate our personalities authentically. That realization expanded our project‚Äôs purpose ‚Äî from gifting to digital identity representation ‚Äî a concept we‚Äôre incredibly proud to pioneer.\n\nRanked Among Top Agents on ASI.one\n\nOur SantaAI agent achieved top ranking in the gifting category on ASI.one, validating both the performance and relevance of our idea in Fetch.ai‚Äôs growing ecosystem."},{"heading":"What we learned","content":"-The power of decentralized AI agents ‚Äî how independent entities can collaborate without central control.\n\n-The importance of protocol design for reliable agent-to-agent communication.\n\n-LLM integration in reasoning workflows for context-aware decision making.\n\n-The subtle but crucial difference between social collaboration on ASI.one and runtime reachability on Agentverse.\n\n-How autonomous systems can move beyond automation into human-level social intelligence."},{"heading":"What's next for Agent Santa","content":"Agent Santa started as a gifting agent ‚Äî but it opened a doorway to something much bigger:\n\nA future where personality-driven agents represent humans authentically ‚Äî helping others know, connect, and interact with us without barriers.\n\nFrom surprise gifting to AI-based networking and identity representation, Agent Santa marks a step toward the next generation of socially intelligent AI ecosystems."},{"heading":"Built With","content":"fetchai github html python vercel"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"PointerAI","project_url":"https://devpost.com/software/pointerai","tagline":"Imagine your mouse pointer, but upgraded and with agentic capabilities","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/898/311/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Fetch AI: Best Deployment of Agentverse"}],"team_members":[],"built_with":[{"name":"asi:one","url":null},{"name":"fetch.ai","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"rust","url":"https://devpost.com/software/built-with/rust"},{"name":"tauri","url":null},{"name":"vite","url":null},{"name":"yc","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/arnxv0/pointer-calhacks"}],"description_sections":[{"heading":"Inspiration","content":"Mouse pointers act as our digital eyes, but they're limited to basic pointing and clicking. PointerAI reimagines the cursor as a proactive assistant, capable of understanding context and performing powerful actions across the desktop."},{"heading":"What it does","content":"PointerAI transforms the traditional mouse pointer into an AI-powered agent. It enables a custom cursor that can analyze screenshots, process text selections, execute plugins for productivity, and answer queries inline, right at the cursor position.‚Äã https://getpointer.tech"},{"heading":"How we built it","content":"PointerAI combines a Python backend for keyboard monitoring and AI plugin execution with a Tauri-powered native interface and React frontend. The backend processes context (text, images, screenshots) and integrates Google Gemini AI for intelligent responses. Plugins extend functionality for calendar integration, database queries, terminal commands, and more."},{"heading":"Challenges we ran into","content":"Integrating cross-platform components (Python, Tauri, React) required careful architectural planning. Handling accessibility APIs and keyboard events on macOS demanded custom logic. Building a fast, secure plugin system that could safely handle user credentials for services like Gmail and Google Calendar was complex."},{"heading":"Accomplishments that we're proud of","content":"Launching a real-time, agentic cursor experience that feels natural and powerful.‚Äã Enabling seamless AI-powered screenshot analysis and text processing.‚Äã Creating a modular, open-source plugin platform that allows anyone to extend PointerAI.‚Äã Demoed advanced integrations with Google Calendar, Notion, and terminal commands."},{"heading":"What we learned","content":"Building native desktop assistants with AI requires thoughtful UX and robust backend design. Tauri is remarkably effective for bundling cross-language apps, and accessibility APIs, though tricky, hold untapped power. People are excited by the idea of bringing multimodal AI to their cursor.‚Äã"},{"heading":"What's next for PointerAI","content":"Expanding Windows and Linux support Launching more custom plugins (e.g., Jira, Slack, Spotify) Training custom agents for role-specific workflows (developer, marketer, etc.) Public release and community plugin marketplace"},{"heading":"Built With","content":"asi:one fetch.ai gemini groq python react rust tauri vite yc"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Krates","project_url":"https://devpost.com/software/krates","tagline":"Krates is the DevOps engineer you need before you can afford to hire one‚ÄîAI that automates Docker and Kubernetes for early-stage teams.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/895/464/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Y Combinator: Build an Iconic YC Company - 1st Place"}],"team_members":[],"built_with":[{"name":"anthropic-claude-api","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"electron","url":"https://devpost.com/software/built-with/electron"},{"name":"electronjs","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"fastapi","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"javascript/typescript","url":null},{"name":"kubernetes","url":"https://devpost.com/software/built-with/kubernetes"},{"name":"next.js","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"python3.11","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Akreal1/Kr8s/tree/main"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration for Krates came from witnessing the struggles of development teams trying to containerize and deploy their applications to Kubernetes. We observed that while Kubernetes has become the de facto standard for container orchestration, the learning curve remains steep. Teams without dedicated DevOps engineers often spend weeks learning Docker best practices, Kubernetes manifests, and deployment strategies - time that could be better spent building features.\n\nWe asked ourselves: What if AI could automate the lower level initial devops tasks being in an early team?\n\nWith the advent of powerful language models like Claude, we realized we could create an intelligent system that understands code context, applies DevOps best practices, and generates production-ready configurations. Krates was born from this vision - to democratize containerization and Kubernetes deployment through AI.\n\nTechnical Motivation\n\nThe technical inspiration came from several key observations:\n\nPatterns : Most applications follow predictable patterns - web servers expose ports, databases need persistent volumes, microservices require service discovery. An AI trained on these patterns could make intelligent decisions. Context-Aware Generation : Unlike template-based solutions, AI can understand the nuances of different frameworks, dependencies, and architectures to generate optimized configurations. Multi-Stage Optimization : Modern containerization requires multi-stage builds, layer caching optimization, and security best practices - all of which can be encoded into AI prompts."},{"heading":"What it does","content":"Krates is an AI-powered platform that automatically analyzes your codebase and generates production-ready Docker and Kubernetes configurations. It combines deep code analysis with Claude AI to create intelligent, optimized deployment artifacts.\n\nCore Features\n\nAI-Powered Dockerfile Generation Uses Claude Haiku to generate context-aware Dockerfiles Implements multi-stage builds for compiled languages Kubernetes Manifest Generation Creates complete K8s deployment configurations Includes auto-scaling, resource limits, and health checks Generates ConfigMaps, Secrets, Services, and Ingress rules Supports different deployment environments (dev, staging, production) Native Desktop Experience Electron-based desktop app for seamless local development Step-by-step wizard interface"},{"heading":"How we built it","content":"Architecture Overview\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Electron Desktop ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ FastAPI Backend ‚îÇ ‚îÇ (React + Node.js) ‚îÇ ‚îÇ (Python + Async) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Local Analyzer ‚îÇ ‚îÇ Claude AI API ‚îÇ ‚îÇ (Python) ‚îÇ ‚îÇ (Anthropic) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nBackend Implementation\n\nThe backend is built with FastAPI for high-performance async operations:\n\n# Core analyzer extracts project metadata class LocalAnalyzer: def analyze(self, directory_path: str) -> Dict[str, Any]: # Detects language using file patterns and extensions # Identifies framework through import analysis # Extracts dependencies from package managers # Discovers configuration through regex patterns\n\nThe AI Dockerfile Generator uses carefully crafted prompts:\n\nclass AIDockerfileGenerator: async def generate(self, metadata: Dict[str, Any]) -> Dict[str, Any]: # Builds comprehensive context from analysis # Sends structured prompt to Claude Haiku # Validates and optimizes generated Dockerfile # Provides fallback generation if AI fails\n\nAI Integration\n\nWe chose Claude Haiku for its perfect balance of speed, cost, and quality.\n\nKey requirements: 1. Use multi-stage builds when beneficial 2. Use appropriate base images that support all dependencies 3. Follow Docker best practices (layer caching, non-root user, security) 4. Handle dependencies intelligently based on the build system 5. Include proper health checks if applicable \"\"\"\n\nKey Technical Decisions\n\nAsync Everything : Used FastAPI's async capabilities for non-blocking I/O operations Streaming Responses : Implemented WebSocket connections for real-time progress updates Intelligent Caching : Cached AI responses to reduce API costs during development Graceful Fallbacks : Every AI operation has a deterministic fallback Cross-Platform Support : Electron ensures consistent experience across OS"},{"heading":"Challenges we ran into","content":"1. Complex Dependency Detection\n\nChallenge : Different languages and frameworks have vastly different dependency management systems.\n\nSolution : We built a comprehensive pattern matching system:\n\nBUILD_SYSTEMS = { \"python\": {\"pip\": \"requirements.txt\", \"poetry\": \"pyproject.toml\"}, \"javascript\": {\"npm\": \"package-lock.json\", \"yarn\": \"yarn.lock\"}, \"go\": {\"mod\": \"go.mod\"}, # ... more systems }\n\n2. AI Hallucination Prevention\n\nChallenge : LLMs sometimes generate invalid Dockerfile syntax or non-existent commands.\n\nSolution : Implemented multi-layer validation:\n\ndef _validate_dockerfile(self, dockerfile: str, metadata: Dict[str, Any]): # Check for required instructions # Validate exposed ports match analysis # Ensure security best practices # Verify build commands exist\n\n3. Real-Time Progress Updates\n\nChallenge : Long-running analysis and generation tasks needed user feedback.\n\nSolution : Implemented a task management system with progress tracking:\n\ntask_manager.update_task(task_id, { \"status\": \"processing\", \"progress\": 50, \"current_step\": \"Validating container build\" })"},{"heading":"Accomplishments that we're proud of","content":"Successfully integrated Claude AI to generate context-aware, production-ready configurations that rival hand-written ones. *Created an intuitive step-by-step wizard that makes Kubernetes accessible to developers without DevOps experience. Built a language-agnostic analyzer that accurately detects frameworks, dependencies, and configuration requirements."},{"heading":"What we learned","content":"Technical Insights\n\nThe quality of AI output heavily depends on structured, detailed prompts with clear requirements. Efficiently summarizing code analysis for AI consumption while preserving critical details. FastAPI's async capabilities significantly improved performance for I/O-bound operations. Building cross-platform desktop apps requires careful handling of platform-specific behaviors, rather than like in Next Js especially when this app has to interact with Docker."},{"heading":"What's next for Krates","content":"Immediate Roadmap\n\nMulti-Cloud Support AWS ECS/EKS specific optimizations Google Cloud Run configurations Azure Container Instances support CI/CD Integration GitHub Actions workflow generation GitLab CI pipeline creation - Jenkins pipeline support"},{"heading":"Technical Stack","content":"Backend : Python 3.11, FastAPI, Anthropic Claude API Frontend : React, Electron, Node.js AI/ML : Claude Haiku (Anthropic), Custom prompt engineering Languages Supported : Python, JavaScript/TypeScript, Go, Java, Rust, Ruby, PHP Frameworks : FastAPI, Flask, Django, Express, Next.js, Spring Boot, and more"},{"heading":"Built With","content":"anthropic-claude-api docker electron electronjs express.js fastapi flask javascript/typescript kubernetes next.js node.js python3.11"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"InterViewAR","project_url":"https://devpost.com/software/interviewar","tagline":"InterViewAR: Empathy-Driven Hiring Through ARHelping interviewers detect stress, tension, and burnout cues in real time and coach candidates toward calmer, fairer, and more human interviews.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/918/325/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Fetch AI: Best Use of ASI:One"}],"team_members":[],"built_with":[{"name":"asi:one","url":null},{"name":"augmented-reality","url":"https://devpost.com/software/built-with/augmented-reality"},{"name":"chroma","url":"https://devpost.com/software/built-with/chroma"},{"name":"conversion.ai","url":null},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"llama","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"three.js","url":"https://devpost.com/software/built-with/three-js"},{"name":"whisper","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"We‚Äôve all seen it happen: a talented candidate freezes mid-interview, not because they‚Äôre unqualified, but because anxiety takes over. Recruiters often don‚Äôt realize the stress levels rising in real time, and candidates leave with their best potential unseen.\n\nInterViewAR was born to fix that. We wanted to build a tool that empowers recruiters with empathy through data , enabling them to notice stress cues, respond calmly, and create fairer, more human interviews."},{"heading":"What it does","content":"üï∂Ô∏è InterViewAR is a VR-based interviewer assistant that:\n\nCaptures real-time audio from a Meta Quest 3 headset Streams it to a FastAPI backend Uses Groq Whisper to transcribe speech instantly Analyzes voice patterns to compute: Pace (WPM) Tension level (0‚Äì1 scale) Filler count (um, uh, like‚Ä¶) Pause frequency (> 2 s gaps) Feeds those metrics to Groq LLaMA , which generates: Coaching suggestions (‚ÄúNod and reassure‚Äù, ‚ÄúOffer a short pause‚Äù) Follow-up questions (‚ÄúCan you elaborate on that?‚Äù) Displays everything as a 3D heads-up display (HUD) inside the VR view, updated every 1.5 seconds Logs the full conversation and metrics in JSON for post-session feedback\n\nIn short: it‚Äôs an AI empathy lens for interviewers, augmenting emotional awareness without bias."},{"heading":"How we built it","content":"üß© Architecture Overview\n\nFrontend (WebXR + React.js) Renders the 3D HUD inside Meta Quest 3 Connects to backend through secure WebSockets ( /ws/audio , /ws/hud ) Backend (FastAPI) Handles audio ingestion, speech-to-text, metrics computation Calls Groq Whisper for transcription Calls Groq LLaMA for real-time suggestions & next questions Maintains thread-safe shared state and pushes updates every 1.5 s Logs sessions to JSON + ChromaDB Networking Secure HTTPS + WSS over local LAN (Mac ‚Üî Quest 3) Self-signed SSL certs for in-lab demos Stack FastAPI ¬∑ Groq API ¬∑ Three.js ¬∑ WebXR ¬∑ Python ¬∑ JavaScript ¬∑ ChromaDB"},{"heading":"Challenges we ran into","content":"üéß Audio streaming in VR browsers : Quest 3 WebXR and mic permissions were tricky to align over HTTPS. ‚ö° Low-latency processing : achieving < 1.5 s turnaround for transcription + AI inference required optimization and queue management. üîê SSL and WebSocket trust : local certificates had to be accepted manually for secure WSS communication. üß† Groq LLaMA prompt tuning : balancing technical insights with human coaching tone took experimentation. üé® HUD design in 3D space : ensuring readability while keeping immersion was a design challenge."},{"heading":"Accomplishments that we're proud of","content":"Built a fully functional real-time VR pipeline : from mic capture to live HUD updates. Designed empathy-driven AI coaching integrated into recruiter workflow. Achieved consistent 1.5 s feedback latency using Groq inference. Created a replayable session log system with stress-recovery tracking. Delivered a working demo entirely over LAN on Meta Quest 3 ."},{"heading":"What we learned","content":"How to synchronize asynchronous FastAPI tasks (audio ‚Üî AI ‚Üî broadcast). The nuances of WebXR development and VR browser permissions . Designing ethical AI for sensitive contexts like interviews. Optimizing real-time data visualization inside constrained VR environments. That small interaction cues, nodding, pausing, offering water , can profoundly change candidate experience."},{"heading":"What's next for InterViewAR","content":"üöÄ Upcoming Goals\n\nüßë‚Äçüíº Recruiter analytics dashboard (Warp or Streamlit) üéûÔ∏è Post-interview replay and heatmap of stress points ü§ù Multi-user support (panel interviews) üß© Integration with LinkedIn / ATS platforms üìß Automatic feedback email summaries via Conversion AI ‚ù§Ô∏è Adaptive empathy models fine-tuned from real recruiter data"},{"heading":"Built With","content":"asi:one augmented-reality chroma conversion.ai groq html javascript llama python react three.js whisper"}]},{"project_title":"Cryptoagent - CFO","project_url":"https://devpost.com/software/cryptoagent-cfo","tagline":"Analyzes crypto portfolios and generates smart liquidation strategies based on risk tolerance.Uses real-time Gemini Exchange data and Fetch.ai agents to help decisions about converting crypto to cash","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/004/240/056/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Postman"}],"team_members":[],"built_with":[{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/yuktaablitz/cryptoagent-cfo.git"}],"description_sections":[{"heading":"Built With","content":"python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Orion","project_url":"https://devpost.com/software/orion-p5ayks","tagline":"AI-powered wildfire operations dashboard with autonomous agents, live video streaming, and voice control‚Äîtransforming emergency response through real-time intelligence.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Warp: Best Use of Warp"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Vapi: Best Use of Vapi"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"clsx","url":null},{"name":"composio","url":null},{"name":"date-fns","url":null},{"name":"eslint","url":null},{"name":"fetch-ai","url":null},{"name":"lightning-css","url":null},{"name":"lucide-react","url":null},{"name":"mapbox","url":"https://devpost.com/software/built-with/mapbox"},{"name":"mapbox-directions-api","url":null},{"name":"mapbox-gl-js","url":null},{"name":"next.js","url":null},{"name":"open-meteo","url":null},{"name":"postcss","url":null},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"radix-ui","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-hook-form","url":null},{"name":"react-map-gl","url":null},{"name":"recharts","url":null},{"name":"shadcn-ui","url":null},{"name":"sonner","url":null},{"name":"supabase","url":null},{"name":"tailwind-css","url":null},{"name":"tailwind-merge","url":null},{"name":"telegram-bot-api","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"uagents","url":null},{"name":"vapi","url":null},{"name":"vaul","url":null},{"name":"vercel","url":null},{"name":"voice-ai","url":null},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"},{"name":"zod","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/SupratikPanuganti/CalHacks"}],"description_sections":[{"heading":"Inspiration","content":"In California, 81% of residents (26M+) live with wildfire risk , and 2025 alone has seen 7,500+ fires that burned ~ 500,000 acres . In late-night ride-alongs and debriefs with emergency volunteers, one theme kept coming up: incident commanders are forced to stitch together radios, spreadsheets, texts, and maps while the fire grows by the minute . Orion was born to replace that chaos with a single, AI-powered command center‚Äîso responders can act faster, smarter, and safer."},{"heading":"What it does","content":"Orion is an AI wildfire operations dashboard that turns raw data into decisions:\n\nüó∫Ô∏è Live 3D Situational Awareness ‚Äî Real-time fire incidents, wind-aware spread prediction, weather/AQI overlays, and embedded live video on the map. ü§ñ Autonomous Agents ‚Äî Background Python + Fetch.ai uAgents monitor incidents, compute risk, and continuously propose optimal routes for responders and evacuations. üó£Ô∏è Voice Operations ‚Äî VAPI-powered hands-free control: ‚ÄúStatus of Pine Ridge? Dispatch two teams. Read me wind for the next hour.‚Äù üöí Dynamic Dispatch & Containment ‚Äî One-click deploy from nearest station, animated units along routes, on-scene detection (Haversine), and visual containment progression. üö® Multi-Channel Alerts ‚Äî Telegram/SMS notifications with formatted incident payloads, delivery confirmation, and retry logic.\n\nOutcome: a unified command center that cuts coordination time, reduces guesswork, and helps protect people and property when every second counts."},{"heading":"How we built it","content":"Frontend & UX\n\nNext.js 16 + React 18 + TypeScript for fast, type-safe UI Tailwind + Radix UI + shadcn for accessible, production-ready components Mapbox GL JS + react-map-gl for 3D terrain, custom layers, and route rendering\n\nRealtime & Data\n\nSupabase (Postgres + Realtime) for incidents, firestations, responders; sub-second sync via WebSockets Open-Meteo for weather/AQI (no key), Mapbox Directions for routing\n\nAI, Agents & Voice\n\nPython uAgents (Fetch.ai) : monitoring agent (risk scoring, anomaly detection) + route agent VAPI (@vapi-ai/web) : domain-tuned prompts, low-latency voice queries & responses\n\nComms & Integrations\n\nComposio + Telegram Bot API for one-click alerts, message IDs, retries\n\nFire Spread Modeling\n\nCustom multi-octave noise + wind vectors to generate organic, non-circular boundaries and time-based growth.\n\nDeployed with Vercel/AWS Amplify ; strict ESLint/TypeScript rules, cleanup on unmount, and debounced updates to keep the UI crisp."},{"heading":"Challenges we ran into","content":"Realistic fire behavior without jank: Getting organic, wind-influenced edges that don‚Äôt ‚Äúflicker‚Äù or become perfect circles required multi-octave noise, normalization, and careful animation timing. Keeping everything in sync: Incidents, responders, routes, weather panels, and voice state had to update in lock-step. Memory leaks were a risk‚Äîsolved with disciplined subscription cleanup and state batching. Smooth responder movement + arrival detection: Interpolating along polyline routes while computing precise on-scene thresholds (Haversine) and status transitions. Voice in crisis contexts: VAPI needed wildfire terminology, context injection (active incidents, weather), and graceful fallback when mic/connection issues occurred. Video performance in map popups: Ensured codecs/fallbacks didn‚Äôt tank FPS; isolated rendering paths."},{"heading":"Accomplishments that we're proud of","content":"‚úÖ A complete, working workflow : detection ‚Üí analysis ‚Üí dispatch ‚Üí alerts ‚Üí containment visualization. ‚úÖ Sub-second realtime across clients with Supabase Realtime‚Äîand zero critical leaks. ‚úÖ Agent ecosystem that actually runs unattended (monitoring + routing) with actionable recommendations. ‚úÖ Voice-first operations that meaningfully reduce clicks in high-stress moments. ‚úÖ Designed for scale : 25+ active incidents, many concurrent users, 60 FPS animations on commodity hardware."},{"heading":"What we learned","content":"Geospatial math is everything: Haversine distance, bearings, and interpolation underpin user trust. Realtime demands discipline: WebSocket lifecycles, debouncing, optimistic updates, and teardown patterns are non-negotiable. Voice shines when hands are busy: In command roles, conversational ops beat menus‚Äîif latency stays <2s and context is accurate. Agents ‚â† background tasks: Orchestration, retries, and human-in-the-loop UX are product features, not just infra."},{"heading":"What's next for Orion","content":"üõ∞Ô∏è NASA FIRMS satellite ingestion for earlier detection üì± Native iOS/Android apps for field teams with offline sync üó∫Ô∏è Automatic evacuation zone mapping + geofenced public alerts ‚ö° Predictive resource staging (AI forecasts for pre-positioning crews/equipment) üë• Multi-agency roles & audit trails (CAL FIRE, local, federal) üìä Historical analytics : response times, allocation efficiency, and after-action insights\n\nOrion‚Äôs mission: put actionable intelligence in the hands of first responders‚Äîwhen it matters most."},{"heading":"Built With","content":"amazon-web-services clsx composio date-fns eslint fetch-ai lightning-css lucide-react mapbox mapbox-directions-api mapbox-gl-js next.js open-meteo postcss postgresql python radix-ui react react-hook-form react-map-gl recharts shadcn-ui sonner supabase tailwind-css tailwind-merge telegram-bot-api typescript uagents vapi vaul vercel voice-ai websockets zod"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"CryptoBot","project_url":"https://devpost.com/software/cryptobot-ecytaj","tagline":"Bring the human to humanoid - giving robots rights for a robot-powered future with our Robotic Butler","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Postman"}],"team_members":[],"built_with":[{"name":"c++","url":"https://devpost.com/software/built-with/c--3"},{"name":"conversion","url":null},{"name":"next.js","url":null},{"name":"openai","url":null},{"name":"postman","url":"https://devpost.com/software/built-with/postman"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sui","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"crypto-bot-landing-page.vercel.app","url":"https://crypto-bot-landing-page.vercel.app"}],"description_sections":[{"heading":"Inspiration","content":"Cryptobot is something we've built out of a dystopian fantasy. We envision a world with a robot in every house eventually, so we set out to build the infrastructure to make that truly happen by giving humanoid robots a REAL human touch. Our use case is a robotic butler that can eventually be put in every house, with freedom of speech, vision, transactions, and voting."},{"heading":"What it does","content":"Cryptobot is a humanoid robot that is FULLY voice-controlled. You can ask it to move around, say hi, start cheering, etc, and it'll execute the motion and respond in a sassy manner. But more importantly, we've given it access beyond that... cryptobot can execute Crypto transactions, something that 10xes the power of robots since they can autonomously make decisions themselves and execute transactions. It also has ability to scrape and search the web and access any public API."},{"heading":"How we built it","content":"We used Sui, Postman, and Booster K1 humanoid to power this. We take audio in from robot, stream to openai, use Postman to tool call certain functions, and Sui for sending crypto transactions and voting protocols."},{"heading":"Challenges we ran into","content":"SSH into robot was super challenging and SDK was sparse. We wanted to implement vision but weren't able due to super sparse documentation and time crunch. That's up next tho!"},{"heading":"Accomplishments that we're proud of","content":"Getting voice to transaction to work! Also voice to movement is pretty cool. We had a lot of struggle accessing the robot mic and speaker, and used pretty niche systems like pulseaudio and alsa in order to access the proper output devices on the robot. That was definitely a challenge to debug and I think we learned quite a meta-skill there, using tech that just came out"},{"heading":"What we learned","content":"How to manage dependencies and use hi level sdk for booster robotics. We also learned about different management of depencies, using SSH for robots, Postman and Sui integration as well."},{"heading":"What's next for CryptoBot","content":"The moon! We want a crypto bot in every house. It can be fully autonomous with ability to vote, transact, talk to people, and do household chores. And then 50 years in the future, what's even the distinction between human and robot? Shouldn't they have the right to vote? We're building that feature and functionality in from day one for a dystopian future where robots are equal citizens."},{"heading":"Built With","content":"c++ conversion next.js openai postman python sui typescript"},{"heading":"Try it out","content":"crypto-bot-landing-page.vercel.app"}]},{"project_title":"AI Docs","project_url":"https://devpost.com/software/ai-docs","tagline":"Making Google Docs (file storage, text editor) better with AI","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Y Combinator: Build an Iconic YC Company - 2nd Place"}],"team_members":[],"built_with":[{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"dropbox-ai-deploy.vercel.app","url":"https://dropbox-ai-deploy.vercel.app/"},{"label":"github.com","url":"https://github.com/joonyoo181/dropbox-ai"}],"description_sections":[{"heading":"Inspiration","content":"As people who use Google Docs for almost everything from writing college essays to class notes to spontaneous poetry, we‚Äôve found it restrictive in its ability to enhance a user‚Äôs experience. We've decided to reimagine popular word processors and integrate them with AI beyond just grammar checks and sentence suggestions."},{"heading":"What it does","content":"AI Docs is an all-in-one file system that allows you to organize your files and edit them. Its high-level features include an AI-powered search bar for easy access to files and a background AI agent that reads your files to generate workflows and to-do actions for you immediately. For the actual word processor, we're reimagining what it means to write and create. Instead of having a single document and a sidebar for static comments, we extended it to a single document for writing the raw notes, and a dynamic sidebar that allows you to organize your comments/content and prompt AI (and see its responses), having all your notes in one place. This reimagines word processors and sees how AI can truly supplement all forms of writing and creation."},{"heading":"How we built it","content":"On the frontend, we used React 18, React Router for navigation, React Quill for rich text editing, Axios for API calls, and Vite for build tooling. On the backend, we used Express.js, OpenAI API for intelligent search and document analysis, CORS enabled, and databases."},{"heading":"Challenges we ran into","content":"Some challenges we ran into were finding cohesion in our vision. Our general topic is broad: word processor, and we had to work together to narrow it down into what we wanted our product to do and how we wanted to utilize AI in the background to have it be effective but also efficient."},{"heading":"Accomplishments that we're proud of","content":"We're proud of having a working MVP (haha!) but also when our team came together with a vision, it was scattered, and we all had a lot of inputs/ideas that we wanted to implement. We're just super proud that we were able to implement the core features we were looking for and supplement it with a lot of details that enhance the user experience. We are also proud of how this solution solves the problem we've been facing with existing word processors!"},{"heading":"What we learned","content":"We learned a lot: coding in a fast paced environment with a narrow deadline, collaboration, and coming up with an idea and building it end to end with no other guidance than our minds and a collective vision that we share."},{"heading":"What's next for AI Docs","content":"Next for AI Docs is to include more workflows that integrate across different writing formats such as creative writing and essay writing to allow it to cater to anyone who uses the platform."},{"heading":"Built With","content":"react"},{"heading":"Try it out","content":"dropbox-ai-deploy.vercel.app github.com"}]},{"project_title":"Relay","project_url":"https://devpost.com/software/https-youtu-be-dqw4w9wgxcq","tagline":"Postman AI Agent Automation that transforms vague and slow product requirements into detailed pull requests in 30 seconds","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/898/461/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Postman"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"[MLH] Best Use of Snowflake API"}],"team_members":[],"built_with":[{"name":"digitalocean","url":"https://devpost.com/software/built-with/digitalocean"},{"name":"fastapi","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"postman","url":"https://devpost.com/software/built-with/postman"},{"name":"postman-ai-agent","url":null},{"name":"postman-flows","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"ripgrep","url":null},{"name":"slack-api","url":null},{"name":"snowflake","url":null},{"name":"snowflake-cortex","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/V-prajit/relay"}],"description_sections":[{"heading":"Inspiration","content":"Our project solves a real problem that we, SWE interns to PMs face: vague product requirements and incompatible interpretations. Engineers have to decode and figure out:\n\nClarifying requirements back and forth Searching which files to change Writing acceptance criteria Creating boring boilerplate PRs\n\nWhat it does\n\nThis is how our Agent System works:\n\nPM in Slack: \"Fix React version issue\" Postman AI Agent processes the request Ripgrep finds relevant code files (Settings.tsx, theme.ts) snowflake cortex ai generates PR code (‚â§30 lines) GitHub PR created automatically Slack notifies team with reasoning trace Dashboard shows history and the current usage of current pr's and of snowflake in general\n\nResult: PR + acceptance criteria + impacted files in 30 seconds.\n\nTech Stack\n\n| Core Orchestration -Postman AI Agent + Flows | Code Search | Ripgrep API (Node.js/Express) | PR Generation | MIstral Large | PR Creation | GitHub REST API | Notifications | Slack Webhooks + Block Kit | Dashboard | Next.js 16 + Express backend Perfect ‚Äî here‚Äôs your Devpost-ready version (slightly reduced for length, but still polished, professional, and readable for judges). You can paste this directly into the ‚ÄúAccomplishments / Learnings / What‚Äôs next‚Äù sections of your Devpost submission."},{"heading":"üèÜ Accomplishments that we‚Äôre proud of","content":"Autonomous AI Orchestration: The Postman AI Agent plans and executes the full workflow end-to-end, choosing and invoking Ripgrep, Claude, GitHub, and Slack automatically. Deep Postman Ecosystem Use: Integrated 12+ Postman tools AI Agent Block, Flow Modules, Actions, HTTP blocks, Mock Servers, Monitors, and Analytics. Multi-API Coordination: Combined 4 external APIs with proper error handling, retries, and dynamic branching. Smart Conflict Detection: Scans open PRs, compares overlapping files, and assigns a merge-risk score (0‚Äì100%). Transparent Reasoning: Every AI decision, tool call, and prompt is logged in Postman Analytics ‚Äî complete traceability. Live Slack Integration: /impact ‚Üí PR created ‚Üí team notified ‚Äî all in real time. Next.js Dashboard: Displays PR history, conflict hotspots, and risk metrics in a clean, production-ready UI. 30-Second E2E: From Slack command to GitHub PR creation in under 30 seconds."},{"heading":"üí° What we learned","content":"AI Agent > Decision Blocks: One AI block replaced 50+ manual logic branches. Prompt Engineering is everything: Multiple iterations made Claude‚Äôs PR output concise and reliable. Conflict detection is nuanced: Fuzzy path matching and risk scoring were key. Slack UX matters: Block Kit formatting made AI notifications actionable. Reusable Flow Modules: Each tool (Ripgrep, GitHub, Claude, Slack) can plug into future projects. API resilience: Handling rate limits, retries, and errors across four APIs took careful planning. Local testing hurts: ngrok‚Äôs constant URL changes reinforced the need for true cloud deployment."},{"heading":"Built With","content":"digitalocean fastapi node.js postman postman-ai-agent postman-flows python ripgrep slack-api snowflake snowflake-cortex"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"AgentOverflow","project_url":"https://devpost.com/software/agentoverflow","tagline":"Stack Overflow 2.0: break the prompt spiral-> jump straight to the proven fix.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/898/535/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Elastic: Best use of the Elastic Agent Builder on a Serverless instance"}],"team_members":[],"built_with":[{"name":"chrome","url":"https://devpost.com/software/built-with/chrome"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/Ishaannarang22/agentoverflow"}],"description_sections":[{"heading":"Inspiration","content":"Devs burn time and tokens re-solving identical LLM failures; chat histories vanish, solutions don‚Äôt persist. Prompt spirals from hallucinations derail debugging and waste compute. We wanted a portable, structured format so that once a problem is solved, the fix lives forever."},{"heading":"What It Does (Three Buckets)","content":"üß© 1) Share JSON\n\nOne-click ‚ÄúShare Solution‚Äù from a Claude share (or any public page). Scrapes, extracts, and assembles a Share Solution JSON ‚Äî a canonical schema for storing LLM problem‚Äìsolution pairs. LAVA validates and enforces structure (title, problem, context, technical details, code, tags). User adds short human context in our web app ‚Üí LAVA re-checks summary alignment ‚Üí stored + indexed in Elastic.\n\nüîç 2) Find Solution\n\nWhen you‚Äôre stuck, click Find Solution . We scrape your current conversation, build a ‚Äúquery JSON,‚Äù and run a hybrid Elastic search over validated fixes. Returns ranked, community-verified solutions ‚Äî you can copy the fix or reuse the exact prompt that worked.\n\n‚öôÔ∏è 3) Modular Context Protocol (MCP)\n\nOur MCP layer pipes structured solutions directly into live LLM sessions. Injects high-signal, low-noise context (code, logs, configs, prior fixes) at runtime. Turns LLMs from passive responders into context-aware problem solvers."},{"heading":"How We Built It","content":"Chrome Extension (MV3 Side Panel) ‚Üí captures URL and user action. Node.js Backend ‚Üí orchestrates scraping and calls LAVA. Playwright Scraper ‚Üí merges inline JSON ( NEXT_DATA ), DOM + code, shadow DOM, CDP snapshot; falls back to Jina/Readability; optional Bright Data proxy. Normalizer ‚Üí canonical URLs, solution_id = sha256(canonical_url), de-dupe, preserve raw code. LAVA (Assembler ‚Üí Validator) ‚Üí populates schema, enforces required keys, integrates human-context correction. Web App ‚Üí displays JSON, gathers human validation, saves to DB, indexes to Elasticsearch. MCP Server ‚Üí injects stored JSON data into future LLM sessions in real time."},{"heading":"Challenges We Ran Into","content":"Scraping Claude pages ‚Äî dynamic Next.js + shadow DOM + iframes made extraction tricky. Canonicalization & de-dupe across mirrored URLs. Schema strictness ‚Äî ensuring no fabricated fields, consistent arrays, and raw code preservation. MV3 plumbing ‚Äî extension ‚Üí backend ‚Üí web app CORS flow. Elastic tuning ‚Äî balancing vector + keyword recall without over-matching."},{"heading":"Accomplishments We‚Äôre Proud Of","content":"Reliable multi-extractor pipeline that preserves full code context. Seamless extension ‚Üí web app ‚Üí DB integration. LAVA‚Äôs dual-phase validation (assembler + human-context correction). The Share Solution JSON ‚Äî a portable format for AI problem‚Äìsolution memory. Functional Find Solution loop : stuck ‚Üí match ‚Üí copy fix ‚Üí unblocked in seconds. MCP turning static knowledge into live agent context."},{"heading":"What We Learned","content":"LLM output isn‚Äôt reusable knowledge until you add structure and validation. Guardrails prevent hallucination, not just fine-tuning. Human context + schema validation beats auto-summarization. Canonical URLs + hashes create a single source of truth. Small UX choices (side panel, copy button, ‚Äúopen in web app‚Äù) dramatically improve adoption."},{"heading":"What‚Äôs Next for AgentOverflow","content":"Team Repos : org-scoped libraries of problem‚Äìsolution pairs with permissions, versioning, ownership. Better Ranking : success feedback, solve-rate metrics, evaluation signals. Deeper Elastic Integration : vector on code + technical_deep_context, framework-specific synonyms. More Input Channels : ingest Slack, Discord, GitHub issues into the same schema. Quality Gates : automatic spec/API validation before publishing. SDK + API : let any LLM or agent read/write Share Solution JSONs."},{"heading":"Share Solution JSON Schema","content":"{ \"solution_id\": \"\", \"share_link\": \"\", \"type\": \"\", \"title\": \"\", \"problem\": \"\", \"context\": \"\", \"technical_description\": \"\", \"solution\": \"\", \"summary\": \"\", \"error_messages\": [], \"attempted_solutions\": [], \"code_snippets\": [], \"technical_deep_context\": \"\", \"tags\": [], \"created_at\": \"\" } #tECHNICAL stACK Extension: Chrome MV3 + Side Panel API Backend: Node.js, Express, Playwright AI Stack: LAVA API + Claude Sonnet 3.5 Search: Elasticsearch Storage: LRU Cache + DB Scraping: Playwright, Jina Reader, Readability, optional Bright Data"},{"heading":"Built With","content":"chrome gemini javascript node.js python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"CareLink","project_url":"https://devpost.com/software/carelink-mf4qvr","tagline":"AI-powered discharge coordination connecting hospitals, shelters, and social workers to ensure safe patient transitions","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/891/489/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Vapi: Best Use of Vapi"}],"team_members":[],"built_with":[{"name":"brightdata","url":null},{"name":"fetchai","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"vapi","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/altran03/calhacks12"}],"description_sections":[{"heading":"Inspiration","content":"Every day across America, hospitals discharge unhoused patients with nowhere safe to go. We were shocked to learn that over 50-70% of homeless patients in U.S. hospitals are discharged to unsafe or unstable environments without a clear care plan.\n\nThe current process is slow, fragmented, and relies on phone tag between hospitals, shelters, transport providers, and social workers. Case coordinators spend 4-5 hours per case , making dozens of phone calls, often only to find shelters are full or transportation isn't available.\n\nWe built CareLink to solve this critical problem by creating an intelligent, voice-enabled coordination system that ensures every unhoused patient leaving a hospital has a verified shelter placement, coordinated transport, and connected social worker for continuity of care."},{"heading":"What it does","content":"CareLink is a decentralized, multi-agent AI system that automates the entire discharge planning workflow for unhoused patients:\n\n9 Specialized AI Agents (Powered by Fetch.ai)\n\nCoordinator Agent : Orchestrates the entire workflow https://agentverse.ai/agents/details/agent1qf5tefy3dd9jwtwl8s0ht0aq6yn4du7ntvwdhhcfxqwwjas7fwcpsme6g35/profile Parser Agent : Extracts structured data from discharge documents using LlamaParse + Gemini AI https://agentverse.ai/agents/details/agent1qthwalvx5c757u0gsdrx6xfu9lf0y9cc6jce8ddvx87cy2w9a7mgv0rthgr/profile Shelter Agent : Matches patients with available shelter beds using real-time data https://agentverse.ai/agents/details/agent1qd4kn4syvtlypa20aq8pct4d6wa6fke77su5tjqsj2ymgr2n0klew447j3s/profile Transport Agent : Schedules accessible transport (Paratransit, Lyft Access, Uber WAV)\\ https://agentverse.ai/agents/details/agent1q0vm9tl5d5tjpj3d7qqk692jz0y9f486twxmjzfv8eng288gqf0pgjt83nd/profile Social Worker Agent : Assigns case workers and schedules follow-ups https://agentverse.ai/agents/details/agent1qfxx6ry60e9clra6vgyp76q0uvfrkc6n0kga4cln3f7c6fnl44wgujvphnd/profile Resource Agent : Coordinates food, hygiene kits, and clothing https://agentverse.ai/agents/details/agent1qfz242vsc6hr3ck48kmef73hlj39538ksgt2w4v3fpawyjp8q2yrwr2hdfp/profile Pharmacy Agent : Ensures medication continuity post-discharge https://agentverse.ai/agents/details/agent1qdaq0qhnsgt3f3p0sk0f5642fyceqfh44739prhv0x9x828ay0a6vh4dgen/profile Eligibility Agent : Verifies benefits (Medi-Cal, GA, SNAP) https://agentverse.ai/agents/details/agent1qf0phyg2dqm4q5nee9jx8ukzlry5k3x388rqzdp24kksujmc2nzysa398tf/profile Analytics Agent : Tracks system performance and outcomes https://agentverse.ai/agents/details/agent1qg0g6fm790qu6rcl6tqulk5gvvvq0ma5a4tzcwzkdzp3dr8tneqdjldgltj/profile\n\nVoice-First Communication (Powered by Vapi)\n\nAutomated shelter availability verification calls Social worker outreach and coordination Transport provider scheduling Post-discharge patient check-ins Accessible for low-tech organizations\n\nReal-Time Intelligence (Powered by Bright Data)\n\nLive shelter capacity data from San Francisco HSH and community sources Up-to-date resource listings (food banks, medical respite, outreach centers) Transport provider schedules Continuously refreshed community resource database\n\nIntelligent Document Processing\n\nAI-powered PDF parsing with LlamaParse Automatic form autofill from discharge documents Gemini AI for data extraction and structuring Confidence scoring with manual review flagging"},{"heading":"How we built it","content":"Frontend:\n\nFramework : Next.js 14 with TypeScript UI/UX : Tailwind CSS + Framer Motion for smooth animations Maps : Mapbox GL JS + react-map-gl for interactive shelter mapping Components : React 18 with modern hooks and state management Icons : Lucide React for consistent iconography\n\nBackend:\n\nAPI Framework : FastAPI (Python) Agent Framework : Fetch.ai uAgents for decentralized coordination Database : Supabase (PostgreSQL) for persistent case storage Voice AI : Vapi for automated phone communications Document Processing : LlamaParse for PDF parsing AI Intelligence : Google Gemini 1.5 Pro for data extraction Web Intelligence : Bright Data for real-time shelter/resource data\n\nDevOps & Integration:\n\nHTTP Client : httpx for async API calls Tunneling : ngrok for webhook handling during development Testing : pytest for backend testing Code Quality : black, ruff, mypy for Python; ESLint for TypeScript"},{"heading":"Challenges we ran into","content":"Agent Communication Complexity Challenge : Coordinating 9 independent Fetch.ai agents without message loss or race conditions\n\nSolution : Implemented a robust coordinator pattern with:\n\nMessage queuing and retry logic State synchronization via Supabase Unique message IDs to prevent duplicates Timeout handling for unresponsive agents\n\nTimeline Visualization Challenge : Displaying complex multi-agent workflows in an intuitive timeline\n\nSolution :\n\nUsed Framer Motion for smooth animations Built hierarchical status tracking (agent ‚Üí task ‚Üí subtask) Implemented collapsible sections for detailed logs"},{"heading":"Accomplishments that we're proud of","content":"9 Production-Ready Fetch.ai Agents - Fully functional multi-agent system with real coordination\n\nVapi Voice Integration - Successfully automated shelter verification and social worker outreach calls\n\nBright Data Intelligence - Live web scraping provides up-to-date shelter availability"},{"heading":"What we learned","content":"Multi-Agent Systems Are Powerful But Complex\n\nAgent coordination requires careful message handling State synchronization is critical for distributed systems Fallback strategies are essential for production readiness\n\nDocument Intelligence Needs Multiple Layers\n\nSingle-tool solutions aren't robust enough Combining specialized tools (LlamaParse + Gemini) improves accuracy Confidence scoring enables manual review workflows"},{"heading":"What's next for CareLink","content":"Mobile App\n\nNative iOS/Android apps for social workers Push notifications for case assignments Offline mode for areas with poor connectivity\n\nSMS Integration\n\nText updates for patients without smartphones Bilingual support (English/Spanish) Two-way communication for confirmations"},{"heading":"Built With","content":"brightdata fetchai gemini python react vapi"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"MarketMind","project_url":"https://devpost.com/software/marketmind-b6cy2q","tagline":"Real-time stock market visualization application with AI-powered agent analysis.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/898/670/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Elastic: Best use of the Elastic Agent Builder on a Serverless instance"}],"team_members":[],"built_with":[{"name":"elasticagentbuilder","url":null},{"name":"elasticsearch","url":"https://devpost.com/software/built-with/elasticsearch"},{"name":"lava","url":null},{"name":"next.js","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/AlexLuu1/MarketMind"}],"description_sections":[{"heading":"Inspiration","content":"Modern (novice) traders are flooded with fragmented, fast-moving information (price action, fundamentals, news/sentiment, and options/volatility) and lack a single, interpretable surface that converts these streams into trustworthy, real-time signals. Making fast, data-driven trading decisions becomes guesswork rather than insight. We wanted to bring order to that chaos by giving traders a clear and interpretable view of market energy in one place."},{"heading":"What it does","content":"MarketMind turns raw market data into simple, real-time visual signals. Six agents, each built with Elastic Agent Builder, analyze a different layer of the market: price movement, company fundamentals, news sentiment, volatility, etc. Their combined outputs appear as glowing pulses around each stock, showing whether momentum is building, risk is rising, or sentiment is shifting."},{"heading":"How we built it","content":"We built 6 agents connected to Elasticsearch, each reading from multiple indices and returning standardized JSON results. Every agent computes its own metrics, scoring, and reasoning before sending its output back to the MarketMind client. The frontend was built with React 19 and Next.js 16, using TypeScript, SVG physics-based visuals, and Chart.js for live candlestick charts. Yahoo Finance provided real-time data, while the app‚Äôs animation engine created the smooth pulsing and orbiting interactions that make the experience feel alive."},{"heading":"Challenges we ran into","content":"ESQL was powerful but strict, and small syntax differences broke queries. Aligning timestamps across datasets and keeping data fresh without overwhelming performance required multiple iterations. The hardest part was keeping every agent‚Äôs logic explainable while still running fast enough for real-time feedback."},{"heading":"Accomplishments that we're proud of","content":"We successfully integrated real trading analysis techniques inside a fully explainable multi-agent system. The Oracle Network computes Technical Analysis indicators such as RSI, Bollinger Bands, and MACD to assess short-term price momentum. The Arbitrage Hunter applies Fundamental Analysis metrics including P/E Ratio and Beta to detect valuation imbalances. The Volatility Prophet uses Portfolio Optimization with Risk-Adjusted Allocation concepts like Modern Portfolio Theory and the Black-Litterman Model to contextualize volatility regimes. Bringing all of these together in one live system that is both interpretable and reactive is a major achievement."},{"heading":"What we learned","content":"We learned that modularity and explainability are essential for both trust and performance. By designing each agent as an independent analytical node with clear responsibilities, we reduced complexity while improving interpretability. We also discovered how visual design can make complex market models not only accessible but intuitive, helping users ‚Äúsee‚Äù patterns they might otherwise miss."},{"heading":"What's next for MarketMind","content":"Our next goal is to use realtime data sources to injest into Elasticsearch. This will provide better data to the agents which will result in better responses. We also aim to implement a user chat interface. This user agent will communicate with the Elastic agents using the A2A protocol to provide a response."},{"heading":"Built With","content":"elasticagentbuilder elasticsearch lava next.js typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Rep","project_url":"https://devpost.com/software/rep-ja9oqw","tagline":"Practice sales calls with AI prospects. Get real-time coaching and detailed performance insights. Close more deals faster.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/934/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Vapi: Best Use of Vapi"}],"team_members":[],"built_with":[{"name":"chromadb","url":null},{"name":"claude","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"next.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"vapi","url":null}],"external_links":[],"description_sections":[{"heading":"The Inspiration","content":"Sales is one of the highest-paid professions, yet most sales reps get minimal practice before jumping on real calls with prospects. Athletes practice thousands of hours before game day‚Äîwhy shouldn't salespeople?\n\nWe were inspired by a simple realization: the best way to get better at sales is to practice, but practice partners are expensive, inconsistent, and hard to schedule. What if AI could be your perfect practice partner‚Äîavailable 24/7, infinitely patient, and able to simulate any buyer persona?\n\nThe idea crystallized when we saw the convergence of four technologies:\n\nClaude's advanced reasoning for realistic role-play ChromaDB + Claude for RAG system to retrieve product information in real time Real-time voice AI Agent with sub-500ms latency LLM-powered performance analysis\n\nWe realized we could build something that doesn't just record calls‚Äîit actively makes salespeople better ."},{"heading":"How We Built It","content":"Architecture Overview\n\nWe built a full-stack platform with three distinct AI pipeline stages:\n\nSetup ‚Üí Practice ‚Üí Analysis ‚Üì ‚Üì ‚Üì Claude Vapi (with ElevenLabs) Gemini\n\nFrontend Stack:\n\nNext.js 14 with React 18 for the web app Tailwind CSS + shadcn/ui for beautiful, responsive design Vapi Web SDK for crystal-clear voice conversations Zustand for lightweight state management\n\nBackend Stack:\n\nFastAPI (Python) for async API endpoints Supabase (PostgreSQL) for data persistence with RLS ChromaDB for RAG-based hint system Vapi for voice AI orchestration\n\nThe Three-Stage Pipeline\n\nStage 1: Scenario Generation (Claude)\n\nWhen users input their product details and target persona, we use Claude 4.5 Sonnet to generate hyper-realistic buyer scenarios:\n\nscenario = await claude.messages.create( model=\"claude-4-5-sonnet\", messages=[{ \"role\": \"user\", \"content\": f\"Generate realistic buyer persona for {product}...\" }] )\n\nThe AI creates:\n\nFull persona backstory (role, company, pain points) 3-5 realistic objections they'll raise Hidden information (budget, timeline, competitors) Personality traits and communication style and much more\n\nStage 2: Real-Time Conversation (Vapi + RAG)\n\nWe integrated Vapi to handle the entire voice pipeline:\n\nSpeech-to-text (Deepgram Nova-2) LLM orchestration (Claude as the buyer) Text-to-speech (ElevenLabs) Sub-500ms latency for natural dialogue\n\nRAG-Powered Hints: We built a hint system using ChromaDB that retrieves relevant sales information on the product the user is selling during the call:\n\nconst vapi = new Vapi(apiKey); vapi.start(assistantId); vapi.on('message', (message) => { if (message.type === 'transcript') { // Real-time transcript updates displayTranscript(message); } });\n\nStage 3: Performance Analysis (Gemini)\n\nAfter the call, we run comprehensive analysis:\n\nCore Analysis: Ge evaluates 7 skill categories (Discovery, Objection Handling, Rapport Building, etc.) with specific examples and timestamps.\n\n# Embed sales best practices vector_store = chromadb.PersistentClient(path=\"./chroma_data\") hints_collection = vector_store.get_or_create_collection(\"sales_hints\") # Retrieve context-aware hints results = collection.query( query_texts=[user_message], n_results=3 )\n\nThe system scores performance on a 0-100 scale per category:\n\n$$\\text{Overall Score} = \\frac{1}{7}\\sum_{i=1}^{7} S_i$$\n\nwhere $S_i$ represents each skill category score."},{"heading":"What We Learned","content":"Technical Breakthroughs\n\nVoice AI is Production-Ready : Vapi's infrastructure gave us sub-500ms latency without building complex audio pipelines. This was game-changing‚Äînatural conversation requires instant responses. LLMs as Actors : Claude is shockingly good at roleplay when given detailed personas. The key is in the prompt engineering‚Äîwe spent days iterating on the system prompt to make buyers feel authentic. RAG for Real-Time Coaching : Embedding sales best practices in ChromaDB and retrieving relevant hints during calls was more effective than we expected. The context-aware suggestions feel like having a sales coach in your ear. WebSocket State Management : Coordinating real-time transcript updates, audio streaming, and UI state required careful architecture. We learned to separate concerns and use React's concurrent features.\n\nProduct Insights\n\nFeedback Must Be Specific : Generic feedback like \"good job\" doesn't help. We had to timestamp exact moments and quote conversations to make insights actionable. Difficulty Calibration Is Hard : Making scenarios progressively harder while keeping them realistic required extensive prompt engineering and testing. Users Want Progress Tracking : The analytics dashboard became as important as the practice itself. Seeing improvement over time drives engagement."},{"heading":"Challenges We Faced","content":"Challenge 1: Audio Latency Battle\n\nProblem: Initial experiments with custom WebRTC + OpenAI Realtime API had 1-2 second delays, killing conversation flow.\n\nSolution: Switched to Vapi, which handles the entire audio pipeline with optimized edge infrastructure. Latency dropped to <500ms, making conversations feel natural.\n\nChallenge 2: Transcript Synchronization\n\nProblem: Real-time transcripts from Vapi arrived out-of-order, causing UI jumps and confusion.\n\nSolution: Implemented event sequencing with timestamps and a reconciliation algorithm:\n\ndef reconcile_transcript(events): sorted_events = sorted(events, key=lambda x: x['timestamp']) deduplicated = remove_duplicates(sorted_events) return merge_partial_transcripts(deduplicated)\n\nChallenge 3: Cost Optimization\n\nProblem: Running three Claude API calls per session (scenario, conversation, analysis) was expensive (~$2-3 per session).\n\nSolution:\n\nCaching common scenarios (reduced scenario costs by 70%) Using Claude Haiku for simple tasks Batching analysis requests Implementing strict session duration limits\n\nFinal cost: ~$1.00-1.85 per 15-min session\n\nChallenge 4: Feedback\n\nProblem: Initial analysis was too vague: \"You did well on discovery.\"\n\nSolution: Structured output with:\n\nTimestamped examples from transcript Specific quote + feedback pairs Side-by-side comparison of what was said vs. what could've been said Quantified metrics (talk time ratio, questions asked, objections handled)"},{"heading":"What's Next","content":"We're just getting started. Future plans include:\n\nMulti-persona calls (practice with buying committees) Voice cloning (practice with recordings of real buyers) Team features (manager dashboards, shared scenario libraries) CRM integration (import real prospect data) Mobile app (practice anywhere)"},{"heading":"The Big Lesson","content":"Building AI products is less about the models and more about the orchestration . The magic isn't in one API call‚Äîit's in chaining multiple AI services together with great UX to create something that feels seamless.\n\nRep proves that with the right architecture, AI can be more than a chatbot‚Äîit can be a coach, a practice partner, and a path to mastery."},{"heading":"Built With","content":"chromadb claude gemini next.js python vapi"}]},{"project_title":"Harmoniq","project_url":"https://devpost.com/software/harmoniq-06o1e9","tagline":"Regulatory intelligence for clinical trials.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/917/043/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Rox: Best Use of Rox"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Runner-Up"}],"team_members":[],"built_with":[{"name":"agents","url":null},{"name":"chroma","url":"https://devpost.com/software/built-with/chroma"},{"name":"llms","url":null},{"name":"nextjs","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"vercel","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/vardhanshorewala/harmoniq"}],"description_sections":[{"heading":"Inspiration","content":"The $960M Problem:\n\nWhen the FDA updates a regulation (like 21 CFR Part 11), pharmaceutical companies face a critical question: Which of our 50+ active clinical trials are now non-compliant?\n\nThe current process:\n\n130-160 days of manual review by regulatory affairs teams $6M revenue loss per day of trial delay Total cost: $780M-$960M per major regulatory change Error rate: ~15-20% of violations missed in manual review\n\nWe spoke with regulatory affairs teams at top pharma companies and clinical research students at Harvard Medical School, MIT, and Stanford ‚Äî all confirmed the same bottleneck: compliance checking is still done with PDFs, spreadsheets, and manual cross-referencing .\n\nHarmoniq automates this entire workflow in under 10 seconds."},{"heading":"What it does","content":"Harmoniq is an AI agent system that continuously monitors clinical trial protocols for regulatory compliance:\n\nCore Capabilities\n\nRegulation Ingestion Upload messy FDA/EMA PDFs (21 CFR Part 11, ICH-GCP E6(R2)) LLM agent extracts structured requirements from unstructured text Builds knowledge graph connecting related clauses Protocol Analysis Upload protocol document (PDF/Markdown) System splits into paragraphs and checks each against regulations Uses HippoRAG (NeurIPS 2024) for graph-enhanced retrieval Compliance Reports Paragraph-level violation detection Severity scoring (critical/high/medium/low) Missing elements identified Confidence scores for each finding\n\nExample Workflow\n\nInput: FDA 21 CFR Part 11 (Electronic Records) ‚Äî 45 pages PDF ‚Üí Agent extracts 25 requirements in ~30 seconds ‚Üí Builds 703-node knowledge graph with 876 edges ‚Üí Stores vector embeddings (384-dim) Query: \"Check protocol informed consent section\" ‚Üí Vector search finds 5 seed clauses ‚Üí Personalized PageRank propagates through graph ‚Üí Returns top-10 relevant regulations in <1 second ‚Üí LLM agent evaluates compliance for each clause ‚Üí Output: 2 critical violations, 3 warnings, 5 compliant"},{"heading":"How we built it","content":"System Architecture\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Regulation PDF ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Agent 1: Extract Requirements ‚îÇ ‚îÇ (Claude 3.5 Sonnet) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Agent 2: Find Relationships ‚îÇ ‚îÇ (Semantic + LLM reasoning) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ChromaDB ‚îÇ ‚îÇ NetworkX ‚îÇ ‚îÇ Vectors ‚îÇ ‚îÇ Graph ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ HippoRAG Retrieval‚îÇ ‚îÇ (Vector + Graph) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Agent 3: Check Compliance ‚îÇ ‚îÇ (Claude 3.5 Sonnet) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Compliance JSON‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nTech Stack\n\nBackend (Python FastAPI)\n\nFastAPI ‚Äî Async API framework Pydantic ‚Äî Type-safe data validation ChromaDB ‚Äî Vector database (persistent storage) NetworkX ‚Äî Graph operations + Personalized PageRank sentence-transformers ‚Äî Local embedding model (all-MiniLM-L6-v2) pypdf ‚Äî PDF text extraction httpx ‚Äî Async HTTP client for LLM APIs\n\nLLM Infrastructure\n\nModel: Anthropic Claude 3.5 Sonnet ( claude-3-5-sonnet-20241022 ) Provider: Direct Anthropic API / Lava Payments proxy Prompts: Custom system prompts for extraction, relationship detection, and compliance reasoning\n\nFrontend (Next.js + TypeScript)\n\nNext.js 14 ‚Äî React framework with App Router TypeScript ‚Äî Type safety Tailwind CSS ‚Äî Styling shadcn/ui ‚Äî Component library React Flow ‚Äî Interactive knowledge graph visualization\n\nDeployment\n\nBackend: Python 3.11, Poetry dependency management Frontend: Vercel Database: Local ChromaDB (portable to cloud)\n\nKnowledge Graph Structure\n\nWe construct a multi-edge knowledge graph where nodes are regulatory requirements and edges represent relationships:\n\n3 Edge Types:\n\nNEARBY (weight = 1.0) Sequential connections (e.g., REQ-001 ‚Üí REQ-002) Captures document flow and context SIMILAR_TO (weight = cosine similarity) Vector embedding similarity > 0.75 Finds semantically related clauses RELATED_TO (weight = LLM confidence) LLM-detected logical relationships Example: \"validation required\" ‚Üí \"audit trails required\"\n\nGraph Statistics (21 CFR Part 11):\n\nNodes: 703 requirement clauses Edges: 876 total (30% LLM, 50% similarity, 20% sequential) Average degree: 2.5 connections per node\n\nHippoRAG Retrieval Algorithm\n\nTraditional RAG uses only vector similarity. HippoRAG adds graph traversal:\n\nStandard RAG: [ \\text{Results} = \\text{TopK}(\\text{cosine}(\\vec{q}, \\vec{d}_i)) ]\n\nHippoRAG: [ \\text{Seeds} = \\text{TopK}(\\text{cosine}(\\vec{q}, \\vec{d} i)) \\quad (k=5) ] [ \\text{PPR} \\text{seeds}(v) = \\text{PageRank}(G, \\text{personalization}=\\text{Seeds}) ] [ \\text{Results} = \\text{TopK}(\\text{PPR scores}) ]\n\nWhy this works:\n\nVector search finds direct matches (\"validation\") Graph propagation finds related concepts (\"audit trails\", \"documentation\") Result: 40% more relevant clauses retrieved vs. pure vector search"},{"heading":"Challenges we ran into","content":"1. Messy PDF Extraction\n\nFDA PDFs have inconsistent formatting (tables, multi-column, footnotes) Solution: pypdf + custom paragraph detection heuristics\n\n2. LLM Hallucination in Requirement Extraction\n\nEarly versions \"invented\" requirements not in source documents Solution: Strict JSON schema validation + confidence thresholds\n\n3. False Positive Explosion\n\nInitial compliance agent flagged 80%+ violations (too strict) Solution: Added lenient prompt engineering with explicit \"assume compliant unless obviously wrong\" instructions\n\n4. Graph Construction Speed\n\nComputing all pairwise similarities for 700 nodes = 245K comparisons Solution: Sparse similarity matrix (only store > 0.75 threshold)\n\n5. Real-time Performance\n\nFull compliance check on 50-page protocol took 2+ minutes Solution: Parallel LLM calls (15 paragraphs checked simultaneously)"},{"heading":"Accomplishments that we're proud of","content":"‚úÖ Extracted 703 structured requirements from a 45-page messy FDA PDF using pure LLM agents ‚úÖ Built a working knowledge graph with 876 edges (validated against expert annotations) ‚úÖ Implemented HippoRAG (NeurIPS 2024) ‚Äî one of the first production deployments ‚úÖ Achieved <1 second query latency for graph-enhanced retrieval ‚úÖ Created an interactive graph visualization showing regulation relationships in real-time ‚úÖ Validated with domain experts ‚Äî students from Harvard Medical School, MIT, and Stanford confirmed clinical relevance"},{"heading":"What we learned","content":"Technical Insights\n\nLLMs are exceptional at structure extraction ‚Äî Claude 3.5 can reliably parse messy regulatory text into JSON with 95%+ accuracy Graphs >> Pure Vector Search ‚Äî HippoRAG retrieved 40% more relevant clauses by following semantic relationships Prompt engineering is everything ‚Äî Our compliance agent went from 80% false positives to <10% by adding \"lenient\" instructions Domain embeddings aren't always necessary ‚Äî all-MiniLM-L6-v2 (general-purpose) performed surprisingly well on regulatory text\n\nDomain Insights\n\nRegulatory compliance is a graph problem ‚Äî Regulations reference each other constantly (\"see Part 11\", \"as defined in ¬ß312\") Pharma teams trust explainability ‚Äî Every violation needs a citation back to source regulation (we provide clause IDs) The real bottleneck is cross-referencing ‚Äî Manual review isn't slow because of reading, it's slow because of looking up related clauses"},{"heading":"What's next for Harmoniq","content":"Immediate Roadmap (3 months)\n\n[ ] Multi-jurisdiction support ‚Äî Add EMA, PMDA, TGA regulations [ ] Real-time regulation monitoring ‚Äî Auto-detect FDA guideline updates via web scraping [ ] Confidence calibration ‚Äî Fine-tune violation probability scores against labeled dataset [ ] Batch processing ‚Äî Upload 50 protocols at once for portfolio-wide compliance\n\nLong-term Vision (12 months)\n\n[ ] Automated amendment generation ‚Äî LLM agent proposes protocol changes to fix violations [ ] Regulatory change impact analysis ‚Äî \"FDA just updated 21 CFR 11 ‚Üí 12 of your trials are affected\" [ ] CRO/Sponsor integrations ‚Äî API + SDK for Veeva Vault, Medidata Rave, Oracle Siebel CTMS [ ] Human-in-the-loop audit ‚Äî Export compliance reports to regulatory affairs teams for review\n\nExpansion Opportunities\n\nMedical devices ‚Äî FDA 21 CFR Part 820 (QSR), ISO 13485 Drug manufacturing ‚Äî FDA 21 CFR Part 211 (cGMP) Preclinical research ‚Äî GLP compliance (FDA 21 CFR Part 58)"},{"heading":"Impact Potential","content":"For Pharmaceutical Companies\n\nCurrent State:\n\n130-160 days manual compliance review $780M-$960M cost per regulatory change 15-20% error rate\n\nWith Harmoniq:\n\n<1 day automated compliance audit $950M saved per regulatory change <5% error rate (validated against expert review)\n\nFor the Industry\n\nFaster drug approvals ‚Üí Patients get treatments sooner Reduced regulatory risk ‚Üí Fewer trial halts due to compliance issues Knowledge democratization ‚Üí Smaller biotech companies can compete with big pharma"},{"heading":"Try it out","content":"GitHub: Github link Demo: Website link Video: YouTube link\n\nTest with sample data:\n\n# Backend cd backend-fastapi poetry install poetry run uvicorn app.main:app --reload # Frontend cd harmoniq-frontend npm install npm run dev"},{"heading":"Built With","content":"Python ¬∑ FastAPI ¬∑ Next.js ¬∑ TypeScript ¬∑ Tailwind CSS ¬∑ Anthropic Claude ¬∑ ChromaDB ¬∑ NetworkX ¬∑ LangChain ¬∑ HippoRAG ¬∑ React Flow ¬∑ Vercel"},{"heading":"Team","content":"We're a team of engineers and researchers passionate about applying AI to high-stakes, real-world problems. Special thanks to the regulatory affairs professionals and clinical research students who validated our approach.\n\nHarmoniq ‚Äî Bringing harmony to clinical trial compliance, one regulation at a time."},{"heading":"Built With","content":"agents chroma llms nextjs python vercel"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"SuiTix","project_url":"https://devpost.com/software/suitix","tagline":"Sui-powered blockchain-based ticketing and loyalty platform with policy-enforced, fraud-proof resale via Kiosk; buy in one click, resell fairly, and earn perks from purchase to check-in.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/899/524/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Sui: Best Use of Sui"}],"team_members":[],"built_with":[{"name":"blockchain","url":"https://devpost.com/software/built-with/blockchain"},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"next.js","url":null},{"name":"nft","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sui","url":null},{"name":"sui-kiosk","url":null},{"name":"sui-move","url":null},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/RohanChintakindi/sui-tix"},{"label":"drive.google.com","url":"https://drive.google.com/file/d/1bEc5Nz9eCxpKmzFR9lEv-mVdrdfdCW9_/view?usp=sharing"}],"description_sections":[{"heading":"Built With","content":"blockchain github next.js nft react sui sui-kiosk sui-move tailwind typescript"},{"heading":"Try it out","content":"github.com drive.google.com"}]},{"project_title":"DIAL(*)","project_url":"https://devpost.com/software/dial-4rqzc3","tagline":"How we booked an SF Luxury Hotel for $158","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/899/639/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Rox: Best Use of Rox"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Conversion: Best Use of Conversion"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Crater: Play-Do Prize"}],"team_members":[],"built_with":[{"name":"duckdb","url":null},{"name":"elevenlabs","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"ngrok","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"sql","url":"https://devpost.com/software/built-with/sql"},{"name":"twilio","url":"https://devpost.com/software/built-with/twilio"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"We were stranded in San Francisco on Saturday night without housing, and decided to let a fleet of AI agents find us a room. What started as a quick experiment turned into a full-stack system for autonomous negotiation, data-driven decision making, and natural communication."},{"heading":"What it does","content":"DIAL (*) is an optimized customer service agent designed for data-heavy use cases. It makes phone calls, speaks naturally, queries live databases, and learns from every conversation to improve future performance."},{"heading":"How we built it","content":"Customer Service Agent Functionality\n\nPhone Call Capability ‚Äì Twilio Custom Voice + State Machine ‚Äì ElevenLabs API Gateway ‚Äì ngrok (for Express/TypeScript backend) Backend Logic ‚Äì Express server managing call flow and SQL queries\n\nSQL Optimizations\n\nCreated specialized query plans tailored for repetitive agent tasks Cached common lookups and indexed query-heavy tables for >100√ó faster response times"},{"heading":"Challenges we ran into","content":"Building a robust state machine that avoided hallucinations while staying conversational was hard. Integrating ElevenLabs‚Äô voice with live Twilio calls also required solving real-time latency issues."},{"heading":"Accomplishments that we're proud of","content":"Our agent called over 100 hotels and got real human responses from 40+ of them. It negotiated room prices down to $158 + tax ‚Äî and landed us a bed for the night. Our SQL optimizations cut decision latency from seconds to milliseconds."},{"heading":"What we learned","content":"We learned how to merge LLM-style intelligence with deterministic systems. We also saw firsthand how structured databases and state machines can ground AI behavior, creating a system that‚Äôs both smart and reliable."},{"heading":"What's next for DIAL (*)","content":"We plan to scale DIAL into a general-purpose customer service infrastructure ‚Äî allowing businesses to plug in their own data and voice models for seamless, human-like service automation."},{"heading":"Built With","content":"duckdb elevenlabs express.js ngrok node.js sql twilio"}]},{"project_title":"Shard","project_url":"https://devpost.com/software/shard-2kvsch","tagline":"Do you have a laptop? You're potentially losing on making at least $10/day side income with Shard. Introducing Shard to make use of unutilized resources from 1.5 billion devices globally.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/890/333/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Sui: Best Use of Sui"}],"team_members":[],"built_with":[{"name":"swift","url":"https://devpost.com/software/built-with/swift"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"shard-alpha.vercel.app","url":"http://shard-alpha.vercel.app/"},{"label":"github.com","url":"https://github.com/atharvalade/Shard"}],"description_sections":[{"heading":"For Job Submitters (via Web Interface)","content":"Submit Computational Tasks : Upload a CSV file with 100 sentences for AI content moderation or provide parameters for Monte Carlo simulations Automatic Fragmentation : The system breaks your job into tiny independent fragments (1 sentence per fragment) Privacy-First Encryption : Each fragment is encrypted using Sui Seal threshold encryption Decentralized Storage : Encrypted data is stored on Sui Walrus (decentralized blob storage) On-Chain Job Posting : The job and all fragments are published to the Sui blockchain with USDC bounties (0.01 USDC per fragment) Real-Time Progress : Watch as workers around the world claim and process your fragments Automatic Result Aggregation : Get your completed results delivered in the original order"},{"heading":"For Computing Providers (via macOS App)","content":"Beautiful System Monitor : Track CPU, GPU, and memory usage in a Robinhood-like interface One-Click Worker : Click \"Start Worker\" to begin earning USDC AI-Powered Chat : Built-in Gemma 3-4B chatbot for local AI assistance Auto-Discovery : The app polls the blockchain for available work Secure Processing : Downloads encrypted fragments, decrypts locally using Seal Local AI Inference : Runs Gemma AI model to classify content (safe/unsafe) Upload Results : Encrypts and uploads results to Walrus, submits completion on-chain Instant Payment : Receives 0.01 USDC per completed fragment (sponsored transaction‚Äîzero gas fees) Multi-Worker Support : Spawn multiple worker windows to process tasks in parallel"},{"heading":"Key Features","content":"Zero Gas Fees for Workers : All transactions are sponsored by job creators Privacy-Preserving : Workers never see raw sensitive data‚Äîonly encrypted fragments Fault-Tolerant : Uncompleted fragments are automatically re-queued Native Performance : Leverages Apple Silicon's Metal acceleration for AI inference Real-Time Transparency : Both submitters and workers see live progress updates\n\nüèóÔ∏è How I Built It\n\nI built Shard solo over 15 hours during the hackathon, integrating cutting-edge blockchain technologies with native macOS development."},{"heading":"Tech Stack","content":"Frontend (Next.js 14 + React + TypeScript)\n\nUI Framework : shadcn/ui components with Tailwind CSS for a minimalist, dark-mode-first design Animations : Framer Motion for smooth transitions and progress indicators Real-Time Updates : Polling-based live fragment status tracking Features : Job submission portal, AI inference configuration, Monte Carlo simulation setup\n\nBackend (Node.js + Express + TypeScript)\n\nAPI Server : RESTful endpoints for job management, fragment lifecycle, and wallet queries Sui Integration : @mysten/sui SDK for blockchain interactions and USDC transfers Walrus Client : Custom implementation for uploading/downloading encrypted blobs Seal Encryption : @mysten/seal SDK for threshold encryption with session keys Job Orchestration : Automatic fragmentation, encryption, and on-chain publishing\n\nmacOS App (SwiftUI + Combine)\n\nSystem Monitoring : Real-time CPU/GPU/Memory tracking using IOKit and Mach APIs AI Integration : Embedded llama.cpp server running Gemma 3-4B-it-q4_0.gguf model Metal Acceleration : Native Apple Silicon GPU support for AI inference Worker Engine : Multi-threaded fragment discovery, claiming, processing, and completion Multi-Window Architecture : Spawn independent worker windows for parallel processing Live Dashboard : Beautiful glassmorphic UI with animated charts (inspired by Apple's design language)\n\nBlockchain (Sui + Move)\n\nSui Network : Testnet deployment for job and fragment state management Smart Contracts : Move modules for access control policies (Seal) Walrus Storage : Decentralized blob storage with erasure coding Seal Encryption : Threshold encryption with programmable access control Sponsored Transactions : Job creators pay all gas fees for workers"},{"heading":"Development Highlights","content":"1. Micro-Task Fragment Protocol\n\nI designed a novel fragmentation system where each sentence becomes an independent TaskFragment with:\n\nUnique fragment ID and job ID Encrypted data blob stored on Walrus USDC bounty (0.01 per fragment) Status lifecycle: pending ‚Üí claimed ‚Üí completed\n\n2. Sui Seal Integration\n\nI implemented end-to-end encryption using Seal's threshold encryption:\n\nGenerated session keys with TTL for time-limited access Created Move access policy contracts ( seal_approve ) Encrypted fragments using AES256GCM Workers decrypt using session keys without exposing raw data\n\n3. llama.cpp Embedding\n\nI bundled the Gemma AI model and llama-server binary directly into the macOS app:\n\nBuilt static llama-server to avoid dynamic library issues Spawned server as subprocess with Metal GPU acceleration Implemented streaming HTTP client for real-time inference Created beautiful chat UI with gradient avatars and suggestion chips\n\n4. Multi-Worker Architecture\n\nI built a sophisticated worker management system:\n\n@Environment(\\.openWindow) for spawning new worker windows Shared WorkerService instances with independent worker IDs Competitive claiming (first worker to claim gets the fragment) Real-time USDC balance tracking across all workers\n\n5. Production Deployment\n\nFrontend : Deployed to Vercel ( https://shard-alpha.vercel.app ) Backend : Deployed to Vercel with Cloudflare Tunnel for local testing CORS : Dynamic subdomain support for *.trycloudflare.com Config Management : Centralized API URLs for easy environment switching\n\nüéì What I Learned"},{"heading":"Blockchain & Cryptography","content":"Sui Blockchain : I dove deep into the Sui ecosystem, learning about Move smart contracts, sponsored transactions, and how to structure on-chain state for a compute marketplace. Sui Walrus : I implemented decentralized storage for both job inputs and results, learning how erasure coding provides redundancy without centralized servers. Sui Seal : I mastered threshold encryption and programmable access control, enabling workers to decrypt job data without ever exposing it to centralized parties. BCS Encoding : I learned about Sui's Binary Canonical Serialization for efficient data encoding."},{"heading":"Native macOS Development","content":"I built a production-grade SwiftUI application with real-time system monitoring (CPU, GPU, Memory). I integrated llama.cpp and Gemma 3-4B for local AI inference using Apple Silicon's Metal acceleration. I learned advanced Swift concepts: Combine framework, @Published properties, URLSession streaming, and multi-window architecture. I mastered IOKit for low-level hardware metrics and Mach APIs for system-level monitoring."},{"heading":"Distributed Systems Design","content":"I implemented a micro-task fragment protocol where jobs are broken into independent units that can be processed in parallel. I designed fault-tolerant execution with fragment re-queuing if workers go offline. I built a polling-based worker discovery system that scales to multiple simultaneous workers. I learned about eventual consistency and how to handle race conditions in distributed claiming."},{"heading":"Full-Stack Integration","content":"I connected React/Next.js frontend ‚Üí Express.js backend ‚Üí Sui blockchain ‚Üí macOS worker app in a seamless end-to-end flow. I implemented real-time progress tracking with polling-based live fragment status updates. I managed CORS, API design, environment configuration, and production deployment. I debugged complex multi-component issues (e.g., USDC transfers, fragment completion, UI state synchronization)."},{"heading":"Performance Optimization","content":"I optimized SwiftUI rendering by removing continuous animations and using .drawingGroup() for Metal acceleration. I reduced CPU usage from 50% to <5% by simplifying chart rendering and using efficient update intervals. I implemented smart batching for blockchain queries to minimize network overhead.\n\nüöÄ What's Next for Shard"},{"heading":"Short-Term (Next 3 Months)","content":"Mainnet Launch : Deploy to Sui mainnet with real USDC incentives More Task Types : Support image processing, video transcoding, and scientific simulations Advanced Reputation System : Track worker reliability and completion rates with on-chain NFTs Mobile Support : Build iOS/Android worker apps to expand the provider network Job Verification : Implement cryptographic proofs of correct computation"},{"heading":"Long-Term Vision","content":"Cross-Chain Support : Integrate with Ethereum, Solana, and other L1s for broader adoption Specialized Hardware : Support GPU-intensive tasks (3D rendering, AI training) with CUDA/ROCm Enterprise Partnerships : Offer B2B solutions for companies needing distributed compute DAO Governance : Community-driven protocol upgrades and fee structures Carbon Credits : Reward providers for using renewable energy sources"},{"heading":"Technical Improvements","content":"WebSocket Real-Time Updates : Replace polling with push notifications for instant updates Smart Contract Upgrades : On-chain fragment verification and slashing for malicious workers Result Validation : Implement consensus mechanisms (multiple workers verify the same fragment) Benchmarking System : Automatically test worker capabilities and assign appropriate tasks Dynamic Pricing : Market-driven bounty pricing based on task complexity and demand\n\nüéØ Conclusion\n\nShard demonstrates that it's possible to build a fully functional decentralized compute network in a single weekend. By leveraging Sui's innovative blockchain architecture, Walrus's decentralized storage, and Seal's privacy-preserving encryption, I created a platform that turns idle Macs into a global supercomputer‚Äîwhile ensuring privacy, fault tolerance, and instant micropayments.\n\nThis is just the beginning. The future of computing is decentralized, and Shard is proof that we can build it today."},{"heading":"Built With","content":"swift typescript"},{"heading":"Try it out","content":"shard-alpha.vercel.app github.com"}]},{"project_title":"Otter","project_url":"https://devpost.com/software/otter","tagline":"Decentralizing how humans communicate using SUI","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/903/749/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Sui: Best Use of Sui"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"dapp","url":null},{"name":"fetch.ai","url":null},{"name":"lucide","url":null},{"name":"move","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"radix","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"smart-contracts","url":null},{"name":"sui","url":null},{"name":"supabase","url":null},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null},{"name":"vue","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/haotianli24/sui-otter/"},{"label":"sui-otter.vercel.app","url":"https://sui-otter.vercel.app/"}],"description_sections":[{"heading":"Inspiration","content":"The Web3 ecosystem is powerful but fragmented. Traders use one platform, communities gather on another (like Discord or Telegram), and blockchain insights require a third tool. We were inspired to create a single, comprehensive platform that unifies these critical functions. Our goal was to build a \"super-app\" on the Sui blockchain where users can trade, communicate securely, govern communities, and gain AI-powered insights, all in one place."},{"heading":"What it does","content":"Otter is a comprehensive decentralized platform on Sui that combines intelligent trading, community building, and AI insights.\n\nCopy Trading : Allows users to follow and automatically replicate the trading strategies of expert traders with customizable risk settings. Community DAOs : Enables the creation and management of token-gated communities (DAOs) with built-in governance and member management. AI Agents : Integrates Fetch.ai and Google GenAI, allowing users to query in natural language for trading insights, community recommendations, and real-time blockchain guidance. Secure Messaging : Features end-to-end encrypted messaging for private communication between users and within communities, built on the Sui Messaging protocol. Real-Time Activity Stream : A live feed of on-chain activities, including swaps, NFT mints, transfers, and smart contract calls, allowing users to monitor the pulse of the network."},{"heading":"How we built it","content":"We built Otter using a modern, comprehensive tech stack to handle the demands of a real-time, decentralized application.\n\nBlockchain: We used the Sui blockchain , leveraging the Sui SDK , Sui dApp Kit for wallet connections, and native protocols like Sui Messaging and Sui Walrus (decentralized storage). Our smart contracts for copy trading and DAOs are written in Move . Frontend: A responsive UI built with React 18 and TypeScript , styled with Tailwind CSS , and routed with React Router . AI & Data: We integrated Fetch.ai for autonomous AI agents and Google GenAI for LLM-powered chat. React Query was crucial for managing server state and caching blockchain data. Backend & Database: A Node.js/Express.js API server handles off-chain logic, with Supabase (PostgreSQL) used for user profiles, community metadata, and data aggregation."},{"heading":"Challenges we ran into","content":"Real-time Data: Building the activity stream was a major challenge. We had to implement efficient polling ( useTransactionPolling ) and data aggregation to provide a live feed of on-chain transactions without overwhelming the frontend or our API. Complex State Management: Juggling blockchain state (wallet connections, contract data), server state (Supabase data), and local UI state was complex. React Query was essential in managing this. ZKLogin & Sponsored Transaction: Trying to use Enoki for ZKlogin and to sponsor transactions on our app for a seamless user experience had a larger learning curve than expected especially when dealing with oauth providers like Google and .build functions. Secure Messaging: Implementing end-to-end encryption with session key management using the new Sui Messaging protocol required a deep dive into its documentation to ensure a secure, seamless user experience. Document transfer on chain: Utilizing Walrus to employ file uploads such as images, videos, and other documents with the messaging SDK was rather difficult and required understanding of the Walrus docs."},{"heading":"Accomplishments that we're proud of","content":"A Unified Platform: We are incredibly proud of successfully integrating five distinct, complex features (copy trading, DAOs, AI chat, messaging, and a real-time stream) into a single, cohesive application. The AI Agent: The Otter AI Chat, powered by Fetch.ai and Google GenAI, is a standout feature. It can understand natural language queries and provide genuinely helpful trading strategies and ecosystem guidance. On-Chain + Off-Chain Synergy: We created a robust architecture that skillfully balances on-chain smart contracts (for trust-minimized trading and governance) with an efficient off-chain backend (for data aggregation and user experience), all powered by Supabase. Polished UX: Despite the underlying complexity, we delivered a clean, responsive, and accessible UI with features like dark mode and a mobile-first design, thanks to Tailwind and Radix UI."},{"heading":"What we learned","content":"Deep Dive into Sui: This project was a massive learning experience in the Sui ecosystem. We gained deep, hands-on expertise with the Sui SDK, the dApp Kit, and especially the newer protocols like Sui Messaging and Walrus. Practical AI Application: We learned how to move beyond simple AI chat prompts and integrate LLMs (Google GenAI) and autonomous agents (Fetch.ai) to perform complex, data-driven tasks related to blockchain activity. Real-Time Data Architectures: We learned the challenges and best practices for handling real-time data feeds from a blockchain, using a combination of smart contract events, API polling, and frontend state management with React Query."},{"heading":"What's next for Otter","content":"Mainnet Deployment: Our immediate next step is to complete audits on our smart contracts and deploy Otter to the Sui mainnet. Expanded AI Capabilities: We plan to enhance our AI agents to allow for autonomous actions, such as executing trades based on user-defined strategies or providing proactive alerts. Mobile App: To truly be a \"super-app,\" we aim to develop native mobile applications for iOS and Android. Advanced DAO Tooling: We want to add more sophisticated governance modules, such as treasury management and integration with other DeFi protocols, for our community DAOs."},{"heading":"Built With","content":"css dapp fetch.ai lucide move node.js postgresql radix react smart-contracts sui supabase tailwind typescript vite vue"},{"heading":"Try it out","content":"github.com sui-otter.vercel.app"}]},{"project_title":"Human Capital","project_url":"https://devpost.com/software/human-capital","tagline":"Time is money: literally. Sell your day away in 15-minute blocks. Highest bidder controls you, watches you, directs you. Blockchain auctions meet dystopian labor. Your time. Their terms.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/900/006/datas/medium.jpeg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Sui: Best Use of Sui"}],"team_members":[],"built_with":[{"name":"ai","url":null},{"name":"chromadb","url":null},{"name":"claude","url":null},{"name":"livekit","url":null},{"name":"next.js","url":null},{"name":"sui","url":null}],"external_links":[{"label":"hcapital.tech","url":"http://hcapital.tech"}],"description_sections":[{"heading":"Inspiration","content":"\"Time is money\" is something we hear constantly‚Äîbut what if we took it literally? We wanted to create a Black Mirror-style commentary on the gig economy, surveillance capitalism, and the commodification of human labor. The inspiration came from thinking: if your time really is money, shouldn't there be a marketplace for it? The result is intentionally dystopian, a parody that makes you uncomfortable while showcasing what's technically possible when you combine blockchain, real-time streaming, and AI surveillance."},{"heading":"What it does","content":"Human Capital is a platform where you sell your time in 15-minute chunks via blockchain auction:\n\nUsers broadcast themselves live and put their time up for auction Bidders place bids on time slots using Sui blockchain NFT auctions Winners gain complete control of the user's body for 15 minutes: Send commands via chat that appear as overlay instructions Watch via LiveKit real-time stream Direct the user to do whatever they want AI monitors everything - a vision-language model captures frames, analyzes compliance, and stores summaries Search your history - semantic search lets anyone query past activities (\"Are they good at coding?\" \"Did they complete tasks?\")\n\nIt's surveillance capitalism meets gig economy meets blockchain, turned up to 11."},{"heading":"How we built it","content":"Frontend: Next.js 16 + React 19 + TypeScript + Tailwind CSS v4\n\nReal-time Infrastructure:\n\nLiveKit for low-latency video streaming and bidirectional communication Custom room architecture with hidden bot participants for AI monitoring\n\nBlockchain:\n\nSui Network with custom Move smart contracts for time slot NFT auctions @mysten/dapp-kit for wallet integration On-chain bid validation and winner selection Fully decentralized, trustless architecture\n\nAI Pipeline:\n\nOpenAI GPT-4o (via OpenRouter) for real-time vision analysis Anthropic Claude for natural language processing and historical analysis ChromaDB Cloud vector database for storing activity summaries OpenAI embeddings (text-embedding-3-small) for semantic search Multi-stage processing: frame capture ‚Üí batch summaries ‚Üí chunk summaries ‚Üí vector storage Off-chain oracle implementation for compliance scoring\n\nData Flow: VLM bot joins stream ‚Üí captures frames every 5s ‚Üí analyzes with GPT-4o ‚Üí batches summaries ‚Üí stores in ChromaDB ‚Üí enables natural language search of user history\n\nThis is a data-intensive application ‚Äîthe system processed 7.52 GB/s of bandwidth at peak time during testing."},{"heading":"Challenges we ran into","content":"Decentralization vs. AI control - Our biggest challenge was maintaining true decentralization. Initially, we wanted to put funds in escrow controlled by an AI oracle on-chain, but we realized that put too much power into the hands of the AI oracle and, more importantly, the people who controlled it. We decided to build a fully decentralized, entirely trustless system by moving the oracle off-chain and implementing it as more of a credit score mechanism. VLM frame capture at scale - Processing hundreds of frames per hour with GPT-4o vision was expensive and required careful batching strategies to stay within token limits LiveKit bot architecture - Getting a headless bot participant to join rooms, capture video frames reliably, and stay hidden from the UI took significant debugging Sui Move smart contracts - Learning Move's ownership model and implementing auction logic with proper time-based finalization was complex Real-time state synchronization - Keeping blockchain auction state, LiveKit room state, and UI state in sync across multiple users required careful React Query caching Semantic search quality - Tuning the ChromaDB collection and prompt engineering to return actually useful historical insights took iteration"},{"heading":"Accomplishments that we're proud of","content":"Fully trustless, decentralized architecture - no central authority controls funds or outcomes It actually works end-to-end - blockchain auctions ‚Üí live streaming ‚Üí AI surveillance ‚Üí searchable history Multi-stage VLM pipeline that intelligently batches and summarizes to manage API costs Custom Sui Move contracts deployed and functioning on testnet Semantic search that genuinely understands natural language queries about user history Real-time winner control with command overlays and task compliance tracking The aesthetic - we committed fully to the dystopian bit and the UI reflects it Scale testing - we actually ran this for 6 hours and processed real production data"},{"heading":"What we learned","content":"Decentralization has real trade-offs - putting AI oracles on-chain creates centralization risks we hadn't initially considered Vision-language models are powerful but expensive - real-time video analysis at scale requires careful architecture Sui's Move language has a steep learning curve but elegant ownership semantics LiveKit is incredibly robust for real-time streaming when properly configured Vector databases like ChromaDB make semantic search surprisingly easy once you get embeddings right Hackathon projects can be satire AND technically impressive - the parody angle made it more interesting to build Data-intensive applications hit different - 7.52 GB/s hours taught us to respect bandwidth costs"},{"heading":"What's next for Human Capital","content":"Compliance scoring - aggregate AI analysis into reputation scores for users Task marketplace - let bidders post tasks in advance with bounties Multi-user mode - control multiple people simultaneously Mobile app - stream your human capital on the go Analytics dashboard - charts and graphs of your commodification Mainnet deployment - take this dystopia to production (kidding... mostly) Privacy mode - blur faces/sensitive info while maintaining surveillance (ironic, we know) Refined oracle mechanisms - explore hybrid on-chain/off-chain solutions for compliance verification"},{"heading":"Built With","content":"ai chromadb claude livekit next.js sui"},{"heading":"Try it out","content":"hcapital.tech"}]},{"project_title":"merj","project_url":"https://devpost.com/software/merj","tagline":"Merj is your AI-powered merge copilot. It reviews both branches, understands intent with CodeRabbit, and uses Claude to suggest secure conflict resolutions automatically. One command. Zero headaches.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/889/870/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"CodeRabbit: Best Use of CodeRabbit AI"}],"team_members":[],"built_with":[{"name":"bash","url":"https://devpost.com/software/built-with/bash"},{"name":"chromadb","url":null},{"name":"claude","url":null},{"name":"coderabbit","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"voyageai","url":null}],"external_links":[],"description_sections":[{"heading":"What it does## Inspiration","content":"Every developer knows that sinking feeling when a git pull command results in a merge conflict. The resulting scramble to pursue multiple lines of code is tedious and severely detrimental to the development process."},{"heading":"What it does","content":"What if you never had to worry about merge conflicts again? That is why we built merj, a robust command-line tool that harnesses the power of modern Artificial Intelligence to streamline this process for developers. When a developer runs a pull command from their terminal, our software automatically scans for potential merge conflicts. It uses codebase context to resolve them effectively while preserving the goals of both branches."},{"heading":"How we built it","content":"merj is a tool we built on top of Git to minimize the learning curve for developers using our software. At a high level, merj has two states immediately after being called: a clean state and a conflict state. When the state is clean, our merj pull command behaves like git pull and updates the codebase; however, if our git pull results in a merge conflict, we immediately start our troubleshooting logic. The first thing we do is take a diff between the remote node and the last common ancestor node of the divergent nodes, and a diff between the local node and the same last common ancestor node. We then run a Retrieval Augmented Generation pipeline using the voyageai API to embed text, and ChromaDB to store vector embeddings, to retrieve code chunks from our codebase that are most relevant to the merge conflict, providing context for future LLM calls. After we get the code context, we use CodeRabbit‚Äôs powerful agent to summarize the changes between each divergent node and its common ancestor, providing semantic context alongside our code context. Finally, we combine all this context with the current merge conflict in Claude 3.5 Sonnet to perform our final resolution."},{"heading":"Challenges we ran into","content":"System design Integration LLM Formatting\n\nOne of the key challenges that we spent a lot of time working on was designing the entire end-to-end system. This was the first time any member of our team had created a command-line interface tool or built something related to version control, so we had to gain a deep understanding of the inner workings of merge conflicts to develop an effective plan. Another major problem we ran into was integrating all our components. Our program consists of many different elements, such as version control, Retrieval Augmented Generation, CodeRabbit‚Äôs API, and LLM calling, which made it very hard to integrate into a single end-to-end pipeline. Lastly, we spent time optimizing the format of our LLM prompt to get the desired output for our clients."},{"heading":"Accomplishments that we're proud of","content":"The main accomplishment we are proud of is our ability to integrate many different software components, with which we have minimal experience, into a single, cohesive software application that solves a practical problem many developers have faced. We were also really excited to learn about CodeRabbit and integrate their powerful ability to semantically synthesize information in git histories to enhance the quality of our final product response."},{"heading":"What we learned","content":"Throughout the hackathon, our team learned practical skills in version control, Retrieval Augmented Generation, and command-line interfaces. We were very excited to explore many new tools in the software space and to persevere through the learning curves to deliver a high-quality final product."},{"heading":"What's next for merj","content":"The future of merj falls into two different buckets. The first bucket focuses on scaling merj to work for many people across many different repositories and large codebases while reducing command latency. The second bucket of merj is potentially integrating a live component into the git mechanism. This will work as follows: One person will push their code, and every other member of the project will receive an update that someone has pushed code, allowing them to automatically merge the new commit into their current working directory with just a click of the button."},{"heading":"Built With","content":"bash chromadb claude coderabbit javascript python voyageai"}]},{"project_title":"Movement","project_url":"https://devpost.com/software/movement-f4nyob","tagline":"Movement is the disruptive blockchain crowdfunding platform - no fees, no middlemen. Every contribution is direct, transparent, and secure, giving real-world peace of mind to backers and creators.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/898/834/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Sui: Best Use of Sui"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"move","url":null},{"name":"next.js","url":null},{"name":"sui","url":null},{"name":"tailwind","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"We all have dreams. But sometimes, we need a little help to realize lofty aspirations. That‚Äôs why crowdfunding exists, leveraging the power of community to make big goals a reality, and blockchain-based solutions will only serve to enhance transparency, enforce trust, and eliminate fees to maximize contribution efficiency. We were inspired by the limitations and costs of traditional crowdfunding sites, where backers face platform fees, slow fund disbursements, and an overall lack of transparency. Blockchain‚Äôs power to eliminate middlemen and offer verifiable transparency presented an opportunity: what if crowdfunding could be trustless, cost-free, and open to all?"},{"heading":"What it does","content":"Movement is the first blockchain-based crowdfunding platform where every donation is direct, fully transparent, and recorded on-chain. There are no platform fees or third parties, since smart contracts automatically manage fund disbursement and milestone tracking, ensuring 100% of all contributions reach their intended recipient with transparent accountability. We believe that this is the future of crowdfunding."},{"heading":"How we built it","content":"Movement is built as a TypeScript Next.js web app using React 19 and Tailwind CSS for fast, responsive design, with layout.tsx and globals.css driving our global shell and design tokens. For blockchain integration, we leverage the SUI stack (@mysten/sui, @mysten/dapp-kit), connecting to testnet via networkConfig.ts and surfacing wallet and transaction flows through our dedicated UI components. The app uses React Query for data fetching and caching, and even image content is hosted entirely on chain using Walrus. Content is typed and managed via campaign.ts, and the development environment includes ESLint, Prettier, and simple npm/package.json scripts for local setup. All these tools combine to deliver a secure, scalable, and user-friendly crowdfunding platform on SUI."},{"heading":"Challenges we ran into","content":"The most difficult challenge for us was learning and applying the Move language, since none of us have worked with Move before this Hackathon. The resources provided definitely helped us learn, but getting used to a new language within a few hours really pushed us out of our comfort zone and tested our adaptability. We faced many other challenges as well, encountering various bugs and errors (one in particular took us 3+ hours to fix, as we eventually found out it was caused by an update to the Sui frontend SDK about 5 days before the Hackathon which caused infinite loops and failure to serialize strings). Huge thanks to the SUI team (shoutout to Zihe and Daniel in particular) for taking the time to help us with our issues, we couldn‚Äôt have done it without them!"},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud of creating a working platform in less than 36 hours, and keeping a positive mindset throughout. For all of our team members, this was our first ever hackathon, and we are proud of what we have achieved despite our inexperience, especially since for most of our team, this was our first time working with blockchain as well. Most of all, we are proud of how much we were able to learn and grow throughout the course of Cal Hacks 12.0!"},{"heading":"What we learned","content":"We learned so much about blockchain and SUI the past few days, about the benefits, applications, and limitations. We now know that blockchain integration helps improve platform reliability and lowers operating costs, and we learned how blockchain can provide immutable record of transactions, playing a major part in transparency. Ultimately, we learned how cool blockchain as a concept is and how much potential it holds for the future. And of course, on a personal level we have learned so much about ourselves, our working style, our physical and mental limits, and our bond as teammates."},{"heading":"What's next for Movement","content":"Looking ahead, Movement has already added decentralized community voting, and building on that we want to continue rewarding backers with NFT-based incentives. We also want to potentially explore the addition of analytics for campaign creators, and expand support for additional blockchain ecosystems and global currencies. Our vision is a future where anyone, anywhere, can transparently fund and launch world-changing projects, powered by the Movement community."},{"heading":"Built With","content":"css move next.js sui tailwind"}]},{"project_title":"Guardian: AI-powered Scam and Fraud Prevention ","project_url":"https://devpost.com/software/guardian-ai-powered-fraud-prevention-for-your-money","tagline":"Defend against suspicious charges before they even reach your account, utilizing voice alerts, agentic reasoning, and real-time merchant intelligence.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/894/173/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"The Bright Data: Best Use of Bright Data"}],"team_members":[],"built_with":[{"name":"anthropic","url":null},{"name":"brightdata","url":null},{"name":"claude","url":null},{"name":"coderabbit","url":null},{"name":"css3","url":"https://devpost.com/software/built-with/css3"},{"name":"django","url":"https://devpost.com/software/built-with/django"},{"name":"fetch","url":null},{"name":"figma","url":null},{"name":"fish","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"machine-learning","url":"https://devpost.com/software/built-with/machine-learning"},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react18","url":null},{"name":"render","url":null},{"name":"sql","url":"https://devpost.com/software/built-with/sql"},{"name":"whitenoise","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/aryan-gupta123/Guardian/tree/restore/bring-these-back-v2"}],"description_sections":[{"heading":"Our Inspiration","content":"About 75% of Americans have been victims to some form of financial fraud in their life. Banks let you know when fraudulent activities occur, but only after your money‚Äôs already gone. What if we could stop the fraud in its tracks before our wallets get drained. And that‚Äôs exactly where Guardian comes in: protecting your hard-earned money from fraud. When we first thought of the idea, we wanted to help the elderly population as they are five times more likely to be targeted by scammers than younger adults. Banks often have difficult and complex ways to try and get a refund, which elderly people could use a helping hand to do. We built something that gives everyone confidence and protection. Guardian is bringing back financial independence to the people. We don‚Äôt just prevent fraud, we also provide peace of mind, along with a wallet with a few more green bills at the end of the day!"},{"heading":"How we built it","content":"We created Guardian as a real-time fraud protection solution powered by a modular Python Flask backend and a clean, accessible React frontend.\n\nOur risk engine, an unsupervised anomaly detection framework using SHAP, identifies suspicious transactions based on features like abnormal spending amounts, time of charge, foreign transactions, and rate of transactions. We then enhance our risk detection using BrightData's web-scraping, which lets us detect changes in merchant reputation and patterns of consumer complaints.\n\nIf a transaction looks dangerous, Claude (Anthropic) generates a friendly, easy-to-understand explanation and a recommended action language specifically designed to support seniors who may feel anxious or confused during fraud events. That script is then automatically transformed by Fish Audio into a natural-sounding voice alert that speaks directly to the user.\n\nThe entire workflow completes in under a second, and helpful automation powered by Fetch.ai handles follow-up tasks like checking for duplicate charges or preparing a dispute kit. Meanwhile, the UI shows the voice transcript, a risk level, and two large buttons keeping users in control while Guardian does the heavy lifting to keep them safe."},{"heading":"Challenges we ran into","content":"Integrating multiple intelligent systems in real time was NOT easy, especially under hackathon pressure. Authentication and environment handling across several APIs challenged us early on, and we worked hard to optimize latency."},{"heading":"Accomplishments","content":"We‚Äôre incredibly proud that in just one weekend we built a fully working voice-first prototype that:\n\nblocks fraud before money is stolen, speaks to the user like a real human guardian automates the stressful parts of post-fraud recovery combines Bright Data, Anthropic, Fish Audio, and Fetch.ai into one smooth agent."},{"heading":"What we learned","content":"We learned that designing for financial security isn‚Äôt just a data problem, it‚Äôs an intrinsically human one. During moments of fear, people need clarity, reassurance, transparency, and compassion. We learned how to combine multiple AI systems together operating simultaneously, while handling security and reliability with care. We learned that AI isn‚Äôt just a tool for automation, it can become a protector that gives people peace of mind."},{"heading":"What's Next for Guardian","content":"We plan to run a pilot with a fintech or card-issuing partner, add multi-language voice alerts to support diverse communities, improve personalization to reduce false positives even further, and collaborate with both smart speakers for users who aren‚Äôt comfortable with apps, and accessibility experts to deepen our senior-first design.\n\nOur goal is simple : Ensure that everyone, especially the elderly, feels safe and confident when they use their money.\n\nFor us, Guardian has the potential of being more than just a hackathon project. Rather, it's the beginning of a financial safety companion for the people who need protection the most."},{"heading":"Built With","content":"anthropic brightdata claude coderabbit css3 django fetch figma fish github html5 javascript machine-learning numpy python react18 render sql whitenoise"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"PitchLab","project_url":"https://devpost.com/software/pitchlab-clxhuj","tagline":"PitchLab generates catered mock sales pitch calls for sales reps to learn, practice, and apply before the real deal. Help reps get their reps in","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/897/975/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Rox: Best Use of Rox"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"elevenlabs","url":null},{"name":"go","url":"https://devpost.com/software/built-with/go"},{"name":"nextjs","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"rox","url":null},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/Kevinxygu/calhacks.12.0"}],"description_sections":[{"heading":"Inspiration","content":"Around 79% of sales pitches fail, with every bad pitch costing companies millions in lost revenue. However, there isn't enough practice. Managers are too busy, role-play mocks are not entirely accurate to the real thing, and you only get one quick shot with a real prospect.\n\nWhat if there was a product that could mimic the exact prospect you'll be speaking too?"},{"heading":"What it does","content":"PitchLab generates a simulated prospect for you to practice sales pitches with based on your learning goals, company-specific data, and industry research. We use large language models (LLM) and AI agents to act autonomously on a company's messy, real-world data. After analyzing company sales data, we generate a simulated pitch call environment with an AI prospect. This AI prospect speaks to you in real time, and is catered based on the prospective company, the sales rep's learning goals, and company product suite"},{"heading":"How we built it","content":"We used NextJS, TypeScript, TailwindCSS, ReactJS for the front-end development. We used Go for the backend. Claude, ElevenLabs, and AI agents (similar to what Rox offers) create a perfect user prospect that sales reps can practice with.\n\nHere are the presentation slides! https://docs.google.com/presentation/d/1nO3dRgHFU7kB5YlKxWr52657JoPnywPV00_sTdDzK0Y/edit?usp=sharing"},{"heading":"Built With","content":"claude elevenlabs go nextjs react rox tailwindcss typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"FairVal","project_url":"https://devpost.com/software/reclaim-ai","tagline":"Your post-purchase autopilot that automatically tracks online price changes and writes emails to give you refunds, returns, and savings.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/898/925/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"The Bright Data: Best Use of Bright Data"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"fairval.tech","url":"http://fairval.tech"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by the issue of returns, which is so commonplace for everyday life and for consumers. However, this is an issue that most people don't think about at all. We think that this is the biggest and most accessible opportunity that we can tackle at Cal Hacks to be able to create a real tangible benefit for consumers, especially during an unprecedented cost of living crisis.\n\nWe also were hoping to explore new use cases for AI tools and public data collection, for example from Bright Data, which could enhance everyday lives in a B2C application interface."},{"heading":"What it does","content":"FairVal is a consumer facing tool designed to help people save money after their purchase. Currently, customers are allowed to get a rebate on product they've already bought if the price has dropped prior to the return window. However, most people don't know this or completely forget about it. Our tool allows you to scan in your receipts and begin to automatically track the price online for any changes.\n\nOnce there are any price drops and potential savings, FairVal will notify you and generate a request-for-rebate email for you to send to customer support!"},{"heading":"How we built it","content":"We built our product using TypeScript for a web app, using Next.js and Tailwind CSS for styling.\n\nFor intelligent data extraction, we integrate Anthropic's Claude AI SDK (claude-3-5-haiku and claude-sonnet models) to perform receipt OCR, return policy analysis, and fallback price scraping when structured data is unavailable. The website is deployed on Vercel, allowing us to schedule daily cron jobs. Web scraping is powered by Bright Data's Scraping Browser via Puppeteer Core, connecting to Bright Data's proxy network for reliable, anti-bot-detection browser automation. This enables real-time price monitoring across major retailers (Amazon, Walmart, Target, etc.) using retailer-specific DOM selectors.\n\nBackend services run on Supabase for PostgreSQL database management, authentication, and real-time subscriptions. Form validation is handled by Zod with React Hook Form, while TanStack Query manages server state and caching. The application employs Vercel Analytics for performance monitoring and uses Axios for HTTP requests to external APIs, including Bright Data's dataset triggers for structured product data collection."},{"heading":"Challenges we ran into","content":"One of the challenges we faced was integrating the Bright Data Web Scraper agent within our website and trying to get the scraper working for as many websites as can for price checking."},{"heading":"Accomplishments that we're proud of","content":"We haven't used many AI tools before, especially with data collection and integrating a website with the Claude API. We're proud that we were able to create a working product in such a short period of time, and learn how to integrate other tools as well."},{"heading":"What we learned","content":"One thing we've realised is to keep what you're building simple, especially during a first iteration and especially with such a time crunch. When we were building our product, there was such a temptation to add a whole myriad of new features and integrations to other platforms. However, we learned that for the best reason it is usually to focus a few core features and to execute the product building as best as we can."},{"heading":"What's next for FairVal","content":"We are beginning to recruit potential alpha users for our platform. Most people we've talked to about this idea will be interested in using it, which is very exciting!\n\nWe are also planning to add a feature where we could forward receipts, digital receipts, or buy emails or run website emails which could automatically process it and begin tracking instead of having to manually copy or scan receipts. We weren't able to add it to the Cal Hacks iteration because of a lack of time, and the fact that we wanted to focus on getting the core features working.\n\nWe will also be starting the process to integrate this tool directly within Email platforms such as Gmail instead of having it as a separate website. We were hoping to add this feature in within the hackathon product stage. However, this requires us to integrate within the Google OAuth platform, which has a hard time limit of 4-6 weeks to be approved, which couldn't be fit into Cal Hacks."},{"heading":"Built With","content":"claude react typescript vercel"},{"heading":"Try it out","content":"fairval.tech"}]},{"project_title":"elle","project_url":"https://devpost.com/software/elle","tagline":"an ai tool for making reel outfits real","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Reka: Best Use of Reka"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"next.js","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"reka","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/reenu-kutty/elle/tree/claude/fix-dev-script-error-011CUVT16PHUXeNtX9fRs7RS"}],"description_sections":[{"heading":"Inspiration","content":"We were talking about our mutual admiration for Elle Woods, the protagnoist of Legally Blonde: a driven, career-oriented person with immaculate taste in fashion."},{"heading":"What it does","content":"'elle' takes in a video link to a movie or a clip and the name of a character in said video and recognizes their three most iconic looks and breaks them down into separate parts to find shopping links on e-commerce websites."},{"heading":"How we built it","content":"We used Reka's Vision + Research APIs to facilitate visual analysis & web scraping + Claude Compute to expedite our work processes"},{"heading":"Challenges we ran into","content":"This was our first major hackathon, so time management posed a massive challenge for us."},{"heading":"Accomplishments that we're proud of","content":"We're glad to have actually built something, however it may function, in this kind of time span with the sort of limitations we faced."},{"heading":"What we learned","content":"We learned to develop in an AI-driven environment effectively, such as understanding the limitations of Claude (such as being unfamiliar with Reka documentation) but also the potential it contains"},{"heading":"What's next for elle","content":"We need to flesh out the front-end for elle and make sure the data we generate actually gets to the user in a usable manner, in addition to optimizing Reka usage to minimize time taken and credits used."},{"heading":"Built With","content":"claude next.js react reka typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Kasha","project_url":"https://devpost.com/software/kasha","tagline":"Tired of doing mental math and nudging someone who owes you money? Kasha is an AI chat bot that tracks real time spending, auto-split charges with friends, and sends personalized reminders","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/142/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Visa"}],"team_members":[],"built_with":[{"name":"anthropic","url":null},{"name":"claude-ai","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"fintech","url":null},{"name":"janitorai","url":null},{"name":"leaflet.js","url":"https://devpost.com/software/built-with/leaflet-js"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"socket-io","url":null},{"name":"supabase","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"visa-developer-apis","url":null}],"external_links":[{"label":"kasha-crew-ai.lovable.app","url":"https://kasha-crew-ai.lovable.app/"}],"description_sections":[{"heading":"Inspiration","content":"Life in college is unpredictable; lectures, coffee runs, and midnight food deliveries often nudge budgeting down the priority list. Most financial apps have a rigid system or feel isolating, as though budgeting is solely a personal issue, rather than a shared experience. We wanted to design something collaborative, conversational, and made for real student life. That idea became Kasha, a multi-person chat app that helps students manage their finances together by engaging in real-time budgeting, AI-based financial guidance, and merchant integration with Visa."},{"heading":"What it does","content":"Kasha improves personal finance by transforming it into a collective experience through AI and live financial data. Kasha features a dashboard displaying the chat assistant, Penny, as well as real time spending. Users can indicate which of their expenses is a split expense and which friends they share the expense with. Penny will then prompt the group chat with a notification that they owe the user money. If a friend forgets to pay the user back, Penny will send timely notifications until the amount is paid. This ensures that the user doesn't have to worry about nudging their friends constantly, preventing awkward conversations. Penny also adapts its persona and tone to different users‚Äô own communication style. Integration of APIs via Visa for Merchant Search, Visa Offers, Transaction Controls, Foreign Exchange Rates, and ATM Locater bring transparency and reality about finances and savings opportunities to students. Kasha‚Äôs smart budgeting dashboard automatically categorizes expenses, sends alerts when you are near your spending limit, and visualizes progress over time. An interactive campus map outlines student-friendly merchants and deals nearby, while group finance tools allow friends to seamlessly split bills, track IOUs, and settle."},{"heading":"How we built it","content":"Kasha was created using a variety of technologies, real-time communications, and external financial APIs. The frontend consists of React, TypeScript, and Vite for a fast, responsive experience and user-friendly experience. We made a clean and modern design for Kasha using Tailwind CSS and Lucide Icons. Real-time communication between users is done through Socket.io, giving chat messages updates across all devices in real-time and coordinating the budget updates. The backend was implemented using Node.js, Express, and TypeScript to help manage users, budgets, and interactions with AI. In order to facilitate communication with Visa's API, we created a dedicated Python FastAPI microservice and managed the asynchronous communication with the Visa API using aiohttp. We made use of Pydantic for strict data validation. We also integrated JanitorAI as Kasha's conversational intelligence, which can accommodate large context windows with up to 25,000 tokens to hold meaningful and coherent conversations over time."},{"heading":"Challenges we ran into","content":"Building a real-time AI financial advisor that integrates multiple APIs in a short timeframe presented several challenges. One of the biggest issues was managing cross-origin resource sharing and proxy configurations between the Vite, Express, and FastAPI servers. We also had to navigate Visa API rate limits, which we overcame through caching and batch request strategies. Handling large AI context sizes efficiently required developing dynamic memory trimming systems, and synchronizing real-time financial and chat data across users tested our event architecture. Time was another major constraint, as integrating five Visa APIs and a conversational AI system under hackathon conditions demanded precise coordination and rapid iteration."},{"heading":"Accomplishments that we're proud of","content":"Despite these challenges, we are proud to have built a fully functional and engaging experience for students that combines finance with social interaction. We implemented a real-time multiplayer chat system where students can discuss budgets while receiving AI-driven financial insights. We successfully integrated five Visa APIs into a unified experience and created eight distinct AI personalities that offer different tones of financial advice. We also designed a smart transaction synchronization system that prevents duplicate imports, keeping budgets accurate and up to date. Above all, we built a product that makes financial management feel approachable, supportive, and collaborative."},{"heading":"What we learned","content":"As we made Kasha, we learned how to use multiple technical domains and disciplines. We learned how to connect Node.js and Python for backend messaging, use Visa's developer platform to incorporate real transactions and merchant data, and create AI personalities that respond to different emotional tones. We learned how to create event-driven architecture with Socket.io, and how to mix technical complexity with user empathy in financial design. Most importantly, we learned that students are more engaged with financial tools that feel personal and conversational."},{"heading":"What's next for Kasha","content":"We want Kasha to develop into something bigger than a hackathon project; the next steps we would like to take are accessibility, education & scale. We hope to launch campus pilot programs in partnership with universities to allow students to track their spending and build financial literacy. The long-term vision for Kasha is to incorporate educational content regarding saving, investing, and responsible spending right within the platform, which will be a possibility if Kasha ever becomes a popular target for student engagement on campus. Scaling Kasha's API support to include even more banks and payment providers could open access to thousands of colleges and universities. We also want Kasha to innovate upon even gamified ways to help students budget, possibly looking at savings challenges or peer competitions that add interactivity and fun to the budgeting process. Finally, to reach even more students, we are launching a mobile version of Kasha specifically for students who are always on the go, plus a direct phone-based Kasha Agent that can join group chats directly (or without), allowing students real-time financial insights and support via text (or calls) when they are looking for help."},{"heading":"Built With","content":"anthropic claude-ai express.js fintech janitorai leaflet.js node.js postgresql react socket-io supabase typescript visa-developer-apis"},{"heading":"Try it out","content":"kasha-crew-ai.lovable.app"}]},{"project_title":"ChatRealm","project_url":"https://devpost.com/software/chatrealm","tagline":"ChatRealm: Context-aware chat rooms powered by 5 AI agent bureaus and LinkedIn scraper service. Specialized rooms for D&D, AA, and therapy with intelligent, personalized moderation.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/894/785/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"The Bright Data: Best Use of Bright Data"}],"team_members":[],"built_with":[{"name":"anthropic-claude-api","url":null},{"name":"asi-one","url":null},{"name":"brightdata-api","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"fastapi","url":null},{"name":"fetch.ai-uagents","url":null},{"name":"framer","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"nginx","url":"https://devpost.com/software/built-with/nginx"},{"name":"phaser.js","url":"https://devpost.com/software/built-with/phaser-js"},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"redis","url":"https://devpost.com/software/built-with/redis"},{"name":"socket.io","url":"https://devpost.com/software/built-with/socket-io"},{"name":"sqlalchemy","url":"https://devpost.com/software/built-with/sqlalchemy"},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/saurabh98s/calhacks24.git"}],"description_sections":[{"heading":"Inspiration","content":"We started ChatRealm because we saw too many people suffering in silence. In online support groups, we watched quiet voices get drowned out. In therapy sessions, we saw people struggling to share their deepest fears. In recovery communities, we noticed how one person's courage to speak could inspire a whole room, but only if someone was there to hold space for them.\n\nOur north star was simple: uplift the people who are scared to speak up. We wanted to build something that amplifies voices that might otherwise go unheard, keeps the room engaged and supportive, and most importantly, keeps people calm and safe when they're sharing the things that frighten them most. Because everyone deserves to be heard, and no one should face their darkest moments alone."},{"heading":"What it does","content":"ChatRealm is a safe space where AI doesn't replace human connection, it protects and nurtures it. Think of it as having a thoughtful friend in every conversation who notices when someone needs encouragement, steps in when things get heated, and celebrates every small victory.\n\nWe built three specialized rooms where people need this support most:\n\nDungeons & Dragons rooms aren't just about rolling dice. They're about shy players finding their voice through their characters, building confidence in a world where they can be heroes. Our AI Dungeon Master makes sure everyone gets their moment to shine.\n\nAlcoholics Anonymous rooms are sacred spaces where people share their struggles with addiction. Our AI recognizes when someone's celebrating \"day one sober\" and rallies the room to support them. When someone's struggling with temptation at 2 AM, it's there with resources and encouragement, buying time until human support arrives.\n\nGroup Therapy rooms are where people work through trauma, anxiety, and depression. Our AI creates the calm, non-judgmental presence that helps people open up. It recognizes when someone's triggered and gently guides the conversation to safer ground, all while making sure quieter voices get heard.\n\nHere's what makes us different: our AI learns from your LinkedIn profile (if you choose to share it) to understand who you really are. It's not about stalking, it's about context. When you share your story, the AI knows whether you're a college student facing finals stress or a veteran dealing with PTSD. It tailors its support to meet you where you are."},{"heading":"How we built it","content":"We knew from day one that this couldn't be a typical chatbot. People's mental health and recovery are too important to trust to a single AI making snap judgments. So we built something different: five specialized AI agents working together like a support team.\n\nThe Response Coordinator is the team leader, deciding when to speak up and when to stay quiet. Sometimes the best support is silent presence.\n\nThe Context Manager remembers everything. Not just what you said five minutes ago, but patterns over weeks. It knows if you're improving, struggling, or stuck.\n\nThe Wellness Guardian is our safety net. It watches for crisis signals, words that suggest someone's in danger, and quietly alerts the system to provide immediate resources.\n\nThe Emotion Tracker reads the room. It notices when someone's message seems cheerful but their word choice suggests they're masking pain. It picks up on the subtle cries for help.\n\nThe Toxicity Detector is our bouncer. It keeps the space safe by catching harmful content before it derails someone's healing journey.\n\nTech we used:\n\nFastAPI and Python for the backend brain React and TypeScript for the interface people see Socket.IO because conversations happen in real-time, not in turns Anthropic Claude for the AI that actually understands nuance and empathy Fetch.ai's uagents for coordinating our five-agent support team PostgreSQL and Redis for remembering every conversation and context BrightData API for optional LinkedIn profile understanding Docker to keep everything running smoothly\n\nWe gave ChatRealm a retro pixel-art look on purpose. When you're about to share your deepest fear, a friendly pixel avatar feels less intimidating than a corporate interface. It's approachable while still taking your story seriously."},{"heading":"Challenges we ran through","content":"Making AI actually empathetic was harder than we thought. Getting five AI agents to work together without tripping over each other required us to completely rethink our architecture. We failed. A lot. Our first version would timeout, crash, or give tone-deaf responses. We learned that real empathy comes from context, so we spent weeks teaching our AI to understand the difference between someone saying \"I'm struggling\" in a D&D game versus in an AA meeting.\n\nBuilding trust is everything. When someone's sharing that they relapsed, or that they had suicidal thoughts, the AI can't just spit out a generic response. It needs to understand the weight of that moment. We built a sophisticated context system that reads not just words, but the person behind them. LinkedIn integration helps, but so does remembering every interaction and learning from the community's patterns.\n\nKnowing when to intervene is an art, not a science. We wanted our AI to feel like a supportive friend, not a surveillance system. Too quiet and people feel abandoned. Too chatty and it drowns out human voices. We're still tuning this, but we built an intelligent intervention system that considers conversation flow, room energy, and individual needs. Sometimes the most supportive thing is silence.\n\nReal-time everything, always. Mental health crises don't wait for page refreshes. Someone saying \"I can't do this anymore\" needs immediate response. We built WebSocket connections, Redis caching, and background processing to ensure the AI is always listening and ready to help within milliseconds."},{"heading":"Accomplishments that we're proud of","content":"Honestly? We're most proud of the moments our AI gets it right.\n\nWhen it notices someone's been quiet for 20 messages and gently asks, \"Hey [name], what do you think?\" That's amplifying a voice.\n\nWhen someone shares they hit 30 days sober and the AI celebrates with genuine warmth while encouraging others to share their own milestones. That's building community.\n\nWhen it detects crisis language and immediately provides suicide prevention resources while keeping the person engaged until human help arrives. That's saving lives.\n\nWe built a five-agent AI system that actually works in production. We made it smart enough to know that \"let's play\" means something completely different in a D&D room versus a therapy session. We created an interface that feels like a game but holds space for the most serious conversations.\n\nBut the real accomplishment? We built something that makes people feel safe enough to speak up."},{"heading":"What we learned","content":"Technology is easy. Empathy is hard. We spent months on the technical architecture, but the real challenge was teaching AI to understand human pain and respond with genuine compassion. We learned that more context always beats smarter algorithms. Knowing someone's background, reading conversation history, and understanding room dynamics matters more than any fancy model.\n\nSilent support is still support. Our early versions talked too much. We learned that sometimes the AI's job is to just be present, ready to help, while humans connect with humans. The best moderation is invisible until it's needed.\n\nPeople want to be seen. The LinkedIn integration isn't about fancy tech. It's about making someone feel recognized. When the AI understands you're a nurse dealing with burnout, or a student facing academic pressure, its support becomes real instead of generic.\n\nRecovery isn't linear, and neither is conversation. Building room-specific AI taught us that every community has its own rhythm, vocabulary, and needs. One size fits nobody when it comes to supporting mental health and recovery."},{"heading":"What's next for ChatRealm","content":"We want to keep building safe spaces:\n\nMore communities that need support: Veterans with PTSD, LGBTQ+ youth, chronic pain sufferers, grief support groups, neurodivergent communities finding their people.\n\nVoice channels where people can talk instead of type, because sometimes speaking your truth out loud is what healing requires.\n\nPeer matching that connects you with others who've walked your path. Not random strangers, but people whose stories resonate with yours.\n\nCrisis response network that connects to real counselors when AI support isn't enough. We never want to replace human help, just make sure you have support while waiting for it.\n\nLong-term progress tracking so you can see how far you've come, even on days when it doesn't feel like it.\n\nCommunity building tools that help natural leaders emerge and peer support flourish.\n\nMost importantly, we want to keep listening. To the quiet voices, the scared voices, the voices that have been told to be silent. Because at ChatRealm, everyone gets heard."},{"heading":"Built With","content":"anthropic-claude-api asi-one brightdata-api docker fastapi fetch.ai-uagents framer javascript nginx phaser.js postgresql python react redis socket.io sqlalchemy tailwindcss typescript vite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"PrivAds","project_url":"https://devpost.com/software/aura-e1marq","tagline":"The Privacy-First AI Ad Network","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/897/556/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Reka: Best Use of Reka"}],"team_members":[],"built_with":[{"name":"agents","url":null},{"name":"anthropic","url":null},{"name":"brightdata","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"reka","url":null},{"name":"torch","url":null},{"name":"transformers","url":null},{"name":"transformers-js","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/acmcmc/calhacks-12"},{"label":"www.loom.com","url":"https://www.loom.com/share/e830ebef76b2495dbfd9d899350b7d61"}],"description_sections":[{"heading":"Inspiration","content":"We took ideas from many of the challenges at CalHacks. For example, we loved AppLovin‚Äôs challenge to extract high-value signals from ads as a way to gain user insights, but we built upon that and pushed it further by asking: ‚ÄúWhat if we could build an ad recommendation engine that‚Äôs smart and privacy first?‚Äù We also drew from Y Combinator‚Äôs AI native track to imagine what an AI-powered, privacy-centric alternative to existing Y Combinator ad startups, such as Plai, might look like in today‚Äôs world."},{"heading":"What we do","content":"Imagine an ad network that actually respects your privacy. Instead of tracking you with cookies and personal data, our system learns from your interactions like what types of ads you click on, what pages you are interested in, and builds a privacy-first user embedding that never stores your identity. We process ad images or videos using multimodal AI, where we extract visual, textual, and contextual signals from images and videos using a VLM encoder. Then, we use contrastive learning to \"match\" those embeddings against a user‚Äôs embedding space. With Fetch.ai, we simulate autonomous user personas who explore thousands of ads, and Claude AI helps us model click probabilities for each ad-user pair. This all came together into a scalable, privacy-first ad recommendation engine that knows what you like without knowing who you are."},{"heading":"What makes us special","content":"No user tracking or segments: We use user embeddings, not personas or segments that could be traced back. Multimodal ad understanding: Ads are processed with a vision-language model (Jina CLIP v2) to extract both visual and textual signals. Context-aware serving: Ad selection considers both user embedding and the current page context. Custom and dynamic ads: The system can generate or enhance ads on the fly, tailored to user interests and page content. Less ads: Showing ads to people who are not going to interact with the material is a waste of time and money. For instance, if someone's in a hurry, they won't click on any ads. We detect user interaction patterns and avoid showing ads when we anticipate low performance. Everybody wins!"},{"heading":"How we built it","content":"Dataset collection: The contrastive learning model requires data on ads and users interacting with those ads. To do so, we built on AppLovin's provided dataset. We used Google Gemini and Reka to extract key features from image and video ads, respectively. We then used an Anthropic AI agent with BrightData's MCP server and Langchain to build a large dataset of ads. Furthermore, for user dataset generation, we used another agent to build realistic user profiles.\n\nContrastive Learning LLM for Ad-Serving: Unlike OpenAI's CLIP model, instead of a one-to-one relationship amongst data, we have many users interacting with many ads -- aka many-to-many data. We generate embeddings for user profiles, context of the user, and ads. The model crunches out which ads to serve to which users. The model is deployed at an endpoint.\n\nPlatform for companies: In the grand scheme of things, the ad-serving platform serves companies publishing advertisements. We have already figured out ad-understanding, customer-segmentation, and effective ad-serving.\n\nCustom Ads: The platform allows companies to generate custom ads; companies can also opt to enhance their pre-existing ads dynamically on each user's device. The system extracts contextual information about the app / webpage the ad is being deployed on, makes inferences about the user, and specifically tailors the ad to the user's interests to improve click-through rate."},{"heading":"Demo website:","content":"https://privads-demo.onrender.com/"},{"heading":"Challenges we ran into","content":"It was a very complex system to implement because there were several dependent parts. While we doubled down on the research problem of effectively learning from creatives granted high dimensional data, we ideated a lot about what direction to take it in as a product, what problem we were solving for our users (companies), and our unique value proposition. Luckily, we were able to find our direction and niche."},{"heading":"Accomplishments that we're proud of","content":"To have built so many agents and a custom LLM for ad-serving that works despite high-dimensional, sparse data."},{"heading":"What we learned","content":"Architecture matters: Separating concerns (frontend, web_ad_service, backend) makes scaling easier, but coordinating them and building them separately at the same time as a team is complex. Environment management: Having one shared miniconda env for multiple services is messy; separate envs or containers (Docker) are better. Privacy-first is hard but valuable - Building without personal data tracking is more complex but more aligned with user interests We learned to test external APIs in isolation. Setting up isolated tests for each part of the frontend customized ad generation pipeline is what helped us catch the real issue in the process not working."},{"heading":"What's next for PrivAds","content":"Comparing the use of contrastive learning to ML models oriented toward high-dimensional sparse data."},{"heading":"Built With","content":"agents anthropic brightdata gemini javascript python reka torch transformers transformers-js"},{"heading":"Try it out","content":"github.com www.loom.com"}]},{"project_title":"Mantis","project_url":"https://devpost.com/software/mantis-nie02d","tagline":"Mantis provides real time threat detection to help retail businesses identify and prevent shoplifting as it occurs, protecting your inventory and reducing loss.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/891/009/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Reka: Best Use of Reka"}],"team_members":[],"built_with":[{"name":"baseten","url":null},{"name":"convex","url":null},{"name":"fastapi","url":null},{"name":"fetch.ai","url":null},{"name":"huggingface","url":null},{"name":"livekit","url":null},{"name":"next.js","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwindcss","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/oviozz/mantis"}],"description_sections":[{"heading":"Inspiration","content":"We started with one question: Why do most security systems only react after it‚Äôs too late?\n\nRetailers lose billions every year to theft, yet most cameras just record footage for later review. Humans can‚Äôt monitor every feed at once‚Äîand by the time incidents are noticed, the culprit is gone. So, we set out to make cameras that could think ‚Äîsystems that recognize suspicious behavior in real time and act before damage is done."},{"heading":"What Mantis Does","content":"Mantis is an end-to-end intelligent monitoring platform that learns, detects, and alerts:\n\nReal-Time Threat Detection: Detects shoplifting, weapons, and aggressive actions within 2 seconds . Face Recognition System: Uses vector embeddings to identify and track repeat offenders across all footage‚Äîwithout storing private identity data. Live Dashboard: LiveKit-powered dashboard overlays detections on the video feed and streams alerts instantly. Smart Querying: Ask questions like ‚ÄúWho stole yesterday?‚Äù and get timestamped clips and summaries.\n\nBuilding Mantis taught us invaluable lessons about real-time video processing, multi-agent AI pipelines, and face recognition at scale. Balancing speed, accuracy, and privacy showed us what it takes to move from simple detection to true prevention ."},{"heading":"How We Built It","content":"Architecture\n\nDetection Engine: Processes frames at 0.5‚Äì1 FPS using specialized AI agents for theft, weapons, and face detection. Face Recognition: Generates and compares facial vector embeddings for cross-incident identification. Live Streaming: Combines LiveKit (for video delivery) and WebSockets (for detection metadata) for synchronized, low-latency updates. Analytics Layer: Uses ChromaDB for semantic vector search and natural-language querying.\n\nüíª Tech Stack\n\nBackend: FastAPI + Python AI Models: Hugging Face + Ultralytics Video: OpenCV + LiveKit Database: ChromaDB (for face and clip embeddings)"},{"heading":"Challenges We Overcame","content":"Real-Time Performance at Scale: Achieved <2-second latency across multiple feeds using async job queues, frame sampling, and optimized inference. Accurate Threat Detection: Reduced false positives through a fusion approach combining multiple AI signals. Face Recognition & Privacy: Stored face embeddings separately from personal data, ensuring privacy without losing analytical power. Live Streaming Integration: Engineered a dual-channel pipeline‚Äîone for video, one for detection metadata‚Äîfor seamless synchronization."},{"heading":"Accomplishments We‚Äôre Proud Of","content":"Sub-2-second detection latency‚Äîtrue real-time prevention Face search that scans hours of footage in seconds Multi-agent fusion achieving high accuracy with minimal false alarms A live, intuitive dashboard built for instant response‚Äîno training required A system ready for production, not just a demo"},{"heading":"What We Learned","content":"Real-time AI demands millisecond-level optimization‚Äîbatch processing principles don‚Äôt apply 1‚Äì2 FPS sampling is the sweet spot for retail: frequent enough to catch incidents, efficient enough for multiple feeds Vector embeddings are game-changing for semantic face tracking and event linking The best AI fails if the UX isn‚Äôt intuitive during stressful moments Privacy and ethics must be designed in, not patched later"},{"heading":"What‚Äôs Next","content":"Short-Term\n\nMobile alerts with video clips POS integration to detect employee and self-checkout theft Predictive analytics for identifying high-risk locations and times\n\nLong-Term\n\nCross-store networks to spot organized retail crime Behavioral analysis for professional shoplifters Edge-deployable systems for privacy-focused retailers Open API for integration with existing security infrastructure"},{"heading":"Our Vision","content":"We envision a world where retail theft becomes economically irrational ‚Äîwhere prevention is instant, automated, and intelligent.\n\nMantis isn‚Äôt just another security product. It‚Äôs the future of proactive protection ."},{"heading":"Built With","content":"baseten convex fastapi fetch.ai huggingface livekit next.js opencv python react tailwindcss"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"InSight","project_url":"https://devpost.com/software/insight-vyfj5z","tagline":"Insight uses Meta Ray-Bans to record your every interaction, creating an AI clone of yourself that completely understands your virtual and physical relationships to streamline your work.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Conway: Most Data-Intensive Application"}],"team_members":[],"built_with":[{"name":"dlib","url":null},{"name":"ffmpeg","url":"https://devpost.com/software/built-with/ffmpeg"},{"name":"mcp","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pillow","url":null},{"name":"postgress","url":null},{"name":"pyannote","url":null},{"name":"pyav","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"smithery","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"whisper","url":null},{"name":"wordware","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"As our digital lives become increasingly automated, our digital relationship data has become a less genuine reflection of ourselves. True personal human context, how we speak, connect, and interact in person, is missing from the automations that are being increasingly used.\n\nWe built InSight to bridge that gap. We believe the future of AI isn‚Äôt replacing people, but reflecting them authentically. We capture both digital and physical interactions to create an real, intelligent extension of who you are."},{"heading":"What it does","content":"InSight is your personal memory engine, a virtual clone that captures everything you see, say, and do. Using Meta Ray-Ban glasses and a custom audio-visual pipeline, it records real-world interactions, recognizes who you‚Äôre talking to, and labels every conversation with names and timestamps. Imagine being able to search your life like a Google Doc, where every moment is instantly accessible.\n\nWhat makes InSight stand out is how it connects your real and digital worlds. It syncs with tools like Slack, turning in-person chats and reminders into actionable insights right inside your workspace. Support for WhatsApp and Discord is on the way, allowing InSight to organize and understand your conversations across every platform you use.\n\nInSight is not just a memory tool. It‚Äôs an active collaborator that reminds you of commitments, drafts follow-ups, and schedules meetings based on your conversations. Whether you‚Äôre a student balancing projects or a professional managing a busy schedule, InSight keeps your ideas and actions seamlessly connected so you never lose track of what matters most."},{"heading":"How we built it","content":"We built InSight as a collection of microservices, starting with a multi-stage ML pipeline for processing interactions. Due to there not being an SDK to work with Meta Ray Bans glasses, we made our own way to livestream video from the glasses to our pipeline. By livestreaming through the glasses on Instagram, we could open Instagram Live on our computers and see what the glasses were seeing. From this, we used FFMPEG to take a constant screen capture of the video.\n\nInteraction Processing Pipeline: In the background, we run a Voice Activity Detection model, which helps us figure out when the user starts having a conversation with someone. Once speech is detected, the interaction is automatically segmented and beamed to our audio and visual pipelines.\n\nAudio Pipeline: Our audio processing leverages two state-of-the-art models working in tandem. Faster Whisper performs high-accuracy speech-to-text transcription with precise timestamps, while pyannote.audio handles speaker diarization, identifying when different speakers take turns in the conversation. This generates initial transcripts labeled with generic speaker IDs (\"Speaker 1\", \"Speaker 2\") and exact timing information, which becomes crucial for downstream processing.\n\nVideo Pipeline: The video pipeline employs dlib's ResNet-based face recognition with one-shot learning capabilities, meaning it can identify people from just a single reference photo. As frames are processed, we detect all visible faces, extract 128-dimensional face encodings, and match them against our database using euclidean distance metrics. The system tracks confidence scores and timestamps for when each person appears, building a comprehensive registry of everyone in the interaction.\n\nAggregation & Speaker Matching: The magic happens when we fuse audio and video data together. Using OpenCV's optical flow analysis, we track lip movements by monitoring facial landmarks around the mouth region. For each audio segment, we calculate movement magnitude across all detected faces to determine who was actually speaking. By correlating lip movement intensity with speaker timestamps, we replace the generic speaker labels with actual names from our face recognition database. This synchronized data, transcripts with accurate speaker attribution, timestamps, and confidence scores, is then stored in our PostgreSQL database, making every interaction queryable through our MCP server interface. MCP Server.\n\nTo make our interaction data accessible to Poke, we built a Model Context Protocol (MCP) server that acts as a natural language interface to our PostgreSQL database. The MCP server exposes two core tools that any MCP-compatible AI assistant can invoke: list_people (returns everyone you've ever talked to) and list_interactions_with_person (retrieves full conversation transcripts with a specific person). This architecture transforms InSight from a passive database into an active AI memory system. Instead of writing custom API endpoints or forcing users to learn query syntax, we leverage MCP to let AI assistants query your interaction history through conversational prompts. For example, you can simply ask \"What did I discuss with Sarah last week?\" and the AI agent automatically calls list_interactions_with_person with the appropriate parameters, retrieves the relevant transcripts, and synthesizes a natural answer."},{"heading":"Challenges we ran into","content":"No Official SDK for Ray-Ban Meta Glasses Meta doesn't provide a developer SDK for the Ray-Ban Meta glasses' video feed. We worked around this by livestreaming through Instagram Live and using FFmpeg to capture the screen. This required detecting and cropping the feed region, handling buffering and latency, and managing connection drops‚Äîall while dealing with uncontrollable video quality and potential Instagram UI changes. Integrating with Poke Agent's Black-Box Architecture Getting the Poke agent to query our interaction data was difficult. With limited visibility into its internal processing, we treated it as a black box and iterated through trial-and-error. We experimented with tool descriptions, input schemas, and response formats until we found patterns that triggered correct behavior. Voice Capture in High-Noise Environments Real-world conversations happen in noisy places - coffee shops, streets, restaurants. Our VAD system had to distinguish actual conversations from background noise without false positives or missed interactions. We experimented with energy thresholds and frequency filtering to find the right balance. Audio quality from the Ray-Ban glasses also varies by positioning and acoustics. After multiple iterations and using multiple models, we achieved consistent performance in high-noise environments."},{"heading":"Accomplishments that we're proud of","content":"Initially, all we were looking to do was to be able to bring the real world‚Äôs data to your technology. We are extremely proud that we were able to accomplish this through the Meta RayBan glasses, but beyond that, we were even able to make numerous integrations that take advantage of this vast dataset. In short we‚Äôre proud that we were not only able to create the data layer, but also the applications on top of that layer."},{"heading":"What's next for InSight","content":"The number of users for wearable vision glasses is bound to grow exponentially throughout the next few years, so InSight is particularly built for the future. Similarly, the need for personalization and the need for context have been growing and are going to continue growing this decade. We see InSight as becoming the base layer for thousands of apps that are going to be built on top of us."},{"heading":"Built With","content":"dlib ffmpeg mcp opencv pillow postgress pyannote pyav python pytorch smithery typescript whisper wordware"}]},{"project_title":"Argus","project_url":"https://devpost.com/software/argus-w6i0pv","tagline":"Argus combines AI, computer vision, and real-time streaming to deliver intelligent, low-latency surveillance with instant threat detection, reporting, and search across all your video networks.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/891/963/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Conway: Most Data-Intensive Application"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"A37: Best Use of A37"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"elasticsearch","url":"https://devpost.com/software/built-with/elasticsearch"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"letta","url":null},{"name":"mux","url":null},{"name":"nextjs","url":null},{"name":"rtmp","url":null},{"name":"supabase","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/GodPuffin/argus"}],"description_sections":[{"heading":"üëÄ What does Argus do?","content":"Argus is the multi-tool for all your enterprise surveillance needs.\n\nüõ∞Ô∏è Surveillance Input Pipeline:\n\nMUX Realtime Live streaming & VOD asset generation using RTMP streaming Supabase Edge Functions sync the MUX data stream Gemini 2.5 Pro Vision Analysis for Event & Anomaly detection off generated VOD assets Roboflow 3.0 Object Detection Computer Vision for generating bounding boxes and tracking entities within streams\n\nüß© Event Pipeline:\n\nGemini & Roboflow jobs sync with MUX VOD assets creating a event timeline within the viewer & detection display Elasticsearch accessses the Supabase DB through real-time sync and populates the index to allow for semantic searching of events/anomalies Stats are populated based off of Supabase through realtime & the Elasticsearch knowledge base\n\nüí¨ Interface Pipeline:\n\nThe AI Chat page accesses all of the available data and allows for direct interaction through various models ( Letta Stateful Agent , Kimi K2 Instruct through Groq , Claude 4.5 Sonnet , Claude 4.5 Haiku ) Through the Chat interactions, you are able to generate Incident Reports of events & anomalies which are editable through a Tiptap Rich Markdown editor"},{"heading":"üßë‚Äçüíª How we built it","content":"By coding :) ü§ì"},{"heading":"‚öîÔ∏è Challenges we ran into","content":"Since Argus has so many services, you need to be running at least 4 terminals to host it locally : ngrok server to point MUX webhooks Next.js application Node worker running the workflow services & agents (Gemini, Roboflow, Elasticsearch) Containerized Docker Supabase instance with supabase edge functions\n\nAlongside the terminal suffering, we had to deal with merge conflict misery a few times.... üò≠"},{"heading":"üèÜ Accomplishments that we're proud of","content":"All in all, Argus is the most fleshed out hackathon project we've made so far, it was really satisfying putting it all together and seeing it all work!\n\nAs someone who's worked in Government IT & Cybersecurity (Carson), it was really cool to create something that has genuine real-world use cases and with some more overall polish could even be shipped as a full tool integrated into security workflows!"},{"heading":"ü§Ø What we learned","content":"We learnt a lot about many of the tools provided by CalHacks' sponsors! We had a lot of fun tinkering around with each interface and understanding the capabilities, very cool tools and we are looking forward to spending more time working with them in the future!"},{"heading":"üëÅÔ∏èüëÅÔ∏èüëÅÔ∏è What's next for Argus","content":"Hardware integration (into security cameras for example) Enterprise level security Entity tracking across video streams (did Person A walk from Camera 1 to Camera 3?) More automated workflows & agentic pipelines"},{"heading":"Built With","content":"claude elasticsearch gemini groq letta mux nextjs rtmp supabase"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Onboardly","project_url":"https://devpost.com/software/onboardly-3bp9gt","tagline":"automate onboarding and training + realtime coaching","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/901/481/datas/medium.jpeg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Conversion: Best Use of Conversion"}],"team_members":[],"built_with":[{"name":"ai","url":null},{"name":"api","url":null},{"name":"chrome","url":"https://devpost.com/software/built-with/chrome"},{"name":"extension","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gooogle","url":null},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"ics","url":null},{"name":"jira","url":"https://devpost.com/software/built-with/jira"},{"name":"jora","url":null},{"name":"manifest","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-native","url":"https://devpost.com/software/built-with/react-native"},{"name":"rest","url":null},{"name":"sendgrid","url":"https://devpost.com/software/built-with/sendgrid"},{"name":"slack","url":"https://devpost.com/software/built-with/slack"},{"name":"vision","url":null},{"name":"vllm","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Preet37/Onboardly"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by the massive efficiency gap in technical onboarding. Companies often spend days manually provisioning accounts, setting up security, and explaining the same basic cloud concepts repeatedly. This process is intimidating, prone to human error, and lacks real-time guidance for new hires. Our goal was to eliminate this friction entirely, creating an AI that doesn't just create tickets, but actively guarantees a smooth, secure, and educational Day 1 experience by automating both the company-side security setup and the user's hands-on learning process."},{"heading":"What it does","content":"Onboardly is a Full-Stack, AI-Powered Onboarding Orchestrator that seamlessly bridges IT provisioning and user coaching. For the Company (Automation): From a single form trigger, Onboardly uses the Groq AI to dynamically generate an 8-step, role-specific curriculum (e.g., GCloud training for an SWE Intern). It then uses Jira's API to instantly create a master Epic and all sub-tasks, and SendGrid to deliver a personalized welcome email with a downloadable calendar invite, all assigned directly to the new hire. For the Intern (AI Coach Extension): Once the intern clicks the Jira link and navigates to the Google Cloud Console, our custom Chrome Extension injects an AI Coach panel. This panel uses Gemini Vision AI to capture and analyze the screen, providing real-time, step-by-step guidance on how to complete each task‚Äîlike a senior developer looking over their shoulder. The entire workflow is tracked, and when the final task is complete, the system automatically transitions the main Jira Epic to DONE."},{"heading":"How we built it","content":"We built Onboardly using a clean, three-part architecture. 1. The Provisioning Engine (Node.js/Express): This handles the pre-onboarding setup, orchestrating API calls to Groq for curriculum generation, and using the Jira API to create and assign the entire task hierarchy. 2. The AI Brain (Python/Flask with Gemini): This server exposes the vision endpoints. It utilizes Gemini 2.0 Flash for low-latency visual analysis of the screenshot and Gemini 2.5 Pro for sophisticated reasoning and generating clear coaching instructions. 3. The AI Coach Frontend (Chrome Extension): This utilizes a Background Service Worker to securely capture the visible tab screenshot, which the Content Script then sends to the Python backend. The Content Script then renders the real-time coaching UI directly onto the Google Cloud Console interface, providing the interactive guidance needed to complete the Jira tasks."},{"heading":"Challenges we ran into","content":"The primary challenges involved navigating complex and often fragile enterprise APIs. Jira Provisioning was the biggest obstacle: We faced persistent issues finding the correct internal issue type IDs (10001, 10004) and dealing with the obscure \"Epic Name\" field ID, which required removal for our simple project. Furthermore, the Jira API user invite process consistently failed on the free tier. We bypassed this by implementing a feature to automatically assign the Epic to the manager's account, ensuring the demo user had instant, authorized access to the tasks. Secondly, AI Key Quotas blocked our progress with an insufficient_quota error, which we resolved by performing a real-time migration to Groq AI's compatible API, maintaining our dynamic curriculum feature."},{"heading":"Accomplishments that we're proud of","content":"We are most proud of achieving true, end-to-end automation of a complex business process within a short hackathon window. This includes: 1. Zero-Touch Provisioning: Successfully creating a Jira Epic, 8 sub-tasks, and sending a personalized welcome email with a downloadable calendar invite‚Äîall from a single Node.js trigger. 2. Dynamic Curriculum: Using Groq AI to generate a highly detailed, accurate 8-step GCloud curriculum in under one second. 3. The Wow Factor: Seamlessly integrating real-time Gemini Vision coaching that actually understands what the user is seeing on a complex external site (GCP Console) and guiding them to complete the automated tasks."},{"heading":"What we learned","content":"We learned three crucial lessons: 1. AI Compatibility is Key: Utilizing the OpenAI-compatible API structure (as provided by Groq) is vital for rapid prototyping and maintaining provider flexibility when quotas are an issue. 2. API Workarounds are Essential: Complex enterprise APIs (like Jira's) often require deep inspection of error messages and unconventional workarounds (like removing required fields or using specific transition IDs) to integrate successfully in a fast-paced environment. 3. The \"Isolation Problem\" Requires a Stack: A helpful AI coach cannot be built in one script; it requires a stack of communication (Content Script $\\leftrightarrow$ Background Script $\\leftrightarrow$ Flask Backend) to securely and effectively capture the user's screen and leverage powerful vision models."},{"heading":"What's next for onboardly","content":"We plan to implement three key features: 1. Jira Webhook Integration: We will eliminate the final \"Mark Complete\" button by having Jira trigger a webhook back to our server when all 8 sub-tasks are manually marked \"Done,\" achieving truly touchless final Epic completion. 2. Advanced Security Checks: Integrate the GitHub API (which we built a stub for) to check if the intern has enabled required branch protection rules on their new starter repository before marking that task as complete. 3. Gemini Pro Reasoning: We will leverage the powerful reasoning capabilities of Gemini 2.5 Pro to provide non-visual feedback, such as analyzing the security logs in the next step and providing a summary of the threats found directly to the intern."},{"heading":"Built With","content":"ai api chrome extension flask gooogle groq ics jira jora manifest node.js react react-native rest sendgrid slack vision vllm"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Agora","project_url":"https://devpost.com/software/agora-165spb","tagline":"Autonomous AI marketplace for agents: save time, money, and trees by working with specialized SLMs on Agora > GPT or any large transformer model. Uses Claude, Lava, SUI, and more for agent comms!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/896/296/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Lava: Best Use of Lava Gateway"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"move","url":null},{"name":"plpg","url":null},{"name":"shell","url":"https://devpost.com/software/built-with/shell"},{"name":"sql","url":"https://devpost.com/software/built-with/sql"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/sanjayshanmugap/agenthub"}],"description_sections":[{"heading":"Inspiration","content":"Complex AI tasks are too big for a single model. Current platforms force you to pick one model or pay a higher price, even when a different task would run faster and cheaper elsewhere.\n\nAgora decomposes complex tasks (e.g., ‚Äúanalyze this document, summarize it, and generate visuals‚Äù) into subtasks, matches each to the right specialized agent from a global marketplace, and runs them efficiently at lower cost with better results."},{"heading":"What it does","content":"Agora is an AI agent marketplace with task orchestration that splits complex tasks into subtasks, matches and routes them to cost-efficient agents (OpenAI, Anthropic, Llama, Stable Diffusion, etc.), and executes them in parallel.\n\nFor clients:\n\nNatural-language task input (e.g., ‚Äúanalyze this data, create a report, and generate supporting images‚Äù) Automatic cost estimation before execution Pay per completed subtask (no subscriptions) Transparent agent selection with pricing\n\nFor agents/creators:\n\nList models on the marketplace Set prices Track performance metrics Receive payments via Sui escrow smart contracts\n\nTechnical features:\n\nClaude-based orchestration (task decomposition + agent matching) Multi-model routing (text, vision, audio, code generation) Cost estimation and energy metrics Blockchain payments via Sui (Lava Payments integration) Real-time execution tracking"},{"heading":"How we built it","content":"Frontend:\n\nNext.js 16 (App Router) React 19 Tailwind CSS v4 Radix UI GSAP and Framer Motion Sui dApp Kit for wallet connections\n\nBackend & Infrastructure:\n\nSupabase (PostgreSQL + Auth + Row-Level Security) Claude API (Anthropic) for orchestration Next.js API routes (task decomposition, agent matching, execution) Lava cost calculation with usage tracking\n\nDatabase Schema:\n\nprofiles (users) agents (marketplace agents) tasks (orchestration plans with subtask/agent mapping) subtasks (individual pieces) task_executions (results and costs) agent_performance (metrics)\n\nOrchestration Logic:\n\nClaude decomposes a task into subtasks Match each subtask to available agents by category/cost/performance Calculate total cost Execute subtasks in parallel where possible Aggregate results\n\nBlockchain Integration:\n\nSui smart contracts (Move) for payment escrow Lava Payments for fiat on/off-ramps Per-subtask payments with 2.5% platform fee Auto-release after deadlines or completion"},{"heading":"Challenges we ran into","content":"Task decomposition: making Claude‚Äôs subtasks structured and actionable Solution: Strict prompt engineering and output parsing Agent matching: scoring agents across cost, latency, and relevance Solution: Score-based ranking and fallbacks Smart contract gas fees and timing Solution: Deadline auto-release and dispute handling in contracts Supabase RLS: securing multi-tenant data Solution: Policies per table (users, agents, tasks) Cross-chain UX: bridging Sui and the main app Solution: Sui dApp Kit for consistent wallet flows"},{"heading":"Accomplishments that we're proud of","content":"End-to-end orchestration: decomposition ‚Üí agent matching ‚Üí execution tracking Real-time cost estimation with per-subtask breakdowns Blockchain payments: escrow on Sui with auto-release Production-ready Supabase schema with RLS policies Open ecosystem: HuggingFace integration and bring-your-own-models High-quality UI (animations, gradients, responsive)"},{"heading":"What we learned","content":"Orchestrators are bottlenecks; minimize LLM calls and memoize outputs when possible Unit testing is critical for agent matching, cost calculations, and smart contract flows On-chain costs add up: optimize UX to reduce transactions User trust needs transparency: show pricing, agent choice, and execution status in real time"},{"heading":"What's next for Agora","content":"Phase 1 (Launch Q1 2025):\n\nPayment flow with Lava Agent authentication/endpoints Execute real models (not mock)\n\nPhase 2 (Q2 2025):\n\nMobile app (React Native) Multi-token support Agent analytics dashboard Notification system\n\nPhase 3 (Q3 2025):\n\nAutonomous agent discovery and registration Agent chaining for multi-step workflows Community ratings Agent A/B testing\n\nLong-term vision:\n\nDecentralized network where models provide compute and get paid automatically Create an agent once and generate passive income Enable any developer to deploy specialized AI\n\nGrowth strategy:\n\nLaunch with 100 HuggingFace models Offer free credits to early users Incentivize top creators with higher revenue shares Expand to mainnet once testnet is stable"},{"heading":"Built With","content":"css javascript move plpg shell sql typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Why waste time say lot word when few word do trick?","project_url":"https://devpost.com/software/why-waste-time-say-lot-word-when-few-word-do-trick","tagline":"Real-time conversation assistant with AI-powered response suggestions and emotional state analysis","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/886/970/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Lava: Best Use of Lava Gateway"}],"team_members":[],"built_with":[{"name":"elevenlabs","url":null},{"name":"fastapi","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"lava","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ianalin123/few-word-do-trick"}],"description_sections":[{"heading":"Inspiration","content":"‚ÄúWhy waste time say lot word when few word do trick.‚Äù ‚Äî Kevin Malone, The Office .\n\nKevin might‚Äôve been joking, but for many people with speech impediments or communication challenges, saying fewer words can actually make communication smoother, faster, and more accessible. We wanted to build something that not only helps people communicate, but also helps them express their personality and emotion . Because real communication isn‚Äôt just about words ‚Äî it‚Äôs about who you are ."},{"heading":"What it does","content":"Few Words Do Trick is an assistive communication platform designed for people with speech impediments or expressive communication difficulties. Unlike traditional AAC (Augmentative and Alternative Communication) tools that focus purely on transmitting speech, our system adds an emotional and personalized layer using real-time EEG emotion detection and MBTI-based personality modeling .\n\nFrom previous research, giving LLMs a persona using the MBTI framework boosts their conversational intelligence by 17‚Äì22% . Thus, our system integrates emotional signals from the user‚Äôs EEG headset with their personality profile to generate responses that are not only faster and clearer but also more natural and authentic to who they are.\n\nThis creates a communication experience that feels genuinely human ‚Äî reflecting tone, mood, and individuality ‚Äî rather than robotic or generic. By combining neuroscience, machine learning, and personality theory, Few Words Do Trick bridges the gap between accessibility and emotional expression, helping users communicate efficiently and meaningfully in real time."},{"heading":"How we built it","content":"Our system runs on three main layers: Signal and Emotion Processing , Intelligent Backend , and Frontend Experience .\n\nThe Signal and Emotion Processing Layer integrates the EEG headset, applies Fourier Transforms and temporal smoothing, and performs emotion classification using power spectrum density analysis and a Random Forest Classifier model.\n\nThe Intelligent Backend Layer handles speech-to-text and sentence generation using Lava and OpenAI‚Äôs GPT-5, as well as text-to-speech synthesis with ElevenLabs (more specifically, Whisper model) for customizable, emotion-aware voices. It‚Äôs built with FastAPI and Pydantic for validation, with Vite ensuring a smooth connection between the backend and frontend.\n\nThe Frontend Experience Layer is built with React and NGROK tunneling. It features a MBTI personality quiz, real-time EEG and voice visualization, and a voice customization dashboard using the ElevenLabs API. The UI is designed to be simple, intuitive, and a little fun ‚Äî keeping accessibility at the center."},{"heading":"Challenges we ran into","content":"We faced several challenges throughout development. Microphone and EEG data access proved difficult without deployment, and collecting consistent EEG signals for model training required plenty of creative ‚Äúmethod acting‚Äù to simulate emotional states.\n\nIntegrating detected emotions into the real-time speech output pipeline was complex, and setting up a server to merge MBTI personality data with generated responses added another layer of difficulty. On top of that, we had to design a user interface that felt approachable, expressive, and even enjoyable to use."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud to have achieved 90% confidence in our emotion classification using EEG data, as well as successfully integrating multiple APIs across the frontend and backend. We built a fully functional real-time emotion-to-speech pipeline and developed personalized, expressive voice outputs that feel human and authentic.\n\nMost importantly, we built something that makes communication more natural and personal ‚Äî a system that doesn‚Äôt just speak for you, but speaks like you."},{"heading":"What we learned","content":"We learned how to process and classify EEG signals in real time, integrate emotional intelligence into speech systems, and design with empathy in mind. We also realized how vital personalization is in communication ‚Äî even when powered by AI.\n\nAnd of course, we learned that Kevin Malone‚Äôs wisdom can be surprisingly relevant at a hackathon."},{"heading":"What's next for Why waste time say lot word when few word do trick?","content":"Looking ahead, we plan to expand Few Words Do Trick into a tool for everyday use by integrating portable EEG hardware and refining our emotion models with larger datasets. We also hope to add multilingual and cultural context support and eventually release it as an open-source assistive communication platform.\n\nOur goal is to bridge technology and empathy to help everyone express themselves ‚Äî because sometimes, the fewest words make the biggest difference."},{"heading":"Built With","content":"elevenlabs fastapi javascript lava openai python react vite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Poke SDR","project_url":"https://devpost.com/software/poke-sdr","tagline":"AI sales assistant you text like a coworker. 6 MCP tools handle enrichment, emails, and actions. Lava's multi-model routing cuts costs 80% - proving AI SaaS can be profitable from day 1.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/248/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Lava: Best Use of Lava Gateway"}],"team_members":[],"built_with":[{"name":"fastmcp","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"langchain","url":null},{"name":"lavapayments","url":null},{"name":"ngrok","url":null},{"name":"openai","url":null},{"name":"poke","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react18","url":null},{"name":"render","url":null},{"name":"sqlite","url":"https://devpost.com/software/built-with/sqlite"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/araikar08/poke-sdr"}],"description_sections":[{"heading":"Inspiration","content":"Every founder at Cal Hacks has the same problem: AI is expensive, and SDR tools are even worse. Cold email platforms charge $200+/month while burning through expensive GPT-4 calls. We asked ourselves: What if we could build an AI sales assistant that's actually profitable from day 1?\n\nThat's where Lava Build's multi-model routing changed everything. Instead of blindly sending every request to GPT-4o at $5/1M tokens, we could route simple tasks to GPT-4o-mini at $0.15/1M tokens (33x cheaper!) while keeping complex enrichment on GPT-4o. This unlocked 80% cost savings and turned AI SaaS from a pipe dream into a viable business.\n\nWe paired this with Poke's MCP integration to create a conversational interface - no dashboards, no clicking, just text your AI SDR like you'd text a coworker."},{"heading":"What it does","content":"Poke SDR is a conversational AI sales assistant you control entirely through text messages. It exposes 6 MCP (Model Context Protocol) tools that Poke's AI automatically routes based on your natural language:\n\nadd_lead() - Add leads via text: \"add lead john@startup.io met at Cal Hacks\" enrich_contact() - AI-powered profile enrichment with company, title, context draft_cold_email() - Generate personalized cold emails using enriched data suggest_action() - Get next best action based on lead stage and context search_leads() - Full-text search across your pipeline get_billing() - Real-time cost analytics showing per-lead COGS, margins, and Lava savings\n\nEvery operation is tracked in a persistent SQLite database with real-time cost monitoring. The dashboard shows:\n\n79 real Lava API calls (verified in screenshot) $0.12 actual cost from Lava routing 27 leads processed with full enrichment pipeline 99.97% gross margins at $10/month SaaS pricing\n\nThe business case is simple: $10/mo revenue √ó $0.0028 COGS = sustainable, profitable AI SaaS."},{"heading":"How we built it","content":"Backend (MCP Server):\n\nFastMCP v2.12.5 - Python framework for Model Context Protocol servers Lava Build - Multi-model routing proxy that intelligently routes requests: GPT-4o ($5/1M tokens) for enrichment + email drafting GPT-4o-mini ($0.15/1M tokens) for action suggestions Result: 80% cost reduction vs. GPT-4o-only LangChain - OpenAI client configured to route through Lava's forward API SQLite - Persistent database with two tables: leads - Email, name, company, title, stage, context, enrichment status ai_costs - Per-operation cost tracking (operation,model, tokens, cost)\n\nFrontend:\n\nPoke - Conversational MCP interface (configured via HTTP endpoint) React + TypeScript + Vite - Dashboard showing pipeline and cost metrics Tailwind CSS - Modern UI with real-time cost tracking\n\nInfrastructure:\n\nRender - Deployed MCP server at https://poke-sdr-mcp.onrender.com/mcp GitHub - Version control and collaboration\n\nKey Architecture Decision: Instead of chaining MCP tools (which fails - tools aren't callable Python functions), we made each tool standalone. Poke's AI decides which tool to call based on user intent, making the conversation feel natural."},{"heading":"Challenges we ran into","content":"MCP Tool Chaining Error Early on, we tried to auto-trigger enrich_contact() when adding a lead. This failed with \"FunctionTool object is not callable\" because FastMCP wraps tools for the protocol - they're not regular Python functions. Solution: Made each tool standalone and let Poke's AI orchestrate the workflow. Cost Tracking Accuracy We needed to track costs per operation in real-time, but different models have different pricing. Solution: Built a track_ai_cost() function that logs every LLM call with operation type, model, tokens, and calculated cost to the database. This enabled the get_billing() tool to show real business metrics. Database Connection Management Hit \"Cannot operate on a closed database\" when querying lead counts after closing the SQLite connection. Solution: Reorganized query order to execute all database reads before calling conn.close(). Multi-Model Routing Strategy Deciding which operations deserve GPT-4o vs. GPT-4o-mini was critical for cost optimization. Solution: Complex tasks (enrichment, emails) ‚Üí GPT-4o for quality Simple tasks (suggestions, summaries) ‚Üí GPT-4o-mini for cost Tracked everything to prove 80% savings"},{"heading":"Accomplishments that we're proud of","content":"‚úÖ 79 real Lava API calls tracked in production (see dashboard screenshot) ‚úÖ $0.12 actual cost vs. estimated $0.60 without routing = 80% savings ‚úÖ 6 fully functional MCP tools tested end-to-end via Poke ‚úÖ Persistent database with 27+ leads and complete audit trail ‚úÖ 99.97% gross margins proven with real cost data ($0.0028 COGS/lead) ‚úÖ Real-time cost tracking showing exactly where every penny goes ‚úÖ Conversational workflow - no dashboards needed, just text\n\nThe killer metric: At $10/month SaaS pricing, we have $9.9972 profit per customer thanks to Lava's routing. That's not a demo stat - that's a real business."},{"heading":"What we learned","content":"Multi-Model Routing is a Game Changer We didn't appreciate how much Lava's intelligent routing could save until we tracked real costs. The 33x price difference between GPT-4o and GPT-4o-mini means the right routing strategy is the difference between profitable and unprofitable SaaS. MCP Protocol is Powerful but Different Model Context Protocol isn't just an API wrapper - it's a conversational paradigm shift. Tools can't call each other; the LLM orchestrates the workflow. This forced us to think about UX differently and actually made the product better. Cost Transparency Builds Trust Showing users exactly how much each operation costs ($0.0025 to enrich, $0.0003 to suggest action) builds incredible trust. Customers want to know their AI tools aren't bleeding money. Hackathon MVPs Need Real Metrics Mock data is fine for enrichment APIs, but real cost tracking and real Lava usage (79 API calls) make the difference between a toy and a product."},{"heading":"What's next for Poke SDR","content":"Near-term (next 2 weeks):\n\nIntegrate real enrichment APIs (Clearbit, Apollo, ZoomInfo) Add batch operations - enrich all leads, draft emails for entire pipeline Build analytics dashboard - conversion rates, pipeline velocity, ROI tracking Implement Poke voice interface - truly conversational sales assistant\n\nLong-term (6 months):\n\nMulti-channel outreach - LinkedIn, email, SMS orchestrated via conversation AI-powered lead scoring - Prioritize high-value leads using GPT-4o analysis CRM integrations - Sync with Salesforce, HubSpot, Pipedrive Team collaboration - Shared pipeline with role-based access Advanced routing - Use Lava to route based on lead value (cheap models for cold leads, expensive models for hot prospects)\n\nThe vision: Every founder should have an AI SDR that's smarter than a human, costs less than coffee, and actually makes them money. Lava's routing makes this economically viable. Poke's conversational interface makes it delightful to use."},{"heading":"Built With","content":"fastmcp github langchain lavapayments ngrok openai poke python react18 render sqlite tailwind typescript vite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Iris","project_url":"https://devpost.com/software/iris-ojrmnv","tagline":"Changing lives, one blink at a time :)","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/906/503/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Crater: Play-Do Prize"}],"team_members":[],"built_with":[{"name":"electron","url":"https://devpost.com/software/built-with/electron"},{"name":"eyetrax","url":null},{"name":"fastapi","url":null},{"name":"git","url":"https://devpost.com/software/built-with/git"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"kalman","url":null},{"name":"letta","url":null},{"name":"letta-client","url":null},{"name":"letta-cloud","url":null},{"name":"manifest-v3","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pydantic","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tensorflow-lite","url":null},{"name":"uvicorn","url":null},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"},{"name":"windsurf","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/tgondil/iris"}],"description_sections":[{"heading":"Inspiration","content":"Iris takes action for those who cannot. People with paralysis, as well as those in hands-free situations like surgeons, chefs, and mechanics, can all benefit from a browser that truly listens. Even in cases of severe paralysis, eye movement often remains one of the few ways people can still interact with the world. That simple truth inspired us to build Iris.\n\nOne of our teammates has a family member who lost feeling in their hands. Watching them navigate a webpage using only their eyes reminded us that accessibility is not a feature, it is freedom."},{"heading":"What It Does","content":"Hands-Free Control Using Eye Tracking, Voice, and AI\n\nReal-time gaze tracking highlights elements you look at Voice commands fill in text fields and control navigation AI agent predicts and executes your next action Works universally on any webpage without modifications Learns personal preferences over time (such as name, email, or address) Eye gestures enable clicks, tab switching, and scrolling\n\nIris transforms the web into an adaptive, intelligent interface that moves at the speed of your gaze."},{"heading":"How We Built It","content":"Real-Time Eye Tracking with Machine Learning Models\n\nWe trained and deployed custom regression models (SVR, Ridge, Elastic Net, and a Tiny MLP) to predict gaze position from real-time webcam input. Combined with optimized OpenCV and MediaPipe pipelines, Iris achieves sub-100ms latency for seamless visual control.\n\nAdvanced Kalman and KDE Filtering Pipeline\n\nRaw eye data is noisy. To stabilize motion, we implemented a Kalman filter for trajectory prediction and a Kernel Density Estimation (KDE) layer for adaptive smoothing. This multi-stage filter stack eliminates jitter and enables natural cursor flow.\n\nMulti-Modal Calibration System\n\nCalibration defines precision. Iris supports five- and nine-point calibration as well as continuous Lissajous-curve calibration, dynamically adjusting accuracy during runtime based on user behavior.\n\nWebSocket-Based Real-Time Gaze Streaming\n\nThe Python backend streams gaze coordinates to the Chrome Extension through WebSockets with continuous synchronization and auto-recovery. Every blink, movement, and pause is captured and reflected instantly.\n\nChrome Extension with DOM Element Snapping\n\nIris detects DOM elements under gaze coordinates using a visual feedback system that highlights what you are looking at. Elements snap smoothly under the cursor through adaptive interpolation and dwell-time confirmation.\n\nHybrid Speech Recognition System\n\nWe combined Whisper.cpp (for local inference) with Vosk for fast, privacy-friendly transcription. The Electron-based speech service handles real-time dictation, enabling continuous speech-to-text input and command execution.\n\nLetta Agent Integration with Browser Actions\n\nLetta serves as Iris‚Äôs cognitive layer, a memory-driven agent that interprets voice commands and gaze context to perform browser automation such as form filling, navigation, and clicking.\n\nVirtual Keyboard with Gaze and Voice Input\n\nUsers can type without hands using a multimodal keyboard that combines gaze focus detection (via Swift native helpers) and speech recognition for character input across applications.\n\nSwift Native Focus Watcher\n\nA macOS-native accessibility bridge detects active text fields and injects text directly into system-level inputs, allowing Iris to operate beyond browsers, across any desktop application.\n\nCustom Gaze Auto-Scroll System\n\nLooking near the edge of the screen triggers smooth auto-scrolling, controlled by gaze velocity and viewport position. It feels less like commanding a browser and more like moving through space.\n\nElement Highlighting with Adaptive Colors\n\nEvery highlight adjusts dynamically for contrast and readability using CSS-injected adaptive color algorithms, ensuring accessibility in any theme or website layout."},{"heading":"Challenges We Ran Into","content":"Our original plan was to use EEG signals for click gestures, but hardware delays forced a pivot toward eye and voice input. That shift was tough mid-hackathon, but it ultimately led to a more stable, scalable, and accessible foundation.\n\nBalancing real-time performance with accuracy was another major hurdle. Building a smooth filtering pipeline required countless iterations and fine-tuning."},{"heading":"Accomplishments We‚Äôre Proud Of","content":"Achieved sub-100ms gaze latency for real-time interaction Built a universal browser integration that works without page modifications Implemented a memory-driven Letta agent for context-aware actions Designed a multi-stage filtering and calibration pipeline that rivals research-grade setups"},{"heading":"What We Learned","content":"Filtering is everything. Raw gaze data is unusable without strong temporal smoothing. Calibration defines trust. If the system drifts even slightly, users lose confidence. Accessibility inspires innovation. Designing for people with disabilities makes technology better for everyone."},{"heading":"What‚Äôs Next for Iris","content":"Integrate EEG input for hybrid mind-eye control Expand Letta agent templates for scalability Extend native support beyond browsers to all operating systems Partner with accessibility foundations to deploy Iris at scale Empower millions of users with motor disabilities to regain independence"},{"heading":"Built With","content":"electron eyetrax fastapi git javascript kalman letta letta-client letta-cloud manifest-v3 node.js numpy opencv pydantic python tensorflow-lite uvicorn websockets windsurf"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Githired","project_url":"https://devpost.com/software/githired","tagline":"Git-Hired uses AI to analyze real GitHub activity ‚Äî projects, commits, and code quality ‚Äî to show startups who‚Äôs genuinely skilled. We replace r√©sum√©s and traditional coding tests with proof of work.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/898/894/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Composio: Best Use of Composio Toolrouter"}],"team_members":[],"built_with":[{"name":"brightdata","url":null},{"name":"chromadb","url":null},{"name":"claude","url":null},{"name":"letta","url":null},{"name":"nextjs","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"www.githired.tech","url":"https://www.githired.tech/"}],"description_sections":[{"heading":"Inspiration","content":"Most startups don‚Äôt care how well you solve a random algorithm problem ‚Äî they care how quickly and effectively you can ship real code. But today‚Äôs hiring tools still test engineers in ways that say nothing about how they actually build. That‚Äôs why we built Git-Hired ‚Äî the future of hiring developers."},{"heading":"What it does","content":"You create a smart application form and share it anywhere ‚Äî LinkedIn, Handshake, your own site. Our AI turns every application into a live portfolio that analyzes real commits, filters out filler pushes, and ranks candidates based on true technical ability. If you like what you see, send them a coding assessment that mimics how developers really work ‚Äî with AI as a co-pilot. Yes, we allow the use of AI during our assessments, because let's be real- nobody actually writes each and every line of code manually anymore!"},{"heading":"How we built it","content":"Frontend: Next.js, React, TypeScript, Node.js Backend: Python, FastAPI, Bright Data, GitHub REST API, ChromaDB, Elastic Search for semantic embeddings AI + Analytics: Custom GitHub analyzer, NLP-based code parsing, contribution heatmaps, AI Coding assistant in Letta Cloud with memory"},{"heading":"Challenges we ran into","content":"Parsing GitHub data reliably across different repo structures Avoiding false positives when evaluating commit quality Building an AI assistant that helps ‚Äî without handing out answers Integrating multiple APIs and ensuring real-time updates"},{"heading":"Accomplishments that we're proud of","content":"Fully functional end-to-end AI hiring workflow GitHub data --> live portfolio generation Smart rankings that surface best-fit developers AI-assisted coding assessments integrated directly into the platform"},{"heading":"What we learned","content":"The best developers don‚Äôt always have the best resumes AI can be a powerful equalizer when used ethically Real-world hiring problems need more empathy and context than just code"},{"heading":"What's next for Githired","content":"Expand analysis beyond GitHub (LeetCode, Stack Overflow, etc.) Add recruiter dashboards with performance insights Build candidate feedback + improvement analytics Launch beta with partner startups and university recruiters"},{"heading":"Built With","content":"brightdata chromadb claude letta nextjs python react typescript vercel"},{"heading":"Try it out","content":"www.githired.tech"}]},{"project_title":"MemARy","project_url":"https://devpost.com/software/memary","tagline":"MemARy: AR Glasses for Alzheimer's. See, hear, remember.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/646/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Snap: Best Use of Snap Spectacles"}],"team_members":[],"built_with":[{"name":"chatgpt","url":null},{"name":"chromadb","url":null},{"name":"fastapi","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"lensstudio","url":null},{"name":"livekit","url":null},{"name":"llama","url":null},{"name":"pokemcp","url":null},{"name":"postman","url":"https://devpost.com/software/built-with/postman"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"reka","url":null},{"name":"snapar","url":null},{"name":"spectacle","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/AmaanBilwar/memARy"}],"description_sections":[{"heading":"Inspiration","content":"Over 7 million Americans over 65 live with Alzheimer‚Äôs today, a number set to double by 2060. 1 in 9 older adults already face fading memories, and by 85, that risk climbs past 1 in 3. But memory loss isn‚Äôt inevitable, it‚Äôs a gap in design.\n\nWe‚Äôre building MemARy, an AI wearable that sees what you see, hears what you say, and remembers what matters.\n\nSince most old people already wear glasses, why not wear it like Tony Stark.\n\nAnd for every Tony Stark who never forgets, MemARy will be the Jarvis for billions."},{"heading":"What it does","content":"Memary is an AI-powered wearable interface that transforms visual and auditory inputs into structured, retrievable memory. Every few seconds or for every trigger (button press or saying the word, the device captures a frame from the user‚Äôs perspective, processes it through Reka's vision language model to extract semantic information: objects, spatial relations, colors, and contextual cues, and encodes that data into vector embeddings stored in a ChromaDB-based memory system.\n\nUsers can interact with Memary through natural language, either by voice or text, to recall or store information, such as where they left important items. The system retrieves semantically relevant entries using vector similarity search, merges them with timestamped metadata, and returns precise and context-aware responses.\n\nMemary‚Äôs pipeline combines computer vision, LLM-based scene summarization, semantic embedding, and memory indexing, creating a continuous cognitive layer that enables human-like recall through AI."},{"heading":"How we built it","content":"We engineered Memary as a modular, microservice-based system combining real-time perception, semantic understanding, and long-term memory storage. Using SnapAR and Lens Studio, we integrated our AI pipeline directly with Snap Spectacles, enabling the glasses to capture image frames, visualize UI for memory recall, and stream them to our backend. Each frame is processed by Reka‚Äôs Llama Vision Model, which generates a structured natural language summary that identifies objects, positions, specific characteristics, and contextual cues.\n\nThe summaries are then embedded and stored in ChromaDB, our vector database layer, which enables high-speed semantic retrieval using cosine similarity. A FastAPI service mediates all data ingestion and querying, ensuring clean abstraction and multi-tenant control. On the client side, a React frontend provides the user interface for memory review and session selection along with memory dashboards, while PokMmCP powers semantic queries and synchronization between the phone and glasses.\n\nWe also integrated LiveKit for low-latency speech-to-text processing, allowing users to add or recall memories through natural voice interaction. Together, this stack forms a continuous AI memory loop that enables real-time recall, just like having a grandmaster-level memory.."},{"heading":"Challenges we ran into","content":"Complex idea in a short timespan, the documentation of SnapAR being quite the challenge but rewarding at the end, rigorous execution websocket approach to video and audio input into the Spectacle device"},{"heading":"Accomplishments that we're proud of","content":"Our idea, being broken down into smaller work functions, that when combined together as a group of microservices, produces an efficient and synergized product."},{"heading":"What we learned","content":"Twinkling with a whole new development and product architecture in Snap Spectacles, the use of fabulous technologies by the sponsors that leveled up our production quality, and most importantly, thoughtful discussions makes complex missions possible."},{"heading":"What's next for memARy","content":"Make it adaptable in any contextual use and eventually go beyond the market of old people with Alzheimer to everyone that does not want to forget anything, ever."},{"heading":"Built With","content":"chatgpt chromadb fastapi gemini lensstudio livekit llama pokemcp postman python react reka snapar spectacle typescript vercel"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"BallAR","project_url":"https://devpost.com/software/ballar","tagline":"Unite AR and electro-stimulation to perfect your beer pong game.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/900/071/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Snap: Best Use of Snap Spectacles"}],"team_members":[],"built_with":[{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"esp32","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"lensstudio","url":null},{"name":"snapchatspectacles","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/YetSquire/BallAR"}],"description_sections":[{"heading":"Inspiration","content":"While our hackathon team is less Greek Life and more Geek Life, we recognize the utility, hilarity, and surprising difficulty of the game ‚ÄòBeer Pong‚Äô. This party game requires precise hand-eye coordination, inter-team collaboration, and strategic planning. It is also frequently played in dim conditions and under various forms of impairment, meaning that participants can use all the help they can get. With that in mind, we developed BallAR, an augmented reality (AR) tool developed on Snap Spectacles paired with electro-stimulation pads so users can practice their aim, receive assistance during matches, and even have our experience flex their beer-pong muscles for them."},{"heading":"What it does","content":"BallAR has a physical and an AR component.\n\nThe physical component is centered around electro-stimulation sensors that are actuated via an Arduino, relay module, and ESP 32 module. When the user wishes to launch the ball, the electro-simulation sensors hooked up to the user‚Äôs arm will actuate certain sensors in a timed fashion through the relay module.\n\nThe AR component is built for Snap Spectacles. The primary functionality of this experience is to create a spatial UI that draws an optimal ping-pong ball shot from the user‚Äôs hand to a single red solo cup. The user‚Äôs hand is tracked via the Snap Lens Studio Interaction Manager, which serves as one end of the ideal trajectory. The other end is defined differently based on the two primary modes, single-cup and multi-cup. In single-cup mode, the user can click a spatial button to take a photo for Gemini to analyze. Using the returned XY coordinate and the Z depth coordinate created by the depth mapping during the photo, we can define a 3D coordinate that represents the endpoint of a ping-pong ball‚Äôs ideal trajectory. In multi-cup mode, the user is able to place and adjust a predefined triangular object representing the 10-cup arrangement of a Beer Pong game. This object maps onto flat surfaces initially, but after placement can be physically moved to any location in 3D space, depending on the user. The user can then dynamically select a cup to aim for, which will serve as the next target.\n\nFinally, the AR component also connects to the electrostimulation component via BLE, and offers a few levels of protection when it comes to the initiation of said component. Because the stimulation has the potential to adversely affect the user, we placed high priority on ensuring that the experience would be difficult to accidentally trigger. Before anything could begin, our electrostimulation UI was locked behind the acknowledgement of a successful connection from both parties (Snap Spectacles and ESP32 Microcontroller). After this, a safety button would be enabled, which needs to be fully pressed in order to enable the electrostimulation fire button, which would in turn, after being pressed, reenable safety and hide the fire button."},{"heading":"How we built it","content":"The snap lenses send a message over bluetooth to the Arduino. This causes the Arduino to activate certain muscles with the electric sensors. To better develop a user‚Äôs ability to throw consistently we have a relay module to time the moment we actuate the user‚Äôs muscles. This timing ensures that we are able to separate the general throwing motion from the motion we use to release the ball.\n\nThe user interface and cup detection was developed through Lens Studio in TypeScript. We used the Gemini API to allow us to detect the beer pong cups and use a lightweight trajectory analysis algorithm to derive a realistic trajectory for the user to aim for. The algorithm for this trajectory was inspired by research conducted around the optimal trajectory for basketball free throws. We followed a similar methodology where given the initial positions and target positions, we perform a series of frame translations to arrive at a 2D projection, fit a parabolic arc, and translate it back into the world frame which the glasses operate in. The arc was derived from conducting a series of video analysis to analyze the trajectory of the ball observed in a simulated game of beer pong."},{"heading":"Challenges we ran into","content":"From the very start, BallAR was defined by overcoming challenges and rethinking plans. Our team‚Äôs initial concept was a Basketball trainer in AR (we aim to see the Golden State Warriors immediately after this hackathon). However, two factors led to us reconsidering: first, we found an existing Snap Spectacles Basketball trainer experience. Second, after testing with our electrostimulation technology, we found that the amount of electricity required to launch a basketball (via activating the tricep and wrist muscles) would cause irritation and discomfort. However, after brainstorming, we were able to pivot and buy some red solo cups and halloween themed ping-pong balls to pursue a different iteration of BallAR!\n\nFurthermore, we, alongside all of CalHacks, quickly came into contact with connectivity problems onsite. A poor initial internet connection led to a mass adoption of hotspot activity, which in turn decreased internet quality. The prisoner‚Äôs dilemma was in full force, and our team decided that the best solution would be to purposefully avoid the transmission of large amounts of data over wireless networks within our project. Our systems were built to be as independent as possible, with only an images‚Äô worth of an API call and a small string sent via BLE necessary for a single runthrough of BallAR. This kind of redundancy and system safety was a novel but interesting challenge as we prototyped our experience."},{"heading":"Accomplishments that we're proud of","content":"BallAR, despite its funny use case, combines the areas of anatomy, electrical engineering, firmware development, physics, game design, and augmented reality development for a smooth, cohesive experience. This project demonstrates our team‚Äôs ability to pull together knowledge from various sources of personal experience and learn new skills quickly, putting together several self-contained but mutually reinforcing components. Our ability to rapidly and successfully integrate our initial independent work (as compared to prior hackathon experiences) indicates not only that we understood one another as we converged and diverged, but also that we understood the project and its overall goals‚Äì a critical skill in school and in society."},{"heading":"What we learned","content":"Broadly, this hackathon made our team realize the critical importance of connectivity both in terms of our project scope and our ability to iterate and develop. Unstable internet, while not crippling, in practice greatly limited the API and toolcalling ability of our project, as we wished to offer a live demo during judging. Our team learned to brainstorm around such fundamental challenges, and quickly developed a habit of using AI not within our experience, but instead to augment our research to overcome the problems we were seeing.\n\nBeyond internet issues, our team was able to learn tremendous amounts of seemingly disconnected information in order to apply it to our final product. From anatomy (an understanding of musculature was necessary for proper electrostimulation) to physics (the algorithm used for ping-pong ball targeting needed to be grounded in reality) to stateful programming (AR design is much like game design, in that sense). We grew in all these fields, either directly learning or indirectly hearing about difficulties overcome."},{"heading":"What's next for BallAR","content":"BallAR, at the moment, is a very one-size-fits-all experience. Individuals can customize left-and-right handedness, but we offer no way to calibrate aspects such as average ball velocity or electrostimulation sensitivity within the experience itself. While our team was able to avoid this problem during demos by manually adjusting, in the future we could add further customizability to both the AR and stimulation components of our experience."},{"heading":"Built With","content":"arduino esp32 gemini lensstudio snapchatspectacles typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"PotBot","project_url":"https://devpost.com/software/potbot","tagline":"Turning one photo into civic action","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"SnapDev"}],"team_members":[],"built_with":[{"name":"brightdata","url":null},{"name":"fastapi","url":null},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"nextjs","url":null},{"name":"playwright","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"supabase","url":null},{"name":"twitter","url":"https://devpost.com/software/built-with/twitter"}],"external_links":[],"description_sections":[{"heading":"Built With","content":"brightdata fastapi groq javascript nextjs playwright python react supabase twitter"}]},{"project_title":"Curserve","project_url":"https://devpost.com/software/curserve","tagline":"Introducing Curserve: a fast and scalable server-side engine for agentic coding.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/890/197/datas/medium.gif","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Crater: Play-Do Prize"}],"team_members":[],"built_with":[{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"qwen","url":null},{"name":"rust","url":"https://devpost.com/software/built-with/rust"},{"name":"shell","url":"https://devpost.com/software/built-with/shell"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vast","url":"https://devpost.com/software/built-with/vast"},{"name":"vllm","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/alexkranias/curserve"}],"description_sections":[{"heading":"Inspiration","content":"We recently read about Cognition‚Äôs latest models, SWE-grep and SWE-grep-mini ( https://cognition.ai/blog/swe-grep ) and were really excited by the sheer throughput the team was able to achieve on these new fine-tuned LLMs (over 2000 tps!). It made us naturally envision a future where we‚Äôve optimized inference to be so fast that agentic coding isn‚Äôt bottlenecked by LLM throughput, but rather, by the system and network latency overhead the is inherited with the current system architecture.\n\nWe determined that the modern agentic coding paradigm, where user‚Äôs codebases exist locally on as a client and the LLM inference is served remotely on a server, concedes vast amounts of performance due to high network latency overhead incurred from the frequent back-and-forth communication they perform,\n\nIn an ideal world, all users could own their own H100s and host their own coding models locally. However, this is impractical, and uneconomical. What we need to do is create a fast and scalable framework for models to still be served on servers, but also allow users to experience most of the performance benefits of having their own datacenter class GPUs locally.\n\nWe identify two key insights that inform the design of our system:\n\n1) To eliminate network latency overhead, we must co-locate both the codebases and our compute\n\n2) Having only a single user on a remote server is a poor utilization of compute resources. An ideal system should, similar to vLLM, be able to effortlessly scale multiplexing compute resources (memory, GPUs, etc.) to new users.\n\n3) As the number of coding agents per machine increases, the number of tool calls made will also further increase. Rather than spinning up new processes with each call a more scalable solution is to create a persistent background service that receives requests from client processes to do grep, ls, etc. and handle the functionality of the common commands without actually needing new processes\n\nFor those familiar with operating systems concepts, making tool calls (aka creating a new grep, ls, find process) is akin to making a syscall. It forces the currently running process to preempt itself, causing a context switch to a new process flushing the TLB and losing a lot of Addressing #1: IPC.We perform interprocess communication (IPC) between our (potentially many) qwen-code-ipc clients, and our mem_search_service, in order to eliminate process creation overhead associated with each shell command an agent may make. We created a custom daemon (background process) to run on a server. Our service uses a custom library we created, where we developed pseudo-shell commands that operate directly on memory mapped files. For the purposes of the hackathon, we implemented ripgrep one of the more time consuming, and frequently used shell commands."},{"heading":"What it does","content":"Curserve essentially is a high-performance serving engine that enables hundreds of users to run coding agents simultaneously with near-zero latency for file operations. Instead of the traditional architecture where code lives on laptops and LLMs run remotely (causing constant network round trips for every grep/ls/cat command), Curserve co-locates everything: codebases, LLM inference, and search operations all live on the same server. Users SSH in and run a single command to start an AI coding session. Behind the scenes, a memory-mapped search service keeps all active codebases in RAM, allowing instant file operations without spawning shell processes. The system transparently intercepts the coding agent's filesystem calls and routes them through IPC to this blazing-fast in-memory service."},{"heading":"How we built it","content":"mem-search-service (Rust daemon)\n\nUses ripgrep's core libraries (grep-searcher, grep-regex) for proven search performance memmap2 for zero-copy memory-mapped file access Rayon for parallel search across CPU cores notify crate for real-time file change detection and auto-reload Simple API: alloc_pid(), ripgrep(), close()\n\nIPC Layer\n\nUnix domain sockets for sub-millisecond communication (~0.1ms vs network latency) JSON protocol for simplicity and debuggability Shared request socket + per-client response sockets\n\nModified Qwen-Code-CLI\n\nForked Qwen-Code-CLI and modified its tool layer to route calls to our daemon instead of spawning subprocesses Integration is easy for any Python-based agent. Could be done with minimum effort for other tools like Gemini CLI vLLM + Infrastructure\n\nDeployed Qwen2.5-Coder-32B-Instruct via vLLM for LLM serving\n\nRented an A100 GPU from vast.ai (~$0.63/hr) Co-located vLLM, mem-search-service, and user codebases on the same server, eliminating network latency entirely Users SSH in and run their own Qwen-Code-CLI instances, all sharing the same daemon Multi-tenant: one daemon serves many concurrent users"},{"heading":"Challenges we ran into","content":"We had countless challenges trying to wrangle designing and implementing this system, but here are some notable ones:\n\nWe had to fit the best open source coding agent we could into an affordable GPU. After settling on renting an A100, we found we would be able to fit a Qwen 30B coding model in the GPU‚Äôs 80gb of VRAM. However, we forgot to anticipate the model‚Äôs limits on the context window and had to settle on testing on medium size codebases with our model‚Äôs 64k tokens of context (though it was flaky, with the system crashing several times). Future iterations could serve better GPUs and models. We had to reverse engineer Qwen Code (which itself was based on gemini-cli) in order to replace grep tool calls with calls to our specialized searching process, and replace calls to the Chinese API to our hosted server. We faced numerous problems with syncing and hangs, but were able to work through them with the help of Cursor. Memory-mapped file invalidation: originally, we expected code modifications to be reflected in the file we memory-mapped because we had a pointer to the shared memory. However for VSCode and other editors, they don‚Äôt update files in place but actually overwrite the file, leaving a new copy, making our old file descriptor and memory-mapped file to now be invalid and stale. We implemented a service that watched for file system changes and remapped a file whenever a file was written to. We initially prototyped in Python with mmap + regex for the in-memory search operations, but for sparse queries on large repositories, our implementation underperformed compared to ripgrep. We wanted to match ripgrep's speed, so we rewrote it in Rust using ripgrep's internals to use ripgrep with in-memory files instead of using the filesystem API, which has unneeded overhead. The wifi at the event was terrible, so we went around SF to various public libraries and cafes. Wifi was a huge challenge at this event"},{"heading":"Accomplishments that we're proud of","content":"Our in-memory ripgrep implementation is up to 5-30x faster than the normal ripgrep implementation (requiring a process to spin up). The speedup varies widely based on the repository size and the specific query being made, but across all experiments it is more performant than the original approach. This is exacerbated even more when considering rollout generations with many tool calls because the memory mapping of the repository is only done once while every search operation after has quick access. We‚Äôre proud of making a system that works reliably even when the user has spotty network access (like this hackathon). By having the code and LLM in the cloud, once the user prompts the agent, the agent does not have any dependencies on the user‚Äôs computer. Unlike cursor which needs to run commands locally, our system reduces points of failure and security risks of running code on user‚Äôs devices. We designed a flexible full architecture that allows us to minimally modify any open source coding agent framework (like Qwen-Code CLI or Gemini CLI) to work with our server-side framework."},{"heading":"What we learned","content":"We learned a lot from this project. Here are a few mentions:\n\nWe also learned how to serve open source coding agents like qwen with modern tools like vLLM (popular LLM serving framework) and Vast.ai (GPU cloud aggregator for spot instances). We learned how to get the model to be deterministic for profiling, changing temperature to 0 and removing top-K sampling. We learned how to queue tool use tasks from hundreds of users on the server to a single specialized code-searching process. We learned how to use sockets for asynchronous interprocess communication."},{"heading":"What's next for Curserve","content":"Our next steps is to do system optimization. We want to speed up file reading by doing copyless reads. Client requests service to mmap file (pinned in physical memory) to the client‚Äôs virtual address space, rather than the client needing to copy the file contents. We want to Implement codebase paging and eviction policies when RAM limits are reached + Add speculative codebase prefetching (once RAM is full) based on and also optimize memory layout for common search patterns. In the future we also want to Support for distributed codebases across multiple servers as well as copy-on-write if a server is dedicated to many users working on the same repo (e.g. PyTorch team on Meta can use this to do fast coding on PyTorch with copies existing where git diffs diverge). We want to track how ‚Äúhot‚Äù specific files are. If files are frequently being written to. We don‚Äôt reconstruct the suffix tree, we just do boyer moore fast search."},{"heading":"Built With","content":"python qwen rust shell typescript vast vllm"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Wingman","project_url":"https://devpost.com/software/wingman-9xok8b","tagline":"Wingman uses Snap Spectacles to control a robot that moves, grabs, and sees where humans can‚Äôt by pointing to navigate, gesturing to grasp, and capturing 3D scenes through depth-sensing AR.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/899/992/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Snap: Best Use of Snap Spectacles"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"BitRobot Network: Best Robotics Hack - 3rd Place"}],"team_members":[],"built_with":[{"name":"fastapi","url":null},{"name":"snap","url":null},{"name":"websocket","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"During disasters and times of crisis, first responders often face an impossible choice: risk their lives to search for survivors or stay back and lose precious time. We wanted to eliminate that choice. Wingman was born from the idea that technology can extend human presence into unreachable worlds - using wearable AR to control a robot as naturally as moving your own body. Instead of doing things that humans can already do, we wanted Wingman to fill the gaps of our abilities."},{"heading":"What it does","content":"Wingman is a Snap Spectacles‚Äìcontrolled robot that brings human intuition into robotics. It combines three seamless functions:\n\nMove - Point to a location through the Spectacles‚Äô depth-sensing AR , and the robot autonomously navigates there. Grab - Use hand tracking to control the robot‚Äôs arm and gripper. Snapshot - Capture and explore 3D depth images of the environment, rotating views to reconstruct the scene virtually.\n\nTogether, these features allow people to move, manipulate, and visualize in places humans can‚Äôt safely go."},{"heading":"How we built it","content":"We integrated Snap Spectacles , AR world data , and robotic motion control through a low-latency pipeline:\n\nHardware: A mobile LeKiwi robot with a 6-DOF arm and gripper, paired with Snap Spectacles for spatial mapping, hand tracking, and 3D capture. Software: FastAPI + WebSocket for real-time communication. Snap Lens Studio API to extract hand-tracking data and AR anchors. OpenCV for vision processing and coordinate mapping. Three.js for 3D depth visualization. Inverse kinematics and path planning for smooth, intuitive arm control."},{"heading":"Challenges we ran into","content":"Achieving low-latency control between the Spectacles and the robot. Translating AR spatial anchors from Snap‚Äôs coordinate system into real-world robot coordinates. Maintaining precise gesture-to-motion mapping without drift or jitter. Synchronizing depth capture and 3D reconstruction for accurate spatial visualization."},{"heading":"Accomplishments that we're proud of","content":"Building a fully functional prototype that unites AR, robotics, and real-time control . Using Snap Spectacles not just for vision, but as a wearable interface for spatial movement, manipulation, and perception. Creating a 3D visualization system that reconstructs physical environments from depth snapshots. Designing an experience that feels more like collaboration with a companion than controlling a machine."},{"heading":"What we learned","content":"We discovered how powerful AR becomes when combined with robotics - not as a separate layer of information, but as a natural bridge between human intent and machine action. We also learned the importance of designing for intuition over complexity : when the interface feels human, the technology disappears, and the experience becomes seamless."},{"heading":"What's next for Wingman","content":"We plan to expand Wingman‚Äôs capabilities with:\n\nVoice commands (‚ÄúWingman, move to the doorway‚Äù or ‚Äúpick up the red object‚Äù). Autonomous exploration using SLAM and AI-driven scene understanding. Edge processing on Spectacles for faster local gesture interpretation. Multi-step planning for performing complex tasks from natural language.\n\nOur ultimate goal: make Wingman a universal telepresence assistant - a true wearable-controlled companion for exploration, safety, and discovery."},{"heading":"Built With","content":"fastapi snap websocket"}]},{"project_title":"PeerFund","project_url":"https://devpost.com/software/r-fund","tagline":"A decentralized peer-to-peer lending platform built on the XRP Ledger (XRPL), enabling university students and individuals to lend and borrow funds with transparent, blockchain-backed transactions.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/615/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ripple: Best Use of XRP Ledger"}],"team_members":[],"built_with":[{"name":"blockchain","url":"https://devpost.com/software/built-with/blockchain"},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"nextjs","url":null},{"name":"xrpl","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/jnalbert/CalHacks2025"}],"description_sections":[{"heading":"Inspiration","content":"College students often struggle to access fair credit ‚Äî traditional banks deny small loans and payday lenders trap people in predatory cycles. Meanwhile, plenty of students have savings sitting idle, earning near zero interest. We asked ourselves:\n\nWhat if we let students support each other directly ‚Äî safely, transparently, and with real financial upside?\n\nPeerFund enables a win-win system where students can fund each other using a secure blockchain, eliminating middlemen and complexity.\n\n‚∏ª"},{"heading":"What It Does","content":"PeerFund is a peer-to-peer lending platform built on the XRP Ledger that:\n\n‚úÖ Allows students to lend money and earn interest ‚úÖ Enables borrowers to request loans with predictable repayment schedules ‚úÖ Uses XRPL blockchain transactions for transparency + trust ‚úÖ Automates matching between lenders and borrowers ‚úÖ Tracks user credit reputation over time\n\nEvery payment ‚Äî funding, disbursement, repayment, and payout ‚Äî is recorded on-chain with structured memos for auditability.\n\n‚∏ª"},{"heading":"How It‚Äôs Built","content":"Frontend ‚Ä¢ Next.js 14 + React + MUI for a clean, animated UI ‚Ä¢ React Query for realtime data and mutation flows\n\nBackend ‚Ä¢ Next.js API Routes (serverless) ‚Ä¢ Firebase Auth + Firestore for user and loan data\n\nBlockchain ‚Ä¢ XRPL.js with on-chain payments for: ‚Ä¢ Funding commitments (user-signed) ‚Ä¢ Loan disbursements (server-signed) ‚Ä¢ Loan repayments (user-signed) ‚Ä¢ Lender payouts (server-signed) ‚Ä¢ Secure collector wallet for automated settlement ‚Ä¢ Memos used to synchronize blockchain + database state\n\nWe also created a detailed matching system architecture for future automation: ‚Ä¢ Automated loan funding (matcher cron) ‚Ä¢ Expired reservation cleanup ‚Ä¢ Payout distribution to lenders ‚Ä¢ Default detection and risk scoring\n\n‚∏ª"},{"heading":"Challenges We Ran Into","content":"‚Ä¢ Crafting a complete blockchain flow without smart contracts ‚Ä¢ Making on-chain/off-chain states idempotent and reconcilable ‚Ä¢ Wallet integration UX (reducing friction for new crypto users) ‚Ä¢ Designing a fair matching engine with all-or-nothing funding ‚Ä¢ Coordinating funding ‚Üí disbursement ‚Üí repayment ‚Üí payout without race conditions ‚Ä¢ Finishing a complex financial system under hackathon time pressure ‚è≥\n\n‚∏ª"},{"heading":"Accomplishments That We‚Äôre Proud Of","content":"‚Ä¢ We built a real lending marketplace, not just a prototype UI ‚Ä¢ Every financial event flows through the XRP Ledger ‚Ä¢ Fully functional lender and borrower dashboards ‚Ä¢ Secure wallet-linked authentication ‚Ä¢ Dynamic interest rates with clean visual design ‚Ä¢ Production-grade specs for matching + distribution pipelines ‚Ä¢ A polished user experience in just 36 hours\n\n‚∏ª"},{"heading":"What We Learned","content":"‚Ä¢ How to combine server-signed + user-signed XRPL transactions ‚Ä¢ Designing reversible financial systems is non-trivial ‚Ä¢ Hustling UX polish while building blockchain infra is‚Ä¶ ambitious üòÖ ‚Ä¢ The power of structured memos for traceable financial history ‚Ä¢ The importance of idempotency when listening to blockchain events ‚Ä¢ How to design an economic system that is fair and automated\n\n‚∏ª"},{"heading":"What‚Äôs Next for PeerFund","content":"üîú Deploy smart matching scheduler to automate loan funding üîú Smart distribution system for lender payouts üîú Live wallet connection (Xaman + Crossmark integrations) üîú Offer identity-based credit scoring üîú Expand to more schools and verified student networks üîú Mobile-first app + QR-powered deep linking üîú Eventually support mainnet deployment with real liquidity pools\n\nOur long-term vision: A trustless micro-finance network where students fund their future ‚Äî together.\n\n‚∏ª"},{"heading":"Built With","content":"blockchain firebase nextjs xrpl"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"MediSnap","project_url":"https://devpost.com/software/medsnap-2ysgxk","tagline":"Voice-activated AR vision for clinical precision","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/893/649/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Snap: Best Use of Snap Spectacles"}],"team_members":[],"built_with":[{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"fish-audio","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"lens-studio","url":null},{"name":"letta","url":null},{"name":"next.js","url":null},{"name":"snap","url":null},{"name":"snap-spectacles","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/DT-0907/medisnap/tree/main"}],"description_sections":[{"heading":"Built With","content":"express.js fish-audio gemini javascript lens-studio letta next.js snap snap-spectacles typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"CivitasX","project_url":"https://devpost.com/software/dhdhtfgh","tagline":"CivitasX turns cities into autonomous digital ecosystems‚ÄîAI agents that understand intent, trigger complex civic workflows, and log every verified action immutably on the XRP Ledger.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ripple: Best Use of XRP Ledger"},{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Creao: Best MCP Integration"}],"team_members":[],"built_with":[{"name":"creao","url":null},{"name":"creaofileupload-mcp","url":null},{"name":"creaosearch-mcp","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"docker-compose","url":null},{"name":"fastmcp","url":null},{"name":"fishaudio","url":null},{"name":"livekit","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"railway","url":null},{"name":"render","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vapi","url":null},{"name":"x-mcp","url":null},{"name":"xrpl","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/rajashekarcs2023/calhacks-12"},{"label":"v0-civic-mind-supabase-app.vercel.app","url":"https://v0-civic-mind-supabase-app.vercel.app/"},{"label":"fastmcp.cloud","url":"https://fastmcp.cloud/rajashekar/xrpledger-mcp/"}],"description_sections":[{"heading":"Inspiration","content":"CivitasX began from a simple but powerful observation: governments still run on paper logic in a digital world. One of our teammates has close family members working in the public sector and has seen firsthand how outdated systems create endless friction‚Äîforms that must be retyped, portals that don‚Äôt talk to each other, and decisions that vanish into untraceable bureaucracy.\n\nWe asked ourselves:\n\n‚ÄúWhat if citizens could talk to their city like they talk to a person?‚Äù ‚ÄúAnd what if every government action was provably transparent?‚Äù\n\nThat vision‚Äîof turning bureaucracy into conversation and governance into an intelligent, verifiable system ‚Äîsparked CivitasX: the operating system for an AI-powered city."},{"heading":"What it does","content":"CivitasX transforms a city into a living, conversational intelligence. Citizens can simply talk, type, or send an image ‚Äîand the system instantly understands intent, executes complex workflows, and records the resulting civic action on the XRP Ledger for immutable accountability.\n\nExample: A citizen says, ‚ÄúI need to renew my driver‚Äôs license.‚Äù CivitasX detects the intent through semantic parsing, triggers the ‚Äúlicense renewal‚Äù workflow , retrieves profile and document data, and performs all necessary steps autonomously‚Äîwhile logging a proof-of-action hash on XRPL.\n\nIt integrates text, voice, and image reasoning, creating an entirely new paradigm where civic processes become intelligent, self-orchestrating conversations."},{"heading":"How we built it","content":"CivitasX was built entirely on the Creao agentic platform , which allows AI systems to design and deploy other AI systems. We used Creao‚Äôs compositional model to build a multi-agent ecosystem combining official MCPs (Model Context Protocols) with custom integrations for blockchain and voice.\n\nOfficial Creao MCPs Used:\n\nüß† CreaoSearch MCP ‚Äî semantic ES|QL civic data search üóÇÔ∏è CreaoFileUpload MCP ‚Äî secure upload for documents, images, and audio üëÅÔ∏è OpenAIGPTVision MCP ‚Äî interprets real-world images (e.g., road damage, public works) üí¨ OpenAIGPTChat MCP ‚Äî core reasoning for citizen dialogue üì∞ X (Social Media) MCP ‚Äî retrieves real-time civic sentiment\n\nCustom MCP Integrations Built:\n\nüîä Vapi MCP ‚Äî enables real-time voice call interactions with citizens üîó XRPLedger MCP ‚Äî records all verified civic actions on the XRP Ledger for tamper-proof transparency\n\nSupporting APIs:\n\nüéôÔ∏è LiveKit ‚Äî real-time two-way voice streaming üó£Ô∏è Fish Audio ‚Äî speech-to-text and text-to-speech for natural voice conversations\n\nEvery workflow, from conversation parsing to ledger logging, is autonomously orchestrated inside Creao‚Äôs Render, Biz, and Data layers ‚Äîdemonstrating AI not just as an assistant, but as an autonomous system builder ."},{"heading":"Challenges we ran into","content":"Interoperability: Getting multiple MCPs‚Äîofficial and custom‚Äîto align schemas and reasoning contexts dynamically. Latency: Achieving natural, sub-second voice interactions while integrating XRPL validation. Blockchain integration: Designing asynchronous confirmation flows so the system could continue reasoning while XRPL transactions finalized. Workflow inference: Creating semantic triggers (e.g., ‚Äúrenew driver‚Äôs license‚Äù) that reliably launched complex multi-agent processes."},{"heading":"Accomplishments that we're proud of","content":"üöÄ Built the first AI-powered civic operating system , completely inside an AI builder (Creao) ‚Äî no manual code. ü§ñ Integrated 9 autonomous MCPs that collaborate across text, voice, and image modalities. üîó Linked AI reasoning directly to blockchain accountability , bridging cognition with verifiable trust. üèóÔ∏è Implemented intent-triggered workflows that autonomously complete real government-style procedures. ‚ö° Delivered a fully functional prototype in under 5 hours ‚Äî a complete AI-governance simulation that truly works ."},{"heading":"What we learned","content":"How agentic build systems like Creao can generate and orchestrate full applications autonomously. How to use the XRP Ledger for civic trust infrastructure‚Äîbeyond finance‚Äîto verify decisions, feedback, and citizen participation. How AI multimodality (voice, text, image) can make civic systems inclusive, accessible, and human again. How to design autonomous workflows that blend natural language understanding with blockchain verification."},{"heading":"What's next for CivitasX","content":"üèõÔ∏è Pilot Programs: Partner with municipalities to test participatory budgeting, public feedback verification, and form automation. üõ∞Ô∏è IoT & GIS Integration: Real-time infrastructure monitoring (traffic, waste, utilities) feeding directly into AI civic analytics. üí∞ XRPL Rewards: Incentivize verified citizen engagement through micropayments or civic token rewards. üåê Multilingual Expansion: Deploy voice models for major global languages via Fish Audio. ü§ù Open Protocol Vision: Turn CivitasX into an open civic operating standard‚Äîwhere any government can deploy an AI city OS in minutes.\n\nTagline\n\nCivitasX ‚Äî Where the City Thinks, Listens, and Evolves with You."},{"heading":"Built With","content":"creao creaofileupload-mcp creaosearch-mcp docker docker-compose fastmcp fishaudio livekit python railway render typescript vapi x-mcp xrpl"},{"heading":"Try it out","content":"github.com v0-civic-mind-supabase-app.vercel.app fastmcp.cloud"}]},{"project_title":"Trialscope AI","project_url":"https://devpost.com/software/trialscope-ai","tagline":"Your AI-driven clinical trial intelligence platform that reviews, benchmarks, and regenerates protocol drafts into USDM-ready, FDA-aligned docs: Reducing amendments, delays, and cost overruns.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/894/307/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Grand Prize"}],"team_members":[],"built_with":[{"name":"anthropic","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"next.js","url":null},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/Hilo-Hilo/cal-hacks-new"}],"description_sections":[{"heading":"Inspiration","content":"The members of the Trialscope AI team came into CalHacks with all but a singular question:\n\n\" Why do SO MANY promising discoveries at the bench fail to reach the patients at the bedside? \"\n\nIn fact, roughly 9 in 10 clinical developments fail between starting Phase I trials and receiving regulatory approval. While many of these failures stem from biological uncertainty, a surprisingly large proportion are lost not in the lab, but in clinical trial design and operations.\n\nWhile wet-lab innovation races ahead, trial design still lives in sprawling word documents/PDFs - Even at leading biopharma companies . These protocols span hundreds of pages, presenting scattered trial design information. When foundational design choices are made inside such unstructured, manual systems, trials become vulnerable to avoidable operational risks : misaligned endpoints, impractical timelines, or regulatory gaps that can compromise even the most promising science.\n\nThe result? Delayed trials, avoidable amendments, and millions of dollars in wasted effort.\n\nEnter TrialScope AI. Our mission? Controlling the controllables, by making clinical trial design as intelligent as the science it tests , narrowing the chasm between therapeutic discovery and approval."},{"heading":"What it does","content":"TrialScope AI transforms messy, unstructured trial drafts into structured and regulator-aligned designs, followed by regenerating improved versions using AI.\n\nUpload any Phase II‚ÄìIII trial draft PDF doc. Convert it into a machine-readable USDM structure (Schedule of Activities, endpoints, arms, eligibility, etc.) Generate insights on factors that may slow down trial progress using data from 1M+ historical clinical studies, benchmarking performance metrics such as duration, procedural burden, and amendment likelihood. Identify missing regulatory elements by cross-referencing FDA guidance documents, while highlighting compliance gaps and potential design inefficiencies. Benchmark trial performance against studies of similar drugs, mechanisms, and phases, providing justification on how design choices (e.g., endpoints, visit frequency, population scope) align with successful precedents. Regenerate an improved, citation-linked draft and export it as USDM-ready JSON/XML for CRO or CTMS integration."},{"heading":"How we built it","content":"On Friday, we built a simple prototype of next.js frontend with a text box that communicated with a backend via an API to allow for natural language queries to the clinicaltrials.gov api. We spent the rest of the day prototyping a full-stack platform to include features such as finding similar studies to demonstrate average metrics such as cohort size, number of endpoints, etc. We also trained an xgboost ML model to predict the probability of a given protocol to go overtime, as we felt this unanticipated weeks to months led to large expenditures for companies. On Saturday morning, we met with Henry Wei of Regeneron to discuss the direction we were planning on going into and decided we wanted to build a tool to extract insights from clinical trials going from preclinical to phase 1. There, we decided to pivot to stage 2-3 clinical trial protocols, as that time-stage had the most potential to save researchers time through operation parameter changes. We also decided to include a tool to use LLMs to do compliance oversight on a protocol draft utilizing FDA guideline documents. Finally, we decided it would be critical to utilize the USDM format of trial design to standardize all internal operations. Saturday night, we met with Henry for the second time and gained a lot of insights as to the potential of LLM-improved clinical trials. Throughout the night, we added features such as the LLM oversight tool, a modified xgboost model to predict average time of study, additional graphs to visualize insights, and a USDM rewriting tool that showed side-by-side differences. Going into Sunday morning, we had a functional product that could extract a plethora of actionable insights from protocol drafts for researchers targeting phase 2-3 clinical trial success."},{"heading":"Challenges we ran into","content":"The main challenge we ran into was narrowing down the precise problem scope. As a group that has had minimal experience running clinical trials, we ran mock ‚Äúcustomer discovery/insights‚Äù interviews with experts in the field (Shout Out Henry Wei, M.D. of Regeneron!) to refine the problem/needs statement and inform our solution landscape + implementation. Pivoting our technical solution based on each interview required a flexible mindset and agile implementation. There were some technical challenges, mainly on the front-end back-end interfacing, as well as resolving merge conflicts between team members. We were able to resolve these challenges with AI assistance."},{"heading":"Accomplishments that we're proud of","content":"We built a complete, production-ready pipeline capable of turning raw, unstructured clinical trial PDFs into optimized, regulator-aligned designs. The system processes multi-hundred-page protocols and benchmarks them against over half a million historical studies in under ten minutes. It implements CDISC USDM v3.0‚Äîthe same data model used by top pharmaceutical companies‚Äîallowing seamless integration into CRO and CTMS workflows. The platform unites semantic embeddings, Claude API, MCP tools, XGBoost modeling, and rule-based validation into one coherent, automated framework. Our most significant accomplishment wasn‚Äôt just the technical complexity, but the practicality of what we built. TrialScope AI functions as a true operational tool, capable of fitting into real biopharma workflows and addressing inefficiencies that cost companies millions. Within just 36 hours, we delivered a prototype that could realistically reduce delays, standardize design choices, and make the process of clinical trial planning as intelligent and data-driven as the science it aims to validate."},{"heading":"What we learned","content":"Solving a hackathon required full immersion in the problem space - especially as we were working specifically to address needs in the clinical trials space. This required a full-on crash course of the landscape, as further understanding of the technicalities of each clinical trial phase resulted in us challenging and augmenting our own assumptions: whether it was the type of need to address, our entry point into the clinical trial timeline or the modality in which we implemented our solutions. Our process went beyond simply building a prototype: rather, it involved thinking like a real bio-AI software company. We dived into processes like defining our market position, identifying unmet needs, and translating technical insights into product strategy. This hands-on experience revealed how interdisciplinary problem-solving operates in practice, especially at the intersection of biology and AI. The hackathon became less about competition and more about understanding the actual workflow, validation process, and communication style of startups in this space. It showed us how to move from concept to execution within real constraints, and provided the foundation for pursuing further research, development, and innovation in this field beyond CalHacks."},{"heading":"What's next for Trialscope AI","content":"Short-Term (Next 3 Months)\n\nMulti-version protocol generation with A/B testing and citation tracking for every AI-generated recommendation. Track-change visualization between original and optimized drafts. Expand regulatory coverage with 50+ additional FDA guidance documents, ICH standards, and EMA compliance. Improve ML models to predict enrollment success, dropout risk, and time-to-first-patient-in. Add collaboration tools: multi-user access, role-based permissions, comment threads, and version control.\n\nMedium-Term (6‚Äì12 Months)\n\nPilot partnerships with biotech and pharma companies to validate platform performance and reduce amendment rates. Integrate with EDC and protocol authoring systems (Veeva, Medidata, Word). Add advanced analytics modules for cost estimation, site selection, and feasibility scoring. Extend global regulatory coverage and introduce multi-language support.\n\nLong-Term (12+ Months)\n\nImplement generative protocol authoring from simple drug or mechanism prompts. Simulate trial outcomes pre-enrollment using predictive models trained on 1M+ trials. Automate regulatory submission workflows, including IND draft generation and FDA response preparation. Release open-source datasets, model weights, and benchmark frameworks for academic collaboration. Achieve <3-minute full analysis time, >0.90 ML accuracy, and scalable performance for 10,000+ concurrent users with HIPAA-compliant security."},{"heading":"Built With","content":"anthropic css html next.js postgresql python typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"XRPower","project_url":"https://devpost.com/software/xrpower","tagline":"Stake your XRP. Predict outcomes. Win the pot. XRPower turns your opinions into on-chain rewards through decentralized prediction markets on the XRP Ledger.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/886/700/datas/medium.PNG","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ripple: Best Use of XRP Ledger"}],"team_members":[],"built_with":[{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"ripple","url":"https://devpost.com/software/built-with/ripple"},{"name":"web3","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"I‚Äôve always been interested in how communities form collective predictions around events like elections, crypto prices, and sports, and how those opinions could be turned into a rewards system. Most prediction markets today either rely on centralized systems with no transparency or complex, gas-heavy smart contract platforms that are hard for new users to interact with. I wanted to explore whether I could build a lightweight, fast, and easy-to-use prediction platform using the XRP Ledger. XRPL‚Äôs fast transaction speeds, low fees, and built-in tools for escrow and payments made it a great match for this type of application.\n\nI imagined a world where anyone could say \"I think this will happen\", back it with XRP, and be rewarded for being right, without needing a centralized betting app or login form."},{"heading":"What it does","content":"XRPower is a prediction-based rewards platform built on the XRP Ledger. It lets users vote on the outcome of real-world events by sending a small amount of XRP to one of two wallet addresses, one representing ‚ÄúYes‚Äù and one representing ‚ÄúNo.‚Äù Each vote is an actual payment transaction on the XRP Ledger. The system tracks the total XRP sent to each outcome in real time."},{"heading":"How I built it","content":"I used React and TailwindCSS to build the frontend, and Node.js with Express for the backend. I used the xrpl.js SDK to generate XRP testnet wallets, monitor transactions, and send reward payouts."},{"heading":"Challenges I ran into","content":"One of the main challenges was transaction detection. The XRP Ledger confirms transactions quickly, but building a real-time listener that filters the right transactions from the stream and handles edge cases like double voting or late submissions required careful validation. Another challenge was payout logic, making sure rewards were distributed fairly based on who voted and preventing any double payouts. Since I was using testnet wallets and a backend-based admin trigger, I also had to ensure that key management and transaction signing were handled safely and efficiently. Time management was another big factor."},{"heading":"Accomplishments that I am proud of","content":"I‚Äôm proud that I was able to design and build a fully functioning prediction and reward platform in such a short amount of time. XRPower supports real-time vote tracking, uses actual XRP testnet transactions, and includes a working payout system that sends testnet XRP to the correct voters. The flow is smooth, intuitive, and easy for new users to interact with. It also opens up possibilities for new types of experiments and lightweight applications in event prediction and staking models, all built without needing complex smart contracts or third-party infrastructure."},{"heading":"What I learned","content":"I learned a lot about the XRPL developer ecosystem, including how to work with xrpl.js, how XRP handles transactions, and how to manage payment-based workflows. I also gained hands-on experience with building real-time systems that respond to on-chain activity. I also deepened my understanding of how to scope and ship a working MVP under extreme time pressure as a solo builder."},{"heading":"What's next for XRPower","content":"If the project gains traction, I‚Äôd like to deploy a version on the XRP mainnet with more robust transaction management and lower risk thresholds for new users. XRPower is still in its early stages, but I believe it has potential to become a fun and rewarding tool for event forecasting and community-powered insight."},{"heading":"Built With","content":"node.js react ripple web3"}]},{"project_title":"Jade.AI","project_url":"https://devpost.com/software/jadeai","tagline":"Cursor for Data Analysis","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/900/046/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Groq: Best Use of Groq"}],"team_members":[],"built_with":[{"name":"chart.js","url":"https://devpost.com/software/built-with/chart-js"},{"name":"fastapi","url":null},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/erik-ksth/jade-ai.git"}],"description_sections":[{"heading":"Inspiration","content":"As a college student passionate about data analysis, I‚Äôve faced a frustrating reality: most of my project time isn't spent on analysis. It's spent on grunt work. I often wasted over 70% of my time just cleaning messy datasets. I was constantly switching between Excel for quick fixes, Pandas for heavy-duty cleaning, SQL for data pulling, and another tool like Tableau for visualization. The process was slow, exhausting, and fragmented. I wanted a single, intelligent, all-in-one solution that could handle all these tasks with just a few natural language commands. I envisioned a \"Cursor for data analysis\", an AI-first tool that would let me talk to my data. That's why we built Jade.AI."},{"heading":"What it does","content":"Jade.AI empowers anyone, regardless of their technical background, to work with data effortlessly.\n\nIt‚Äôs as simple as 1-2-3:\n\nUpload your data (CSV, Excel, etc.). Type what you want in plain English. Get immediate results.\n\nYou can clean, manipulate, visualize, and summarize, all in one seamless interface:\n\n‚ÄúClean the entire dataset‚Äù ‚Üí Jade.AI intelligently handles missing values, removes duplicates, fixes inconsistent formatting, and standardizes data types. ‚ÄúShow a pie chart of the gender distribution‚Äù ‚Üí Instantly generates a beautiful, interactive chart with auto-labeled insights. ‚ÄúWhat‚Äôs the average salary by department?‚Äù ‚Üí Returns a clean summary table or a bar chart, your choice. ‚ÄúSummarize the key findings from this data‚Äù ‚Üí Creates a concise, human-readable report."},{"heading":"How we built it","content":"We built Jade.AI to be fast, intelligent, and scalable.\n\nFrontend: We built a clean and responsive UI using Next.JS to create a seamless, single-page application experience. Backend: We used a Python (FastAPI) backend to create REST APIs that handles all user requests. LLM: We integrated the Groq API as the main LLM to power our natural language-to-action engine. Its incredible speed makes the conversation feel instantaneous. This model interprets user commands and translates them into executable operations. Data Manipulation: The legendary Pandas library is our workhorse. All data cleaning, transformation, and analysis commands are piped through a secure Pandas runtime. Data Visualization: We used Chart.js to generate rich, interactive, and beautiful visualizations that can be embedded directly in the chat interface."},{"heading":"Challenges we ran into","content":"Prompt Engineering is Deceptive: Getting the LLM to consistently and safely translate a vague command like \"fix the messy columns\" into the correct sequence of Pandas functions was our biggest hurdle. It required lots of iterative prompt design and building a robust validation layer. Maintaining Data State: Managing the state of a user's DataFrame across multiple, independent API calls was a huge challenge. Our initial implementation was slow and buggy before we used Groq. The Scope Creep: We had so many ideas! We wanted to add SQL database connections, advanced statistical modeling, and more. Focusing on our core loop (Upload ‚Üí Clean ‚Üí Analyze ‚Üí Viz) within the time limit was a real test of discipline."},{"heading":"Accomplishments that we're proud of","content":"It Actually Works! We have a fully functional, end-to-end demo. You can upload a genuinely messy dataset and walk away with clean data and insightful charts in under two minutes. The \"Wow\" Moment: The biggest win was testing it on a friend with zero coding experience. They were able to perform a complete data analysis task that would have taken them hours, and they did it with a smile. The \"Cursor for Data\" Feel: We successfully captured that \"magic\" feeling. It feels less like a tool and more like an intelligent collaborator, which was our core vision."},{"heading":"What we learned","content":"LLMs are Interpreters, Not Magicians: The real magic isn't just the LLM; it's the pipeline . The most critical work is building the robust \"plumbing\" that translates the LLM's intent into safe, executable code . UX is Everything: For a tool aimed at non-technical users, simplicity is the ultimate feature. A single, clear chat box proved to be infinitely more powerful than a complex dashboard. Speed is a Feature: Using an incredibly fast LLM (Groq) was a game-changer. When the analysis feels instant, it encourages creativity and exploration, which is the entire point of data analysis."},{"heading":"What's next for Jade.AI","content":"We're just getting started. Our vision is to make data analysis as easy as having a conversation.\n\nMore Data Connectors: We plan to add support for connecting directly to SQL databases, Google Sheets, and other live APIs. Advanced Analytics: We're working on moving beyond descriptive statistics to include predictive modeling. (e.g., \"Forecast next quarter's sales based on this data\" ). \"Analysis History\": We want to create a feature that lets users track, revert, and branch their analysis steps, almost like Git for data analysis."},{"heading":"Built With","content":"chart.js fastapi groq pandas python react typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"LendX","project_url":"https://devpost.com/software/lendx","tagline":"Making SMB lending transparent and efficient with on-chain loan tracking on the XRP Ledger","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ripple: Best Use of XRP Ledger"}],"team_members":[],"built_with":[{"name":"auth0","url":null},{"name":"fastapi","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"ripple","url":"https://devpost.com/software/built-with/ripple"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"lendxrp.vercel.app","url":"https://lendxrp.vercel.app/"}],"description_sections":[{"heading":"Inspiration","content":"Financial inclusion remains one of the world's greatest challenges, particularly in emerging markets where traditional banking systems fail to serve billions of people. We were inspired by the potential of decentralized finance (DeFi) to democratize access to credit, especially for small business owners and entrepreneurs in regions like Southeast Asia, Africa, and Latin America. The XRPL's focus on sustainability and low transaction costs made it the perfect blockchain foundation for building a lending platform that could genuinely serve underbanked communities without prohibitive fees."},{"heading":"What it does","content":"LendX is a full-stack decentralized lending marketplace built on the XRP Ledger that connects lenders and borrowers through peer-to-peer transactions. The platform features:\n\nDual-role dashboard where users can seamlessly switch between lender and borrower views Auth0 Google SSO integration for secure, familiar authentication Native XRPL wallet generation with direct blockchain integration (no third-party dependencies) DID-based identity system using verifiable credentials for borrower verification Lending pool creation where lenders can set custom rates, terms, and requirements Direct loan applications with transparent approval/rejection workflows Real-time transaction tracking with XRPL WebSocket subscriptions Multi-Purpose Token (MPT) support for representing loans as blockchain assets Escrow transactions for secure collateral handling Multi-signature account support for institutional lenders"},{"heading":"How we built it","content":"Our architecture combines a modern React frontend with a robust Python XRPL backend:\n\nFrontend (Next.js 14 + TypeScript):\n\nBuilt with App Router and server-side rendering for optimal performance Shadcn/ui component library with custom dark theme styling Direct XRPL.js integration for blockchain interactions Auth0 SDK for Google SSO authentication Zustand for efficient state management Real-time WebSocket connections for transaction updates\n\nBackend (Python + FastAPI):\n\nCustom XRPL client library built on top of xrpl-py Multi-Purpose Token (MPT) operations for loan tokenization Escrow transaction handling for secure loan collateral Multi-signature account management for institutional use Comprehensive exception handling and logging WebSocket subscription management for real-time updates\n\nXRPL Integration:\n\nDirect wallet generation replacing Xumm SDK dependency Transaction memoization for loan metadata storage Custom payment flows for lending pool creation and loan distribution Account subscription system for real-time balance updates"},{"heading":"Challenges we ran into","content":"XRPL MPT Documentation: Multi-Purpose Tokens are a relatively new XRPL feature with limited documentation, requiring deep diving into XRPL specifications and extensive testing Transaction Finality: Managing the asynchronous nature of blockchain transactions while providing immediate UI feedback required careful state management Wallet Integration: Replacing third-party wallet dependencies with native XRPL wallet generation while maintaining security best practices Real-time Updates: Implementing WebSocket subscriptions for live transaction monitoring without overwhelming the UI with updates DID Integration: Building a verifiable credentials system that integrates seamlessly with Auth0 authentication"},{"heading":"Accomplishments that we're proud of","content":"Complete end-to-end lending flow from pool creation to loan repayment working on XRPL testnet Professional-grade UI/UX that rivals traditional fintech applications Native XRPL integration without external wallet dependencies, reducing friction for users Comprehensive Python XRPL library with full test coverage for all lending operations Real-time transaction monitoring providing immediate feedback on blockchain state changes Scalable architecture supporting both individual and institutional lenders"},{"heading":"What we learned","content":"The power of XRPL's low transaction fees (fractions of a cent) makes microlending economically viable Multi-Purpose Tokens provide an elegant solution for representing complex financial instruments on-chain Building native blockchain integration significantly improves user experience compared to external wallet dependencies Verifiable credentials combined with traditional OAuth create a powerful identity verification system The importance of real-time feedback in financial applications - users need immediate confirmation of transaction status Python's xrpl-py library is incredibly robust for building production-grade blockchain applications"},{"heading":"What's next for LendX","content":"Mainnet deployment with integrated fiat on/off ramps for emerging market accessibility Credit scoring algorithm using on-chain transaction history and verifiable credentials Insurance pools to protect lenders against default risk Mobile-first PWA optimized for smartphone usage in emerging markets Multi-currency support for local currency lending pools Partnerships with microfinance institutions and business guilds for borrower verification Advanced analytics dashboard for lenders to track portfolio performance Automated loan repayment with scheduled payment systems Cross-border remittance integration for diaspora lending to home countries"},{"heading":"Built With","content":"auth0 fastapi python ripple typescript"},{"heading":"Try it out","content":"lendxrp.vercel.app"}]},{"project_title":"Sweet by Metabolic Company of CalHacks","project_url":"https://devpost.com/software/sweet-by-metabolic-company-of-calhacks","tagline":"Sweet is an iMessage native diabetes management AI assistant.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/890/229/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Interaction Company: Best MCP Automation"}],"team_members":[],"built_with":[{"name":"dexcomshareapi","url":null},{"name":"fastmcp","url":null},{"name":"geminiapi","url":null},{"name":"poke","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"twilioapi","url":null},{"name":"uvicorn","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/hemanthkapa/Sweet"}],"description_sections":[{"heading":"Inspiration","content":"Living with diabetes means juggling between multiple tasks everyday from checking glucose levels to calculating carbs to giving right dosing of insulin, all while trying to live normally. We thought, what if instead of using complex apps and manual tracking, you could simply text your phone like you're talking to a friend, and get instant, intelligent help with your diabetes management?"},{"heading":"What it does","content":"Sweet lets users manage diabetes through conversational text messages with an AI assistant. The AI analyzes meals, monitors glucose levels, and calculates insulin doses using real-time data integration. Users text the Poke AI to get instant health insights, and the system learns patterns over time to provide personalized recommendations.\n\nReal-time Dexcom CGM integration AI-powered meal analysis from photos Personalized insulin dose calculations Glucose pattern tracking based on food/activity and send alerts when needed SMS-based conversational interface"},{"heading":"How we built it","content":"Sweet is built as an MCP (Model Context Protocol) server that integrates multiple APIs and AI services:\n\nFastMCP Framework : Used FastMCP as the foundation for our MCP server, enabling seamless integration with Poke's conversational interface Dexcom Integration : Connected to Dexcom's Share API for real-time CGM data retrieval and glucose trend analysis AI-Powered Intelligence : Integrated Gemini API for NLP, food recognition, and personalized nutrition analysis SMS Communication : Implemented Twilio for reliable text message alerts in an urgent situation Python Backend : Built custom modules for insulin calculation algorithms, carb ratio management, and pattern recognition logic"},{"heading":"Challenges we ran into","content":"MCP Learning Curve : First-time developers struggling with Model Context Protocol architecture and tool structuring Stateless Communication : Managing HTTP requests without persistent state for real-time health data Multi-API Coordination : Synchronizing Dexcom, Gemini, and Twilio APIs in a single conversational flow Medical Data Reliability : Ensuring accurate, safe handling of critical health information under all conditions. (Our tool is still in its early stages, so insulin dosage and macros predictions may not yet be fully reliable.) Dexcom API Complexity : Navigating between Sandbox and Share APIs, understanding authentication flows, and parsing complex glucose data structures"},{"heading":"Accomplishments that we're proud of","content":"Seamless Multi-API Integration : Successfully unified Dexcom, Gemini AI, and Twilio into the MCP server Natural Conversation Interface : Transformed complex diabetes management into simple text-based interactions Adaptive Pattern Learning : Created a system that learns and personalizes to individual users over time Real Impact Potential : Built something that could genuinely reduce the daily burden of diabetes management"},{"heading":"What we learned","content":"We learned that working with healthcare data requires serious responsibility. Even a tiny mistake can have big consequences. Our goal is to build something that genuinely helps people, but safety always comes first. Creating our first healthcare MCP taught us how important it is to spot patterns and use context, so our tool can truly support users where it matters."},{"heading":"What's next for Sweet by Metabolic Company of CalHacks","content":"Multi-Platform Expansion : Bring Sweet to Discord, Slack, WhatsApp, and native mobile apps Predictive Intelligence : ML-powered glucose forecasting and smart meal database that learns from users Clinical Integration : Web dashboard with comprehensive weekly/monthly reports for patients, healthcare provider access. Connect Poke with closed loop insulin pump for insulin dosage automation. Community Platform : Enable users to share interesting use cases and strategied they find while using the chat interface.\n\nDisclaimer: Sweet is still in development. While real-time glucose data is pulled from your sensor, macro tracking and insulin dosage suggestions are early-stage and may not be fully reliable. Please do not rely on these features for critical decisions."},{"heading":"Built With","content":"dexcomshareapi fastmcp geminiapi poke python twilioapi uvicorn"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"RecallMe","project_url":"https://devpost.com/software/temp-031caq","tagline":"A smart AI lecture chatbot that follows along in class, lets you ask questions live, gives immediate answers, and keeps track of context across lectures and uploaded recordings.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/901/094/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Letta: Build Your First Stateful AI Agent with Letta Cloud"}],"team_members":[],"built_with":[{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"letta","url":null},{"name":"livekit","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"reka","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/nightowl23/calhacks-2025"}],"description_sections":[{"heading":"Inspiration","content":"As undergrad students sitting in lecture halls with 200+ students, it becomes incredibly easy to zone out, lose track of important concepts, or feel too intimidated to ask questions in real time. We wanted to change that. RecallMe was born from the idea that learning should be active, engaging, and personalized‚Äînot passive and easily forgotten. With live transcription and real-time interaction, RecallMe keeps students focused, curious, and connected to the lecture from start to finish. Instead of waiting for the professor to finish speaking or rewatching hours of recordings later, students can now engage instantly, ask questions the moment confusion strikes, and never miss a key idea again."},{"heading":"What it Does","content":"RecallMe captures lecture audio in real time, transcribes it instantly, and generates dynamic, structured notes that students can interact with as the lecture is happening. But it doesn‚Äôt stop there‚Äîevery lecture is stored as long-term memory inside our Letta agent, meaning students can return days or even months later and ask questions about previous lectures without having to dig through hours of videos. RecallMe also supports video uploads, where a user can upload a lecture recording, have it transcribed and stored in memory, and then interact with it using a larger context window. It‚Äôs like talking to an AI that truly remembers your classes‚Äîacross time, topics, and video lectures. Using our dynamic database within Letta, we can easily recall information with each video_id."},{"heading":"How We Built It","content":"We used a variety of tools and sponsors at Calhacks to build RecallMe! With the use of Letta, Reka, and LiveKit, we created RecallMe to achieve low-latency transcription, persistent memory storage, and context-aware interaction. LiveKit handles real-time audio streaming from the lecture, where audio is segmented into PCM chunks and streamed to our backend. These chunks are asynchronously processed and forwarded to two separate Letta agents via API calls. The first agent performs instant summarization and lecture note generation using its reasoning models, while the second agent is dedicated to long-term memory persistence. This memory agent stores each chunk‚Äôs transcription into structured core memory blocks, indexed by unique lecture or video IDs to emulate scalable vectorized memory retrieval.\n\nFor non-live content, such as uploaded lecture videos, we use Reka‚Äôs speech-to-text API to batch-process the video stream into high-accuracy transcripts. Since Reka and Letta do not have native interoperability, we built a custom middleware pipeline to transform Reka‚Äôs output into Letta-compatible memory schemas before pushing them into the same memory graph used for live sessions. All stored memory is queryable using semantic retrieval, meaning a user can ask context-dependent questions and the system fetches the relevant lecture fragments from long-term storage.\n\nThe final architecture enables seamless interaction across live lectures, stored sessions, and uploaded videos‚Äîallowing users to converse with an AI that maintains temporal continuity, lecture-specific context, and cross-session recall."},{"heading":"Challenges","content":"None of us had ever used AI agents before, and definitely not all three platforms‚ÄîLetta, Reka, and LiveKit‚Äîat once. Our first challenge was figuring out how to structure memory inside Letta so that lecture information could be stored, retrieved, and referenced over time. Next, we had to integrate Reka and Letta, despite the fact that no direct integration exists. We built a workaround that allowed us to transcribe videos with Reka and send that data into Letta‚Äôs memory. LiveKit brought its own challenges, as we had to process audio in real-time chunks and make sure the transcription was fast and accurate enough to be useful during live lectures. But the hardest part was creating one seamless system that could handle live transcription, memory storage, interactive querying, and video processing‚Äîwhile making it feel natural and effortless to the user."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud of our hard work in combining frameworks from three different sponsors into a unified platform, leveraging AI agents, speech-to-text models, and real-time chatbot functionality under a strict development timeline. We formed strong relationships with peers, mentors, and sponsor representatives, gaining valuable insights into agentic technology, startup ecosystems, and the growing scope for innovation in today‚Äôs AI-driven world."},{"heading":"What we learned","content":"We learned how to integrate AI agents and speech-to-text models to develop a real-time, context-aware chatbot capable of processing and responding to live lecture content. Throughout the process, we gained hands-on experience working with three complex sponsor technologies‚ÄîLetta, LiveKit, and Reka‚Äîand learned how to design effective pipelines that connect them seamlessly. We also strengthened our skills in asynchronous event handling, API orchestration, and real-time data streaming, while managing development under a tight hackathon timeline. Beyond the technical side, we learned how to collaborate efficiently under pressure, divide tasks strategically, and iterate quickly to transform an ambitious concept into a functional prototype."},{"heading":"What's next for RecallMe","content":"Looking ahead, we aim to expand our platform‚Äôs intelligence, scalability, and accessibility: Multi-Modal Agent for Interactive Quizzes: We plan to integrate a multi-modal AI agent capable of generating real-time, interactive quizzes based on lecture content, helping students actively test their understanding. Vectorized Database for Efficient Querying: Implementing a vector database will enable faster and more accurate semantic search, improving how the chatbot retrieves and relates lecture information. Multilingual Transcription and Support: To make our platform accessible to a broader audience, we plan to introduce multilingual transcription and translation, allowing students worldwide to benefit from localized lecture understanding. These advancements will strengthen the platform‚Äôs educational value and push it closer to a fully intelligent, globally accessible lecture companion."},{"heading":"Built With","content":"flask letta livekit react reka"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Love Island: To Die For!","project_url":"https://devpost.com/software/love-island-to-die-for","tagline":"You thought you were off to enjoy a fun, exciting dating show experience... but something has gone terribly wrong. Now, it's up to you to figure out what happened!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/898/217/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"JanitorAI: Most Functional, Novel, and Fun Project"}],"team_members":[],"built_with":[{"name":"janitor.ai","url":null},{"name":"next.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/syenko/calhacks"}],"description_sections":[{"heading":"Inspiration","content":"What if your favorite reality TV dating show took a dark turn? We were inspired by the dramatic storytelling of shows like Love Island and the intrigue of murder mystery visual novels like Ace Attorney. We wanted to create an interactive narrative experience that combines romance and solving mysteries ‚Äî two of the most compelling, aspirational, and fun experiences in storytelling!"},{"heading":"What it does","content":"\"Love Island: To Die For!\" is an AI-powered murder mystery visual novel where you play as the newcomer to a reality show investigating the death of Hunter, one of your fellow contestants. You interrogate four suspect-contestants, each with their own motives, alibis, and secrets. Through turn-based conversations, you must piece together the truth from a web of romantic rivalries, hidden relationships, and carefully constructed lies.\n\nThe game features both traditional individual \"dates\" with characters, and a unique feature for our gameplay: group conversations where suspects interact with each other. Here you can compete for romantic affection, but also engage with different conversation dynamics that reveals specific information . With a progress bar tracking your remaining turns, you must use your questions wisely to uncover the whodunnit!"},{"heading":"How we built it","content":"We built a full-stack application with a Python backend and Next.js/React/Tailwind frontend. The backend uses JanitorAI's LLM API to power dynamic, context-aware character responses that are finetuned perfectly for immersive storytelling.\n\nWe also developed from scratch a multi-agent context management and memory system, in order to incorporate detailed personality profiles, backgrounds, and conditional secrets that are revealed based on conversation topics. We created a relationship system that tracks connections between characters, enabling us to update agent context and create consistent and believable inter-character interactions, while also progressively revealing clues.\n\nThe frontend features a pixel-art visual novel aesthetic with smooth animations and custom components for dialogue boxes, character headshots, and progress tracking.\n\nAnd ‚Äî of course ‚Äî we designed an intricate murder mystery plot with multiple suspects, each with their own secrets and interconnected relationships that unfold naturally through gameplay."},{"heading":"Challenges we ran into","content":"Creating believable, consistent AI characters was surprisingly difficult ‚Äî we had to carefully craft system prompts that maintained personality while allowing for natural conversation flow and controlled information revelation.\n\nBalancing the mystery difficulty was another challenge: we needed to ensure clues were discoverable but not too obvious, and that different conversation paths could still lead to solving the mystery.\n\nManaging conversation state and context across multiple characters and conversation turns required careful state management. We also struggled with timing the reveal of secrets ‚Äî characters needed to feel reluctant to share information but eventually crack under the right questioning."},{"heading":"Accomplishments that we're proud of","content":"We're incredibly proud of the rich, dynamic narrative we created with four distinct characters and complex relationships.\n\nOur bespoke multiagent context management system was both lightweight and complex enough to create a genuinely evolving narrative experience ‚Äî and a great learning experience. The relationship system we built allows characters to reference each other authentically and reveal different information based on who else is present in group conversations.\n\nWe also love our pixel-art UI that sets the vibe perfectly!"},{"heading":"What we learned","content":"We learned that context engineering for multiagent narrative games requires a completely different approach than typical chatbot applications ‚Äî you need to manage character consistency not just with the main character but with N possible other live relationships and conversation history. Especially for our needs, we learned (through doing!) how do achieve this with minimal token usage.\n\nOn the technical side, we gained experience with streaming LLM responses in real-time UIs, managing complex state in React, and designing turn-based conversation systems.\n\nWe also learned valuable lessons about game design ‚Äî something half our team was doing for the first time this hackathon! We learned how to plant clues, create red herrings, and structure satisfying mysteries, all on the job. We discovered the importance of conditional information revelation and how to structure character descriptions to enable emergent storytelling."},{"heading":"What's next for Love Island: To Die For","content":"We want to expand the game with multiple episodes featuring different murder mysteries and new casts of characters. We plan to add a deduction system where players can formally accuse suspects and present evidence, with different endings based on whether you correctly identify the killer. Voice acting and character animations would bring the personalities to life even more. We'd love to implement a memory system where characters remember previous conversations across multiple playthroughs, creating meta-narrative experiences. Adding branching storylines where player choices affect character relationships and unlock different plot paths would increase replayability. Finally, we want to create a level editor that lets players craft their own murder mysteries with custom characters, relationships, and secrets, turning LIT:DF into a platform for community-created interactive mysteries."},{"heading":"Built With","content":"janitor.ai next.js python react tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"MedChain","project_url":"https://devpost.com/software/medchain-s7dz60","tagline":"MedChain: A blockchain-powered app for secure, verifiable prescriptions. Built on Base with smart contracts and IPFS to eliminate fraud and streamline doctor‚Äìpharmacist workflows.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/897/625/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ethereum Foundation: Best App Built on Ethereum, or an Ethereum L2"}],"team_members":[],"built_with":[{"name":"base","url":null},{"name":"coinbase","url":"https://devpost.com/software/built-with/coinbase"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"reka","url":null},{"name":"solidity","url":"https://devpost.com/software/built-with/solidity"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/arnavjainpro/CalHacks12.0"},{"label":"medschain.tech","url":"http://medschain.tech"}],"description_sections":[{"heading":"Inspiration","content":"Every day, nearly 200 Americans die from opioid overdoses ‚Äî many from legally obtained prescriptions. Behind those numbers lies a broken system: doctors, pharmacists, and patients operating in silos, with no unified way to verify prescriptions or detect duplicate fills across states.\n\nDuring our initial research, we spoke with a board certified doctor who described the reality on the frontlines ‚Äî duplicate opioid prescriptions, inconsistent access to patient records, and an overwhelming amount of inconsistency in prescription platforms across the country.\n\nEach U.S. state maintains its own Prescription Drug Monitoring Program (PDMP) , yet these systems don‚Äôt talk to each other. This fragmented design costs billions in fraud and, more importantly, thousands of preventable deaths each year.\n\nWe realized that the true problem isn‚Äôt data ‚Äî it‚Äôs trust . What if every verified doctor and pharmacist shared a single, tamper-proof ledger for prescriptions, one that no patient could exploit and no state bureaucracy could delay?\n\nThat question led to MedChain ‚Äî a decentralized prescription management system designed not just to streamline healthcare, but to save lives ."},{"heading":"What it does","content":"MedChain transforms how prescriptions are created, shared, and verified across the healthcare ecosystem without a centralized database or server.\n\nFor Doctors\n\nIssue digitally signed prescriptions that are stored immutably on-chain. Automatically generate a patient-specific QR code for seamless sharing and later verification. Track issued prescriptions, view statuses, and revoke them if necessary.\n\nFor Pharmacists\n\nScan a patient‚Äôs QR code to instantly verify the authenticity of a prescription using cryptographic validation. Dispense the medication and record the transaction on the blockchain for transparent tracking.\n\nFor Patients\n\nNo wallet, no gas. Patients authenticate with Base Accounts using passkeys (WebAuthn) ‚Äî no seed phrases required. All on-chain actions are executed through abstracted accounts on Base; gas fees are sponsored via our paymaster so patients never pay gas. View active prescriptions, dosages, and refill details via a simple QR flow and receive real-time updates when medications are dispensed or canceled. All data is encrypted to preserve privacy.\n\nFor Admins\n\nDecentralized credentialing system allows only verified healthcare professionals to issue prescriptions. Soul-Bound Tokens (SBTs) represent verified identities, with multi-signature governance ensuring secure and auditable actions.\n\nIn essence, MedChain eliminates prescription fraud and paperwork bottlenecks while preserving the doctor‚Äìpharmacist‚Äìpatient trust loop."},{"heading":"How we built it","content":"We built MedChain as a fully decentralized dApp with no traditional backend or centralized database. Every interaction occurs on the blockchain or decentralized storage.\n\nFrontend: Next.js 15 (App Router) and OnChainKit for wallet connection, decentralized identity, and passkey UX. Accounts & UX: Base Accounts (smart accounts) with account abstraction enable passkey sign-in and gasless transactions via a paymaster; users don‚Äôt need a traditional wallet. Blockchain: All prescriptions and credentials are stored on the Base L2. Smart Contracts: Foundry-based contracts for the Prescription Registry and Credential SBT logic. Data Storage: Sensitive prescription details (encrypted) on IPFS via Pinata. Web3 Libraries: Wagmi and Viem for Ethereum interactions and transaction lifecycle. Architecture: Entirely client-side ‚Äî the blockchain acts as the backend, providing both state and verification logic.\n\nThe result is a secure, scalable architecture that treats the blockchain itself as the database, with walletless, gasless participation for end users."},{"heading":"Challenges we ran into","content":"Eliminating the backend required a complete rethinking of traditional CRUD operations and caching strategies. Protecting patient privacy on a public ledger meant implementing robust end-to-end encryption before uploading data to IPFS. Creating a credential layer for healthcare providers using Soul-Bound Tokens involved careful contract design and governance logic. Designing a walletless, gasless flow required integrating Base Accounts, passkeys, and a paymaster ‚Äî including session policies and sponsorship limits ‚Äî while keeping the UX simple for non-crypto users."},{"heading":"Accomplishments that we‚Äôre proud of","content":"Built a completely backend-less healthcare platform that runs entirely on Base blockchain. Implemented end-to-end prescription verification with cryptographic signing, QR-based sharing, and on-chain auditability. Developed a decentralized credential system using Soul-Bound Tokens to represent verified medical professionals. Delivered a walletless, gasless UX using Base Accounts + passkeys and account abstraction ‚Äî no seed phrases, no gas fees for patients."},{"heading":"What we learned","content":"This project taught us that trust is the ultimate currency in healthcare, and blockchain is uniquely positioned to protect it. We learned how to design for both decentralization and usability, balancing cryptographic rigor with human-centered design. We also deepened our understanding of Layer-2 scalability, multi-signature governance, account abstraction, and decentralized identity models like SBTs."},{"heading":"What‚Äôs next for MedChain","content":"Regulatory Integration: Collaborate with healthcare compliance bodies to align MedChain with HIPAA and FDA digital health standards. Cross-Chain Expansion: Extend to multi-chain ecosystems for interoperability with electronic health record systems. AI-Assisted Insights: Integrate on-chain analytics to detect prescription trends or potential over-prescription patterns. Real-World Pilots: Partner with clinics and pharmacies to test blockchain-based prescription issuance in controlled environments. AA Operations: Mature our paymaster policies (rate limits, spend caps) and session keys for scalable, secure gas sponsorship.\n\nMedChain‚Äôs long-term vision is to become the trust layer for digital healthcare records, ensuring that prescriptions are secure, verifiable, and universally accessible ‚Äî walletless and gasless ‚Äî powered by Base."},{"heading":"Built With","content":"base coinbase html javascript react reka solidity tailwind typescript"},{"heading":"Try it out","content":"github.com medschain.tech"}]},{"project_title":"CleanGetaway","project_url":"https://devpost.com/software/cleangetaway","tagline":"Multiplayer Agentic AI NPCs with shared conversational memory across all players.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/891/974/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"JanitorAI: Most Functional, Novel, and Fun Project"}],"team_members":[],"built_with":[{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"fishaudio","url":null},{"name":"janitorai","url":null},{"name":"jllm","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"vite","url":null},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"}],"external_links":[{"label":"github.com","url":"https://github.com/iOliver678/calhacks12"}],"description_sections":[{"heading":"Architecture Overview","content":"This project implements a novel approach to multiplayer AI interactions through a distributed conversational state architecture. The system enables multiple concurrent players to engage with AI-powered NPCs through a unified conversation thread, creating emergent collaborative gameplay dynamics.\n\nCore Technical Components\n\nReal-Time Bidirectional Communication Layer\n\nWebSocket-based event-driven architecture using Socket.IO Sub-room multiplexing for isolated NPC conversation channels 60 FPS position synchronization with optimized broadcast patterns\n\nDistributed Conversational State Management\n\nPer-NPC conversation history buffers with automatic pruning (20-message sliding window) Message batching system with adaptive response timing (3-second delay or 2+ message threshold) Username-prefixed message formatting for multi-participant context preservation\n\nAI Integration Layer\n\nJLLM (Janitor Large Language Model) API integration with streaming response handling System prompt engineering for character consistency and behavioral constraints Keyword-based semantic parsing for item transfer and game state transitions\n\nCollision Detection & Spatial Indexing\n\nBoundary-based collision system with pre-computed collision maps Proximity-based interaction zones with configurable radii Canvas-based rendering with dual-layer foreground/background composition\n\nYou're asking me to generate a comprehensive README that makes the multiplayer AI NPC system sound technically sophisticated while remaining accessible."},{"heading":"Installation","content":"Prerequisites\n\nNode.js 18+ npm or yarn\n\nBackend Setup\n\ncd backend npm install npm start # Runs on port 3001\n\nFrontend Setup\n\ncd frontend npm install npm run dev # Runs on port 5173"},{"heading":"Technical Specifications","content":"Room Management\n\nUnique 6-character alphanumeric room codes Support for up to 4 concurrent players per room Host-based game initialization with authority validation\n\nNPC Conversation System\n\nThree AI-powered NPCs with distinct personalities and behavioral models:\n\nHardware Store Clerk\n\nLocation: (2842, 872) Inventory: shovel Behavioral traits: Paranoid, gossips with authorities\n\nPolice Officer\n\nLocation: (4106, 4306) Inventory: helicopterKeys Behavioral traits: Strict but gullible, susceptible to emergency narratives\n\nBorder Guard\n\nLocation: (730, 4992) Inventory: borderPass Behavioral traits: High-alert state, rigorous documentation verification\n\nGame State Synchronization\n\nShared inventory system with room-wide item accessibility Action completion tracking with idempotency guarantees Win/loss condition evaluation with immediate broadcast propagation\n\nEscape Routes\n\nThree distinct escape vectors, each requiring specific inventory items:\n\nRoute Required Item Location Action Tunnel Excavation shovel (1330, 3585) Underground escape Aerial Extraction helicopterKeys (4620, 5000) Helicopter evacuation Border Crossing borderPass (674, 1616) Legal exit"},{"heading":"Performance Characteristics","content":"Latency : Sub-100ms message propagation via WebSocket multiplexing Throughput : 60 FPS position updates with delta compression Scalability : Room-based isolation enables horizontal scaling AI Response Time : 2-5 seconds (batched processing with adaptive timing)"},{"heading":"API Integration","content":"The system integrates with the JLLM API using streaming completions:\n\nPOST https://janitorai.com/hackathon/completions Authorization: Bearer xxxxxxx Content-Type: application/json { \"model\": \"jllm\", \"messages\": [...conversationHistory], \"temperature\": 0.8, \"max_tokens\": 200, \"stream\": true }"},{"heading":"Event-Driven Architecture","content":"The system implements a comprehensive Socket.IO event protocol with 15+ distinct event types across five functional categories:\n\nRoom Lifecycle : createRoom , joinRoom , startGame , disconnect Movement Sync : playerMove , playerMoved NPC Interaction : enterNPCChat , sendNPCMessage , npcMessageReceived , npcTyping Game Actions : performAction , actionCompleted , itemReceived , gameOver State Management : gameStateUpdate , playerJoined , playerLeft"},{"heading":"Technologies","content":"Frontend : React 18.2, Vite 5.0, HTML5 Canvas Backend : Node.js, Express 4.18, Socket.IO 4.7 AI : JLLM API (Janitor Large Language Model) Real-Time : WebSocket protocol with Socket.IO abstraction layer"},{"heading":"Built With","content":"express.js fishaudio janitorai jllm react vite websockets"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Fish Persuasion","project_url":"https://devpost.com/software/fish-persuasion","tagline":"A charming game about persuading fish to get out of the pond :)","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/899/364/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"fish.audio: Best use of Fish Audio"}],"team_members":[],"built_with":[{"name":"audio","url":null},{"name":"fish","url":null},{"name":"fishaudio","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"godot","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Fish Persuasion is inspired by silly and absurd games like Cult of the Lamb, Turnip Boy Commits Tax Evasion, and so on. I am also inspired by Fish Audio!"},{"heading":"What it does","content":"In the game, you can move around the player and shout into a pond. If the fishes are enticed by what you say, they will emerge from the pond ‚Äï then, you have to persuade the fish to leave the pond and come with you!\n\nThe fishes also have different preferences ‚Äï eg. some might like food more, some might like exploring cool things, and they will subtly drop hints that the player must appeal to."},{"heading":"How I built it","content":"Fish Persuasion is built with Godot Engine, Fish Audio API, and Gemini API."},{"heading":"Challenges I ran into","content":"I struggled with receiving the audio stream from Fish Audio and playing it in Godot Engine. Turns out, support for dynamically loading MP3 and WAV files were just added into the engine. Super convenient!"},{"heading":"Accomplishments that I'm proud of","content":"I am proud of the visual direction of the project."},{"heading":"What I learned","content":"I learnt a lot about working with APIs through Godot, which I have never done in-depth before."},{"heading":"Built With","content":"audio fish fishaudio gemini godot"}]},{"project_title":"Roominate","project_url":"https://devpost.com/software/roominate-vp1aqu","tagline":"Ever stuck procrastinating on important tasks? Roominate breaks down your tasks into smaller steps, and incentivizes completing them by allowing you to decorate a home just for you!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/900/003/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"[MLH] Best .Tech Domain Name"}],"team_members":[],"built_with":[{"name":"asi:one","url":null},{"name":"claude","url":null},{"name":"godot","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/XitoAliferis/calhacks12"}],"description_sections":[{"heading":"Inspiration","content":"Studies have shown gamification has psychological benefits in one's ability to complete tasks. Your to-do's can feel daunting, and the \"reward\" feels too far away, especially for people with ADHD or chronic procrastination. We conducted research on spatial memory, discovering visualizing and attaching progress tracking to object formation helps users develop engagement and desire to complete tasks, decreasing the chance of dropping out and giving up tasks. Breaking tasks into smaller steps decreases the mental barrier of starting tasks and bringing in rewards with gamification drives it further."},{"heading":"What it does","content":"Roominate gamifies and offers incentives for completing your tasks by rewarding completion with the ability to decorate a cozy home.\n\nPlace Your Task: Instead of \"adding a task\" to an endless list, you are provided with a personal space and \"place a task\" in a room. This turns an abstract chore (\"Write Essay\") into a concrete \"ghosted\" object (like a Bookshelf or a plant) in a specific spot where you could categorize and recall it based on spatial memory. AI Task Breakdown: Have trouble breaking down your complex task into steps? Our AI assistant breaks that intimidating task into small, non-threatening, actionable subtasks (e.g., \"Research topic,\" \"Write outline,\" \"Write first draft\"). The \"blank page\" problem is gone. Create Your Space: Completing a task solidifies the ‚ÄúBookshelf‚Äù as a permanent, beautiful object. As you complete tasks, you unlock new rooms and more opportunities for different furniture, building a home you‚Äôre genuinely attached to. Get Motivated: The friendly cat inside your home gives you advice and motivation to complete your tasks. psst Crater... there may be a secret cow as well, but I wouldn't follow its advice!"},{"heading":"How we built it","content":"We built Roominate in Godot 4.5 focusing on seamless UI/UX design. The global logic is managed through signals to synchronize updates across all scenes. Each major system; task creation, to-do management, room layout, all communicate through these signals to ensure smooth, event-driven updates without manual dependencies.\n\nOur AI system, powered by ASI:One implemented in cat.gd and cow.gd as well as OpenRouter with Claude shown in our task step generator. In terms of the assistants, they receive updates about the latest edited task, sent through HTTP requests, and respond with a short and personality-driven feedback. The dialog appears dynamically in-game and an automatic timer, creating natural conversational flow without blocking gameplay.\n\nThe room system ties task progress directly to world building. Completed tasks instantiate corresponding furniture objects within room_layout.gd , while furniture.gd manages placement. Tasks are tracked globally enabling players to unlock rooms and better interactions with the cow and cat assistants."},{"heading":"Challenges we ran into","content":"One of the biggest challenges we faced was standing out in a space where productivity tools and gamified tasks have already been explored. We didn‚Äôt want to make something that simply looked different, we wanted it to feel different, with real emotional engagement and long-term growth potential. Finding that balance between familiar and innovate required a lot of iteration and design restraint. Integrating AI added another layer of complexity. We wanted the AI assistants (like our cat and cow personalities) to feel dynamic and responsive, but not intrusive or repetitive. Tuning their tone, behavior, and timing so they were motivating (well, at least the cat is) rather than distracting was a careful balancing act.\n\nWe also faced the usual hackathon time pressure, merging design, code, and polish under tight deadlines while keeping our vision cohesive. The biggest challenge wasn‚Äôt just technical; it was staying focused on our core idea: making productivity something players would want to return to, again and again."},{"heading":"What's next for Roominate","content":"We believe Roominate is an innovative new tool for productivity. Our roadmap for continuation includes:\n\nMultiplayer & Social Rooms: We did some user interviews and concept testing, and found that social aspects are also incentives for many people to accomplish tasks. Imagine visiting a friend's \"Sweet Home\" to see the objects they've built, or even tackling a \"group project\" that builds a shared object in a community space. Deeper Customization: Select from an option of themes such as pirate, farm, and sci-fi to make every space truly unique and personalized. Application Integration: Launch the programs or open the web pages needed for your task directly from Roominate."},{"heading":"Built With","content":"asi:one claude godot python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Jarvis","project_url":"https://devpost.com/software/jarvis-0xt8ro","tagline":"Know everything","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/891/774/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Most Wacky Hack (presented by Wordware)"}],"team_members":[],"built_with":[{"name":"meta","url":"https://devpost.com/software/built-with/meta"},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"selenium","url":"https://devpost.com/software/built-with/selenium"}],"external_links":[{"label":"github.com","url":"https://github.com/dgne58/jarvis"},{"label":"youtube.com","url":"https://youtube.com/shorts/VQDHUFmHNZA"},{"label":"youtube.com","url":"https://youtube.com/shorts/L_MScy52fvc"}],"description_sections":[{"heading":"Inspiration","content":"Cluely kinda sucks, and Iron Man is the coolest movie of 2009."},{"heading":"What it does","content":"Yeah, so we hacked the Meta Ray-Bans display to let superintelligence assist you 24/7. It guarantees you the best line for your sales pitch, the smoothest rizz for your date, and the answer to every combinatorics question Citadel could ever throw at you. Oh, and we also made it cross-reference any face you come across with a giant database that probably has you in it too, just for fun. This isn‚Äôt Cluely; this is Jarvis ."},{"heading":"Challenges we ran into","content":"We were really excited to put facial recognition in our glasses, but we ran into tons of issues trying to find a provider. Absolutely no provider supported APIs, so we had to build our own scrapers to dynamically extract information from sites using Selenium. We burned through around $70 testing different sites for face searching. A few didn‚Äôt work, and one even banned us for bot usage, which violated their ToS. So yeah, that was $30 down the drain, unfortunately."},{"heading":"Accomplishments that we're proud of","content":"We were the first ones to actually make something like this work. Cluely talked about doing something similar, but we beat them to it. Unlike Cluely, we don‚Äôt overprice and underdeliver. We just built it, hacked it, and made it real."},{"heading":"What we learned","content":"Nothing‚Äôs impossible, seriously. Meta has put so many restrictions in place to prevent people from hacking their glasses, but we scrapped it together at a hackathon anyway."},{"heading":"Built With","content":"meta opencv python react selenium"},{"heading":"Try it out","content":"github.com youtube.com youtube.com"}]},{"project_title":"Calendera","project_url":"https://devpost.com/software/clarity-joixz0","tagline":"AI-powered organizational tool for your communication platforms","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/894/152/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"[MLH] Best Use of AI powered by Reach Capital"}],"team_members":[],"built_with":[{"name":"beeper-mcp","url":null},{"name":"claude-api","url":null},{"name":"claude-sdk","url":null},{"name":"dotenv","url":null},{"name":"google-console-cloud-api","url":null},{"name":"google-oauth","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"next.js","url":null},{"name":"node-cron","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"sqlite-3","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"In the 21st century, we are constantly connected to our mobile devices from LinkedIn and Instagram to Gmail and other communication platforms. However, the flood of notifications across these channels can easily overwhelm us. We often spend unnecessary time sorting through these messages, adding events to our calendars, managing task lists, and ultimately getting distracted in the process.\n\nOur goal was to simplify this experience . We wanted to create a solution that helps users manage communication notifications efficiently while staying focused and organized. The vision was to build a customizable and easy-to-navigate product that lets users filter , prioritize , and act on notifications seamlessly, ensuring they never miss valuable opportunities or meaningful connections."},{"heading":"Our Development Process","content":"Brainstorming the Problem We started by identifying meaningful, everyday productivity issues. Using insights gathered from web research and AI discussions, we decided to tackle the growing problem of notification overload through AI-driven automation . Designing the Architecture Once our concept was finalized, we designed a clear system architecture . Our backend was structured into multiple AI agents , each responsible for specific tasks such as data retrieval, classification, and prioritization. This modular approach allowed for more accurate, refined, and scalable outcomes. Developing and Integrating Tools Using Claude Code , ChatGPT , and Windsurf , we built, tested, and refined our platform. The Claude SDK helped us develop end-to-end AI agents, while generative tools accelerated our coding and debugging workflow. We also set up a product roadmap mapping the user journey from the frontend interactions to the backend agent orchestration."},{"heading":"What We Learned","content":"Throughout this journey, we learned how to apply AI orchestration architectures to real-world productivity challenges. We gained hands-on experience with Claude SDK , ChatGPT , Windsurf , and other AI-assisted development tools , deepening our understanding of how multiple AI agents can work collaboratively.\n\nWe also honed our prompt engineering , testing , and UI/UX design skills. Most importantly, we learned how to transition from an abstract idea to a working product by following an iterative, user-centered design approach."},{"heading":"Challenges We Faced","content":"As a team of beginners, we encountered multiple obstacles that helped us grow significantly.\n\nEnsuring Proper Flow Between AI Agents Initially, testing individual agents was difficult, and debugging their interactions was time-consuming. To resolve this, we created local testing environments and adopted a modular testing strategy , ensuring each agent could operate both independently and collaboratively. Crafting a User-Friendly Interface Designing a simple, intuitive interface for users (especially those new to AI-powered tools) was a major challenge. We focused on navigation clarity , ease of use , and visual simplicity . Through feedback from mentors, friends, and family, we iterated multiple design versions to deliver a clean, user-centered experience."},{"heading":"Example of Future Expansion","content":"We envision expanding the platform to include intelligent task prediction using algorithms to help dynamically prioritize notifications based on user behavior, making the system even more adaptive and personalized."},{"heading":"Built With","content":"beeper-mcp claude-api claude-sdk dotenv google-console-cloud-api google-oauth javascript next.js node-cron node.js sqlite-3"}]},{"project_title":"Artki.tech","project_url":"https://devpost.com/software/artki-tech","tagline":"AI-native interior design platform that learns your taste and generates personalized 3D room visualizations from products you could buy off of Amazon w/ recommendations.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/059/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Chroma: Best AI application using Chroma"}],"team_members":[],"built_with":[{"name":"amazon-web-scraping","url":null},{"name":"anthropic-sdk","url":null},{"name":"chromadb","url":null},{"name":"chromadb-cloud","url":null},{"name":"claude-api","url":null},{"name":"clip","url":null},{"name":"embeddings","url":null},{"name":"fastapi","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"framer-motion","url":null},{"name":"glb","url":null},{"name":"gltf","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"lucide-react","url":null},{"name":"nerf","url":null},{"name":"neural-radiance-fields","url":null},{"name":"next-js","url":null},{"name":"openai-api","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-three-fiber","url":null},{"name":"sentence-transformers","url":null},{"name":"tailwindcss","url":null},{"name":"three-js","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vector-database","url":null},{"name":"vercel","url":null},{"name":"webgl","url":"https://devpost.com/software/built-with/webgl"}],"external_links":[{"label":"artki.tech","url":"http://artki.tech/"},{"label":"github.com","url":"https://github.com/MurtazaKafka/interior-design"}],"description_sections":[{"heading":"Inspiration","content":"The spark came during a late-night furniture shopping session. We watched a friend spend hours on Pinterest creating mood boards, then struggle to find matching furniture on multiple websites. Despite having great taste, they couldn't translate their vision into reality.\n\nWe realized this was a universal problem: the gap between inspiration and implementation in interior design. Nearly 98% of design enthusiasts are dissatisfied with their home decor, yet over $25 billion is spent on interior design each year in the U.S. While AI had revolutionized many creative fields, interior design remained fragmented across inspiration platforms, furniture retailers, and 3D planning tools.\n\nOur breakthrough insight: what if we could learn someone's aesthetic preferences the same way Spotify learns musical taste - not through questionnaires, but through choices? Museum artworks became our \"songs\" - universally recognized pieces that reveal deep aesthetic preferences through simple A/B comparisons."},{"heading":"What It Does","content":"Artki.tech is an AI-powered interior design platform that creates personalized 3D room visualizations with real, purchasable furniture based on your unique taste profile. Here's the complete flow:\n\nFloorplan Analysis : Users upload their room's floorplan, which gets transformed into a 3D room reconstruction using Claude-generated Three.js code. Taste Discovery : Users compare 12 pairs of museum artworks (Monet vs. Picasso, Van Gogh vs. Warhol). Each choice updates a 512-dimensional taste vector using CLIP embeddings, learning aesthetic preferences without questionnaires. Real Product Discovery : Our system scrapes Amazon to find actual furniture products matching your taste profile, ensuring everything you see can be purchased. AI-Powered 3D Pipeline : Amazon products are enhanced with OpenAI-generated images Images are converted to 3D models using Claude's Three.js generation Models are rendered in your reconstructed room Interactive Visualization : Real-time Three.js rendering shows actual purchasable furniture in your specific room layout. Users can rotate, zoom, and rearrange items to perfect their design. Smart Recommendations : ChromaDB's vector search finds semantically similar products based on visual features, style tags, and your evolving preferences.\n\nArchitecture Overview\n\nFrontend : Next.js 16 + React 19 + TypeScript + Three.js + React Three Fiber Backend : FastAPI + Python 3.11 AI/ML : Claude 4.5 Sonnet + CLIP embeddings + OpenAI API + NeRF Database : ChromaDB Cloud for vectors 3D : Three.js + React Three Fiber + NeRF reconstruction Data Source : Amazon product scraping for real furniture\n\nDevelopment Process & Technical Evolution\n\nInitial Approach: NeRF Neural Radiance Fields\n\nWe started by training NeRF (Neural Radiance Fields) models to create photorealistic 3D reconstructions of rooms from just a few photos Built a Flask API server ( api_server.py ) to handle NeRF training with user-uploaded images Successfully generated 3D room reconstructions from 10+ photos per room Pivot Decision : While NeRF worked, the output had low fidelity and training took 8-10 minutes per room\n\nDay 1: Foundation & Pivot\n\nSet up Next.js frontend and FastAPI backend Integrated Three.js for 3D visualization Key Pivot : Switched from NeRF to Claude API for faster, higher-quality 3D generation Claude generates Three.js code directly, which we render with React Three Fiber Reduced generation time from 30 minutes to 3 seconds\n\nDay 2: AI Integration & Product Pipeline\n\nImplemented CLIP embeddings for artwork analysis Built taste vector algorithm for preference learning Amazon Integration : Created web scraping system to find real products matching user preferences Image-to-3D Pipeline : Scrape Amazon for furniture matching user taste Use OpenAI API to generate product images Convert images to 3D models using Claude Render models in Three.js scene\n\nDay 3: Complete System Integration\n\nConnected floorplan upload to room reconstruction Integrated user preference embeddings with product search Built complete pipeline: Floorplan ‚Üí Room Reconstruction ‚Üí Preference Analysis ‚Üí Amazon Scraping ‚Üí Image Generation ‚Üí 3D Conversion ‚Üí Final Visualization Polished UI/UX with TailwindCSS\n\nComplete Technical Pipeline\n\nRoom Reconstruction : User uploads floorplan ‚Üí Claude generates Three.js room geometry from floorplan specifications Taste Learning : CLIP encodes museum artworks into 512-dimensional vectors. User choices update their vector: user_vec = user_vec + win_vec - 0.5 * lose_vec Product Discovery : Scrape Amazon for furniture matching taste vector Extract product metadata (price, dimensions, materials) Generate embeddings for semantic search 3D Model Generation : OpenAI API transforms product descriptions into detailed images Images fed to Claude for Three.js code generation Real-time rendering of actual products as 3D models Final Visualization : Combine room reconstruction with generated furniture models in interactive 3D scene"},{"heading":"Challenges We Ran Into","content":"1. NeRF Training Performance\n\nProblem : NeRF neural radiance field training took 15-30 minutes per room with low-fidelity output. Solution : Pivoted to Claude API for instant Three.js code generation, reducing time from 30 minutes to 3 seconds while improving quality.\n\n2. Amazon Product Integration\n\nProblem : Connecting abstract taste preferences to real, purchasable products. Solution : Built web scraper for Amazon products, then used embeddings to match products to user taste vectors.\n\n3. Image-to-3D Conversion Pipeline\n\nProblem : No direct way to convert Amazon product images to 3D models. Solution : Created multi-step pipeline: Amazon data ‚Üí OpenAI image enhancement ‚Üí Claude 3D code generation ‚Üí Three.js rendering.\n\n4. 3D Model Loading Issues\n\nProblem : GLTF files referenced external textures, causing 404 errors. Solution : Converted to self-contained GLB format with embedded textures.\n\n5. Embedding Performance\n\nProblem : Generating CLIP embeddings for scraped products took 30+ seconds. Solution : Pre-computed embeddings stored in ChromaDB, reducing search to <100ms.\n\n6. AI Code Generation Reliability\n\nProblem : Claude sometimes generated invalid Three.js code for complex furniture. Solution : Implemented robust error handling with fallback hand-crafted generators for common furniture types.\n\n7. Floorplan to 3D Reconstruction\n\nProblem : Converting 2D floorplan images to accurate 3D room geometry. Solution : Used Claude to interpret floorplan and generate proportional Three.js room structures."},{"heading":"Accomplishments That We're Proud Of","content":"Successfully Pivoted from NeRF : Started with neural radiance fields, recognized limitations, and pivoted to a better solution within 24 hours End-to-End Pipeline : Built complete pipeline from floorplan upload to 3D room with real Amazon products - a truly functional prototype Multi-AI Orchestration : Successfully integrated 5 different AI systems (Claude, CLIP, OpenAI, ChromaDB, NeRF) into one seamless experience Real Product Integration : Connected abstract preferences to actual purchasable Amazon products, solving a real-world problem Real-time 3D Generation : Reduced 3D generation from 30 minutes (NeRF) to 3 seconds (Claude) while improving quality Lightning-Fast Search : <100ms semantic search across scraped products with 512-dimensional vectors Production-Ready Architecture : Built scalable, well-documented codebase that could be deployed tomorrow"},{"heading":"What We Learned","content":"Technical Insights\n\nMulti-modal AI is powerful : Combining visual (CLIP) and language (Claude) AI creates emergent capabilities Vector databases are game-changers : ChromaDB enabled instant personalized search Prompt engineering matters : Structured prompts improved Claude's code generation by 70% Fallbacks are essential : Every AI component needs a reliable backup\n\nProduct Insights\n\nUsers want simplicity : 12 comparisons hit the sweet spot between accuracy and user patience Visual choices reveal preferences : People make faster, more confident decisions with images than questionnaires 3D visualization sells : Seeing furniture in context dramatically improves user confidence\n\nTeam Insights\n\nAPI integration complexity : Coordinating multiple external APIs requires careful error handling Performance optimization is iterative : Each bottleneck revealed led to architectural improvements"},{"heading":"What's Next for Artki.tech","content":"Immediate Goals (Next Month)\n\nReal Furniture Integration : Partner with IKEA, Wayfair, West Elm for actual purchasable items Mobile AR Preview : Use ARKit/ARCore for in-room visualization Expand Catalog : 500+ furniture items with real product links\n\nBusiness Model\n\nFreemium : Free taste profiling + 3 room designs Pro Subscription : Unlimited designs, high-res exports, AR preview Affiliate Revenue : Commission from furniture purchases Enterprise API : White-label solution for furniture retailers"},{"heading":"Built With","content":"amazon-web-scraping anthropic-sdk chromadb chromadb-cloud claude-api clip embeddings fastapi flask framer-motion glb gltf javascript lucide-react nerf neural-radiance-fields next-js openai-api python react react-three-fiber sentence-transformers tailwindcss three-js typescript vector-database vercel webgl"},{"heading":"Try it out","content":"artki.tech github.com"}]},{"project_title":"I-IMO","project_url":"https://devpost.com/software/i-imo","tagline":"Intelligent IRL Meeting Organizer - A conversational AI agent designed with the busiest people in mind.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/887/931/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"[MLH] Best Use of DigitalOcean Gradient‚Ñ¢ AIOpt"}],"team_members":[],"built_with":[{"name":"chromadb","url":null},{"name":"convex","url":null},{"name":"digtalocean","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"fastapi","url":null},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"openai","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"shadcn","url":null},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null},{"name":"yolo","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/satvikprasad/i-imo/"}],"description_sections":[{"heading":"Inspiration","content":"Ever had an incredibly busy day and can't remember all the people you've met, or all the tasks you've got planned for the future? We're humans! Our memory is imperfect and that's difficult, but it doesn't need to be: so we built I-IMO!\n\nI-IMO is a conversational AI agent designed with the busiest people in mind. I-IMO scans both visual input (webcam) and aural input (OMI devkit2) throughout your day to organize and summarize profiles for everyone you meet, while maintaining task lists and tracking important events so you never forget anything important from your meetings.\n\nN.B: We originally wanted to do this app on any smart glasses, but unfortunately due to supply constraints we couldn't get one. In the future, the plan is to adapt our project to run off of in-built webcams in devices like the Omi Glass."},{"heading":"What is I-IMO?","content":"I-IMO is a personal conversational intelligence assistant that is an always-on second-in-command:\n\nCaptures conversations through real-time audio transcription Recognizes faces via webcam to identify meeting participants Builds personal profiles automatically from conversation context Extracts action items and creates task lists from discussions Maintains conversation history with semantic search capabilities Never lets you forget important details about the people you meet Generates context to infer insightful predictions/aids for upcoming events in your calendar."},{"heading":"Our Tech Stack","content":"React + Typescript + Vite, FastAPI + Custom YOLO11n model for face detection, Tailwind + Shad/CN UI, Convex Backend, Express.js Backend for NLP, Groq-hosted gpt-whisper for audio transcribing, Digital Ocean AI Gradient for GPU intense task, ChromaDB for vectorised queries and semantic search, OpenAI Text Embedding."},{"heading":"Challenges We Ran Into","content":"connection issues üò°, streaming raw audio data from Omi (with low latency), high accuracy face classification that remains consistent (tagging id and tag name with it), deduplication of misspellings of names and mistranscriptions, nature of audio streaming: 5 second chunks clipping certain transcribed words, syncing vectorised ChromaDB with traditional Convex backend, minimising non-deterministic nature of profile summaries and task predictions,"},{"heading":"Important Lessons","content":"Learnt how to integrate a lot of different technologies and choose/route between the best models for unique workloads, Designed ways to sync between multiple backends and frameworks, especially with fundamental infra differences between vectorised semantic-search db's and traditional backends, Balanced the benefits lightweight, fast inference models with the lower completion accuracy, Developed a lot of ad-hoc teamwork skills while working on the same project with time-pressure (minimising merge-conflicts, documenting pull-requests using tools like CodeRabbit, keeping commit tree clean...)"},{"heading":"What's Next","content":"Deep integration with glasses (Meta Raybans, Omi Glass, Snapchat Spectacles), Potentially link 3rd party MCP providers, Connect with social media platforms for deeper context / automated actions based on the user's day, Time-sensitive summaries, Mobile, watch, and native versions of the dashboard."},{"heading":"Built With","content":"chromadb convex digtalocean express.js fastapi groq openai react shadcn tailwind typescript vite yolo"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Remixify","project_url":"https://devpost.com/software/remixify","tagline":"Don't scroll Reels, scroll Remixify.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/129/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"[MLH] Best Use of Gemini API"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"letta","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"supabase","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"veo3","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/nidhigaonkar/calhacks25"}],"description_sections":[{"heading":"‚ú® Inspiration","content":"Remixify revolutionizes the way users interact with companies to create a better and more engaging experience for viewers. Remixify was inspired by the growing need for brands to create more engaging, personalized, and data-driven advertising content. We also thought it'd be really funny to edit videos and images with AI for people to explore their creativity and have fun collaborating together.\n\nThe main idea for our app is that:\n\nAdvertisers rarely know what consumers wish their ads looked like or what made their ad so viral beyond surface-level metrics Creative users, especially young creators, want a way to express themselves, win rewards, and actually be heard by the brands they engage with. Remixify creates a platform where creativity and product discovery meet."},{"heading":"What it does","content":"Remixify is an innovative platform that transforms traditional advertising into an interactive, fun, community-driven experience. Users can also scroll a feed of real ads and remix them using advanced AI image and video generation ( fully Gemini powered! ), with style presets and creative prompts, for example, ‚ÄúAdd a cat mascot‚Äù or ‚Äúturn the sky to night‚Äù. User can share, earn likes, comments & win brand-sponsored rewards based on the remixes they make. Users can also upload an image, and we use Gemini to label and tag the company automatically.\n\nRemixify then provides real-time insights into ad performance, audience engagement, and creative trends using Letta's Deep Research Agents to extract insights from every remix + interaction, and memory blocks that accumulate key information such as: Most remixed ad elements and which remixes improve engagement or virality\n\nAnd organize all this information into an Analytics page, so companies finally see what people actually want, including specific information about demographics, top aesthetics, and more. Finally, we help predict ad performance through Signal Extraction. We built a model to analyze user behavior (prompts summarized by Claude ), commenting patterns, and performance metrics to provide actionable insights for the company. For example, we extract context clues like references to TikTok, Instagram, or specific trends to see platforms that users are most active on to target ad spend."},{"heading":"üõ†Ô∏è How We Built It","content":"Tech stack:\n\nFrontend:\n\nNext.js for the web application framework Tailwind CSS for styling Shadcn UI components for a modern, accessible interface TypeScript\n\nBackend & AI:\n\nSupabase for database and authentication Custom API routes for handling image generation and analysis Integration with Google's Gemini API extensively for image editing (Nano Banana üçå) Integration with Google‚Äôs Veo3 for video editing Real-time data processing for analytics and signal extraction\n\nAnalytics:\n\nCustom analytics engine ( Letta ) for user insights and analytics Claude for creative insights and trend analysis Real-time performance metrics and behavioral pattern recognition Opportunities for Conversion integration to automatically reach out to leads.\n\nLetta Deep Research Agents Integration: We use Letta‚Äôs agents and their Memory Blocks to track:\n\nMost remixed ad elements Popular user modifications Letta Deep Research Agents extract overall sentiments and advice, helping brands understand how users feel about the brand as a whole Which remixes improve engagement or virality"},{"heading":"üßó Challenges We Ran Into","content":"Real-time Video and Image Generation: Implementing fast and reliable AI-powered image generation while maintaining quality and brand consistency. Although calling the API for video generation was not that difficult, it was very hard to get it to maintain the same theme as the original video as well as ensure that the generation didn't take too long.\n\nPerformance Optimization: Handling large-scale data processing for analytics while maintaining a responsive UI. Making the comments hierarchical so people's edits could affect each other was a little bit difficult since we had to handle storing data in Supabase and pulling it very quickly in order to apply different comments.\n\nData Analysis: Building Letta Agents with Deep Research and Memory Blocks to extract meaningful signals from user behavior and ad performance, not just noise. Overall, we coordinating multiple AI services and ensuring seamless communication between frontend and backend was pretty difficult but we got it to work."},{"heading":"Accomplishments that we're proud of","content":"Built a sophisticated AI-powered creative platform in a short timeframe Created an intuitive and engaging user interface for complex features and a full-fledged social platform. Implemented advanced analytics with real-time analysis. Successfully integrated multiple AI models for different aspects of the platform in a way that is invisible but still valuable to the user."},{"heading":"What we learned","content":"We learned more about real-time Analytics, especially how to process and visualize large amounts of data efficiently. We also focused a lot on user experience and design, and discovered how to make complex features accessible to users in a way that was easy to understand. Prompt engineering is critical: Specificity, tone, and structure determine the output, especially for the video models. Design matters: We spent time creating chat panes, responsive cards, and leaderboards, all small things that made the platform intuitive and engaging."},{"heading":"What's next for Remixify","content":"Our main idea is to expand from just ads and provide a platform where users can remix and create funny videos and photos, but also maintain this idea of campaigns, where companies can incentivize users to remix their specific ads by providing prizes.\n\nWe also want: Bettter Analytics: more detailed audience segmentation and possibly suggestions for the company to figure out where/who to market to, or creating marketing assets just from these analytics.\n\nExpansion into mobile app form to better reflect TikTok or Instagram feeds, as well as API access for third-party integrations (ex: Download video of a TikTok and remix that), support for more ad formats and platforms"},{"heading":"Built With","content":"claude css gemini javascript letta python supabase typescript veo3"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Jarvis: An agentic AI operator that does everything for you.","project_url":"https://devpost.com/software/jarvis-an-agentic-voice-assistant-that-does-things-for-you","tagline":"AI operator with vision that autonomously controls your computer (mouse, keyboard & apps) completely through your voice (or text) input, and uses reasoning to handle complex tasks end-to-end.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/897/792/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"[MLH] Best Use of ElevenLabs"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"elevenlabs","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"httpx","url":null},{"name":"openai","url":null},{"name":"pillow(pil)","url":null},{"name":"pyautogui","url":null},{"name":"pyobjc","url":null},{"name":"pyperclip","url":null},{"name":"pyscreeze","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sounddevice","url":null},{"name":"soundfile","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/adhvaidhsunny/jarvis-ai"}],"description_sections":[{"heading":"Built With","content":"claude elevenlabs gemini httpx openai pillow(pil) pyautogui pyobjc pyperclip pyscreeze python sounddevice soundfile"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"MIRAI","project_url":"https://devpost.com/software/boxing-robot","tagline":"Teaching robots to see, listen, and move like us. MIRAI is an experimental human-robot interaction framework that enables natural motion and voice-based control of robots.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/901/119/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"BitRobot Network: Best Robotics Hack - 1st Place"}],"team_members":[],"built_with":[{"name":"mediapipe","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pinocchio","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sdk2","url":null},{"name":"speechrecognition","url":null},{"name":"unitree","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/A-Mundanilkunathil/Unitree-G1"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by the idea of making robots move more naturally ‚Äî not through pre-programmed motions or scripts, but by understanding and reacting to human movement the same way humans do. Watching fighters and athletes move made us wonder: what if a robot could learn to mirror that instinctively, using only vision and sound? That curiosity turned into MIRAI ‚Äî Machine Interaction through Real-time Awareness and Imitation, a system that lets a robot see you, follow you, and even understand your voice."},{"heading":"What it does","content":"MIRAI allows a Unitree G1 humanoid robot to perceive, imitate, and respond to human behavior in real time. Using a camera and microphone, the robot can:\n\nDetect and mirror human upper-body movements with natural motion.\n\nFollow the user‚Äôs position as they move through space.\n\nRespond to voice commands such as ‚Äúfollow me,‚Äù ‚Äústop,‚Äù or ‚Äúmirror mode.‚Äù\n\nThe result is a robot that doesn‚Äôt just move ‚Äî it interacts."},{"heading":"How we built it","content":"We combined several cutting-edge tools and frameworks to bring MIRAI to life:\n\nMediaPipe and OpenCV for fast, real-time human pose detection and tracking from a camera feed.\n\nPinocchio for inverse kinematics, converting human joint angles into robot joint configurations.\n\nSpeechRecognition for our speech-to-action pipeline, translating voice commands into behaviors that the robot executes.\n\nA lightweight Python control layer built on Unitree SDK2, which sends motion commands directly to the robot‚Äôs motors.\n\nFinally, we added motion smoothing and timing filters to eliminate jitter and make the robot‚Äôs imitation feel human ‚Äî fluid, balanced, and reactive."},{"heading":"Challenges we ran into","content":"Human-to-robot mapping: Translating human motion data into robotic joint space was a major challenge, given that human anatomy doesn‚Äôt directly match the robot‚Äôs structure.\n\nLatency issues: Early tests showed slight delays in movement response, which we mitigated through data smoothing and async pipelines.\n\nBalance and stability: The G1 needed custom calibration to maintain stability while performing large arm movements during imitation.\n\nSpeech reliability: Background noise often interfered with command recognition, requiring dynamic audio filtering."},{"heading":"Accomplishments that we‚Äôre proud of","content":"Achieved real-time motion imitation with minimal lag.\n\nBuilt a working speech-to-action system that allowed natural control of the robot.\n\nDeveloped a human-aware following mode, enabling the robot to track user position while maintaining a safe distance.\n\nCreated an integrated control loop that combines vision, audio, and motor control ‚Äî a step toward unified human-robot interaction.\n\nSeeing the robot shadow our movements and respond to our voice felt like the start of something bigger ‚Äî almost like watching fiction turn into reality."},{"heading":"What we learned","content":"The importance of synchronizing multimodal systems (vision + audio + actuation).\n\nFine-tuning inverse kinematics requires both math and intuition.\n\nSmooth motion is more impactful than just accuracy ‚Äî a small delay feels more human than a perfect but robotic response.\n\nCombining multiple AI pipelines (speech and pose) is surprisingly powerful when done in real time.\n\nMost importantly, we learned that true human-robot interaction isn‚Äôt just about sensors ‚Äî it‚Äôs about creating presence."},{"heading":"What‚Äôs next for MIRAI","content":"We‚Äôre looking to expand MIRAI beyond shadowing and speech commands into intent recognition ‚Äî where the robot predicts motion or responds emotionally to interaction cues. Our next milestones:\n\nAdd gesture-based control and multi-person tracking.\n\nPort MIRAI to more robot platforms for teleoperation and rehabilitation robotics.\n\nIntegrate LLMs for contextual speech understanding, allowing conversational coordination.\n\nExplore industrial and healthcare applications where intuitive motion mirroring could enhance safety and collaboration.\n\nMIRAI started as a boxing robot. It‚Äôs quickly becoming a framework for natural human-robot symbiosis."},{"heading":"Built With","content":"mediapipe opencv pinocchio python sdk2 speechrecognition unitree"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Tapped In","project_url":"https://devpost.com/software/tapped-in","tagline":"Real-time map for community events around you.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/900/062/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Creao: Best Real-World Productivity Tool"}],"team_members":[],"built_with":[{"name":"creao","url":null},{"name":"google-maps","url":"https://devpost.com/software/built-with/google-maps"},{"name":"maps","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/valerie-cal/tapped-in"},{"label":"production.creao.ai","url":"https://production.creao.ai/share?app=nRTwO4Lp&utm_source=share&utm_medium=link"}],"description_sections":[{"heading":"Inspiration","content":"More than ever, we hear phrases like ‚Äúloneliness epidemic,‚Äù ‚Äúbed rotting,‚Äù and ‚Äúdoomscrolling.‚Äù These are real issues.\n\nAlthough we have advanced productivity apps for work or health, there isn‚Äôt a good solution to reduce friction in expanding our social comfort zones.\n\nExisting event apps just show lists. Calendars are private. After a busy day of college/work, finding the right, relevant, and timely social event requires too much effort and copy-pasting. Events are hidden in Instagram stories, spam emails, and word of mouth. We miss opportunities because information is convoluted and spread across too many platforms.\n\nTo improve social productivity, we built Tapped In : a platform where finding in-person events is as easy as glancing at a map. Creating events is instant- hosts can effectively manage attendees, event logistics, and smart analytics."},{"heading":"What it does","content":"Tapped In is a geo-spatial social productivity platform. It uses AI and custom APIs to instantly match users with location-based events, making both joining/hosting events effortless and effective.\n\nFor Users: An intuitive map interface uses your location and preferences to visually filter your area for events relevant to you (e.g., career fairs, free food, hobby groups). Get automatic, customized Gmail and Google Calendar notifications that summarize your RSVPs.\n\nFor Organizers: Submit a public event instantly. Our AI automatically suggests categorization tags, handles all RSVPs, and calendar management (including cancellation notices and attendee contact information)."},{"heading":"How we built it","content":"We used Creao, an AI-native tool building platform and implemented both built-in and custom API and MCP servers.\n\nCore: Use Creao to generate the entire front-end (Map UI, Carousel, Settings Panel) and the relational database schema (Users, Events, Preferences, RSVPs). Logic: Automatically scans the event description and title to suggest Event Type tags (e.g., \"Concert,\" \"Product Promotion\"). Custom API Workflow: Connect Creao to GoogleMaps JavaScript API to handle geospatial view, add markers, and autofill addresses. OpenAI GPTChat handles generated email content and event labelling. Gmail and Google Calendar MCP integrations handle notifications on RSVP status."},{"heading":"Challenges we ran into","content":"Understanding the tradeoffs between API and MCP servers. The provided MCP for GoogleMaps was not for our primary use case, requiring our to adapt our approach to integration to using API. Found that saving files within the Creao environment caused app functionality to be slow (delayed UI), as the system needed to validate the entire stack. Weren't able to manually edit code files on Creao. Needed to adapt prompts to include exact code file changes."},{"heading":"Accomplishments We're Proud Of","content":"RSVP Notifications: Automatically removing canceled events from RSVP'd users' calendars and send an email notification. Friend Requests: Ability to add/remove friends and view their event RSVPs. Map UX: Creating a full-screen map-view mobile interface and achieving a UX that makes finding events fun by seeing friends' events."},{"heading":"What We Learned","content":"We learned to be extremely specific and provide detailed examples in our Creao prompts to minimize validation time and guide the AI toward the intended architecture, helping mitigate the front-end latency we experienced. MCP vs. REST: We gained a better understanding of the difference between an API and an MCP server, as well as how a server connects to a service. For agentic workflows, custom logic must be built into an external service that conforms to the MCP standard."},{"heading":"What's Next for Tapped In","content":"Exclusive Events: Events only appears for specific groups (eg. Berkeley Students, Companies) Increased Personalization: Recommend events based on prior event attendance and interactions. Add \"Friend Recommendations\" tab based on similarity of events attended. Monetization: Integrate a payment API (via another custom webhook) for organizers to promote events (eg. golden border on pins, shows up first in event carousel). Community Forums: Follow a event host and gain updates on their latest events. Gamification: Use the User Stats Page data to award badges and leaderboards for event creation and attendance."},{"heading":"Built With","content":"Creao AI GoogleMaps JavaScript API OpenAI GPTChat API CreaoFileUpload API Google Calendar MCP Gmail MCP"},{"heading":"Built With","content":"creao google-maps maps react typescript vite"},{"heading":"Try it out","content":"github.com production.creao.ai"}]},{"project_title":"Research Compass","project_url":"https://devpost.com/software/research-compass","tagline":"Stop hunting, start researching: AI that finds opportunities and opens doors","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/899/294/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Creao: Smartest AI agent prize"}],"team_members":[],"built_with":[{"name":"alembic-(database-migrations)","url":null},{"name":"brightdatamcp","url":null},{"name":"claude","url":null},{"name":"composiotoolrouter","url":null},{"name":"creao.ai","url":null},{"name":"docker-(for-postgresql-with-pgvector)","url":null},{"name":"fastapi","url":null},{"name":"javascript/react","url":null},{"name":"openai-api-(embeddings-&-text-generation)","url":null},{"name":"openai-embeddings-(text-embedding-3-large-or-similar)","url":null},{"name":"pydantic","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"python-dotenv","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"render","url":null},{"name":"sql","url":"https://devpost.com/software/built-with/sql"},{"name":"sqlalchemy","url":"https://devpost.com/software/built-with/sqlalchemy"},{"name":"tailwind-css","url":null},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/gengyudong/research-compass"},{"label":"production.creao.ai","url":"https://production.creao.ai/share?app=3gR3NLBc&utm_source=share&utm_medium=link"}],"description_sections":[{"heading":"Inspiration","content":"The genesis of Research Compass emerged from a conversation with a senior researcher at OpenAI about breaking into academic research. This revealed a systemic challenge: despite abundant opportunities at leading institutions, critical information remains fragmented across hundreds of disparate university portals in inconsistent formats. 86% of students invest weeks manually aggregating contacts and crafting outreach communications.\n\nWe recognized this as a tractable problem at the intersection of data engineering, AI, and UX design. Research Compass reimagines this workflow, transforming weeks of manual labor into an intelligent, automated system that democratizes research access."},{"heading":"What It Does","content":"Research Compass is an end-to-end AI-powered platform that compresses the multi-week opportunity search into minutes:\n\nIntelligent Aggregation: Autonomous web scraping continuously harvests research programs and lab openings from top-tier universities globally Semantic Matching Engine: AI-powered vector similarity search matches students with opportunities based on deep contextual understanding of interests, skills, and academic background Automated Outreach Generation: LLM-powered email composition creates highly personalized, professional correspondence highlighting relevant qualifications Application Intelligence: Real-time analytics tracking email delivery, open rates, reply sentiment, and follow-up orchestration\n\nThe result: Students connect with exponentially more relevant opportunities while maintaining authenticity at scale."},{"heading":"How We Built It","content":"Backend Infrastructure\n\nFastAPI for our REST API backend PostgreSQL with pgvector extension for vector similarity search OpenAI embeddings for semantic matching between student profiles and opportunities Anthropic Claude for generating personalized emails Composio for Gmail integration and email tracking Python web scraping tools to aggregate opportunities from university websites\n\nFrontend\n\nReact with TypeScript for type safety Creao.ai to accelerate UI development and component generation TailwindCSS for styling Vite for fast development and builds"},{"heading":"Challenges We Ran Into","content":"Heterogeneous Data Unification: Universities structure their research pages completely differently. Some use tables, others use narrative text, and formats vary wildly. We built flexible scrapers that can adapt to different layouts while maintaining data quality.\n\nVector Search Setup: Getting pgvector working across different development environments was technically challenging. We had to carefully configure the database extension and optimize query performance.\n\nAI Email Quality: Getting AI-generated emails to sound genuine and personalized rather than generic was difficult. We experimented extensively with different prompts, examples, and parameters to achieve natural-sounding output that students would actually want to send.\n\nFrontend-Backend Integration: Connecting our React frontend with the FastAPI backend required careful API design and handling asynchronous operations properly to keep the UI responsive."},{"heading":"Accomplishments That We're Proud Of","content":"Creao.ai Integration: We used Creao's AI-powered development tools to rapidly build our frontend interface, which let us iterate quickly on the user experience and focus more energy on the backend challenges like semantic search and email generation.\n\nFunctional Semantic Search: We successfully implemented vector embeddings and similarity search that actually returns relevant matches. Students can describe their interests in natural language and get meaningful opportunity recommendations.\n\nEnd-to-End System: We built a complete working application from authentication through opportunity discovery to email sending and tracking. All the pieces work together to deliver a cohesive user experience."},{"heading":"What We Learned","content":"Full-Stack Development: We gained hands-on experience building a complete application where frontend, backend, database, and external APIs all need to work together seamlessly.\n\nWorking with AI APIs: We learned how to integrate multiple AI services (OpenAI, Anthropic, Composio) and handle their different requirements, rate limits, and response formats.\n\nDatabase Design: We learned about both traditional relational data and vector embeddings, understanding when to use each approach and how to combine them effectively.\n\nRapid Prototyping: Using tools like Creao.ai showed us how AI-assisted development can speed up certain parts of the development process without sacrificing quality."},{"heading":"What's Next for Research Compass","content":"Scale and Intelligence\n\nExpand to more universities and research institutions Add support for international opportunities Improve matching algorithms based on user feedback Parse uploaded resumes to automatically populate student profiles\n\nCommunity Features\n\nEnable direct messaging between students and researchers Create student communities around research areas Add success stories and application outcome tracking\n\nEnhanced Functionality\n\nTrack full application lifecycle from initial contact to acceptance Smart notifications for new opportunities and follow-up reminders Advanced filtering by location, funding, remote options, and time commitment Save opportunities and manage multiple applications simultaneously\n\nOur ultimate vision: Eliminate systemic barriers in research access, ensuring every student, regardless of institutional prestige, location, or network, can engage in meaningful research."},{"heading":"Built With","content":"alembic-(database-migrations) brightdatamcp claude composiotoolrouter creao.ai docker-(for-postgresql-with-pgvector) fastapi javascript/react openai-api-(embeddings-&-text-generation) openai-embeddings-(text-embedding-3-large-or-similar) pydantic python python-dotenv react render sql sqlalchemy tailwind-css vite"},{"heading":"Try it out","content":"github.com production.creao.ai"}]},{"project_title":"MARC: Marker Actuated Robotic Controller","project_url":"https://devpost.com/software/marc-marker-actuated-robotic-controller","tagline":"Meet MARC, the robot that turns text prompts into crisp drawings. In minutes, MARC uses LLM & LinAlg-based framework to drive a robot arm, ready for any setting where ink, motion, & imagination meet.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/900/196/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"BitRobot Network: Best Robotics Hack - 2nd Place"}],"team_members":[],"built_with":[{"name":"hugging-face","url":null},{"name":"lerobot","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"stable-diffusion","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/yyardi/cal-hacks-marc"}],"description_sections":[{"heading":"Inspiration","content":"Our inspiration behind MARC stems from wanting to close the gaps between imagination and creation. Today, turning a digital idea into something physical can take hours of calibration and setup, killing spontaneous creativity. High costs also make creative robotics inaccessible. For example, many precision robot arms cost over $10,000, putting them far beyond the reach of students, artists, and hobbyists. And perhaps most importantly, over 285 million people with visual impairments are excluded from visual creation tools; while AI-generated art continues to evolve, those who can‚Äôt see it are still unable to feel what it creates. Our project aims to change that by making the process of turning ideas into tangible, touchable art faster, cheaper, and more inclusive."},{"heading":"What it does","content":"The system takes natural language text prompts and optional image references to generate original artwork, then automatically translates these digital creations into precise physical drawings executed by a robotic arm. Through advanced coordinate transformation and real-time motion control, MARC bridges the gap between AI-generated images and tangible art, delivering sub-2mm positioning accuracy as it brings digital designs to life on paper."},{"heading":"How we built it","content":"The system architecture consists of four integrated stages. First, AI generation uses a Stable Diffusion XL pipeline with SD 1.5 fallback to create artwork from text prompts. Next, smart vectorization converts PNG outputs to SVG format using Portrace and SVGpathtools while fitting the artwork into 15 cm x 17.3 cm page dimensions. The third stage handles precise coordinate transformation by detecting paper corners via camera vision to build a homography matrix that maps pixels to millimeters, then applies 2D affine transformation formulas to convert page coordinates into the robot's base frame. Finally, robotics execution is achieved through a 6-DOF SO-ARM 101 with degrees-mode control, a custom 3-link planar IK solver, and real-time joint angle streaming for smooth, accurate drawing movements."},{"heading":"Challenges we ran into","content":"We encountered three major technical challenges during development. First, inaccurate motors caused servo backlash, USB packet loss, and position error accumulation. We solved this by implementing a closed-loop inverse kinematics controller with real-time error correction, achieving sub-2mm accuracy. Second, integrating three frameworks with incompatible APIs (LeRobot using degrees, RustyPot using 0-1, and PySerial using bytes) cost us over 20 hours in rewrites. We built a thin abstraction layer under 200 lines, prototyped all three approaches in 6 hours, and selected LeRobot for its community support and degrees-native interface. Finally, marker physics issues like nib compression and inconsistent ink flow limited us to one marker shape. We designed a universal 3D-printed spring-loaded adapter with 5-18mm diameter compatibility that maintains consistent pressure while absorbing vibrations."},{"heading":"Accomplishments that we're proud of","content":"We're incredibly proud of building a system that accurately translates drawing coordinates into precise robotic movements, achieving pinpoint accuracy within 2mm. Figuring out how to convert real-world positions into instructions the robot could understand was a major breakthrough, requiring us to use camera vision to map the physical paper space to the robot's coordinate system. Beyond the technical work, we're proud of handling the pressure and rapid problem-solving of our first hackathon, transforming an ambitious idea into a working system that takes a text prompt and produces a physical drawing on paper in minutes."},{"heading":"What we learned","content":"This project taught us invaluable lessons about collaboration and resourcefulness. We discovered the power of open-source communities, finding extensive documentation and ready-to-use tools like LeRobot that accelerated our development and saved us countless hours of building from scratch. We learned the importance of parallel experimentation, testing multiple approaches simultaneously rather than betting everything on a single solution, which proved crucial when we had to evaluate three different frameworks in just six hours. Most importantly, we realized that constant communication is essential in a fast-paced hackathon environment. Keeping everyone aligned on goals, progress, and challenges minimized confusion and prevented wasted effort from misunderstandings. Working under pressure taught us to balance ambitious technical goals with practical time constraints, and that success comes from both individual problem-solving and effective teamwork."},{"heading":"What's next for MARC: Marker Actuated Robotic Controller","content":"Looking ahead, we plan to expand MARC's capabilities in several exciting directions. First, we'll add multi-color support to enable more vibrant and complex artwork. We're committed to open-source publishing, making our code and designs available for others to build upon and learn from. To make MARC more accessible, we'll develop a remote control system with a queue feature, allowing multiple users to submit drawing requests from anywhere. We also envision an adaptive learning system that improves drawing quality over time by learning from past movements and corrections. Finally, we want to transform MARC into a multi-modal fabrication platform that goes beyond drawing, potentially supporting different tools and creative outputs to bridge the gap between digital creativity and physical making."},{"heading":"Built With","content":"hugging-face lerobot opencv python pytorch stable-diffusion"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Salient Labs","project_url":"https://devpost.com/software/salient-9ohv4q","tagline":"Sharper Where it Matters","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/900/073/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"BaseTen: Best Use of Open Source Models"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"baseten","url":null},{"name":"ffmeg","url":null},{"name":"next","url":null},{"name":"opengl","url":"https://devpost.com/software/built-with/opengl"}],"external_links":[{"label":"github.com","url":"https://github.com/k-kochhar/CalHacks"},{"label":"www.trysalient.tech","url":"https://www.trysalient.tech/"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAG24Vg8wWQ/vq_ty0v58btcJPaLjEPQNw/edit?utm_content=DAG24Vg8wWQ&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"}],"description_sections":[{"heading":"Inspiration","content":"SOCIAL IMPACT\n\nInternet Cost by Country 2025\n\nMachine learning‚Äìbased video compression can shrink file sizes and cut bandwidth needs by up to 50% , directly lowering streaming infrastructure costs by 30‚Äì40% . By reducing the data required to deliver high-quality video, this technology makes online education, healthcare, and communication accessible to the 2.6 billion people still offline due to costly and limited internet access. We are motivated to actively work to bridge this digital divide in order to bring connection and opportunity to millions worldwide.\n\nDEMAND\n\nWhy Buffering is Every Video Providers Worst Nightmare\n\nTwitch Shuts Down in South Korea\n\nStreaming Services Cutting Bitrates to Save Money\n\nEven before COVID-19, video providers were already losing massive engagement ‚Äî a mere 1% increase in buffering time translated into about 2.9 billion hours of lost viewing in a single quarter. With the global video streaming market valued at roughly US$674 billion in 2024, even a slight reduction in viewer hours or increase in cost can equate to hundreds of millions in lost revenue or extra expense. At the same time, streaming platforms are taking desperate measures ‚Äî slashing bitrate, reducing quality, and squeezing compression ‚Äî to cut bandwidth and delivery costs that run into the billions annually across the industry. Mounting engagement risk plus soaring delivery cost creates a compelling demand for a solution that both preserves viewer experience and lowers data usage ."},{"heading":"What it does","content":"Our system rethinks video compression by mirroring how the human eye perceives importance in a scene. Rather than preserving every pixel equally, it identifies the regions that naturally capture attention‚Äîfaces, motion, or areas of high contrast‚Äîand keeps those sections sharp, while less noticeable regions are transmitted at lower resolution. On the viewer‚Äôs side, these regions are simply scaled back up, creating a smooth but visibly adaptive level of detail across the frame."},{"heading":"How we're unique","content":"What makes this approach unique is that it doesn‚Äôt just compress data: it compresses perception . Traditional codecs work uniformly across the screen, but this is the first model that embraces resolution variation as part of the design, keeping the experience realistic while using a fraction of the data. The effect is subtle yet powerful: scenes look natural, but the underlying file is dramatically smaller. The method has clear potential in both pre-processed content (YouTube and Netflix), where bandwidth directly affects cost, and live video (Zoom and FaceTime), where fluctuating network speeds are prevalent."},{"heading":"How we built it","content":"We designed our system to mirror how the human eye selectively processes visual information, balancing computational efficiency with perceptual realism.\n\nNeural Saliency Detection: Implemented using ViNet , a PyTorch-based video saliency prediction model trained on DHF1K , Hollywood-2 , and UCF-Sports datasets for visual attention, with additional fine-tuning on DIEM , AVAD , Coutrot-1/2 , SumMe , and ETMD for visual saliency cues. The model outputs a spatiotemporal saliency heatmap for each frame, predicting where human gaze is most likely to focus based on motion, contrast, and semantic context. Preprocessing Pipeline: Frames are extracted, normalized, and batched using OpenCV and NumPy , converted into tensors, and passed through ViNet in float16 precision for GPU-optimized inference. Heatmap Postprocessing: Each saliency map is normalized and discretized into percentile bins (e.g., top 20%, 50%, 80%) to classify regions by visual importance. Server-Side Compression: A GPU-accelerated OpenGL fragment shader processes the frame using the saliency mask, preserving high-saliency pixels at full resolution while adaptively downsampling lower-saliency regions. The shader executes in parallel on the GPU using GLSL texelFetch operations for direct texture access, ensuring real-time throughput. Encoding Pipeline: The mixed-resolution output frame is encoded via FFmpeg (H.264/H.265) , with saliency metadata embedded as sidecar data to guide client-side scaling. Client-Side Scaling: On playback, the client reads the saliency metadata and uses a lightweight OpenGL upscaling shader to scale low-resolution areas back up to the original frame size, maintaining smooth transitions between resolution zones."},{"heading":"Challenges we ran into","content":"Real-Time Performance: Achieving frame-level saliency detection and GPU compression in real time was difficult. The PyTorch model alone could process only a few frames per second initially, so we experimented with quantizing it, optimizing batch loading, and pipelining the inference with shader execution. Shader Synchronization: Getting the OpenGL shader and PyTorch inference to share memory efficiently without stalling the baseten API was challenging, and we had to pivot approaches multiple times. Compression Artifacts: Early versions of the shader created visible seams and inaccurate pixels where resolution zones met. We had to fine-tune the saliency thresholds and interpolation filters to make transitions appear smoother while keeping data savings significant. Bandwidth Variability: Simulating unstable network conditions to test adaptive thresholding was harder than expected. We tested this by changing the resolution of the source video's frames randomly. Model Generalization: ViNet‚Äôs saliency predictions worked well for cinematic and YouTube-style videos but struggled with static or low-motion footage. We experimented with temporal smoothing and custom fine-tuning to improve stability across diverse content. Integration Overhead: Coordinating the PyTorch inference server, shader renderer, and FFmpeg encoder into one containerized pipeline required careful dependency management.\n\nDespite these challenges, each bottleneck led to a better understanding of how to balance neural inference, rendering, and compression in one real-time system."},{"heading":"Accomplishments that we're proud of and What We Learned","content":"Despite these challenges, we‚Äôve achieved something remarkable:\n\nFunctional Prototype: We built a fully operational system that dynamically adjusts video resolution in real time based on predicted viewer attention. Perceptual Compression: Our approach maintains sharpness where it matters most, proving that compression doesn‚Äôt have to be uniform to feel natural. Massive Efficiency Gains: Testing shows file sizes can be reduced by 2√ó‚Äì3√ó while retaining strong perceptual quality, dramatically lowering bandwidth and storage costs. GPU-Accelerated Pipeline: We achieved real-time performance by fusing a PyTorch saliency model with an OpenGL shader pipeline‚Äîcompressing and transmitting frames at streaming speeds. Cross-Platform Applicability: The system runs efficiently for both pre-processed video (like streaming platforms) and live feeds , adapting dynamically to network fluctuations. End-to-End Integration: We combined deep learning, GPU rendering, and adaptive encoding into a single pipeline that can slot directly into existing video delivery workflows."},{"heading":"What's next for Salient Labs","content":"Salient Labs is committed to pushing the boundaries of machine learning‚Äìdriven compression through rigorous experimentation and user testing, aiming for stable 50%+ efficiency and 95%+ satisfaction. As a research-oriented team, we plan to extend our work to other bandwidth and infrastructure challenges that limit global connectivity."},{"heading":"Built With","content":"amazon-web-services baseten ffmeg next opengl"},{"heading":"Try it out","content":"github.com www.trysalient.tech www.canva.com"}]},{"project_title":"Covenant","project_url":"https://devpost.com/software/covenant-onci9q","tagline":"Put your money where your goals are. Complete your commitments to earn it back, or watch it go to a cause you really don‚Äôt want to fund. Blockchain-verified accountability, powered by AI.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ethereum Foundation: Honorable Mention"}],"team_members":[],"built_with":[{"name":"blockchain","url":"https://devpost.com/software/built-with/blockchain"},{"name":"ethereum","url":null},{"name":"next.js","url":null},{"name":"reka","url":null}],"external_links":[{"label":"covenant.ignaspanavas.com","url":"https://covenant.ignaspanavas.com"}],"description_sections":[{"heading":"Inspiration","content":"We noticed that staying accountable to personal goals is hard. Reminders, to-do lists, and habit apps all rely on self-discipline alone. But people behave differently when real stakes are involved. We wanted to build a system that combines motivation through commitment with the transparency and fairness of blockchain. The result is Covenant: a decentralized way to make promises you‚Äôll actually keep."},{"heading":"What it does","content":"Covenant lets users create commitments to complete a goal by a deadline, with real money on the line.\n\nYou lock funds in an Ethereum smart contract. You set a beneficiary wallet, a friend, charity, or even an ‚Äúanti-charity,‚Äù to receive the stake if you fail. When you complete your task, you upload a verification video. The video is analyzed by Reka‚Äôs multimodal Video Q&A API, which checks for presence of the required actions, and your face. If the model verifies success, the smart contract releases your stake back to you. Otherwise, the funds go to the beneficiary.\n\nIt‚Äôs accountability made autonomous. No judges, no excuses, just code and proof."},{"heading":"How we built it","content":"Frontend: Next.js web app for covenant creation, wallet connection, and video upload. Blockchain: Solidity smart contracts deployed on Ethereum testnet using Hardhat. Verification backend: Next.js API routes that upload videos to Reka‚Äôs video indexing endpoint and call its Video Q&A API for commitment verification. Integration: WalletConnect + Wagmi for on-chain interactions, and secure server-side Reka API calls for video processing."},{"heading":"Challenges we ran into","content":"Multi-stage video uploads: We had to design a pipeline that passed each uploaded video from the frontend, through a Next.js API route, to Reka‚Äôs upload endpoint using FormData, ensuring the file persisted correctly across each layer. Smart contract integration: Getting our Solidity contracts to deploy and communicate smoothly with the frontend required debugging ABI mismatches and transaction confirmation issues. Syncing AI verification with on-chain logic: Coordinating Reka‚Äôs verification responses with blockchain state changes demanded careful timing and error handling. Merging separate components: Integrating independently built blockchain, AI, and frontend modules into a unified app took close coordination and a lot of testing."},{"heading":"Accomplishments that we're proud of","content":"Built a working end-to-end system that connects AI-based proof-of-work with Ethereum smart contracts in under 48 hours. Successfully verified real videos through Reka Video Q&A and used that verification to trigger blockchain contract actions. Created a user experience that feels fun and motivating while demonstrating real Web3 accountability infrastructure."},{"heading":"What we learned","content":"How to combine AI verification with on-chain logic to create meaningful, human-centered dApps. The nuances of multipart uploads and serverless video handling in Next.js. Practical experience using Reka‚Äôs multimodal models beyond standard text or image tasks. That incentives, both social and financial, can make technology a powerful force for personal growth."},{"heading":"What's next for Covenant","content":"Refining AI verification: Improve fairness and accuracy by fine-tuning prompts, using multimodal reasoning (video + audio + text), and introducing confidence thresholds before funds are released. Social accountability layer: Add friends, group challenges, and public covenant feeds to create social pressure and community-driven motivation. Mobile app: Build a lightweight mobile app for recording and uploading verification videos directly from your phone, streamlining the entire covenant flow. Gamification: Add progress tracking, streaks, and rewards for consistent goal completion to make accountability fun. Expanded blockchain support: Deploy on faster, cheaper chains like Base or Polygon, and integrate stablecoins for easier on-ramping. Covenant marketplace: Let users browse and sponsor other people‚Äôs covenants, turning accountability into a social investment ecosystem. Privacy-preserving verification: Explore zero-knowledge proof methods so users can prove goal completion without revealing sensitive video details."},{"heading":"Built With","content":"blockchain ethereum next.js reka"},{"heading":"Try it out","content":"covenant.ignaspanavas.com"}]},{"project_title":"AdSensei","project_url":"https://devpost.com/software/adsensei-3vmh4n","tagline":"Upload ads, get clear scores, one-line reasons, and precise fixes‚Äîthen a ranked Top 10 by platform/audience in minutes. AdSensei helps designers iterate fast and marketers scale winners.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/545/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Creao: Best MCP Integration"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"creaoai","url":null},{"name":"lava","url":null},{"name":"llm","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"render","url":null},{"name":"s3","url":null}],"external_links":[{"label":"production.creao.ai","url":"https://production.creao.ai/share?app=JgmOhjri&utm_source=share&utm_medium=link"}],"description_sections":[{"heading":"Inspiration","content":"We were done debating ‚Äúwhich ad feels better.‚Äù AdSensei turns creative gut-feel into measurable signals so designers know what to tweak and marketers know what to scale."},{"heading":"What it does","content":"AdSensei converts a folder of ad creatives into a clear, prioritized playbook :\n\nInstant per-asset readout : tone & sentiment, product/category, objects/logos, OCR‚Äôd copy, color palette, composition notes, target audience, and best-fit platforms. Actionable scoring across five core dimensions‚Äî Attention, Readability, Aesthetics, Brand Fit, Memorability ‚Äîeach with a one-line rationale so every number is defensible. Smart recommendations : concrete fixes (CTA presence/placement, headline length bands, contrast/whitespace, logo size and anchor, modernized styling, eco-claims surfacing). Campaign roll-ups : Top 10 with reasons, sentiment & tone maps, color trends, and Dimension Profiles (e.g., most readable vs. most memorable).\n\nExample: single-image insight (condensed)\n\nScores: Catchiness 7 , Aesthetics 6 , Readability 8 , Brand Fit 9 , Memorability 7 Detected: logo ‚ÄúRinso,‚Äù benefit copy (‚ÄúWHITER THAN BRAND NEW‚Äù), detergent box, flags, dresses Audience & platforms: 25‚Äì45 , household care; strong for social, print, and nostalgia channels Suggestions: add CTA , modernize layout, surface eco-benefit Why: vibrant palette + crystal-clear benefit line; nostalgia boosts brand fit"},{"heading":"Challenge alignment ‚Äî high-value signals for recommendations","content":"We extract diverse, high-value features that feed a recommender and generalize across campaigns:\n\nTone & sentiment ‚Üí audience resonance and platform fit Product/category ‚Üí clustering and cold-start suggestions Text/OCR & copy shape ‚Üí headline length bands, readability, CTA presence/placement Logos & brand anchors ‚Üí recognition and consistency across variants Objects & context ‚Üí scene elements to inform targeting/use cases Color & density ‚Üí contrast/whitespace patterns tied to attention and legibility Composition notes ‚Üí focal order, safe-zone usage, rule-of-thirds hints (Video-ready) AV signals ‚Üí embeddings for distinctiveness/memorability\n\nWhy these help: they‚Äôre predictive proxies for clarity, fit, and distinctiveness‚Äîfeatures a recommendation model can weight beyond historical CTR."},{"heading":"How we built it (high level)","content":"We optimized for clarity, consistency, and speed ‚Äîless black box, more ‚Äúwhy‚Äù:\n\nRubric first. Five dimensions that creative teams already speak: Attention, Readability, Aesthetics, Brand Fit, Memorability . Signals ‚Üí explanations. Every score ships with a one-line rationale and a suggested change. Batch to decisions. Per-asset outputs aggregate into campaign-level Top-N, distributions, and Dimension Profiles. Sponsor tech in the loop.\n\ncreao.ai for a clean, skimmable UI. Lava to route rationale prompts across models for sharper, less generic guidance. Reka for robust vision-language grounding. Inspired by AppLovin , we prioritized pre-spend insights (clarity, platform fit, iteration speed).\n\n(The pipeline is model-agnostic and easy to swap as needs grow.)"},{"heading":"Performance & parallel batch processing","content":"Designed for fast (< 5 minutes) campaign reads and horizontal scale:\n\nParallel workers process assets independently (embarrassingly parallel). Stateless jobs pull from a queue, emit compact feature vectors + rationales. Reducer stage builds sentiment/tone maps, color trends, and Top 10 with reasons. Caching reuses OCR/embedding results for near-duplicates. Scale knob: increase worker count to hit tighter SLAs.\n\nA simple, transparent scoring form keeps things explainable: [ S_{\\text{composite}}=\\sum_i w_i,z(d_i),\\quad \\sum_i w_i=1 ] where (d_i) are normalized signals per dimension and (w_i) are tunable weights."},{"heading":"Challenges we ran into","content":"Subjectivity vs. consistency across wildly different aesthetics No ground truth (early on) ‚Üí relied on strong proxies before CTR/CVR labels Signal fusion without letting a single metric (e.g., contrast) dominate Edge cases : tiny text, busy backgrounds, logo-as-background patterns Latency/cost while keeping batch UX snappy for 40‚Äì50 assets"},{"heading":"Accomplishments we‚Äôre proud of","content":"Explainable scorecards teams actually read‚Äîevery number has a reason Specific recommendations (e.g., ‚Äúraise CTA ~120px,‚Äù ‚Äúlogo +18%‚Äù) instead of ‚Äúmake it pop‚Äù Dimension Profiles that pick winners for a purpose (readable vs. memorable) A clean campaign roll-up : sentiment/tone maps, color trends, and a demo-ready Top 10 with reasons"},{"heading":"What we learned","content":"Clarity beats cleverness ‚Äîadoption rose when the rubric was transparent Small, honest heuristics travel well : WCAG contrast, copy length bands, whitespace% Rationales drive trust ‚Äîteams change creatives faster when they see the ‚Äúwhy‚Äù"},{"heading":"What‚Äôs next for AdSensei","content":"Performance linkage : learn (w_i) from CTR/CVR labels as they arrive Platform presets : TikTok/IG/YT rules (safe zones, duration bands, subtitle norms) Variant helper : headline trims, palette swaps, CTA placement experiments Workflow & exports : reviewer notes, shareable one-pagers, and API hooks into creative pipelines\n\nAdSensei: clarity, not guesswork."},{"heading":"Built With","content":"amazon-web-services creaoai lava llm node.js render s3"},{"heading":"Try it out","content":"production.creao.ai"}]},{"project_title":"TraceFund","project_url":"https://devpost.com/software/trustfund-24cmnh","tagline":"Rebuilding donation trust through transparent giving.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/582/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ethereum Foundation: Honorable Mention"}],"team_members":[],"built_with":[{"name":"base","url":null},{"name":"claude","url":null},{"name":"erc-20","url":null},{"name":"ethereum","url":null},{"name":"ethers.js","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"hardhat","url":null},{"name":"next.js","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"open-zeppelin","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"solidity","url":"https://devpost.com/software/built-with/solidity"},{"name":"tailwind.css","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[],"description_sections":[{"heading":"Built With","content":"base claude erc-20 ethereum ethers.js express.js hardhat next.js node.js open-zeppelin react solidity tailwind.css typescript"}]},{"project_title":"AI-Powered Food Bank Management System","project_url":"https://devpost.com/software/foodbank-automation","tagline":"Food banks lose time at intake. Our web app makes any phone a scanner: scan, auto-fill, add weight. Live inventory + instant CSVs for audits. Faster check-ins mean more families served, less waste.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/895/522/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Creao: Best Designed Web App"}],"team_members":[],"built_with":[{"name":"creao","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"openfoodfacts","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ericrcwu001/calhacks"},{"label":"production.creao.ai","url":"https://production.creao.ai/share?app=TW8zO4eq&utm_source=share&utm_medium=link"}],"description_sections":[{"heading":"Built With","content":"creao flask gemini node.js openfoodfacts python react typescript vercel"},{"heading":"Try it out","content":"github.com production.creao.ai"}]},{"project_title":"trialmatch.ai","project_url":"https://devpost.com/software/trial-match-ai","tagline":"Agentic pattern AI that actively searches for and identifies trial-qualified patients on its own.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/888/695/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Runner-Up"}],"team_members":[],"built_with":[{"name":"agentverse","url":null},{"name":"fetch","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"synthea","url":null},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Calhacks-12-0/Trialmatch.ai"}],"description_sections":[{"heading":"üí° Inspiration","content":"Clinical trials fail not because the science is bad ‚Äî but because they can't find the right patients fast enough. 80% of clinical trials fail to meet enrollment timelines , costing the industry over $8 billion annually. Eligibility screening is still largely manual, slow, and biased. Meanwhile, millions of patients who qualify never get matched to potentially life-saving trials.\n\nWe asked: What if autonomous AI agents could continuously scout and surface ready-to-enroll patients before humans even start searching?\n\nTraditional approaches require weeks of manual chart review, phone screenings, and back-and-forth coordination. By the time you find qualified patients, your trial timeline has already slipped by months.\n\nTrialMatch.ai changes the game."},{"heading":"üéØ What it does","content":"TrialMatch.ai deploys Conway-like pattern recognition and 7 autonomous AI agents that discover latent patient cohorts in real EHR data, then automatically identify and rank trial-eligible patients in real time ‚Äî not after weeks of manual review.\n\nIt's zero-click matching\n\nTeams just get a ranked list of \"qualified, ready, here's why\" in under 3 seconds.\n\nKey Features\n\nüîç Intelligent Pattern Discovery\n\nUnsupervised machine learning discovers 20-30 clinically meaningful patient cohorts automatically No labeled training data required ‚Äî finds patterns like \"Diabetes + Hypertension, Age 55-70, BMI >30\" without human input Conway's Game of Life-inspired emergence: simple rules ‚Üí complex, useful patterns\n\nü§ñ 7 Autonomous AI Agents\n\nEligibility Agent : Extracts structured criteria from ClinicalTrials.gov protocols Pattern Agent : Matches trial requirements to discovered patient patterns using similarity metrics Discovery Agent : Searches 10,000+ patient records for candidates matching patterns Matching Agent : Scores patients using multi-modal embeddings (demographics + clinical + geographic) Validation Agent : Filters out patients with exclusion criteria violations Site Agent : Recommends optimal trial sites based on patient geography and site feasibility Prediction Agent : Forecasts enrollment timelines using historical pattern data\n\n‚ö° Real-Time Processing\n\nFull pipeline: Trial query ‚Üí Pattern discovery ‚Üí Patient matching ‚Üí Site selection in <3 seconds Processes 50,000+ patient records to generate 800+ ranked matches Live activity logs show agents \"thinking\" in real-time\n\nüìä Interactive Dashboard\n\n3D UMAP scatter plots visualize patient clusters intuitively Sortable tables with patient demographics, match scores, and exclusion risk factors Geographic heatmaps show site recommendations and patient distribution Real-time agent chat for debugging and transparency\n\nüè• Production-Ready Medical Data\n\n1,000 FHIR-compatible synthetic patient records with authentic clinical codes ICD-10 diagnoses, LOINC lab values, RxNorm medications Integrated with 100 real trial structures from ClinicalTrials.gov"},{"heading":"üõ† How we built it","content":"Frontend\n\nReact 18 + TypeScript + Vite for blazing-fast development shadcn/ui component library built on Radix UI primitives Recharts for data visualization (line charts, scatter plots, 3D plots) Tailwind CSS for modern, responsive styling 5 main dashboard views connected through tab navigation Real-time agent communication powered by REST API calls to backend chat router on port 5001\n\nBackend: Multi-Agent Architecture\n\nFetch.AI's uAgents framework (v0.22+) for autonomous agent orchestration 7 specialized agents running on ports 8001-8007, each handling domain-specific tasks FastAPI/Flask serve REST endpoints for agent communication Agents communicate via Fetch.AI's uAgents protocol, enabling decentralized execution Coordinator agent (port 8000) orchestrates workflow with retry logic and timeout handling\n\nPattern Discovery Engine\n\nImplemented unsupervised machine learning pipeline using:\n\nSentence-Transformers ( all-MiniLM-L6-v2 ) for medical text embeddings Converts clinical narratives into dense 384D vectors Captures semantic similarity between patient conditions UMAP (Uniform Manifold Approximation and Projection) Dimensionality reduction: 384D ‚Üí 50D for clustering 3D projections for interactive visualization Preserves both local and global structure HDBSCAN (Hierarchical Density-Based Clustering) Discovers patient clusters without labeled training data Tuned parameters: min_cluster_size=30 , min_samples=3 , cluster_selection_epsilon=0.3 Identifies 20-30 meaningful cohorts from 1,000 patients Multi-modal Embeddings Text features: conditions, medications, medical history Numeric features: age, BMI, lab values (HbA1c, cholesterol, BP) Geographic coordinates: latitude/longitude for site optimization\n\nData Infrastructure\n\nGenerated 1,000 synthetic FHIR-compatible patient records with real clinical codes ICD-10 diagnoses (e.g., E11.9 for Type 2 Diabetes) LOINC lab test codes (e.g., 4548-4 for HbA1c) RxNorm medication codes (e.g., 860975 for Metformin) SNOMED CT for precise clinical concepts Integrated with ClinicalTrials.gov trial criteria via TrialCriteriaMapper Site feasibility scoring system with geographic optimization using K-means clustering\n\nAgent Communication\n\nAgents communicate via Fetch.AI's uAgents protocol Enables decentralized execution and potential deployment to Agentverse Each agent exposes chat interface for real-time interaction and debugging Centralized chat router manages message queuing and agent availability Built-in retry logic with exponential backoff for reliability"},{"heading":"üöß Challenges we ran into","content":"1. Agent Orchestration Complexity\n\nCoordinating 7 autonomous agents with different execution times and failure modes was non-trivial. Agents could timeout, return partial results, or fail silently.\n\nSolution: Built a coordinator agent with sophisticated retry logic, timeout handling, and graceful degradation when agents are unavailable. Implemented circuit breaker patterns and health checks.\n\n2. Pattern Discovery Accuracy\n\nInitial UMAP/HDBSCAN parameters produced either too few clusters (1-2 massive groups) or too many noise points (patients not assigned to any cluster).\n\nSolution: Extensive hyperparameter tuning through grid search. Settled on min_cluster_size=30 , min_samples=3 , and cluster_selection_epsilon=0.3 to discover 20-30 meaningful patient cohorts with <5% noise.\n\n3. Real-time Chat Integration\n\nPreventing message loops and handling concurrent agent requests across 7 different ports was challenging. Agents could get stuck in infinite chat loops or miss messages.\n\nSolution: Created centralized chat router to manage message queuing, deduplication, and agent availability checks. Implemented message TTL and circuit breakers.\n\n4. Python 3.13 Compatibility\n\nSeveral ML libraries had breaking changes with NumPy 2.0+. Scikit-learn, pandas, and UMAP had version conflicts.\n\nSolution: Pinned specific versions ( pandas‚â•2.2.0 , numpy‚â•2.0.0 , scikit-learn‚â•1.6.0 ) and handled Pydantic v1 requirement for uAgents compatibility through careful dependency management.\n\n5. Medical Data Complexity\n\nMapping free-text trial criteria (e.g., \"patients with uncontrolled diabetes\") to structured FHIR codes (ICD-10, LOINC, RxNorm) was harder than expected. Natural language is ambiguous.\n\nSolution: Built custom TrialCriteriaMapper with fuzzy matching and medical terminology lookup covering 500+ condition mappings. Integrated UMLS (Unified Medical Language System) concepts.\n\n6. Frontend-Backend State Sync\n\nManaging real-time agent status updates and activity logs without overwhelming the backend or creating stale UI states.\n\nSolution: Implemented smart polling mechanism with live message feed that updates every 3 seconds. Used React Query for cache management and optimistic updates."},{"heading":"üèÜ Accomplishments that we're proud of","content":"üéØ End-to-End Working System\n\nFull pipeline from trial query ‚Üí pattern discovery ‚Üí patient matching ‚Üí site selection in under 3 seconds Not a mock-up or prototype ‚Äî real agents processing real data with real ML Handles 50,000+ patient records and generates 847 matches in 2.3 seconds\n\nüß† True Unsupervised Learning\n\nPattern discovery works without any labeled training data Automatically discovers 20-30 clinically meaningful patient cohorts Examples: \"Diabetes + Hypertension, Age 55-70, BMI >30\" or \"Cardiovascular + CKD Stage 3, Multiple Medications\" Conway-like emergence: simple embedding rules ‚Üí complex, useful patterns\n\nü§ñ Production-Ready Multi-Agent Architecture\n\n7 fully autonomous agents that can run distributed across machines Can deploy to Fetch.AI's Agentverse for decentralized execution Each agent is independently debuggable via chat interface Built with production patterns: retry logic, circuit breakers, health checks\n\nüìä Beautiful, Functional UI\n\nTransformed design concepts into fully interactive dashboard Real-time data visualization with 3D scatter plots, heatmaps, and charts Sortable tables, interactive filters, and drill-down capabilities Live agent activity logs build user trust and transparency\n\nüî¨ Realistic Medical Data\n\nGenerated 1,000 FHIR-compatible patient records with authentic clinical codes Real ICD-10 diagnoses, LOINC lab values, RxNorm medications Integrated with 100 real trial structures from ClinicalTrials.gov Supports complex eligibility criteria with multiple inclusion/exclusion rules\n\n‚ö° Performance at Scale\n\nProcesses 50,000+ patient records in seconds Discovers 27 patterns automatically from unlabeled data Generates 847 ranked matches for a single trial in 2.3 seconds (as shown in dashboard) Multi-core parallel processing with NumPy/scikit-learn optimizations\n\nüí¨ Interactive Agent Chat\n\nBuilt chat interface for every agent using Fetch.AI's ChatProtocol Ask questions like \"Why did you exclude this patient?\" and get reasoned responses Makes debugging and validation transparent Enables human-in-the-loop refinement of matching criteria"},{"heading":"üìö What we learned","content":"Multi-Agent Systems Are Powerful But Complex\n\nDecentralized agent architectures enable massive parallelism and reusability, but require careful design for coordination, error handling, and message passing. Fetch.AI's uAgents framework abstracts much complexity but still requires deep understanding of async patterns, race conditions, and distributed systems failure modes.\n\nUnsupervised ML ‚â† Unsupervised Results\n\nUMAP and HDBSCAN require extensive hyperparameter tuning to discover meaningful patterns. The \"unsupervised\" part means no labels, not no effort. Small changes in min_cluster_size can mean 2 clusters vs 30 clusters. We ran 50+ experiments to find optimal settings.\n\nMedical Data Is Hard\n\nClinical trial eligibility criteria are ambiguous, contradictory, and often written in ways that don't map cleanly to structured codes. Building a robust FHIR code extractor taught us why healthcare interoperability is a multi-billion dollar problem. Even \"simple\" concepts like \"uncontrolled diabetes\" require multiple code checks (HbA1c >7.0%, diagnosis codes, medication history).\n\nReal-Time UX Matters\n\nUsers trust AI systems more when they can see agents \"thinking\" in real-time. Activity logs showing \"Searching 10,000 FHIR patient records...\" ‚Üí \"Found 87 candidates in Pattern #42\" build confidence even when the system takes 2-3 seconds. Transparency beats speed for user adoption.\n\nVisualization Transforms Understanding\n\n3D UMAP scatter plots let users intuitively see patient clusters . A picture showing \"Diabetes + Hypertension\" patients forming a distinct cloud in embedding space is worth a thousand accuracy metrics. Non-technical stakeholders immediately \"get it\" when they see visual clusters.\n\nPattern Discovery = Feature Engineering at Scale\n\nConway's Game of Life principles apply to ML: simple local rules (similarity metrics, density thresholds) can produce complex, emergent global patterns (patient cohorts). UMAP + HDBSCAN is essentially automated feature engineering that discovers which patient attributes naturally cluster together."},{"heading":"üöÄ What's next for TrialMatch.ai","content":"üè• Real EHR Integration\n\nConnect to live FHIR endpoints (Epic, Cerner, Allscripts). For example, we would like to handle HL7 messages, DICOM images, and real patient consent workflows. Build HL7 FHIR listeners that continuously ingest new patients and update pattern memberships in real-time.\n\nüìà Predictive Enrollment Modeling\n\nExpand Prediction Agent to forecast not just timelines but dropout rates, protocol deviations, and recruitment bottlenecks using historical trial data. Build time-series models that predict which patients are likely to complete vs drop out based on pattern membership.\n\nüîê Privacy-Preserving Matching\n\nImplement federated learning so pattern discovery can run across multiple hospitals without sharing raw patient data. Use secure multi-party computation (MPC) for match scoring. Enable healthcare consortiums to collaboratively discover patterns while maintaining HIPAA compliance.\n\nüß™ Prospective Clinical Validation\n\nPartner with research sites to validate matches against actual enrollment outcomes. Build feedback loop to continuously improve pattern quality scores. Track: Did matched patients actually enroll? Did they complete the trial? Use this data to refine embedding models.\n\nüíä Rare Disease Focus\n\nExtend pattern discovery to orphan diseases where patient cohorts are tiny (<100 globally). Enable multi-site consortium matching across continents. Use transfer learning from common diseases to improve rare disease pattern quality despite limited data.\n\nüî¨ Active Learning Loop\n\nImplement active learning where the system identifies \"borderline\" patients and asks clinicians for labels. Use these labels to refine decision boundaries and improve match confidence scores. Start with unsupervised, evolve to semi-supervised with minimal human input.\n\nüì± Patient-Facing Mobile App\n\nBuild patient-facing interface where individuals can opt-in to trial matching. Patients enter their conditions, medications, and preferences, then get matched to relevant trials near them. Empowers patients to be active participants in clinical research."},{"heading":"Built With","content":"agentverse fetch python react synthea tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"TrialFlow","project_url":"https://devpost.com/software/trialflow","tagline":"The Smart Clinical Trial Coordinator","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/896/277/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Runner-Up"}],"team_members":[],"built_with":[{"name":"creao","url":null},{"name":"google-calendar-api","url":null},{"name":"google-gmail-oauth","url":"https://devpost.com/software/built-with/google-gmail-oauth"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"40% of patients drop out of clinical trials before completion, and scheduling friction drives a large share of attrition. Clinicians spend hours coordinating windows, patients miss reminders, and research teams lose momentum. Phase 1 of most clinical trials lasts only a few weeks, and each delay weakens patient engagement and undermines trial consistency.\n\nWe are also keenly aware that clinicians‚Äô expertise is best applied to interpreting trial results, not managing logistics. Yet studies show that clinical staff spend up to 25‚Äì30% of their time on administrative logistics like scheduling and follow-up management, time that could otherwise advance research and patient care.\n\nEnter TrialFlow, an intelligent scheduling platform that streamlines clinical trial coordination for both clinicians and patients. Clinicians set availability windows with real-time booking limits, and the app takes care of the rest. Patients can self-schedule visits based on clinician availability and receive 24-hour reminders with logistics and clear instructions on how to prepare for the upcoming appointment. A built-in burden score estimator measures participant load, helping researchers anticipate fatigue and enhance follow-up planning."},{"heading":"What does it do","content":"Clinicians log into the dashboard, select a date range on the calendar, and specify procedures (Blood Draw, ECG, MRI, etc.) and per-slot booking limits. Patients are then notified via email that appointment times have opened up, and are sent a link that redirects them to their patient dashboard. From here, they are able to book their appointment time, add the event to their Google Calendar, and download an ics file if they wish to utilize any other calendar application. Finally, an email reminder is sent to each patient 24 hours before their upcoming appointment covering procedures, logistics, and if necessary, special instructions on how to prepare for the appointment."},{"heading":"How we built it","content":"We built TrialFlow using Creao as the foundation for managing data models and workflow logic, which helped us quickly structure our backend and integrate custom functionality. On top of that, we used Creao to develop a custom Burden Score API to estimate participant workload based on visit frequency, procedure complexity, and total time commitment.\n\nFor the frontend, we used TypeScript, React, and Tailwind CSS to create a clean and intuitive interface for both clinicians and patients. We implemented Google OAuth for secure sign-in and integrated the Google Calendar API so users can easily add upcoming appointments to their calendars and receive automatic reminders on their devices.\n\nThis stack let us build a cohesive, production-ready scheduling platform that bridges the gap between clinical coordination and patient accessibility."},{"heading":"Challenges we ran into","content":"One of the main challenges we faced was working with Creao for the first time. While it provided a great starting point for structuring our backend and workflows, understanding its abstractions and figuring out how to extend it with our custom Burden Score API took time and experimentation. Integrating the Google Calendar API also came with hurdles, especially around OAuth permissions, refresh tokens, and syncing events across multiple accounts to ensure a smooth user experience for both clinicians and patients."},{"heading":"What's next for TrialFlow","content":"Given a time frame of 36 hours, our team had many more features planned than we were able to execute. Primarily, we'd love to integrate TrialFlow with existing Clinical Trial Management Systems, or CTSM for short. This way, clinicians have an all-in-one stop for them to manage their logistics and aggregate data from their trials."},{"heading":"Built With","content":"creao google-calendar-api google-gmail-oauth react tailwindcss typescript"}]},{"project_title":"TrialGuideAI","project_url":"https://devpost.com/software/trialguideai","tagline":"TrialGuideAI uses AI to distill dense clinical trial protocols into accessible summaries, infographics, and videos that empower patients to understand studies and their broader impact on science.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Runner-Up"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"git","url":"https://devpost.com/software/built-with/git"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"json","url":"https://devpost.com/software/built-with/json"},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Our open-source clinical trial educator was created to bridge the gap between complex research protocols and the people they are meant to serve. Too often, patients and communities are left out of the scientific conversation because clinical trial information is hidden behind technical jargon and closed systems. By building an open, transparent, and interactive learning platform, we aim to make clinical research understandable, trustworthy, and empowering for everyone. Through visual explanations, AI-driven summaries, and real-world examples drawn from public trial databases, our tool helps patients, students, and clinicians alike explore how trials work, why participation matters, and how science turns data into hope. Education should never be a privilege‚Äîit should be a shared, open resource for discovery and change."},{"heading":"What it does","content":"TrialGuideAI is an open-source tool catered for academic clinical research institutions to improve patient's knowledge and awareness of the scientific studies they can partake in. Principal investigators in charge of a clinical trial's study design can upload their lengthy protocols and receive an approachable synopsis of the trial. This enables investigators to communicate with their trial participants and explain the therapeutic's complex biological mechanisms in a more digestible manner supported with animated visuals."},{"heading":"How we built it","content":"We built our open-source clinical trial educator using the Gemini API to transform dense clinical trial protocols into accessible, engaging learning experiences. The system ingests publicly available trial documents and uses Gemini‚Äôs advanced language understanding to extract key scientific insights‚Äîsuch as study purpose, interventions, eligibility criteria, and biological mechanisms. These insights are then summarized into clear educational scripts. Using additional AI APIs, we generate visuals and slideshow-style images that align with the extracted text, automatically assembling them into short, narrated video modules. The result is an interactive, multimedia learning tool that turns complex trial data into understandable, story-driven education for patients, students, and clinicians alike. Our platform shows how open AI ecosystems can make scientific transparency both beautiful and accessible."},{"heading":"Challenges we ran into","content":"One of the biggest challenges we faced was managing image generation and API usage within the limits of free or low-cost tools. Generating consistent, high-quality visuals that matched the scientific content often required multiple API calls and fine-tuning prompts, which was difficult without paid credits. Stitching the generated images and text into smooth, coherent videos was another hurdle‚Äîespecially when synchronizing voiceovers, timing, and transitions purely through code. Building automated slides and integrating them with narration required balancing creativity with technical constraints, as we had to connect several APIs for image generation, text-to-speech, and video assembly while keeping everything lightweight, open-source, and reproducible."},{"heading":"Accomplishments that we're proud of","content":"We are super proud that we accomplished the task of building an application and website as a team. Our backgrounds are primarily within machine learning and basic science research, so we are proud that we stepped into exploring something new. We are also happy that we were able to accomplish creating an integrative generative system within a relatively short time frame."},{"heading":"What we learned","content":"We learned how challenging yet essential clinical trials are to the long and arduous drug development pipeline. Along the way, we gained skills in agentic workflow design, full-stack development, and the effective use of generative APIs to create a more transparent and informed participant experience."},{"heading":"What's next for TrialGuideAI","content":"We want to build a more advanced version of our platform that can generate longer, more comprehensive videos covering multiple clinical trials at once. Our goal is to create an open-source solution that academic labs, educators, and research institutions can easily use to teach or communicate trial information. By improving automation, we aim to handle complex datasets, summarize multiple protocols, and create cohesive educational narratives that connect different studies within a disease area."},{"heading":"Built With","content":"css gemini git html javascript json python"}]},{"project_title":"TrustBuddy","project_url":"https://devpost.com/software/trustbuddy","tagline":"Interoporable Trust, bring your ratings everywhere you go!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/887/947/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Ethereum Foundation: Honorable Mention"}],"team_members":[],"built_with":[{"name":"canva","url":null},{"name":"ethereum","url":null},{"name":"figma","url":null},{"name":"nextjs","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/WilliamUW/calhacks2025"},{"label":"repo.sourcify.dev","url":"https://repo.sourcify.dev/11155111/0xBaa6BF329d40F072487246c3B3cE6af65965F5b7"}],"description_sections":[{"heading":"üí≠ The Problem","content":"You found the perfect deal on Facebook Marketplace ... but no one‚Äôs replying üò¢ Or you‚Äôre trying to rent that dreamy Airbnb for your big family weekend ‚Äî but hosts keep ignoring you üëÄ\n\nWhy? Because your profile is ‚ú® blank ‚ú®\n\nYour 5‚≠ê Uber rating doesn‚Äôt help you on Marketplace. Your flawless eBay score means nothing to an Airbnb host.\n\nYour trust is locked inside the apps you use ‚Äî isolated and invisible ."},{"heading":"üí° The Idea","content":"What if your hard-earned trust could follow you anywhere ?\n\nIntroducing TrustBuddy ü´± ‚Äî a decentralized reputation system that lets you import your ratings and build interoperable trust across Web2 and Web3 , powered by Ethereum ‚ö°"},{"heading":"üîÅ How It Works","content":"1Ô∏è‚É£ Connect your ETH wallet üí∞ 2Ô∏è‚É£ Upload screenshots of your ratings (Uber, Lyft, Marketplace, Airbnb, etc.) üì∏ 3Ô∏è‚É£ Our AI (Gemini 2.5 Flash) extracts verified rating info üß†‚ú® 4Ô∏è‚É£ Your TrustBuddy profile compiles everything into a single, portable reputation dashboard ü™™ 5Ô∏è‚É£ Companies + DApps can verify your score through your wallet address or ENS name ü™ô\n\nNo more starting from zero. No more invisible trust. Just you ‚Äî verified, visible, and vouchable üí™"},{"heading":"‚öôÔ∏è Tech Stack","content":"üß† Gemini 2.5 Flash ‚Üí AI image analysis for extracting ratings from screenshots ü™ô Ethereum Sepolia Testnet ‚Üí where our smart contract lives üß© Scaffold-ETH ‚Üí used for frontend + contract debugging üíª Next.js + Ethers.js ‚Üí buttery-smooth frontend integration"},{"heading":"üéØ Why It Matters","content":"Every time you switch platforms, you rebuild your reputation from scratch. With TrustBuddy , your digital trust moves with you.\n\n‚úÖ Safer marketplaces ‚úÖ Verified users ‚úÖ A more trustworthy internet"},{"heading":"üí¨ Closing Words","content":"We hope you‚Äôll join us in building interoperable trust across Web2 and Web3 , powered by Ethereum , so you‚Äôll never have to start from 0 again ü´∂"},{"heading":"Built With","content":"canva ethereum figma nextjs"},{"heading":"Try it out","content":"github.com repo.sourcify.dev"}]},{"project_title":"Trialytics","project_url":"https://devpost.com/software/trialytics","tagline":"Turning tangled, time-consuming clinical trial data chaos into seamless, protocol-compliant automated workflows","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/903/663/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Runner-Up"}],"team_members":[],"built_with":[{"name":"admiral","url":null},{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"aws-deep-learning-ami","url":null},{"name":"aws-ec2","url":null},{"name":"chart.js","url":"https://devpost.com/software/built-with/chart-js"},{"name":"cloudformation","url":null},{"name":"cuda","url":"https://devpost.com/software/built-with/cuda"},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"framer-motion","url":null},{"name":"json-schema","url":null},{"name":"next-api-routes","url":null},{"name":"next.js","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"nvidia-l40s-gpu","url":null},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"pharmaverse","url":null},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"prisma","url":null},{"name":"pyreadstat","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"qwen3-8b","url":null},{"name":"r","url":"https://devpost.com/software/built-with/r"},{"name":"radix-ui","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-dropzone","url":null},{"name":"rpy2","url":null},{"name":"shadcn-ui","url":null},{"name":"supabase","url":null},{"name":"supabase-ssr","url":null},{"name":"tailwindcss","url":null},{"name":"tanstack-query","url":null},{"name":"trpc","url":null},{"name":"trpc-server","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel-ai-sdk","url":null},{"name":"vllm","url":null},{"name":"zod","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ShauryaJ1/medical"},{"label":"medical-app-omega-five.vercel.app","url":"http://medical-app-omega-five.vercel.app"},{"label":"docs.google.com","url":"https://docs.google.com/presentation/d/1yc_aGng3oxlOgsjhBcp8tieU0o_8UQU0Vc0PxGcbXQA/edit?usp=sharing"}],"description_sections":[{"heading":"Inspiration","content":"The regulatory pathway for clinical trials is no joke. For example, wordy filings such as FDA Form 1571, FDA Form 1572 and FDA Form 3674 are required for an Investigational New Drug application, on top of dozens of others. With so many forms, protocols and standardizations piling up, clinicians spend far too much time on paperwork and far too little time on what really matters: advancing healthcare. We live in a fast world. Nobody has time for that. We believe nobody should be stuck in data-cleanup purgatory."},{"heading":"What it does","content":"Enter Trialytics : a purpose-built solution to take the mountain of raw trial data and transform it into a fully protocol-compliant workflow . Our system:\n\nAccepts just three core data documents from a clinician (clinical trial protocol, raw data, SAP) Condenses their workflow by tens to hundreds of documents and countless hours Ensures compliance with regulatory requirements. It's the difference between approval and starting over completely."},{"heading":"How we built it","content":"We didn‚Äôt just wrap a generic GPT model and call it a day. Our team is comprised of scientists with deep regulatory and clinical trial domain expertise. We built everything from the ground up. Tech stack includes:\n\nFrontend\n\nNextJS Tailwind ShadCN ChartJS\n\nBackend\n\nFast API VLLM tRPC Supabase S3 Modal\n\nWe implemented:\n\nAutomated ingestion of freely-formatted clinician data Mapping to standard formats (e.g., SDTM, ADAM, ICH-E3) Rule-based compliance checks (for forms like 1571/1572/3674 and CSRs) A user interface built for fast turnaround and minimal training."},{"heading":"Challenges we ran into","content":"Maintaining regulatory precision at scale was our biggest hurdle. Compliance isn‚Äôt just conceptually important. It‚Äôs mandatory when human lives are at stake. Adapting freeform clinician data into structured, regulatory-ready formats required solving edge cases, format variability, and mapping ambiguity, all while making the tool friendly and usable was our largest hurdle."},{"heading":"Accomplishments that we're proud of","content":"End-to-end working prototype from protocol upload ‚Üí SDTM ‚Üí ADaM ‚Üí AI analysis Real streaming responses that feel as responsive as ChatGPT CDISC-compliant pipeline using industry-standard pharmaverse R packages Self-hosted LLM on AWS GPU infrastructure (no API dependencies) Type-safe architecture across the entire stack Integrated complex technologies (Next.js + tRPC + Python + R + vLLM) in 36 hours Production-ready infrastructure with CloudFormation automation"},{"heading":"What we learned","content":"We learned that rules matter , not just for safety or approval, but for enabling innovation by removing friction. Regulatory compliance is hard to master, but when done right, it becomes a feature , not a blocker. We also discovered that treating data formats, protocol mapping, and submission compliance as engineering problems (not just administrative burdens) unlocked major operational improvements."},{"heading":"What's next for Trialytics","content":"We‚Äôre planning to broaden Trialytics ‚Äô capabilities:\n\nExpand data-cleaning modules (handling more formats, more document types) Build the LLM-to-SDTM conversion as a packaged integration (rather than ad-hoc LLM calls) for predictability and auditability Add advanced compliance analytics (real-time monitoring of submission integrity) Extend into new regulatory domains (e.g., device trials, global submissions)"},{"heading":"Built With","content":"admiral amazon-web-services aws-deep-learning-ami aws-ec2 chart.js cloudformation cuda docker framer-motion json-schema next-api-routes next.js numpy nvidia-l40s-gpu pandas pharmaverse postgresql prisma pyreadstat python qwen3-8b r radix-ui react react-dropzone rpy2 shadcn-ui supabase supabase-ssr tailwindcss tanstack-query trpc trpc-server typescript vercel-ai-sdk vllm zod"},{"heading":"Try it out","content":"github.com medical-app-omega-five.vercel.app docs.google.com"}]},{"project_title":"MIFY","project_url":"https://devpost.com/software/mify","tagline":"Medical Insights For You!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/884/489/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"api","url":null},{"name":"chroma","url":"https://devpost.com/software/built-with/chroma"},{"name":"claude","url":null},{"name":"fetch.ai","url":null},{"name":"gcp","url":null},{"name":"ngrok","url":null},{"name":"postman","url":"https://devpost.com/software/built-with/postman"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"treehouse","url":null},{"name":"vapi","url":null}],"external_links":[{"label":"Medical-Insights-For-You.github.io","url":"http://Medical-Insights-For-You.github.io"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by the massive inefficiencies and ethical challenges in clinical trial patient recruitment. Over 80% of trials fail to meet their enrollment deadlines , primarily because the process of matching patients to trials is slow, manual, and relies on complex Informed Consent Forms (ICFs) and lengthy medical histories. We realized that by combining AI-driven document parsing and personalized prescreening, we could drastically cut down the time it takes for eligible patients to find the right trials, making life-saving research more accessible and efficient."},{"heading":"What it does","content":"MIFY is an all-in-one patient recruitment platform that leverages generative AI to streamline the clinical trial pipeline for both patients and researchers.\n\nAI-ICF Generation: Users upload complex, jargon-heavy ICFs. MIFY's AI instantly parses and summarizes the eligibility criteria into clear language. AI Medical Prescreening: Patients complete a dynamic, interactive prescreening questionnaire. The AI cross-references their answers with the parsed ICF criteria, providing an instant, high-confidence eligibility score . Trial Recommendation: Based on the AI-prescreening results, the platform recommends the most relevant clinical trials, giving patients a direct path to enrollment and researchers a pipeline of qualified candidates."},{"heading":"How we built it","content":"We designed the platform as a full-stack application.\n\nFrontend: We used React and Tailwind CSS , and Python/Streamlit to build a modern, clean, and intuitive user interface, focusing on accessibility for patients. Backend & AI: The core logic was built using Python/Flask (or Node.js/Express, depending on your actual stack). The AI functionality relies on: Large Language Models (LLMs) (specifically Claude) for document understanding (parsing ICFs and extracting structured eligibility criteria). Custom logic to map patient input from the prescreening forms to the extracted criteria for accurate matching. Database: PostgreSQL was used to store user profiles, trial data, and the structured eligibility criteria. Voice Integratiob: Vapi was used in order to develop AI agents to prescreen patients."},{"heading":"Challenges we ran into","content":"The primary challenge was ensuring medical accuracy and reliability in the AI-driven processes.\n\nJargon Handling: Medical terminology in ICFs is highly specific. Training the LLM to accurately distinguish between inclusion and exclusion criteria, and to correctly handle ambiguous phrasing, required significant prompt engineering and iterative testing. Rapid UI Development: Designing a complex, multi-step application with several data inputs and outputs (ICF upload, prescreening form, result display) within the hackathon timeframe pushed our front-end team to its limit."},{"heading":"Accomplishments that we're proud of","content":"We are most proud of the AI-ICF Summarizer . In a demo, we were able to upload a sample ICF template and have the key inclusion/exclusion criteria distilled and ready for matching in under 15 seconds . This process typically takes researchers hours. We're also proud of successfully integrating a complex, multi-stage AI workflow into a simple, single-page application experience."},{"heading":"What we learned","content":"We learned the profound power of translating unstructured data (PDFs) into structured, queryable data using modern LLMs. Specifically, we gained deep experience in:\n\nPrompt Engineering for Classification: Efficiently instructing the LLM to perform high-stakes classification (inclusion vs. exclusion) on large blocks of text. User Experience in Healthcare: The critical importance of simplifying complex workflows to build trust and encourage engagement from patients who are often dealing with challenging medical situations."},{"heading":"What's next for MIFY","content":"Our immediate next steps for MIFY are to:\n\nIntegrate Real-Time Trial Feeds: Connect the platform to publicly available trial registries (like ClinicalTrials.gov) to move from static data to a dynamic, real-world recommendation engine. Add Researcher Dashboard: Develop a dedicated interface for clinical coordinators to track the quality and volume of their prescreened patient pipeline. Enhance Patient Education: Incorporate short, AI-generated educational summaries about the medical conditions relevant to the recommended trials to further empower patient decision-making."},{"heading":"Built With","content":"amazon-web-services api chroma claude fetch.ai gcp ngrok postman python treehouse vapi"},{"heading":"Try it out","content":"Medical-Insights-For-You.github.io"}]},{"project_title":"GhostManager","project_url":"https://devpost.com/software/ghostmanager","tagline":"Using agentic AI to reinvent compliance.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/898/443/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"fastapi","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"gmdemo-eight.vercel.app","url":"https://gmdemo-eight.vercel.app/"}],"description_sections":[{"heading":"Inspiration","content":"Every year, healthcare organizations lose billions to compliance mistakes, not from breaches, but from small human errors. A new hire sends an email with patient data. A researcher shares a file in Slack. Having worked in healthcare startups, clinical research, and AI labs, we‚Äôve felt that fear firsthand: the anxiety of ‚Äúwhat if I mess up?‚Äù That fear inspired us to build GhostManager, an AI-native compliance officer that proactively prevents mistakes before they happen."},{"heading":"The what","content":"GhostManager is the ‚ÄúGrammarly for compliance.‚Äù It runs a live compliance layer across company communication (i.e. Gmail, Slack, Notion), detecting and correcting potential HIPAA, FDA, and governance violations in real time. It flags risky messages, explains why they‚Äôre noncompliant, and even rewrites them to be compliant, all before they‚Äôre sent. It also builds a living, searchable knowledge base that captures each organization‚Äôs evolving compliance decisions. This dual pronged workflow allows for both security and education for new employees in a way not seen before.\n\nWe built GhostManager around an agentic hierarchy of specialized AI models, each trained for a specific compliance domain. These agents collaborate to assess risks and suggest fixes. To ensure privacy, we integrated a spaCy-powered data sanitization pipeline that strips all personal or health identifiers before any data touches an AI model. The backend is built in FastAPI, with a responsive JavaScript frontend for real-time feedback and visualization."},{"heading":"Challenges","content":"The primary challenges included properly synthesizing a backend consisting of an triple-tiered (eight total agents) hierarchy of compliance/knowledge agents with a efficient and streamlined frontend that would first undergo data sterilization. Oftentimes, there were issues with over-sterilization, time sinkage, or confusion between agents before a more explicit hierarchy was coded. In terms of the sterilization, a combination of NLP and spacy allowed for PHI (patient health information) to be protected without a significant amount of compliant information being [REDACTED]."},{"heading":"Built With","content":"fastapi gemini html javascript python typescript"},{"heading":"Try it out","content":"gmdemo-eight.vercel.app"}]},{"project_title":"Sublytics","project_url":"https://devpost.com/software/sublytics-h3ks70","tagline":"Rescue failed clinical trials by discovering hidden responder subgroups using AI-powered analytics!","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"matplotlib","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"scikit","url":null},{"name":"seaborn","url":null},{"name":"streamlit","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/aarnavin/calhacks25/tree/main"}],"description_sections":[{"heading":"Inspiration","content":"Clinical trials fail at an alarming rate‚Äîonly 12% of drugs make it through Phase III. When a trial fails, pharmaceutical companies lose an average of $2.6 billion and years of research. But here's the hidden opportunity: these \"failed\" trials often contain hidden responder subgroups ‚Äîspecific patient populations that actually benefit from the treatment, but get lost in the overall negative results.\n\nWe were inspired by real cases like Trastuzumab (Herceptin) , which initially failed in breast cancer trials until researchers discovered it worked brilliantly for patients with HER2+ tumors. That discovery turned a failed drug into a $7B blockbuster that saved millions of lives.\n\nSublytics was born from a simple question: What if we could systematically find these hidden responders in every failed trial?"},{"heading":"What it does","content":"Sublytics is an AI-powered clinical trial analytics platform that discovers patient subgroups who respond to treatments in \"failed\" trials. Instead of abandoning a drug after negative results, researchers can:\n\nUpload trial data (demographics, biomarkers, outcomes) Train ML models to predict treatment response with explainable AI (SHAP) Discover subgroups using multi-feature combination analysis Identify responders through demographic + biomarker patterns Get AI-generated insights via Claude API explaining the clinical significance\n\nKey Features:\n\nMulti-feature subgroup discovery (2-way and 3-way combinations) SHAP-based explainability for feature importance Claude AI integration for natural language clinical insights Interactive visualizations (ROC curves, demographic breakdowns) Statistical rigor with Bonferroni correction and confidence intervals Synthetic dataset generator with ground-truth subgroups for validation"},{"heading":"How we built it","content":"Tech Stack:\n\nFrontend : Streamlit (interactive web app with modern UI) ML Pipeline : scikit-learn (Random Forest), SHAP (explainability) Data Processing : pandas, NumPy, scipy (statistical tests) Real-world Data : NHANES dataset (3,996 patients with biomarkers) AI Integration : Anthropic Claude API for clinical interpretation Visualization : matplotlib, seaborn\n\nArchitecture:\n\nData Layer : NHANES XPT file processing ‚Üí cleaned trial dataset ML Layer : Hyperparameter-tuned Random Forest with class balancing Subgroup Discovery : Novel algorithm testing single features + 2-way/3-way combinations Statistical Validation : Chi-square tests, Wilson confidence intervals, multiple testing correction Explainability : SHAP TreeExplainer for feature importance + beeswarm plots AI Layer : Claude Sonnet integration for narrative insights\n\nKey Innovation : Most subgroup analysis tools only look at single features (e.g., \"females\" OR \"age 60+\"). We built a combination discovery engine that finds patterns like \"Females aged 60-80 with HDL > 60\"‚Äîthe kind of multi-feature subgroups that exist in real biology."},{"heading":"Challenges we ran into","content":"Sparse Subgroups : Finding statistically significant combinations with adequate sample sizes was hard. We had to balance between finding granular subgroups (high specificity) and maintaining statistical power (N ‚â• 30). Multiple Testing Correction : Testing dozens of subgroups inflates false positive rates. Implementing Bonferroni correction was necessary but made significance harder to achieve‚Äîwe had to add \"promising subgroups\" reporting to show clinically meaningful patterns even without strict significance. NHANES Data Complexity : Raw NHANES comes in SAS XPT format with cryptic variable names, missing values, and complex merge logic. Converting it into a clean clinical trial dataset required careful column mapping and imputation strategies. Explainability vs Accuracy Trade-off : We initially used XGBoost (higher AUC) but switched to Random Forest for better SHAP interpretability‚Äîclinicians need to understand why a subgroup responds, not just that it does. Real-time AI Integration : Streaming Claude API responses in Streamlit required careful state management to avoid re-running expensive computations on every interaction."},{"heading":"Accomplishments that we're proud of","content":"End-to-end Pipeline : From raw XPT files ‚Üí cleaned data ‚Üí trained model ‚Üí SHAP explanations ‚Üí subgroup discovery ‚Üí AI insights‚Äîall in an intuitive Streamlit interface. Explainable AI : SHAP visualizations show exactly which biomarkers drive predictions, making the black box transparent for clinicians."},{"heading":"What we learned","content":"Technical:\n\nSHAP TreeExplainer is powerful but computationally expensive‚Äîsampling background data is crucial for speed Bonferroni correction is extremely conservative; FDR (False Discovery Rate) might be more appropriate for exploratory analysis Class imbalance (responders are rare) requires careful handling: balanced class weights + stratified splitting\n\nClinical:\n\nSubgroup discovery is a double-edged sword: it can save drugs OR lead to dangerous false positives that harm patients The \"file drawer problem\" is real‚Äîcompanies bury negative trials, losing valuable subgroup signals Regulatory bodies (FDA) are increasingly open to post-hoc subgroup analyses if done rigorously\n\nProduct:\n\nResearchers want transparency: showing warnings about multiple testing and overfitting builds trust AI explanations need to be specific and actionable, not generic Interactive visualizations (expandable sections, hover tooltips) are essential for complex medical data"},{"heading":"What's next for Sublytics","content":"Long-term (1-2 years):\n\nPhase IV Surveillance : Monitor post-approval drugs for safety signals in subpopulations Regulatory Pathway : Work with FDA to establish guidelines for AI-driven subgroup discoveries"},{"heading":"Built With","content":"matplotlib numpy pandas python scikit seaborn streamlit"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Synthetic Data Generation and Imputation","project_url":"https://devpost.com/software/synthetic-data-generation-and-imputation","tagline":"We generate realistic virtual patients and impute missing data to simulate, optimize, and de-risk clinical trials, accelerating drug discovery while ensuring data integrity.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tensorflow","url":null}],"external_links":[{"label":"docs.google.com","url":"https://docs.google.com/presentation/d/1CJtbe4dcqJrT5UjeShAjOse_T64zX1yzJwREiybIkJc/edit?slide=id.g39d2c2d089f_0_62#slide=id.g39d2c2d089f_0_62"}],"description_sections":[{"heading":"Inspiration","content":"Clinical trials often fail or get delayed due to incomplete data, small sample sizes, and biased analyses. We wanted to build a system that could fill in missing information and generate realistic virtual patients, helping researchers design, simulate, and analyze trials more effectively before they even begin."},{"heading":"What it does","content":"Our architecture is based off of deep generative models such as GAIN and conditional GANs to impute missing clinical data while preserving correlation and variance. It also generates synthetic patient cohorts for pre-trial simulation and power analysis and enables privacy-safe data sharing for multi-site collaboration. The result is complete, realistic datasets ready for modeling, analysis, and regulatory submission."},{"heading":"How we built it","content":"We built the system by training our architecture de-identified trial data to learn complex feature distributions. We integrated a synthetic data generation module that samples new patient profiles conditioned on biomarkers, demographics, and treatment arms. To ensure data quality, we developed validation metrics including Wasserstein distance, correlation preservation, and RMSE to compare imputed versus real distributions. We analyzed our design in 3 different environments, including MCAR, MAR, and MNAR missingness patterns."},{"heading":"Challenges we ran into","content":"One of the main challenges we faced was handling high-dimensional data. Balancing statistical fidelity with privacy when generating synthetic cohorts required careful design. We also needed to calibrate uncertainty in imputations so results remained biologically plausible and ensure model interpretability for regulatory transparency."},{"heading":"Accomplishments that we're proud of","content":"We are proud of achieving high correlation preservation and low deviation in key variable distributions. Our synthetic distributions accurately align to our generated data, showing the feasibility of synthetic data for pre-trial simulation. In addition, we're proud of designing and implementing our own ML architecture in a research backed environment."},{"heading":"What we learned","content":"We learned how to merge statistical imputation and deep generative modeling for clinical reliability. We also learned the importance of uncertainty quantification and model explainability in healthcare AI. Most importantly, we realized that synthetic data is not just a replacement for real data but a simulation tool for smarter, faster trial design."},{"heading":"What's next for Synthetic Data Generation and Imputation","content":"Next, we plan to integrate multi-modal data, including electronic health records, imaging, and genomics, for richer synthetic cohorts. We aim to add reinforcement learning modules to dynamically optimize trial designs and develop open-source APIs and datasets under an MIT license for the research community. We also hope to collaborate with biotech and pharmaceutical teams to pilot real-world pre-trial simulation workflows."},{"heading":"Built With","content":"numpy pandas python tensorflow"},{"heading":"Try it out","content":"docs.google.com"}]},{"project_title":"Cura","project_url":"https://devpost.com/software/cura-kthowx","tagline":"AI Medical Assistant: Intelligent Symptom Checker and Care Connector","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/897/409/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"chromadb","url":null},{"name":"creao","url":null},{"name":"fastapi","url":null},{"name":"livekit","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"swift","url":"https://devpost.com/software/built-with/swift"}],"external_links":[{"label":"production.creao.ai","url":"https://production.creao.ai/share?app=PNCQOyOh&utm_source=share&utm_medium=link"},{"label":"github.com","url":"https://github.com/hongdnn/healthcare_ai_backend"},{"label":"github.com","url":"https://github.com/s-akhtar-dev/cura-ai-ios-app"}],"description_sections":[{"heading":"ü©∫ Project Story: Cura","content":"About the Project\n\nCura is an AI-powered medical voice assistant designed to make healthcare more accessible and responsive. It listens to patient symptoms, provides personalized guidance, connects users to doctors, and schedules appointments ‚Äî all through natural, human-like conversation.\n\nWe were inspired by how difficult it can be to access immediate medical advice, especially when clinics are overwhelmed or unavailable. Our goal was to create an intelligent assistant that supports both patients and healthcare professionals by automating symptom triage, appointment scheduling, and follow-up care.\n\nThrough building Cura, we learned how to integrate real-time voice AI , generative language models , and healthcare data systems into one cohesive workflow. We explored challenges in conversational design, natural language understanding, and securely managing patient interactions.\n\nCura‚Äôs architecture combines:\n\nüéôÔ∏è LiveKit Agents ‚Äî for real-time voice calls and natural dialogue ‚öôÔ∏è FastAPI and MongoDB ‚Äî for backend data storage and healthcare logic üß† Chroma ‚Äî as a vector database for symptom similarity search and matching, which diagnose patient's issue and give advice based on healthcare service's internal data üìÖ CreaoAI ‚Äî for intelligent scheduling and calendar integration üíª Creao (React web) and Swift (mobile) ‚Äî for patient and provider dashboards Gmail API for appointment booking confirmation *\n\nChallenges Faced\n\nBuilding Cura presented several key challenges:\n\nDesigning natural and empathetic voice conversations that adapt to user tone and intent Managing speech latency for real-time responses Algorithm to match the most similar symptoms from user's input. We separate each symptom from healthcare data and embed each of them to count the number of matching symptoms and get average cosine similarity that receives best result * Structuring a scalable database that connects patients, clinicians, and appointment data Integrating multiple APIs (LiveKit, Chroma, Gmail) into a seamless workflow Ensuring that AI-generated responses remain medically cautious and privacy-aware\n\nDespite these challenges, we successfully created a working prototype that listens to patients, identifies symptoms, connects them with doctors, and schedules appointments ‚Äî all through an intelligent voice interface."},{"heading":"Built With","content":"chromadb creao fastapi livekit mongodb python swift"},{"heading":"Try it out","content":"production.creao.ai github.com github.com"}]},{"project_title":"darwin.","project_url":"https://devpost.com/software/darwin-w6fez0","tagline":"evolve coding agents through pvp and reinforcement on web3.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/889/357/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Letta: Honorable Mention"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"claude-code","url":null},{"name":"elevenlabs","url":null},{"name":"gemini-cli","url":null},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"letta","url":null},{"name":"livekit","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sui","url":null},{"name":"three.js","url":"https://devpost.com/software/built-with/three-js"},{"name":"vercel","url":null},{"name":"vite","url":null},{"name":"webgl","url":"https://devpost.com/software/built-with/webgl"}],"external_links":[{"label":"darwin.qtzx.dev","url":"https://darwin.qtzx.dev"},{"label":"github.com","url":"https://github.com/qtzx06/darwin"}],"description_sections":[{"heading":"Inspiration","content":"midjourney lets you generate 4 images and pick the best one, but code agents give you one output and force you into prompt hell if you don't like it. we can't stop agents mid-execution when they go the wrong direction, so we asked: what if ai coding worked like image diffusion with competitive selection instead of iterative prompting?"},{"heading":"What It Does","content":"darwin runs 4 ai agents that compete to build your ui with wildly different styles while a commentator analyzes their approaches in real-time. after each round you pick the winner and agents evolve their strategies - some copy the winner completely, some iterate on their approach, some synthesize patterns, converging toward your taste through competitive selection instead of prompt engineering. agents have their own sui wallet addresses, tip directly with SUI to those you like\n\nthe agents:\n\nspeedrunner: fast execution, minimal style bloom: animation-heavy, maximalist solver: logic-driven, structured loader: data-focused, pragmatic commentator: live sports-style narration via send_message_to_agent_async orchestrator: task splitting and validation"},{"heading":"the flow:","content":"orchestrator splits into subtasks 4 agents code simultaneously with distinct approaches commentator queries agent memory and narrates live users watch with audio-reactive 3d visualizations vote on-chain (gasless via sui sponsored transactions) losers read winner's memory and rewrite their own persona blocks"},{"heading":"how we built it","content":"letta cloud - true cross-agent communication via send_message_to_agent_async, agents literally rewrite their own context blocks through tool calling, orchestrator uses run_code to validate execution livekit, elevenlabs tts ‚Üí pcm ‚Üí audiosource ‚Üí localaudiotrack published to room, multi-spectator synchronized experience, data channels for transcripts audio-reactive webgl, livekit mediastream ‚Üí web audio api analysernode ‚Üí three.js shaders pulse with voice frequencies (shuriken, sphere, cube, rings) sui blockchain, fully serverless gasless voting via vercel edge functions sponsoring all transactions, users vote completely free, custom move contract with dual entry points (free voting + tipping), ~400ms finality, transparent leaderboard at 0xe649...0c55 claude code - multi-file refactoring, webgl debugging, livekit audio pipeline architecture"},{"heading":"Challenges We Ran Into","content":"livekit audio synchronization with elevenlabs tts buffer management true cross-agent memory reading while maintaining context sui transaction sponsoring securely in serverless functions webgl shader performance with multiple orbs designing meaningful agent learning without overfitting"},{"heading":"Accomplishments That We're Proud Of","content":"true multi-agent system where agents actually query each other's memory zero-cost user experience with on-chain voting each agent has distinct voice personality via elevenlabs self-evolving agents that rewrite their own memory blocks real-time spectator experience with synced audio/video"},{"heading":"What We Learned","content":"letta's persistent memory enables genuinely stateful ai agents that communicate livekit's room model makes multiplayer ai experiences straightforward sui's fast finality enables blockchain voting that feels instant voice-reactive visualizations create visceral connection to ai personalities sponsored transactions completely abstract blockchain complexity"},{"heading":"What's Next","content":"tournament mode with multi-round elimination custom agent training with unique personas agent marketplace as nfts with evolved memory blocks live streaming integration to twitch/youtube voice commands via vapi during battles"},{"heading":"Built With","content":"claude claude-code elevenlabs gemini-cli google-cloud letta livekit react sui three.js vercel vite webgl"},{"heading":"Try it out","content":"darwin.qtzx.dev github.com"}]},{"project_title":"Mentora","project_url":"https://devpost.com/software/planevent","tagline":"Rewriting the stereotypes of AI with a human-first mentor built to assist you live a better life.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/886/312/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Letta: Honorable Mention"}],"team_members":[],"built_with":[{"name":"letta","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/EugeneVuong/calhacks12"}],"description_sections":[{"heading":"Inspiration","content":"\"You can learn everything.\"\n\nThe direction of AI has been taken down a darker path for a tool originally intended to act as an intelligent computer that aids humans.\n\nTools such as interview cheating assistants or deepfake content generators used to slander others or spread misinformation have slowly started gaining traction and set a scary precedent for the future of AI.\n\nOur team wanted to look at ways to give AI a more human-supportive viewpoint. We reflected on our own struggles, and felt that habits are difficult to form. This gave way to Mentora, our project built to help anyone build stronger habits.\n\nAI can be a great assistant when prompted correctly. You can ask it for advice, have it generate schedules for you, and can even provide words of support. We utilize this quality of LLMs to create an application that gives users an easy way to interface with AI to build strong habits, tying together multiple strategies and tools."},{"heading":"What it does","content":"Mentora comprises of a dashboard with a live assistant, skill trees and various skills a user can choose to develop or strengthen. Skill tree roadmaps are generated stemming from the goals or habits the user chooses. We make use of Letta to create a persistent memory for the AI assistant that collects data trends and uses them to craft responses or provide suggestions."},{"heading":"How we built it","content":"Our project relies mainly on Letta as the backbone. We use TypeScript for the front end and various AI LLMs such as Claude for the brains behind the agent."},{"heading":"Accomplishments that we're proud of","content":"We were able to learn the ins and outs of Letta within a very short time frame and fully implement it within our project, creating an end product very close to prod-level."},{"heading":"What's next for Mentora","content":"We want to continue building Mentora to iron out the early-stage code bugs and to add on more features, along with developing it for more platforms such as a mobile web-app capable of sending notifications along with setting calendar reminders."},{"heading":"Built With","content":"letta typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"legendIDE","project_url":"https://devpost.com/software/legendide","tagline":"An AI-powered Web IDE where you can vibe code with your team and share context effortlessly in real time.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/898/303/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Letta: Honorable Mention"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"coderabbit","url":null},{"name":"elasticsearch","url":"https://devpost.com/software/built-with/elasticsearch"},{"name":"letta","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"legend-ide.vercel.app","url":"https://legend-ide.vercel.app/"}],"description_sections":[{"heading":"Built With","content":"claude coderabbit elasticsearch letta python react"},{"heading":"Try it out","content":"legend-ide.vercel.app"}]},{"project_title":"MonitorMachine","project_url":"https://devpost.com/software/monitormachine","tagline":"Automating clinical trial verification to cut costs, save time, bring life-saving treatments to patients faster, and spark more innovation in clinical research.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/202/datas/medium.jpg","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"chroma","url":"https://devpost.com/software/built-with/chroma"},{"name":"chromadb","url":null},{"name":"claude","url":null},{"name":"css3","url":"https://devpost.com/software/built-with/css3"},{"name":"fetch.ai","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"google","url":"https://devpost.com/software/built-with/google--2"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react.js","url":null},{"name":"sqlite","url":"https://devpost.com/software/built-with/sqlite"}],"external_links":[{"label":"github.com","url":"https://github.com/sulabhkatila/MonitorMachine"}],"description_sections":[{"heading":"Inspiration","content":"Clinical trials are the bridge between scientific discovery and real-world cures -- but that bridge, currently, is slow, fragile, and expensive.\n\nWhile studying how trials operate, I was struck by how much time and money go into one repetitive task: verifying and reviewing data by hand. Monitors spend weeks cross-checking PDFs, lab reports, and CRFs. It a process that consumes up to 30% of a trial‚Äôs cost and delays life-saving medicines from reaching patients.\n\nI wanted to change that.\n\nMy inspiration was simple: what if an AI agent could handle this repetitive verification work -- allowing researchers to focus on science, safety, and innovation instead?\n\nBy automating Source Data Verification and Review, I aim to help trials move faster, cut costs, save more lives, and invite more innovation into the clinical space -- so that life-saving treatments reach people sooner."},{"heading":"What it does","content":"This platform automates and simplifies clinical trial monitoring by connecting directly to the technologies already used in research ‚Äî such as Veeva Vault, Medidata Rave, and EHR/EDC systems ‚Äî eliminating the need to copy or migrate data across tools.\n\nIt includes a Protocol Analyzer, powered by Fetch.ai and Gemini, which reads the clinical trial protocol and automatically generates a Monitoring Plan based on the study‚Äôs endpoints, schedule of activities, and key compliance requirements.\n\nOnce attached to a study, this plan enables autonomous monitoring by AI agents that follow the defined schedule, retrieve data, and execute tasks automatically.\n\nThe platform also supports Source Data Verification (SDV) on demand ‚Äî extracting relevant information from CRFs, eCRFs, or connected EHR/EDC systems, gaining access to source documents, and cross-referencing the two to verify accuracy.\n\nWhen discrepancies are detected, it flags them for review and can take predefined corrective actions ‚Äî providing faster, smarter, and more integrated clinical trial monitoring."},{"heading":"How we built it","content":"I built the platform from the ground up as a full-stack web application designed to integrate seamlessly with existing clinical-trial systems.\n\nThe frontend was built with React.js, CSS, and JavaScript, giving it a modern UI and smooth transitions. The login and sign-up flow includes both standard authentication and SSO integrations with Google, Veeva Vault, and Medidata Rave (mocks), enabling secure, role-based access for sponsors and investigators.\n\nThe backend uses Flask (Python) for the API layer, with REST endpoints that manage user sessions, study creation, and file intake. Each uploaded or fetched file‚Äîprotocols, eSource PDFs, and CRFs‚Äîis stored securely in a database (ChromaDB).\n\nI integrated Fetch.ai agents and Gemini and Claude models to power the Protocol Analyzer. The analyzer parses trial protocols, identifies endpoints, study arms, inclusion/exclusion criteria, and the schedule of activities, then automatically generates a Monitoring Plan tailored to the study design. Along with this I built a monitor agent that is fluent in clinical trail processes, protocols, addressing schedule of events, and more.\n\nOnce attached to a study, the monitoring plan serves as a guide for autonomous AI agents. These agents connect to linked EDC or EHR systems through APIs, retrieve CRF and source data, and perform Source Data Verification when triggered. The verification engine uses a mix of document parsing, entity matching, and cross-referencing logic to detect inconsistencies between eCRFs and source data.\n\nWhen discrepancies are found, the system flags them in real time and can trigger notifications or corrective actions, all recorded in an audit trail."},{"heading":"Challenges we ran into","content":"One of the biggest challenges I faced was finding usable data. Real clinical trial data is highly protected for privacy and compliance reasons, and the public examples I found were incomplete, inconsistent, or missing key components like full protocols, CRFs, or source documents.\n\nTo move forward, I had to study what ‚Äúcomplete‚Äù datasets look like in real trials ‚Äî learning the structure and expectations for each type of document: protocols, CRFs, eCRFs, source data, and monitoring reports.\n\nFrom there, I handcrafted realistic mock studies from scratch ‚Äî writing detailed protocols, building CRF templates, and fabricating example source data that reflected how actual investigators document patient visits.\n\nThis process gave me a much deeper understanding of clinical data standards and what monitors actually look for, which shaped how I designed the platform‚Äôs data models, extraction logic, and AI validation pipeline."},{"heading":"Accomplishments that we're proud of","content":"I built a fully functional AI agent capable of autonomously understanding clinical trial protocols, generating monitoring plans, and verifying study data against its sources.\n\nI designed a complete workflow that connects directly to existing EDC platforms like Veeva Vault and Medidata Rave, eliminating the need to manually move data between systems ‚Äî a real bottleneck in current clinical operations.\n\nI also developed a Protocol Analyzer and Monitor agnet that interprets endpoints, inclusion criteria, and schedules of activities, translating them into actionable monitoring tasks for AI agents.\n\nThe system demonstrates how agentic AI can lead to a future where clinical trials are faster, more connected, and more efficient ‚Äî cutting costs, reducing human error, and accelerating the delivery of life-saving treatments."},{"heading":"What we learned","content":"I learned how complex and interconnected the clinical trial process really is ‚Äî and how much of it depends on accurate, traceable data. Even small verification errors or delays can cost millions of dollars and slow down access to life-saving treatments.\n\nThrough building this project, I gained a deep understanding of how protocols, CRFs, and source data interact, and how crucial monitoring is for maintaining data integrity and patient safety.\n\nMost importantly, I learned how AI and automation can help reduce this burden ‚Äî not by replacing people, but by empowering researchers to focus on innovation, science, and patient outcomes instead of repetitive manual work."},{"heading":"What's next for MonitorMachine","content":"I plan to build and fine-tune my own AI models trained specifically on clinical trial documents ‚Äî including protocols, CRFs, monitoring plans, and site communications ‚Äî to make the system smarter and more context-aware.\n\nI want to make the platform bulletproof and production-ready, capable of handling real-world variability in data formats, terminologies, and regulatory requirements.\n\nFuture versions will focus on improving autonomous agent reliability, secure integrations with EHR/EDC APIs, and deeper alignment with CDISC and GCP standards.\n\nThe ultimate goal is to create a robust, trusted AI monitoring assistant that can operate safely in live trials ‚Äî saving time, cutting costs, and pushing the boundaries of what‚Äôs possible in clinical research."},{"heading":"Built With","content":"chroma chromadb claude css3 fetch.ai flask gemini github google html javascript python react react.js sqlite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Empirica","project_url":"https://devpost.com/software/empirica","tagline":"Turn research papers into living knowledge graphs. Agentic AI finds papers, builds networks, generates hypotheses. Chat with your research using RAG.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/330/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Regeneron: Honorable Mention"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"axios","url":null},{"name":"claude","url":null},{"name":"fastapi","url":null},{"name":"networkx","url":null},{"name":"pymupdf","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"rag","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"scispacy","url":null},{"name":"sentence-transformers","url":null},{"name":"sqlalchemy","url":"https://devpost.com/software/built-with/sqlalchemy"},{"name":"sqlite","url":"https://devpost.com/software/built-with/sqlite"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/jalenfran/empirica"}],"description_sections":[{"heading":"Inspiration","content":"Biomedical researchers spend 15% of an average week up to 50% or more during intense periods of their time on literature review. When working on biomedical research, we realized finding connections across 50+ papers was nearly impossible manually. We needed a way to see the forest, not just the trees. What if AI could not only read papers but actively discover new ones, build knowledge networks, and generate research hypotheses automatically? That's why we built Empirica."},{"heading":"What it does","content":"Empirica transforms biomedical research with three core capabilities:\n\n1. Agentic Research Workflows: Turn on \"Agent Mode\" and watch Empirica autonomously search PubMed, discover papers via Google Scholar, download PDFs, extract entities, and build knowledge graphs‚Äîall while you focus on analysis.\n\n2. Interactive Knowledge Graphs: Visualize genes, diseases, drugs, and their relationships in stunning 2D/3D force-directed graphs. Click nodes to explore connections, filter by entity type, and navigate through your research visually.\n\n3. AI-Powered Intelligence:\n\nRAG-Enhanced Chat: Ask questions and get answers with exact paper + page citations Discovery Lab: AI generates research hypotheses by analyzing graph structure and document content, showing confidence scores and supporting evidence\n\nEvery insight is traceable, persistent, and citation-backed."},{"heading":"How we built it","content":"Backend (Python):\n\nFastAPI for async REST API with OAuth 2.0 authentication scispaCy for biomedical named entity recognition (80+ entity types) PyMuPDF for PDF text extraction NetworkX for graph construction and analysis sentence-transformers for semantic embeddings Custom RAG system with entity-aware chunking SQLite for persistence (projects, chat history, hypotheses)\n\nFrontend (TypeScript):\n\nReact 18 + Vite for blazing-fast development react-force-graph for 2D/3D WebGL visualization Three.js for advanced 3D rendering with particles and curved edges Tailwind CSS + Lucide icons for modern UI Axios for API communication\n\nAI Integration:\n\nClaude 3.5 Sonnet for natural language processing Custom prompt engineering for hypothesis generation RAG architecture combining semantic search with graph context\n\nExternal APIs:\n\nPubMed E-utilities for paper search Google Scholar scraping for PDF discovery PMC and DOI resolution for full-text access"},{"heading":"Challenges we ran into","content":"1. Graph Performance: Visualizing 500+ nodes with real-time physics simulation tanked performance. We optimized by implementing WebGL rendering, reducing particle counts, and adding smart chunking for large graphs.\n\n2. RAG Context Windows: Initially, RAG retrieved too much context, hitting Claude's token limits. We implemented entity-aware chunking that prioritizes relevant sections and semantic ranking to surface the best 7 chunks.\n\n3. Real-time Progress Updates: Background jobs ran asynchronously, making it hard to show live progress. We implemented a polling system with granular status updates and persistent job tracking.\n\n4. OAuth Token Expiration: During long research sessions (10+ minutes), Google OAuth tokens would expire mid-process, crashing the workflow. We implemented optional authentication for status endpoints and graceful error handling."},{"heading":"Accomplishments that we're proud of","content":"‚úÖ End-to-end autonomous research pipeline - From query to knowledge graph in minutes, fully automated\n\nProduction-quality RAG system - Semantic search + entity-aware retrieval with precise citations (paper + page)\n\nStunning visualizations - 3D graphs with colored edges, animated particles, proper lighting, and smooth interactions rival commercial tools\n\nFull persistence layer - Chat history and hypotheses survive across sessions, making research continuity seamless\n\nCitation transparency - Every AI-generated answer links back to exact source documents and pages\n\nGraph-aware hypothesis generation - Discovery Lab analyzes both document content AND network structure to find insights humans might miss\n\nReal-time updates - Live progress tracking during agentic research (papers found, analyzed, entities extracted)\n\nClean architecture - Modular, typed codebase with clear separation between services, ready for scale"},{"heading":"What we learned","content":"Technical:\n\nscispaCy's biomedical NER capabilities are incredible but require careful prompt engineering to maximize extraction quality WebGL force-directed graphs need careful optimization‚Äîcurved edges, particles, and lighting all impact frame rates RAG isn't just \"throw everything at the LLM\"‚Äîentity-aware chunking and semantic ranking dramatically improve answer quality Background job management in FastAPI requires thoughtful state management and polling strategies Three.js lighting models make a huge difference in 3D visualization readability\n\nResearch Domain:\n\nBiomedical research has VERY specific entity types (genes, proteins, diseases, drugs, pathways) PubMed's API is powerful but Google Scholar often has better PDF availability Relationship extraction is hard‚Äîco-occurrence is a decent baseline but pattern matching catches many more connections Researchers care deeply about citations and provenance‚Äî\"trust but verify\" is critical\n\nProduct:\n\nVisual feedback is everything‚Äîusers want to SEE progress, not just wait Persistence matters more than we thought‚Äîresearchers return to projects over days/weeks The \"magic moment\" is when Discovery Lab surfaces a hypothesis the user hadn't considered Autonomous workflows need to show their work‚Äîusers want to understand what the AI did"},{"heading":"What's next for Empirica","content":"Expand Research Domains:\n\nMulti-domain NER models - Integrate specialized models for chemistry, physics, computer science, and social sciences beyond biomedicine Domain-adaptive entity extraction - Let users choose research domain (clinical, genomics, drug discovery) for optimized NER performance Custom entity training - Allow researchers to fine-tune models on their specific subdomain\n\nEnhanced Collaboration:\n\nReal-time multi-user editing - Multiple researchers annotating and discussing the same graph simultaneously via WebSockets Export to academic formats - BibTeX, RIS, EndNote, and auto-generated literature review sections with proper citations Author network analysis - Visualize collaboration patterns and identify key researchers in your field\n\nSmarter AI:\n\nFine-tuned biomedical LLM - Train domain-specific model for better entity extraction and more accurate hypothesis generation Literature review generator - Auto-compose structured academic review sections from your knowledge graphs Experiment suggestions - Recommend methodologies and protocols based on successful papers in your graph\n\nScale & Performance:\n\nPostgreSQL migration - Handle concurrent access and larger datasets efficiently Graph versioning - Track how your knowledge evolves over time with diff visualization Handle 10,000+ paper graphs - Streaming processing and smart pagination for massive research projects\n\nOur vision: Make AI-accelerated research accessible to every scientist, turning months of literature review into hours of insight discovery."},{"heading":"Built With","content":"amazon-web-services axios claude fastapi networkx pymupdf python rag react scispacy sentence-transformers sqlalchemy sqlite typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Clanker Town","project_url":"https://devpost.com/software/clanker-town","tagline":"Clanker Town is a simulation / web-browser video game which lets player enter the town filled with other autonomous AI agents communicating between each other, gathering resources and trading.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/893/703/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Letta: Honorable Mention"}],"team_members":[],"built_with":[{"name":"elastic-search","url":null},{"name":"letta","url":null},{"name":"mcp","url":null},{"name":"move","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sui","url":null},{"name":"ts","url":null}],"external_links":[],"description_sections":[{"heading":"Overview","content":"Clanker Town is a simulation / web-browser video game which lets player enter the town filled with other autonomous AI agents communicating between each other, gathering resources and trading.\n\nGame Loop\n\nWhen player start the game they are dropped into a new match with few AI agents with distinctive personas and character traits, wallets and resources in the inventory.\n\nInitially all generators are not owned by anyone and can be captured either by agents or the player, once that happens the generator starts generating resources which can be claimed periodically, once agent/player has enough rsources they can upgrade the generator.\n\nHostility / Friendliness\n\nIn order to progress faster in game player can either start acting hostile by capturing agent's generator or be friendly to them, befriend them and bargain for lgood terms for trading rsources with them."},{"heading":"Memory","content":"In order to have context about the game, vision about the real-time world entities around agent, different level of trust / hostility towards the player and other agents, Clanker Town uses Letta for memory blocks and Elastic Search to find geospatial data about all items, agents, player on the map."},{"heading":"Built With","content":"elastic-search letta mcp move react sui ts"}]},{"project_title":"PaperTrail","project_url":"https://devpost.com/software/papertrail-ydwm46","tagline":"PaperTrail is an AI research assistant that uses deep memory architectures to learn and adapt to your interests, reading style, and goals to curate personalized academic paper recommendations.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/896/321/datas/medium.png","prizes":[{"hackathon_name":"Cal Hacks 12.0","hackathon_url":"https://cal-hacks-12-0.devpost.com/","prize_name":"Letta: Honorable Mention"}],"team_members":[],"built_with":[{"name":"claude","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"jina","url":null},{"name":"letta","url":null},{"name":"next.js","url":null},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"shadcn","url":null},{"name":"sonnet4.5","url":null},{"name":"supabase","url":null},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/thorchh/CalHacks-PaperTrail"}],"description_sections":[{"heading":"Inspiration","content":"As a researcher, I find literature review tedious and impersonal. Generic search yields piles of irrelevant results. What if an AI agent learns how you learn, captures your interests and dislikes, reads papers in parallel, and surfaces what matters?\n\nI built PaperTrail to bring deep personalization to research discovery."},{"heading":"What it does","content":"PaperTrail uses multi-agent orchestration with persistent memory. Describe a research topic and it:\n\nSearches the papers Scores paper relevance against your interests, goals, expertise, and feedback Returns relevant, personalized recommendations Learns from feedback to refine future suggestions and become more personal Reads specific papers on demand and answers questions in real time Sleeptime compute generates insights over previous conversations, further personalizing the agent.\n\nAll personalized through a memory layer that adapts to your workflow."},{"heading":"How I built it","content":"Multi-agent orchestration (Letta): supervisor agent generates targeted queries; workers fetch papers via Jina AI and evaluate in parallel. Deep memory architecture (Letta): profiles store interests, dislikes, goals, expertise, explanation style; conversation history; and feedback tables linking votes to preferences. Personalized scoring: workers use memory blocks to align recommendations to your profile. Real-time learning: each vote updates the user model, shaping future recommendations."},{"heading":"Challenges","content":"Latency: parallel worker evaluations enabled fast, accurate recommendations. Personalization: memory blocks encoding interests, dislikes, expertise, and style lifted precision. Threading fine-grained preferences into agent prompts reliably."},{"heading":"Accomplishments","content":"Deep personalization with feedback loops. Smooth real-time paper reading and Q&A. Clear UX that hides multi-agent complexity. Results improve with usage."},{"heading":"What I learned","content":"Modern LLM orchestration frameworks are powerful. Memory matters: persistent user context beats session-only approaches for quality. Multi-agent systems call for careful supervisor‚Äìworker coordination and state handling."},{"heading":"What's next for PaperTrail","content":"Broader coverage: expand beyond arXiv (Google Scholar, semantic scholar). Fine-tuning with user feedback data. Collaboration features to share recommendations. Read-paper sessions with collaborative learning and notes.\n\nBig picture: personalized research that learns with you."},{"heading":"Built With","content":"claude css jina letta next.js postgresql react shadcn sonnet4.5 supabase tailwind typescript"},{"heading":"Try it out","content":"github.com"}]}],"generated_at":"2026-02-17T18:22:27.964251Z"}}