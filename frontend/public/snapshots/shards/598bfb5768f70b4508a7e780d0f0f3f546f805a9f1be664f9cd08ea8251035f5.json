{"version":"v1","hackathon_url":"https://arangodbhackathon.devpost.com","generated_at":"2026-02-18T16:53:28.098625Z","result":{"hackathon":{"name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","url":"https://arangodbhackathon.devpost.com","gallery_url":"https://arangodbhackathon.devpost.com/project-gallery","scanned_pages":5,"scanned_projects":105,"winner_count":6},"winners":[{"project_title":"AgentBIM","project_url":"https://devpost.com/software/agentbim","tagline":"RAG enabled BIM authoring and processing using natural language","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/299/477/datas/medium.jpg","prizes":[{"hackathon_name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","hackathon_url":"https://arangodbhackathon.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"arangodb","url":null},{"name":"ifc","url":null},{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/tewodros18/arangodb-hack"}],"description_sections":[{"heading":"Inspiration","content":"I was inspired by the challenge of making BIM data more accessible and interactive. Working with BIM models can be tedious, often with multiple back-and-forths. I wanted to create a tool that would allow them to query and explore building information using natural language, simplifying decision-making and collaboration."},{"heading":"What it does","content":"AgentBIM is an intelligent agent that leverages natural language processing and graph databases to provide interactive access to BIM data. Users can ask questions about building elements, relationships, and spatial properties using plain English. AgentBIM translates these queries into AQL for an ArangoDB graph, which is built from parsed IFC data using IfcOpenShell and NetworkX. It then returns the relevant information, visualized or in text, making BIM data intuitive and actionable."},{"heading":"How we built it","content":"I started by developing a Python script using IfcOpenShell to parse IFC files and extract building elements and relationships. This data was then transformed into a NetworkX graph for analysis. I used ArangoDB to store the graph data, leveraging its graph database capabilities. The \"ArangoGraphQAChain\" was implemented using LangChain, which connected the natural language interface to the ArangoDB database. I also incorporated a front-end interface built with Gradio to enhance user interaction."},{"heading":"Challenges we ran into","content":"Parsing complex IFC files and accurately mapping them to a graph database proved challenging. I struggled with handling various relationship types and ensuring data consistency. Developing a robust natural language processing pipeline that could accurately interpret diverse queries was also difficult. Integrating all these components into a seamless workflow required extensive debugging and optimization."},{"heading":"Accomplishments that we're proud of","content":"Created a system that allows users to query BIM data using natural language. AgentBIM demonstrates the potential of AI to revolutionize the construction industry."},{"heading":"What we learned","content":"I gained valuable experience in working with IFC files, graph databases, and natural language processing. I also discovered the power of natural language interfaces for making complex data accessible."},{"heading":"What's next for AgentBIM","content":"I plan to expand AgentBIM's capabilities by incorporating more advanced natural language processing techniques, including intent recognition and context awareness. I'll also focus on improving the visualization of query results and adding support for more complex queries. I am going to add more robust error handling and increase the amount of IFC properties that are parsed."},{"heading":"Built With","content":"arangodb ifc langchain langgraph python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"AskStreets: Querying and Visualizing Street Networks","project_url":"https://devpost.com/software/askstreets-querying-and-visualizing-street-networks","tagline":"An agentic AI app that uses OpenStreetMap data to answer queries and generate insights into geographic street networks.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/310/345/datas/medium.png","prizes":[{"hackathon_name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","hackathon_url":"https://arangodbhackathon.devpost.com/","prize_name":"Second Place"}],"team_members":[],"built_with":[{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"networkx","url":null},{"name":"openai","url":null},{"name":"openstreetmap","url":"https://devpost.com/software/built-with/openstreetmap"},{"name":"osmnx","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/msradam/askstreets/blob/main/askstreets-gpu.ipynb"}],"description_sections":[{"heading":"Requirements","content":"Python 3.10 An ArangoDB instance, e.g. a local Docker container (for GPU acceleration) Nvidia CUDA toolkit, a compatible NVIDIA GPU, and RAPIDS (follow the install guide here ) A credentials.yml file with API keys for your desired AI platform (see sample file in repo)"},{"heading":"Running the Code","content":"Clone the repo, then in the askstreets directory:\n\npython3.10 -m venv env source env/bin/activate pip3 install -r requirements.txt\n\nEnsure your ArangoDB instance is running, e.g. to startup the local Docker container:\n\ndocker run -e ARANGO_ROOT_PASSWORD=<root_password> -p 8529:8529 arangodb/arangodb\n\nThen startup the Jupyter server and load the desired notebook:\n\njupyter-notebook askstreets-gpu.ipynb\n\nThere are two versions of the AskStreets notebook:\n\naskstreets-gpu.ipynb which is the hackathon submission with GPU acceleration and fully answered query samples askstreets.ipynb which has cleared cell output and does not have GPU acceleration\n\naskstreets-gpu.ipynb also contains output for additional queries that were not demo'd in the video submission."},{"heading":"Inspiration","content":"During my internship at UNICEF Innovation in NYC, I used OpenStreetMap, OSMnx, and NetworkX to calculate distances between schools and health facilities in UNICEF programme countries using national street and road networks. By writing code to execute graph algorithms, I was able to generate data to address a real-world issue.\n\nI would like to generalize this challenge towards a broader use case: if you're a city planner, business owner, architect, etc., you may wish to ask questions about street networks (e.g. accessibility of services, routed distances between landmarks, crowded intersections, etc.) without needing to code lengthy algorithms. This is where AskStreets comes in: by providing the ability to translate natural language queries into street network analysis."},{"heading":"What it does","content":"The Jupyter Notebook submission contains the proof-of-concept for AskStreets. The agentic app uses a LangGraph ReAct agent that accepts user queries and calls multiple tools that can geocode, generate and run AQL, generate and run OSMnx/NetworkX code, and visualize points on a Folium map.\n\nBy passing a query to the query_street_network function, it will invoke the ReAct agent to run these tools to interpret the query, execute code, and provide a natural language response or map visualization for the specific question."},{"heading":"How I built it","content":"I used OSMnx to download street network graphs and geographic features for certain locations, prepared this data to load into ArangoDB, then wrote the LLM-based tools and ReAct agent code for the agentic app."},{"heading":"Challenges I ran into","content":"Prompt engineering was a large aspect of this project; I needed to revise the prompts per tool multiple times as I continuously tested and analyzed the output of the ReAct agent, so that I could provide the AI models with more context to accurately interpret user queries and assemble the correct code. Modifying the tools to work in tandem with each other to generate the correct intermediate queries to pass between them was also challenging, but ultimately rewarding."},{"heading":"Accomplishments that I'm proud of","content":"I particularly enjoyed seeing the outcome of these tools, which are able to accurately interpret user queries about street networks and correctly identify the geographic attributes to filter or run algorithms against. I especially appreciated that by loading additional datasets like OpenStreetMap features and health facility data into ArangoDB, along with the graph network, the AQL tool was able to pull data across these sources to answer user queries with a higher degree of specificity."},{"heading":"What I learned","content":"I learned how to work with the LangChain and LangGraph libraries, how to invoke LLMs and prompt engineer to improve answers to queries, and how to prepare OSMnx data to load into ArangoDB."},{"heading":"Citations","content":"Boeing, G. (2024). Modeling and Analyzing Urban Networks and Amenities with OSMnx. Working paper. https://geoffboeing.com/publications/osmnx-paper/"},{"heading":"What's next for AskStreets","content":"Working with geospatial data has so much potential! In the submission notebook, I demonstrate at the end how health facility data can be overlaid with the street network graph and OpenStreetMap features data so that it can also be queried by AQL. By overlaying and combining even more data sets, we can enhance the app's ability to answer many different types of queries.\n\nDue to joining the hackathon late, there were tools I would have liked to fully implement but lacked refinement time. For example, a tool to dynamically pull in more data from the OpenStreetMap API based on a user query, a tool to more accurately translate location names, or updates to the visualization tool to draw paths between points. The tool prompts could also be further tuned to be more precise and avoid redundant operations. Different models could be deployed for each tool for their particular use case, with more lightweight models assigned to easier tasks.\n\nThis app can be further enriched with a UI that can not only accept queries, but also automatically download OSM road networks and features from a user-specified location. It can even be integrated with a sophisticated mapping tool like kepler.gl that offers more visualization options for large geospatial datasets."},{"heading":"Built With","content":"langchain langgraph networkx openai openstreetmap osmnx"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"GDELT Open Intelligence Agent","project_url":"https://devpost.com/software/gdelt-open-intelligence-agent","tagline":"A web app that uses LLM agents to help you query the GDELT Open Intelligence knowledge graph in natural language and visualize the output of your queries","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/315/070/datas/medium.png","prizes":[{"hackathon_name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","hackathon_url":"https://arangodbhackathon.devpost.com/","prize_name":"First Place"}],"team_members":[],"built_with":[{"name":"arangodb","url":null},{"name":"cugraph","url":null},{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"networkx","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/QasimKhan5x/GDELT-AQL-NetworkX-Agent/blob/main/GDELT_OpenIntelligence_ReWOO_GraphRAG.ipynb"}],"description_sections":[{"heading":"Inspiration","content":"I wanted to build a single, seamless system where an LLM can analyze geopolitical events (from the GDELT dataset) by leveraging powerful search capabilities, graph analytics, and a user-friendly interface – all orchestrated under an agentic pattern. The potential to glean real-time insights from a massive global events dataset was a compelling challenge and a big inspiration for me."},{"heading":"What it does","content":"The GDELT Open Intelligence Agent accepts natural language queries about global events, then dynamically selects the appropriate tools to:\n\nRetrieve structured data via AQL (including read and write). Perform text-based searching/ranking (FTS) and vector search on event descriptions. Execute advanced spatiotemporal graph analytics accelerated by cuGraph. Return results in a user-friendly format through a Streamlit interface and graph visualization."},{"heading":"How I built it","content":"Agentic Pattern —> ReWOO: I used a ReWOO-based (Reasoning Without Observation) approach for orchestrating an LLM’s plan-and-execute workflow. Human in the Loop for Update/Delete: Critical updates and deletes require human confirmation to mitigate potential mistakes from the agent. Full text search, Geospatial, & Vector Search: Combined ArangoDB’s native full-text, geospatial, and vector search features for partial matches, location based tasks, semantic similarity queries. Memory: Stored context across conversation turns so the agent can recall prior user queries/decisions. Graph Visualization: Rendered results in a plotly chart, showing how events, actors, and locations interconnect. Streamlit Interface: Provided an accessible UI for interactive queries, letting non-technical users query and visualize results."},{"heading":"Challenges","content":"Agentic Pattern —> Plan and Execute: While powerful for complex tasks, it can be slower and overkill for simpler queries. ReAct can lead to wasted calls and cost, plus limited traceability. I needed careful orchestration to balance costs and speed. I spent a lot of time trying to get these two patterns to work for me, but they turned out to be unsuitable for my usecase."},{"heading":"Accomplishments","content":"Successfully handling various types of queries: from partial text searches to advanced network centralities, all under a single agent that reasons about the best tools for each request."},{"heading":"What I learned","content":"Agentic Design Patterns: I explored how ReWOO, ReAct, and Plan-and-Execute differ and how to best apply each. GPU Acceleration for Graph Analytics: Offloading heavy computations can greatly improve performance. For graphs with over 100k nodes and edges, CPU is infeasible. cuGraph scales very well! Designing Agents for Graph Databases: I discovered best practices for bridging LLM reasoning with ArangoDB’s graph and search features. Features of ArangoDB: Embracing ArangoSearch, multi-model queries (AQL, graph traversals, geospatial, analyzers), vector indexing, and more."},{"heading":"What’s next for GDELT Open Intelligence Agent","content":"Further refine the Agentic and GraphRAG patterns to boost accuracy and reduce latency. Explore additional embeddings and improved vector indexes for faster semantic search. Expand the Streamlit interface with more interactive analysis and real-time data ingestion."},{"heading":"Built With","content":"arangodb cugraph langchain langgraph networkx openai python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Neuthera - Drug discovery toolkit","project_url":"https://devpost.com/software/neuthera-drug-discovery-platform","tagline":"NeuThera is an AI-driven drug discovery toolkit integrating multiple SOTA generative models for de novo molecular design. Combines graph-based retrieval with advanced compound fingerprint embeddings.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/315/590/datas/medium.png","prizes":[{"hackathon_name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","hackathon_url":"https://arangodbhackathon.devpost.com/","prize_name":"Third Place"}],"team_members":[],"built_with":[{"name":"arango","url":null},{"name":"biomart","url":"https://devpost.com/software/built-with/biomart"},{"name":"biopython","url":null},{"name":"biosnap","url":null},{"name":"chatgpt","url":null},{"name":"chemberta","url":null},{"name":"chembl","url":"https://devpost.com/software/built-with/chembl"},{"name":"deeppurpose","url":null},{"name":"drugbank","url":null},{"name":"faiss","url":null},{"name":"graphrag","url":null},{"name":"huggingface","url":null},{"name":"langchain","url":null},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"pdb","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"rdkit","url":null},{"name":"tamgen","url":null},{"name":"torch","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Redomic/NeuThera-Drug-Discovery-Toolkit"}],"description_sections":[{"heading":"Inspiration","content":"Traditional drug discovery methods are hindered by high costs, long timelines upwards of 20 years, and a high attrition rate in clinical trials. With the rise of AI and computational biology -- Generative models and in-silico validation techniques have shown promise in accelerating early-stage drug design. However, current models often operate independently of each other, lacking an integrated pipeline for end-to-end drug candidate generation.\n\nNeuThera was proposed as a modular drug discovery starter toolkit, integrating multiple state-of-the-art generative molecular design models such as TamGen , chemBERTa , and DeepPurpose with other advanced tooling like graph-based retrieval, molecular fingerprint embeddings, ADMET profiling, etc."},{"heading":"What it does","content":"The goal is to create a fully modular agentic AI framework capable of generating, validating, and optimizing novel drug candidates in an end-to-end pipeline - creating and maintaining a graph database of all FDA approved and generated compounds for further repurposing or discovery.\n\nNeuThera supports both end-to-end drug discovery automation and interactive, user-guided drug design workflows .\n\nGenerate de novo molecules: using multiple SOTA generative models, including Transformer-based molecular generator models. Ability to generate millions of compounds with complete virtual ADMET profiling for validation. All generated compounds are viable in the real world. biomedical knowledge-base: Combines 15+ datasets from BioSNAP, DrugBank, Chembl, and PDB to create a starting point for drug discovery and repurposing. Molecular Vector Embedding Space: Vector embeddings from chemBERTa facilitate lead optimization, scaffold hopping, and similarity search. In-Silico Testing: With generated compounds and target proteins, uses DeepPurpose to predict binding affinity without requiring real world intervention"},{"heading":"How we built it","content":"NeuThera is architected as a multi-model system, integrating specialized tools and frameworks to create a starter toolkit for end-to-end drug discovery. The modular nature of the technology used allows researchers to expand the tooling, as all necessary data and functions are already provided.\n\nCore Modules TamGen: A transformer-based generative model for de novo molecular design, trained on 20 million+ SMILES of known bioactive compounds. All generated compounds are validated and docked on target protein using DockBox before final result. DeepPurpose: A multi-model framework used to check the binding affinity between a drug and a target protein. As all generated compounds from TamGen are already validated with docking coordinates, DeepPurpose fits in perfecting with this pipeline. chemBERTa: Transformer-based model trained on 120+ million SMILES to create meaningful vector embeddings. Used to create vector space of all FDA Approved drugs + generated compounds for advanced analytics. Knowledge Graph & Retrieval Modules ArangoDB : A multimodal database storing structured relationships between genes, proteins, diseases, drugs, and molecular structures. Graph-based querying for retrieving relevant molecular information, linking known drug-target interactions to novel compounds. Molecular Similarity & Lead Optimization Morgan/Circular Fingerprints: Used for molecular embedding, leveraging Tanimoto similarity and vector representations. Vector Space Search: for identifying structurally similar compounds within large-scale chemical libraries. Graph-based lead optimization: Using molecular graphs and chemical property analysis to refine generated compounds. GraphRAG & Biomedical Reasoning GraphRAG framework Augments traditional RAG (Retrieval-Augmented Generation) methods by incorporating graph-based reasoning for biomedical data Ontological mapping : Integrates structured biomedical ontologies (e.g., DrugBank, ChEMBL) to enhance retrieval and inference."},{"heading":"Challenges we ran into","content":"Data inconsistencies and scattered datasets: As the biomedical data space is vast and varied from field to field (Most use different identifiers), it required us multiple days to put together the graph database using only open-source mappings. A lot of the datasets used required combining multiple different mappings to get the required fields. Outdated libraries and models: As most of the technology we're using is state of the art, they are not mature enough to work well with different technologies. Example: TamGen only has around 30 stars on github and required very specific library versions to work. We had to rewrite some of the code to work for our needs and combine with our tech stack. Sadly, we've had to discard nx-arangodb as it does not function well with TamGen which is a core unit of our project. Scaling the solution: As college students with almost no resources, we've had to keep our AI model (GPT-4o) usage to a bare-minimum. As such, we could not fine tune it to work as we intended, though it works well ~75% of the time. We wish to work on this project for a long and with adequate funding, we can run a model with much better reasoning abilities and fine tune to be extremely useful."},{"heading":"Accomplishments that we're proud of","content":"TamGen code rewrite to work without CUDA: Our code rewrite for TamGen can be a valid contribution for their repository. Biomedical knowledge retrieval: Combing 15+ datasets enables us to do structured hypothesis-driven drug design. Scalable molecular similarity search: using vector embeddings for rapid lead identification and generated drug repurposing."},{"heading":"What we learned","content":"Got a glimpse of how cutting edge research for generative AI works. How vast and wonderful the open source community for biomedical fields are. Working with multiple tooling and creating coherence between them. Using SOTA technologies like ArangoDB and GraphRAG to create meaningful toolings"},{"heading":"What's Next for NeuThera?","content":"Enhancing generative models with a feedback loop: Integrating diffusion-based generative modeling to improve the novelty, drug-likeness, and synthetic accessibility of generated compounds. Implementing a reinforcement-driven feedback loop for iterative optimization TamGen generates an initial batch of 10000 de novo compounds. DeepPurpose predicts binding affinity for each compound with the target protein. Compound encoders select the highest-scoring compounds as reference for next batch. Loop continues until convergence, maximizing binding affinity while optimizing ADMET properties. Automated lead optimization and drug repurposing: Integrating Graph Neural Networks (GNNs) on molecular embeddings to predict novel indications for existing compounds. Scaffold hopping via vector space traversal to explore chemically diverse, high-affinity derivatives. Modular tooling for user-defined extensions: Allowing users to integrate custom generative models, scoring algorithms, functions, etc. Supporting custom scoring functions, including multi-objective optimization for ADMET, pharmacokinetics, and toxicity filtering. Advanced UI/UX for visualization and interactive drug design: Developing an interactive web platform with: AI-Chatbot system Molecular visualization for ligand-protein interactions and generated compounds. Graph-based relationship exploration to analyze drug-target-disease links. Live compound generation and scoring dashboard, enabling real-time feedback on molecular design."},{"heading":"Built With","content":"arango biomart biopython biosnap chatgpt chemberta chembl deeppurpose drugbank faiss graphrag huggingface langchain pandas pdb python rdkit tamgen torch"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Data Engineer's Buddy","project_url":"https://devpost.com/software/trial-kjzbys","tagline":"Using ArangoDB & NetworkX for AI-powered management of enterprise data","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/311/654/datas/medium.png","prizes":[{"hackathon_name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","hackathon_url":"https://arangodbhackathon.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"arangodb","url":null},{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"networkx","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/HrishikeshP-01/DEBy-Project/tree/main"}],"description_sections":[{"heading":"Inspiration","content":"Problem Statement\n\nData in large organizations is spread across multiple DBs on several different DBMS This results in a significant cost of operation from a data engineering standpoint.\n\nProposal\n\nOver the course of this hackathon, I've explored how ArangoDB & NetworkX can be used to aid AI in the management of enterprise data. A variety of tasks such as data cataloging, lineage tracking, day-to-day data operations which traditionally requires the collaboration of several teams could be done within minutes by storing the metadata in a multimodal DB such as ArangoDB. Packages & libraries such as NetworkX & CuGraph can then be leveraged by AI agents to deliver insights & perform data engineering tasks within minutes. The multimodal offering of ArangoDB allows for metadata to be stored in such a way that a variety of data engineering tasks can easily be performed withing minutes."},{"heading":"What it does","content":"Note: For this hackathon, I've focused on the data engineering tasks that can be performed by AI agents as that is universal & applicable to all enterprises. The delivery of insights is specific to the data & hence won't be applicable to everyone so I've chosen to focus on that at this stage. DEBy - Data Engineer's Buddy is an intelligent agentic app that assists with Data Operations in Enterprises At this stage, DEBy is able to:\n\nIdentify upstreams & downstreams Assist with ETL Refresh scheduling Intelligently calculate refresh delays Perform impact analysis resulting from changes in a data model"},{"heading":"How we built it","content":"Data - I've stored the relationships between data structures in the form of Arango Graph & metadata such as refresh details in the form of Arango Collections App - Created using Python, LangChain, LangGraph & OpenAI API"},{"heading":"Challenges we ran into","content":"Identifying the best way to leverage multimodal features of ArangoDB to capture the structure of enterprise data Agent had to learn the relationships between enterprise data structures & the nature of dependencies Teaching the agent data operation tasks"},{"heading":"Accomplishments that we're proud of","content":"Using ArangoDB to capture the relationships between SQL objects & storing metadata critical for Data Operations Agent can identify upstream & downstream dependencies & intuitively understand the implications of dependencies with minimal prompting. Agent can perform easily perform tedious Data Operation tasks such as refresh scheduling & lineage tracking The agent can create visualizations for all of the above features"},{"heading":"What we learned","content":"ArangoDB's multimodal features can be easily used to capture information about enterprise data structures. Using NetworkX & CuGraph, the data can be parsed in realtime by AI agents to extract insights & automate complex Data Operations tasks."},{"heading":"What's next for DEBy","content":"Create an enterprise ready solution leveraging ArangoDB to simplify management of enterprise data Additional features for DEBy that aims to automate complex Data Operation tasks Leverage the multimodal features of ArangoDB to make DEBy the one-stop solution for all of enterprise specific requirements of a Data Engineer"},{"heading":"Built With","content":"arangodb langchain langgraph networkx openai python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Scopium","project_url":"https://devpost.com/software/scopium-lna7ro","tagline":"Expand the Scope of Your Codebase! Unlock insights like never before—query your entire codebase effortlessly. Navigate, search, and understand your code with precision.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"Building the Next-Gen Agentic App with GraphRAG & NVIDIA cuGraph","hackathon_url":"https://arangodbhackathon.devpost.com/","prize_name":"Public Choice"}],"team_members":[],"built_with":[{"name":"arango","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"langchain","url":null},{"name":"mistral","url":null},{"name":"networkx","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"github.com","url":"https://github.com/AdityaS8804/scopium.git"}],"description_sections":[{"heading":"Inspiration","content":"Working with new open-source libraries can be overwhelming, especially when trying to understand a large codebase. What if there was a tool that allowed developers to interact with their codebase conversationally, helping them debug and navigate massive projects more efficiently? Enter Scopium —a tool designed to make exploring and understanding complex codebases easier."},{"heading":"What it does","content":"Scopium allows developers to talk to their codebase through an interactive chatbot. It transforms the entire codebase into a graph representation , making it easier to navigate, debug, and analyze relationships between different components. Key features include:\n\nConversational Interface: Ask questions about your codebase and receive meaningful insights. Graph-Based Code Representation: Converts code into a structured graph, where nodes represent code components (functions, classes, files) and edges capture relationships. Streamlined Debugging: Identify dependencies, trace errors, and optimize workflows with an intelligent, structured approach."},{"heading":"How we built it","content":"To bring Scopium to life, we followed a structured approach:\n\nChunking the Codebase: Breaking down the source code into meaningful nodes. Capturing Relationships: Establishing edges between nodes to map out dependencies and structures. Graph Storage & Retrieval: Leveraging graph databases for efficient querying and retrieval. AI-Powered Querying: Implementing NLP models to facilitate a natural conversation with the code."},{"heading":"Challenges we ran into","content":"Efficient Chunking: Ensuring that code is split into meaningful units while maintaining contextual integrity. Handling Large Codebases: Optimizing performance for extensive repositories. Context-Aware Conversations: Making chatbot responses precise and helpful."},{"heading":"Accomplishments that we're proud of","content":"Innovative Graph Representation: Successfully designed a system to convert code into a navigable knowledge graph. Seamless Codebase Interaction: Enabled developers to query their codebase intuitively. Enhanced Debugging Workflow: Provided an efficient method to trace and resolve issues in large projects."},{"heading":"What we learned","content":"Graph-Based Code Analysis: The power of using graph structures for code understanding. NLP in Developer Tools: How AI can bridge the gap between humans and raw source code. Optimizing Large-Scale Systems: Tackling performance issues in large codebases."},{"heading":"What's next for Scopium","content":"Scopium is just the beginning. Future developments include:\n\nDeeper Code Insights: Advanced analytics on code complexity, optimization suggestions, and security checks. Multi-Language Support: Expanding support to more programming languages. IDE & GitHub Integration: Seamless integration with popular developer tools. Live Debugging Assistance: Real-time tracking of runtime errors and potential fixes.\n\nScopium aims to revolutionize the way developers interact with code, making large projects more accessible and debugging less of a hassle. Stay tuned for more updates!"},{"heading":"Built With","content":"arango flask langchain mistral networkx react"},{"heading":"Try it out","content":"github.com"}]}],"generated_at":"2026-02-18T16:53:28.098625Z"}}