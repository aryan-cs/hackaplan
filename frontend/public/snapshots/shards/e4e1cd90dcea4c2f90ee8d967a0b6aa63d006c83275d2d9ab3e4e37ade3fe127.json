{"version":"v1","hackathon_url":"https://hackprinceton-fall-2025.devpost.com","generated_at":"2026-02-17T06:04:21.146845Z","result":{"hackathon":{"name":"HackPrinceton Fall 2025","url":"https://hackprinceton-fall-2025.devpost.com","gallery_url":"https://hackprinceton-fall-2025.devpost.com/project-gallery","scanned_pages":9,"scanned_projects":193,"winner_count":37},"winners":[{"project_title":"TerraLink","project_url":"https://devpost.com/software/terralink-h5vuel","tagline":"TerraLink tackles the net-zero bottleneck: slow, costly site selection for renewables. We use multi-agent AI and Google Earth Engine to find optimal sites in minutes.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/953/740/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Overall Hack [Courtesy of Amplitude, Anthropic, OpenAI]"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Sustainability Hack [Courtesy of EaglePlan]"}],"team_members":[],"built_with":[{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"geojson","url":"https://devpost.com/software/built-with/geojson"},{"name":"google-earth-engine","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"lucide-react","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"restful-api","url":null},{"name":"tailwind-css","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/valeriacartagena/terralink-ai"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAG4KdiiCQk/yXAGWI9APPQwKcD5YJAiNA/edit?utm_content=DAG4KdiiCQk&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"}],"description_sections":[{"heading":"Inspiration","content":"The world needs to massively scale solar, wind, hydro, and geothermal by 2050 to hit climate targets, but one of the biggest bottlenecks is simply finding where to build. Analysts from energy companies routinely spend 6-18 months on manual site selection, burning through consultant fees and delaying urgently needed projects. We realized that combining LLMs with free satellite data could flip this: an agentic system that lets anyone discover credible, climate-aligned renewable energy sites in minutes for pennies, accelerating the energy transition instead of waiting on paperwork and GIS bottlenecks."},{"heading":"What it does","content":"TerraLink automates renewable energy site discovery by combining multi-agent AI with Google Earth Engine's satellite data. Users describe their project in plain English (\"30-acre solar farm in Texas\"), and our system analyzes thousands of locations using real satellite imagery to identify the best sites, ranked by solar irradiance, terrain slope, land cover, and proximity to protected areas."},{"heading":"How we built it","content":"TerraLink uses a four-agent architecture orchestrated through sequential API calls:\n\n1. Query Parser (Gemini) : Converts natural language (\"affordable wind sites near Austin\") into structured parameters (energy type, region, acreage, criteria weights)\n\n2. Dataset Discovery Agent : Searches Google Earth Engine's 10,000+ satellite datasets to find relevant data sources (solar irradiance, elevation, land cover, protected areas)\n\n3. GEE Query Agent (Python) : Executes Google Earth Engine API calls to fetch and process satellite imagery, then applies a weighted scoring algorithm.\n\n4. Results Explainer (Gemini) : Generates natural language insights explaining why each site scored high, with specific metrics and actionable recommendations.\n\nThe frontend (React + Tailwind CSS) provides an interactive chat interface where users can adjust criteria weights with sliders and see results update in real-time without re-querying satellites. The *backend *(Flask + Python) orchestrates agent communication, handles GEE authentication via service accounts, and manages API rate limiting across Gemini and Google Earth Engine."},{"heading":"What we learned","content":"Multi-agent systems are more maintainable than monolithic AI: each agent can be upgraded independently. Google Earth Engine is incredibly powerful but has a steep learning curve for Python API authentication and raster algebra. LLMs excel at translation tasks: Gemini perfectly bridges natural language ‚Üî structured data and data ‚Üî explanations. Caching is critical: GEE queries take 20-40 seconds; caching identical region queries is essential for UX Free satellite data changes everything: $0 imagery access means we can offer this to underserved communities."},{"heading":"What's next for TerraLink","content":"Model Context Protocol (MCP): Build MCP servers for GEE catalog search and land ownership lookup, enabling Gemini to autonomously discover datasets. Multi-modal Analysis: Add PDF permit parsing and drone imagery processing for comprehensive site assessments. Streaming Responses: Implement Server-Sent Events to show agent \"thinking\" in real-time. Predictive Modeling: Train custom ML models for energy yield forecasting based on historical weather patterns."},{"heading":"Built With","content":"flask gemini geojson google-earth-engine javascript lucide-react numpy python react restful-api tailwind-css"},{"heading":"Try it out","content":"github.com www.canva.com"}]},{"project_title":"MindPad","project_url":"https://devpost.com/software/mindpad","tagline":"Reignite the wonder of learning - one gesture at a time.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/950/110/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Overall Hack [Courtesy of Amplitude, Anthropic, OpenAI]"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Practical AI Innovation by Amazon"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Gemini API by MLH"}],"team_members":[],"built_with":[{"name":"ann","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"figma","url":null},{"name":"gemini-api","url":null},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"mediapipe","url":null},{"name":"openai-agent-sdk","url":null},{"name":"openai-api","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pyautogui","url":null},{"name":"pynput","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/krishgolcha/MindPad"}],"description_sections":[{"heading":"üåü Inspiration","content":"150 years ago, the smartest student in class was the one with the most knowledge. Today, it's the one who can ask the best questions. Yet, modern classrooms rely on static, disconnected tools - slides, whiteboards, and notes - that fail to capture the dynamic nature of human learning.\n\nStudents today juggle lecture slides, notes, videos, and AI tools across different tabs - a fragmented experience that slows real understanding. While LLMs and note-taking tools help, they rarely adapt to how each student actually learns. Many students struggle with passive, screen-based learning experiences - especially neurodiverse or physically limited learners. We wanted to design a tool that makes studying more accessible, tactile, and interactive, enabling learning through movement, speech, and visualization.\n\nWe built MindPad to reintroduce that magic - helping students think, speak, and learn like humans, not machines."},{"heading":"ü™Ñ What it does","content":"MindPad is an AI-powered study and exploration platform that helps students learn, revise, and understand course material through gestures, voice, and an intelligent interactive canvas.\n\nUsing advanced computer-vision and language-model technology, MindPad blends gesture recognition, voice interaction, and an AI-powered canvas into one seamless experience. MindPad lets students:\n\nInteract Hands-Free: Use real-time hand-gesture recognition (OpenCV + MediaPipe + custom ANN for detection + classification) to navigate slides, highlight key points, or sketch diagrams on the AI canvas without touching a device. Learn by Talking: Speak naturally to the OpenAI Agent SDK-based voice agent to ask questions, generate examples, or request diagrams and clarifications during study sessions. Understand Through Visualization: The intelligent canvas can automatically draw charts, concept maps, and summaries in real time from lecture transcripts or uploaded PDFs for more engaging learning experiences. Promote Kinesthetic Learning: Encourages active engagement by letting students interact physically with course content through gestures: proven to improve comprehension and memory retention. Enhance Accessibility: Designed with a touch-free interface for students with motor or mobility challenges, allowing voice-first and gesture-only navigation. Together, these tools turn passive reading into active multimodal learning."},{"heading":"‚öôÔ∏è How we built it","content":"Architecture Model: (in our gallery)\n\nLanguages: Python ‚àô HTML ‚àô CSS ‚àô TypeScript\n\nFrameworks and Tools: OpenCV ‚àô MediaPipe ‚àô PyAutoGUI ‚àô Pynput ‚àô OpenAI Agent SDK ‚àô Figma ‚àô Custom ANN\n\n1. Gesture Recognition and Classification\n\nWe built a real-time gesture detection and control pipeline using OpenCV and MediaPipe. Landmark Extraction: MediaPipe captures and tracks 21 hand landmarks per frame. Feature Engineering: We calculate pairwise distances and angles between key landmarks to generate gesture vectors. Classification Model: A custom Artificial Neural Network (ANN) trained on labeled gesture datasets classifies gestures (e.g., scroll, tap, annotate). System Control: Classified gestures are mapped to PyAutoGUI and Pynput actions, enabling users to perform mouse clicks, slide navigation, or drawing without touching a device. This pipeline runs in under 200ms latency and achieves 99% classification accuracy on test gestures.\n\n2. Voice Agent Integration\n\nTo make interaction natural and multimodal, we integrated a voice-driven AI assistant using the OpenAI Agent SDK. The agent performs tool-calling for real-time tasks: generating charts, summarizing concepts, or writing on the web-based canvas. Spoken queries are transcribed, processed, and passed through the OpenAI API. The agent determines whether to generate text, draw a figure, or retrieve lecture material, returning the result seamlessly to the user interface.\n\n3. Web-Based Intelligent Canvas\n\nThe core of MindPad‚Äôs user experience: supports gesture-based drawing, AI annotations, and voice-generated content. Students can ask the agent to \"draw a graph,\" \"summarize this chapter,\" or \"create a concept map,\" and the canvas updates dynamically. This layer connects all input modes - gesture, voice, and knowledge - into one synchronized workspace.\n\n4. Frontend and UI/UX Design\n\nWe used HTML/CSS/Figma to design an intuitive, distraction-free interface optimized for learning. Smooth animations and transitions ensure gesture and voice interactions feel organic. We implemented adjustable gesture sensitivity, high-contrast UI themes, and multimodal input support to ensure accessibility for users with different learning and mobility needs."},{"heading":"‚è≥ Challenges we ran into","content":"Synchronizing gesture recognition, voice commands, and AI input in real-time Designing smooth hand gesture thresholds for accuracy and comfort Integrating OpenAI Agents with web-based rendering and tool calls Managing latency across multimodal pipelines"},{"heading":"üèÜ Accomplishments that we're proud of","content":"Created an accessible, multimodal workspace that supports diverse learning styles - visual, auditory, and kinesthetic - making technology more human-centered. Built a functional gesture + voice + AI canvas system from scratch in under 36 hours Created a seamless interface for students to learn dynamically in a multimodal format Achieved high accuracy and responsiveness while maintaining a clean UX"},{"heading":"üí° What we learned","content":"Building MindPad taught us that true immersion happens when technology adapts to humans, not the other way around. Developing multimodal systems requires careful user-centric calibration, and we saw how even minor gesture differences make a world of a difference. We learned that accessibility and engagement go hand in hand, and that designing for kinesthetic and voice-based input not only improves inclusion but also enhances comprehension for all learners. When integrated right, multimodality helped us unlock creative, human-centered learning and improve focus and retention.\n\nOur biggest takeaway was that the future of education lies in adaptive, expressive learning interfaces that let students think beyond text."},{"heading":"üöÄ What's next for MindPad","content":"Integrate MindPad with learning platforms like Notion, Canvas, and Google Classroom for direct lecture import Add personalized learning insights for students via emotion and engagement tracking to detect confusion and tailor feedback Expand accessibility features such as customizable gesture ranges, AR sign-language recognition, and real-time captioning for a fully inclusive learning environment Support collaborative study sessions via shared multimodal canvases"},{"heading":"Built With","content":"ann css figma gemini-api html mediapipe openai-agent-sdk openai-api opencv pyautogui pynput python typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Watt's Up","project_url":"https://devpost.com/software/watt-s-up","tagline":"An AI-driven sustainability platform that transforms rooftops into renewable power insights: revealing untapped solar potential, energy savings, and carbon reduction opportunities in seconds.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/946/342/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Overall Hack [Courtesy of Amplitude, Anthropic, OpenAI]"}],"team_members":[],"built_with":[{"name":"dedalus-labs-sdk","url":null},{"name":"google-gemini","url":null},{"name":"google-maps","url":"https://devpost.com/software/built-with/google-maps"},{"name":"hugging-face","url":null},{"name":"nasa-power-api","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"segformer-b0","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"watts-up.tech","url":"https://watts-up.tech/"},{"label":"github.com","url":"https://github.com/deepanshgandhi/Watts-Up"}],"description_sections":[{"heading":"Inspiration","content":"We realized that most people genuinely want to adopt clean energy but they just don‚Äôt know where to start. The information gap between wanting solar and knowing if it‚Äôs worth it is surprisingly wide. Getting reliable estimates often means weeks of outreach, technical evaluations, and confusing data.\n\nAt the same time, satellite and irradiance data that could answer these questions already exist. They are just fragmented, technical, and inaccessible to the people who could use them most. That disconnect felt like both a technical challenge and a societal problem worth solving.\n\nSo we set out to build something simple but powerful: a tool where anyone, whether an individual, organization, or policymaker, can instantly see how much energy their roof could produce, how much they would save, and how much carbon they would offset, with no middlemen or guesswork.\n\nWatts Up was built with our belief that sustainability should be data driven, transparent, and easy to act on. If we can make people see rooftops not as static structures but as sources of untapped potential, we turn awareness into action."},{"heading":"What it does","content":"Watts Up is an AI-powered solar intelligence platform that transforms any rooftop into a personalized clean-energy report in seconds. You start by entering an address and outlining the area of the roof you want to analyze. Once you click ‚ÄúAnalyze Roof,‚Äù the platform uses satellite imagery, geospatial data, and AI-driven computer vision to evaluate how effectively that location can harness solar power.\n\nIn moments, Watts Up generates a detailed, interactive dashboard that shows:\n\nSolar Score : a performance rating indicating the site‚Äôs solar suitability. Energy Forecasts : estimated daily and annual generation based on NASA irradiance and climate data. System Insights : roof area, optimal panel configuration, and system capacity. Financial Outlook : installation cost, payback period, ROI, and long-term savings. Environmental Impact : projected carbon offset, CO‚ÇÇ reduction, and tree-equivalent contribution. Savings Mirror : upload your monthly electricity bill to instantly compare current utility expenses with projected solar costs and savings, featuring visual breakdowns of payback timelines and cumulative ROI. Energy Equtiy & Access Index : built into the platform's policy recommendation reports, this feature introduces the WattsUp Equity Score (0-100), which measures disparities in solar adoption across income, zoning, and race demographics using Census and building data. The index helps identify underserved neighborhoods and informs city councils or NGOs seeking to target grants, rebates, or community solar programs.\n\nThe experience feels immediate, visual, and data-driven: replacing lengthy consultations with intelligent, automated insight.\n\nWatts Up combines creativity in design, depth in functionality, and a clear social mission: making clean energy adoption simple, accessible, and measurable. It‚Äôs a step toward a future where anyone can understand their renewable potential with a single click."},{"heading":"How we built it","content":"We started by integrating the Google Maps API to allow users to input an address and draw their desired rooftop area directly on an interactive map. Once the region is defined, our backend pipeline processes it through a series of AI and data-driven stages.\n\nWe used NASA‚Äôs POWER API to gather solar irradiance, temperature, and climate data for the coordinates selected by the user. The imagery from Google Maps is then analyzed using SegFormer-B0 , a transformer-based model fine-tuned for rooftop segmentation. Through PyTorch and OpenCV , we calculate usable roof area, slope, and shading to estimate effective solar capture potential.\n\nThe system combines this information with performance and cost models to produce detailed metrics such as expected energy output, system size, cost savings, payback period, ROI, and CO‚ÇÇ offsets. To make the experience intelligent and conversational, we used Google Gemini 2.5 Flash and the Dedalus Labs SDK (Claude Sonnet 4 agents) to power dynamic insights, localized incentive discovery, and report generation.\n\nThe frontend was built with React 18 , TypeScript 5.8 , and Vite 5.4 , focusing on a clean, fluid interface that visualizes complex data with simplicity and elegance. Every design choice: from the color gradients to the live performance metrics was crafted to make sustainability feel modern, interactive, and approachable.\n\nWe collaborated across design, data, and engineering to ensure every part of the product worked cohesively. The final result is a fully functional prototype that seamlessly blends geospatial analytics, AI, and climate intelligence into one accessible experience."},{"heading":"Challenges we ran into","content":"Building Watts Up required merging several complex systems: geospatial mapping, AI vision models, and climate data; into one seamless workflow. That came with its share of challenges.\n\nOne of the biggest hurdles was aligning NASA irradiance data with map coordinates in real time. Small projection mismatches created large accuracy errors, so we had to carefully calibrate and normalize the datasets for consistent results.\n\nAnother challenge was optimizing the computer vision pipeline . Segmenting rooftops from satellite imagery sounds simple, but varying roof angles, shading, and vegetation made detection difficult. We had to fine-tune SegFormer-B0 and post-process its masks with OpenCV to reach the 95% confidence level shown in our reports.\n\nWe also faced performance bottlenecks when running inference and generating solar analytics on the fly. To solve this, we implemented caching and lightweight data pipelines to keep the experience interactive and responsive.\n\nDesigning the user interface was equally challenging: balancing technical precision with visual clarity. We wanted to present data like ROI and carbon offsets in a way that feels intuitive and motivating, not overwhelming.\n\nIntegrating every part under pressure was demanding, but it reinforced our commitment to building solutions that are both technically sound and meaningful."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud that Watts Up evolved from an idea into a fully functional solar intelligence system within a short time frame.\n\nEnd-to-end integration: Built a working pipeline that combines Google Maps, NASA irradiance data, and AI-based roof segmentation into real-time solar analytics. Functional precision: Achieved over 95% accuracy in roof boundary detection and energy potential estimation using our computer vision pipeline. Interactive experience: Designed a clean, map-based interface that lets users draw, analyze, and visualize their rooftop potential in seconds. Scalable foundation: Structured the system so it can expand from single rooftops to city-wide or enterprise-scale energy mapping. Impact-driven design: Created a tool that not only demonstrates technical capability but also drives awareness and accessibility in renewable energy adoption, incorporating the idea of the Energy Equity & Access Index.\n\nThe most rewarding outcome was seeing the system deliver reliable, data-backed results that could realistically guide clean energy decisions."},{"heading":"What we learned","content":"Building Watts Up taught us how to bridge data science, geospatial analysis, and AI into a cohesive, real-world application.\n\nWe learned how to process and align datasets from different coordinate systems, how to fine-tune a transformer-based vision model for variable image quality, and how to optimize inference speed for real-time interactivity. Integrating APIs from Google Maps and NASA POWER required handling data normalization, unit conversion, and latency challenges that pushed us to think beyond standard pipelines.\n\nWe also gained a deeper understanding of the energy modeling side: translating irradiance and temperature data into practical metrics like kWh output, ROI, and carbon savings.\n\nOn a broader level, we learned that sustainability tech requires both technical precision and accessibility. Data alone isn‚Äôt enough; how it‚Äôs presented determines whether people act on it. That insight guided every design and engineering decision we made."},{"heading":"What's next for Watt's Up","content":"Watts Up began as a hackathon project, but it quickly became something we can‚Äôt stop thinking about. In just a few hours, we proved that AI and geospatial data can turn complex solar modeling into an experience anyone can use and now we want to take it further.\n\nWe plan to keep developing Watts Up into a full-scale platform that supports real-world deployment and impact. Our next steps include:\n\nExpanding data coverage: integrating higher-resolution satellite imagery and more detailed irradiance datasets. City-scale mapping: building dashboards that let municipalities and utilities identify high-impact renewable zones. API access: creating endpoints for energy companies, real-estate platforms, and sustainability startups to use our analytics. Financial integration: adding cost calculators, rebate information, and ROI projections tailored to region and policy. Mobile-first design: launching an app that makes solar analysis instant, accessible, and portable. Partnerships for impact: collaborating with environmental organizations and local governments to use Watts Up for policy planning and awareness campaigns.\n\nEven though it started at a hackathon, we‚Äôre excited to keep building, testing, and scaling it; because the potential for clean energy shouldn‚Äôt end when the event does."},{"heading":"Built With","content":"dedalus-labs-sdk google-gemini google-maps hugging-face nasa-power-api numpy opencv python pytorch react segformer-b0 typescript vite"},{"heading":"Try it out","content":"watts-up.tech github.com"}]},{"project_title":"Synovia","project_url":"https://devpost.com/software/presurg","tagline":"See surgical outcomes before the first incision.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/956/247/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Healthcare Hack [Courtesy of Daylight Health]"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"fastapi","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/arishs24/HackPrinceton2025"},{"label":"synovia.tech","url":"https://synovia.tech/"}],"description_sections":[{"heading":"Inspiration","content":"Neurosurgeons remove 500,000 brain tumors per year and 20% of surgeries have unexpected complications because surgeons can't predict tissue behavior. Traditional pre-operative mapping takes hours and only shows current function - not what happens when tissue is removed. We asked: \"What if AI could predict surgical consequences in real-time?\""},{"heading":"What it does","content":"Synovia predicts neurological consequences of brain tissue removal in under a 10 seconds using AI.\n\nInput: Brain region, coordinates, volume to remove, patient age Output: Predicted deficits (motor, language, cognitive), recovery timeline, surgical approach recommendations, risk probabilities\n\nNeurosurgeons can test multiple \"what if\" scenarios instantly before making the first incision - like a flight simulator for brain surgery.\n\nML & Simulation Backend (FastAPI + Python):\n\nPhysics-driven FEA Engine: Implemented finite element analysis (FEA) to simulate stress propagation, strain tensors, and displacement fields in cortical regions following virtual resections.\n\nMaterial Modeling: Incorporated viscoelastic tissue parameters and nonlinear elasticity constants from neurophysiology literature to ensure biomechanical realism.\n\nGemini 2.0 Integration: Leveraged Google Gemini‚Äôs multimodal reasoning for real-time neurological interpretation‚Äîmapping FEA-derived stress fields to potential post-surgical deficits and recovery profiles.\n\nMulti-stage ML Pipeline: Combined voxel-wise CNN-based segmentation (for 2D‚Üí3D reconstruction) with physics-informed neural networks (PINNs) for mechanical field prediction.\n\nNormalized Coordinate Framework: Designed a spatial reference system aligning MRI voxel space with Talairach coordinates for precise lesion and FEA localization.\n\nData Validation & Schema Design: Built Pydantic-based integrity checks for volumetric and biomechanical inputs, ensuring stable end-to-end model serving.\n\nAPI Orchestration: FastAPI routes for /upload, /segment, /simulate, and /fea endpoints handle DICOM ingestion, NIfTI processing, and mesh export pipelines.\n\nüß© 3D Visualization Frontend (Next.js + Three.js):\n\nInteractive Brain Reconstruction: Converted segmented 3D meshes (.STL) into dynamically rendered Three.js geometries, enabling surgical region selection and deformation visualization in real-time.\n\nPhysics-Aware Rendering: Integrated vertex color gradients mapped to stress tensor magnitudes and principal strain vectors for intuitive biomechanical insight.\n\nCoordinate Mapping Engine: Real-time projection of simulation coordinates onto the anatomical mesh‚Äîsynchronizing physics outputs with interactive model state.\n\nWebSocket-Driven Feedback Loop: Enabled continuous updates from FEA solver to front-end for real-time visualization of stress redistribution during virtual resection.\n\nShader-Enhanced Display: Custom GLSL shaders for material translucency, lighting realism, and cortical depth cues to better illustrate internal deformation patterns.\n\nEnd-to-End Integration: Seamless pipeline from 2D MRI upload ‚Üí 3D reconstruction ‚Üí physics-based FEA ‚Üí Gemini-powered interpretation‚Äîall accessible through a single web interface."},{"heading":"Challenges we ran into","content":"Some of the challenges we ran to included finding a problem space we all cared for and a solution we wanted to build out, and merging some of our features to make sure they were compatible and connected."},{"heading":"Accomplishments that we're proud of","content":"Physics-driven modeling: Integrated real-world biomechanical physics into our simulations to accurately predict post-surgical brain stress and deformation. Our FEA-based engine mimics true tissue responses, not just visual approximations.\n\n2D MRI ‚Üí 3D Brain Reconstruction: Built a full physics and ML-powered segmentation pipeline that converts 2D MRI slices into anatomically precise 3D models‚Äîenabling dynamic visualization and region-specific stress mapping.\n\nML-powered intelligence: Leveraged Gemini‚Äôs large-scale reasoning and fine-tuned ML inference to interpret 3D outputs, identify high-risk neural zones, and generate explainable insights for neurosurgical planning.\n\nML: Trained reasoning using Gemini API to do analysis.\n\nSeamless integration: Built a complete end-to-end pipeline from 3D brain visualization to AI-powered predictions."},{"heading":"What we learned","content":"We learned about the importance about persistence and gained more knowledge about how to convert 2D scans to 3D models."},{"heading":"What's next for Synovia","content":"Patient-specific MRI upload and automated brain segmentation Historical outcome database - train on real neurosurgical cases Multi-region scenarios - predict combined resection impacts Voice-guided planning with ElevenLabs for hands-free operation during surgery"},{"heading":"Built With","content":"css fastapi gemini html python typescript"},{"heading":"Try it out","content":"github.com synovia.tech"}]},{"project_title":"Jigsaw: Make your PCB boards click together","project_url":"https://devpost.com/software/jigsaw-make-your-pcb-board-click","tagline":"Jigsaw compresses days of part hunting and spec-checking into minutes, without removing humans from the loop. This tool is perfect for professionals and hobbyists to speed up PCB development.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/947/238/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Business + Enterprise Hack [Courtesy of Orcava AI, Eragon AI]"}],"team_members":[],"built_with":[{"name":"dedalus","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"jigsaw-five.vercel.app","url":"https://jigsaw-five.vercel.app/"},{"label":"www.figma.com","url":"https://www.figma.com/slides/94eWyD99wBcK8kr5nobDi2/Jigsaw?node-id=4-639&t=PplOcCx70slVACQC-1"},{"label":"github.com","url":"https://github.com/charlespers/Jigsaw"}],"description_sections":[{"heading":"Inspiration","content":"At Princeton, all of our hardware friends have the same complaint: the hardest part of PCB design is finding for compatible parts and buying them before they go out of stock.\n\nCharles, one of our team members, is on Princeton Electric Speedboating. He spends over two months making PCBs for the boat, most of it clicking through Digi-Key and Octopart, reading 50+ page datasheets, and rebuilding material lists when parts conflict or go out of stock. Our friend Charlie from the Robotics Club maintains a ‚Äúspreadsheet of doom‚Äù in Google Sheets just to track which component works with what.\n\nWe hate listening to them complain, so we built Jigsaw to solve this problem"},{"heading":"What it does","content":"Jigsaw is a compatibility tool for PCB design. You describe your board in plain language ‚Äì\n\n‚ÄúMake me a temperature and humidity sensor with WiFi and Bluetooth powered by USB-C (5V) for consumer use.‚Äù\n\nJigsaw:\n\nAnalyzes requirements and identifies key components hierarchically (MCU/SoC ‚Üí power ‚Üí radios ‚Üí sensors) Searches suppliers for optimal parts based on specs, pricing, availability, and footprint support Validates compatibility across the whole stack ‚Äì voltages, interfaces, pin counts, packages\n\nInstead of comparing hundreds of options, you just sanity-check a short list of datasheets we recommend."},{"heading":"How we built it","content":"Compatibility engine We represent each component with an AI agent to decide the hierarchical plan. In other words, we want to find compatibility starting with the most restrictive components. We use the Dedalus MCP service to orchestrate tools for supplier search, spec lookup, and part list reconciliation. The compatibility engine then builds a small ‚Äúcomponent graph‚Äù and checks this information against each other.\n\nBackend: Flask Frontend: React + Typescript SPA"},{"heading":"Challenges we ran into","content":"Getting ‚Äúreal engineer‚Äù workflows right. We had to talk to 11 ece majors and strip away our naive version of ‚ÄúAI designs the whole PCB.‚Äù Real EEs want help with compatibility and not a magical black box schematic that they don‚Äôt trust.\n\nIt‚Äôs easy for an LLM to claim two parts are compatible when they‚Äôre not. We had to force agents to ground every decision in actual spec fields (voltage ranges, interfaces, packages) and only then let the model narrate the reasoning.\n\nWe wanted users to see the AI think out loud. Getting Server-Sent Events stable, handling pauses for clarifying questions, and resuming analysis with the right state was trickier than expected."},{"heading":"Accomplishments that we're proud of","content":"For our demo, we sent it over to a few friends and they double checked that our results were legit.\n\nWe actually fill the gap between CAD and search. Our demo shows Jigsaw sitting between KiCad/Altium-style tools and Digi-Key/Octopart-style search ‚Äì a layer that doesn‚Äôt exist today. You can watch the reasoning stream as it explains why each component is chosen and what the alternatives are, instead of getting a mysterious list of part numbers."},{"heading":"What we learned","content":"Fancy agents don‚Äôt matter unless every step is tied to real data. We learned to design prompts and tools so the model can‚Äôt just guess. Also picking a super niche problem for a hackathon was hard bc we wanted to do user interviews but the people we wanted to talk to weren't up at 3am."},{"heading":"What's next for us","content":"We emailed a few ECE professors at Princeton over the weekend so we are excited to hear their thoughts and talk to them more about our ideas. Also, after to talking to over 11 Electrical and computer engineering students and grad students at Princeton, we our excited to send them the site so they can test it out for themselves!"},{"heading":"Built With","content":"dedalus flask react"},{"heading":"Try it out","content":"jigsaw-five.vercel.app www.figma.com github.com"}]},{"project_title":"Lume - Your tech-savvy guide.","project_url":"https://devpost.com/software/lume-zrlypk","tagline":"A voice-activated, on-screen tutor that shows seniors exactly where to click with highlights, simple steps, and natural speech.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/955/836/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Education + Entertainment Track"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of ElevenLabs by MLH"}],"team_members":[],"built_with":[{"name":"chromeextension","url":null},{"name":"claude","url":null},{"name":"css3","url":"https://devpost.com/software/built-with/css3"},{"name":"dedaluslabs","url":null},{"name":"dom","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"flask-cors","url":null},{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"json","url":"https://devpost.com/software/built-with/json"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"whisper","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/parker-rho/lume/"},{"label":"docs.google.com","url":"https://docs.google.com/presentation/d/1NXArtw0Tl35p9bWDRRm6lS37j5w3qGfq/edit?usp=sharing&ouid=100649767292587076920&rtpof=true&sd=true"}],"description_sections":[{"heading":"Inspiration","content":"We‚Äôve all been there: helping a parent or grandparent unmute on Zoom, find the ‚ÄúShare Screen‚Äù button, or open an email attachment. Small tech tasks that take seconds for us can feel impossible for older adults, creating frustration and dependence. We wanted to change that. Lume was born from the idea of a patient, tech-savvy helper--like a grandkid who‚Äôs always available--that can listen, see, and guide seniors through technology with confidence."},{"heading":"What it does","content":"Lume is a voice-activated, on-screen tutor that shows seniors exactly where to click. It listens to natural questions (‚ÄúHow do I join a Zoom meeting?‚Äù), uses AI to understand what‚Äôs on their screen, and then visually highlights the correct buttons step by step--while speaking instructions aloud."},{"heading":"How we built it","content":"Lume runs on a multi-agent architecture that connects speech, perception, and visual guidance through an intelligent feedback loop.\n\nVoice Input & Transcription The user speaks naturally (‚ÄúHow do I join a Zoom meeting?‚Äù). We use OpenAI‚Äôs Whisper/Wispr model to transcribe audio into text in real time. Perception Layer (Screen Understanding) A custom HTML annotator parses the webpage‚Äôs DOM and converts it into a structured JSON representation of all visible elements ‚Äî buttons, labels, and text. This data, along with the user‚Äôs transcribed request, is passed into our Dedalus Labs MCP server, which acts as the orchestrator between all agents. Agent 1: Planner Using Claude Sonnet 4, this agent interprets the user‚Äôs intent and generates a JSON plan of sequential steps with interactive elements (e.g., ‚ÄúLocate Login ‚Üí Enter Email ‚Üí Click Join‚Äù). Agent 2: Visual Executor Another Claude Sonnet 4 agent identifies the exact on-screen elements matching each step and triggers dynamic highlights around the correct buttons, allowing users to follow along visually. Step Output & Voice Guidance Each step is read aloud via ElevenLabs Text-to-Speech, providing calm, human-like spoken instructions while the interface highlights the next clickable area. Event Listener & Feedback Loop Lume continuously monitors the screen--when a highlighted element is actioned upon (ie. clicked, typing, etc.), it moves to the next instruction until the full workflow (like logging in or joining a call) is completed."},{"heading":"Challenges we ran into","content":"Designing the agent architecture and deciding how each agent feeds into the next Getting prompt engineering right to produce clear, natural steps tied to interactive elements Syncing real-time visual highlights with spoken instructions Keeping latency low across multiple model calls and screen updates"},{"heading":"Accomplishments that we're proud of","content":"Built a functional multi-agent system with real-time interaction Engineered agents that coordinate smoothly across inputs Applied serious prompt engineering for clear, natural steps Made it flexible enough to work on any website Designed an interface easy for even non-tech-savvy users"},{"heading":"What we learned","content":"Accessibility is emotional--confidence and reassurance matter as much as usability Prompt engineering is as much design as it is logic Real-time coordination between vision, voice, and interaction takes precise orchestration"},{"heading":"What's next for Lume - Your tech-savvy guide.","content":"Expand beyond browsers to desktop apps and smart displays Continue refining accessibility features: clearer voices, simplified visuals, personalized pacing. Add multi-language voice support so seniors can get guidance in their native language"},{"heading":"Built With","content":"chromeextension claude css3 dedaluslabs dom flask flask-cors html5 javascript json openai python whisper"},{"heading":"Try it out","content":"github.com docs.google.com"}]},{"project_title":"FoodBridge","project_url":"https://devpost.com/software/foodbridge-ac6nei","tagline":"Restaurants dump billions in food while shelters starve. FoodBridge fixes this by turning waste into instant tax rewards while feeding communities. Good for people. Good for profit.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/956/126/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Rookie Hack"}],"team_members":[],"built_with":[{"name":"java","url":"https://devpost.com/software/built-with/java"},{"name":"nextjs","url":null},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"www.foodbridge.me","url":"http://www.foodbridge.me"},{"label":"github.com","url":"https://github.com/kyaw-nyc/foodbridge"}],"description_sections":[{"heading":"Inspiration","content":"One night my dad came home from his factory job, exhausted, and said something that has stayed with me ever since:\n\n\"Every single day at the factory, we waste around 200 perfectly good donuts. Great food just thrown in the trash.\"\n\nI could not stop thinking about those donuts, all that food going straight into the garbage while people just a few miles away were going to sleep hungry. My dad still works there today, and now that our team has the skills to actually build things, it feels wrong not to try and do something. That is where FoodBridge comes from: a platform built to make sure no good food is wasted while people are still going without meals.\n\nFoodBridge is meant to be simple, practical, and hard to say no to: businesses save money through tax deductions for excess food donations, helping solve hunger; it's a win-win situation for everyone."},{"heading":"What it does","content":"Restaurants and food businesses throw away huge amounts of perfectly edible food every day, while shelters and community kitchens struggle to meet demand. There is no simple, real time way for them to find each other at the exact right moment.\n\nFoodBridge fixes that, and turns that \"waste\" into tax savings and impact.\n\nAt a high level, FoodBridge:\n\nConnects restaurants with nearby shelters and food banks in real time Helps restaurants unlock impressive tax deductions for eligible food donations Helps restaurants with their outreach and community building, and the best part is it saves them even more money\n\nFor restaurants, FoodBridge:\n\nLets you list surplus food in seconds at the end of a shift Shows a map of nearby shelters and food banks, ranked by urgency of need Lets you schedule a pickup or drop off with a few clicks Automatically generates donation receipts and records that can be used as documentation for potential tax deductions in consultation with a tax professional Summarizes your impact over time, for CSR reports, marketing, and brand goodwill\n\nFor shelters and food banks, FoodBridge:\n\nShows a live map of nearby surplus offers Lets staff set daily food needs, which we turn into an easy-to-read \"health bar\" that signals urgency Provides a simple way to claim donations and message restaurants to coordinate logistics\n\nIn short:\n\nRestaurants dump billions of dollars worth of food while shelters starve. FoodBridge turns that waste into instant tax documentation and real meals for communities. Great for the community, great for businesses."},{"heading":"How we built it","content":"Lots of celsius and snacks and claude and codex + cursor + a lot of brain power. On the serious note tho, we started by mapping the flow of food: where surplus is created, when shelters need it most, and what information both sides actually care about.\n\nFrom there, we built:\n\nA restaurant dashboard where businesses can log in, list surplus items, see nearby shelters, and schedule donations A shelter dashboard where organizations can set their daily food needs, see offers on a map, and claim or request donations A matching engine that connects surplus food with nearby shelters based on location, timing, and need A built-in messaging system so restaurants and shelters can coordinate without leaving the platform An email layer that sends donation confirmations and records to restaurants through the Gmail API\n\nBehind the scenes, we experimented with predictive logic to estimate shelter demand and help highlight high priority donations.\n\nThe stack was powered by a lot of Celsius, snacks, and late nights, with tools like Claude, Codex, Cursor, and a Figma MCP server helping us go from design to code much faster."},{"heading":"Challenges we ran into","content":"1. Predictive analysis\n\nDesigning a useful \"need score\" for shelters was much harder than it sounded. We had to think about:\n\nTime of day Typical peak demand How to deal with missing or noisy data\n\nWe wanted a system that felt intuitive, not random, so tuning that logic took time.\n\n2. Gmail API integration\n\nImplementing the Gmail API was rough. OAuth, scopes, and formatting emails correctly without breaking everything took a lot of debugging. Getting automated confirmation emails to reliably send right after a donation was a big learning experience."},{"heading":"Accomplishments that we are proud of","content":"We actually shipped a full stack app, not just a slide deck Restaurants can log in, list surplus food, and see nearby shelters on a map Shelters can set their food needs and claim donations Messaging works, so both sides can coordinate directly inside the platform Most importantly, restaurants receive automated donation confirmations that give them a clear record of what was donated, to whom, and when\n\nWe are especially proud that FoodBridge makes the tax side simple and automatic for busy restaurant owners. Instead of juggling spreadsheets and emails, they get a clean, centralized history of their donations that can support tax preparation and CSR storytelling."},{"heading":"What we learned","content":"We learned:\n\nHow to work with real APIs, including authentication, rate limits, and messy JSON How to go from Figma designs to a working product, keeping design and implementation in sync How many real world constraints shelters and restaurants face, and how important it is to keep the user experience extremely simple\n\nWe also learned that building \"tech for good\" means thinking like an operator: if it does not save time or money for the restaurant, they will not use it, even if the mission is noble. That is why the tax benefit and documentation flow is front and center."},{"heading":"What is next for FoodBridge","content":"We do not want this to stay as just a hackathon project.\n\nWe plan to run a demo pilot program in New York City during winter break, and where food waste and food insecurity are both visible and urgent.\n\nWe already own the domain: foodbridge.me\n\nOur next steps:\n\nPartner with a small group of local restaurants and one or two shelters to run a focused pilot Tighten the matching and notification system so it fits into daily closing routines, not extra work Improve impact and tax reporting, so restaurant owners can literally see: How many meals they helped provide The total estimated value of donated food Downloadable records they can share with accountants and marketing teams\n\nFoodBridge started with 200 wasted donuts. Our goal is that one day, stories like that feel impossible, because there will always be a bridge between surplus food and the people who need it most, and a clear financial reason for businesses to help.\n\nAlso checkout our Tax doc: https://drive.google.com/file/d/1K9O1U38-kf5RImyC-3LoWRUYuJok7GME/view?usp=sharing"},{"heading":"Built With","content":"java nextjs tailwind typescript"},{"heading":"Try it out","content":"www.foodbridge.me github.com"}]},{"project_title":"Interactive DAW","project_url":"https://devpost.com/software/interactive-daw","tagline":"Interactive DAW using webcam and ultrasonic sensor. One hand selects instruments and triggers quantized hits. The other controls pitch. Always on loop, and a clear HUD. Portable on any laptop.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/955/621/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Hardware Hack"}],"team_members":[],"built_with":[{"name":"loop-midi","url":null},{"name":"mediapipe-hands","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"raspberry-pi","url":"https://devpost.com/software/built-with/raspberry-pi"},{"name":"reaper","url":null},{"name":"ultrasonic-sensor","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/sprkds/InteractiveDAW"}],"description_sections":[{"heading":"Inspiration","content":"We came in knowing we wanted to do a hardware project, and when looking at the available hardware, we found an ultrasonic distance sensor and the first thing that came to mind was a theremin . A musical instrument designed to change pitch and play notes via hand gestures. So then we discussed and came to an idea of making digital audio workstations (DAWs) more interactive by making it possible to choose instruments, record, and play them all with just your hands, one tapping beats the other controlling pitch something not that far from the theremin inspiration."},{"heading":"What it does","content":"Interactive DAW lets you make music with two hands using only a webcam, laptop and our distance sensor pi setup. The camera hand selects instruments with different hand gestures, triggers quantized hits with a pinch, and a fist changes modes between [‚ÄúInstrument Select‚Äù, ‚ÄúPlay Mode‚Äù] and a special gesture in play mode allows for recording and playback to the DAW directly. The pitch hand controls note pitch by distance; hold it at a certain distance, then pinch with the camera hand to produce the corresponding frequency and hold for note length."},{"heading":"How we built it","content":"Software:\n\nLaptop_Node: OpenCV + MediaPipe Hands with a small state machine - instrument select ‚Üí play ‚Üí recording. Gestures: finger count to choose instrument, pinch to trigger/hold, fist to state transition. A simple HUD provides user feedback. Events are timestamped and sent to the DAW via a MIDI adapter. We used Reaper as our base DAW, and used loopMIDI a software to create MIDI ports in combination with Reaper‚Äôs ‚ÄúActions‚Äù feature to send MIDI notes to the port or actions and have Reaper be able to respond with recording, play back, instrument select, etc.\n\nPi_Node: We just used pigpiod to listen for the sensor measurements and convert them into actual numbers. There were some other complications, we made sure to try to filter implausible values and reduce noise as much as we can and make sure we correctly define hits from the hand. As for sending the distance measurements from the pi_node to the laptop_node we used routeOSC which we were able to do since we had an ethernet connection from the pi to the laptop and just set up an OSC port for one to listen to and the other to send to.\n\nHardware: An ultrasonic sensor runs on a Raspberry Pi with a voltage divider on ECHO to 3.3 V and common ground. Readings are smoothed and mapped to pitch, and this module plugs into the software path without messing with the camera. There's also the Brio webcam connected to the laptop for the time being, it would have been nice to have webcam on the pi_node but figuring out how to send that much data in the time that we add + only an 8gb sd card for the pi made it hard for us to figure that out."},{"heading":"Challenges we ran into","content":"1. Raspberry Pi setup ate time A couple of flaky card readers plus a stubborn micro SD made flashing and booting Pi OS painful. We had to go out and buy our own SD card reader. Swapping readers/cards a couple of times, and starting fresh fixed it for us, but it cost us a lot of time. Additionally figuring out a way to get into the pi while headless and without an easy way to ssh in made it difficult. We ended up being lucky enough to find an ethernet cord and after flashing the pi with Pi OS we were able to get in pretty easily.\n\n2. Ultrasonic noise and power problem Our second biggest hardware problem was probably figuring out how to fix the power problems between our Raspberry Pi and our ultrasonic sensor. Basically one of the pins outputs 5V but Pi gpio pins take in 3.3v. So we had to look around at the bottom of the misc. Hardware to find any amount of resistors that would give us a ‚Öî ratio to split the voltage. We ended up being incredibly lucky and found 3 1k ohm resistors that we used to divide the ECHO pin voltage down to 3.3V from 5V for the pi. Additionally we also had some noise issues in the beginning with the sensor but we were able to figure it out.\n\n3. Camera hand gesture state machine There was a lot of tuning and messing around with the opencv hand rig model to get different gestures to correspond to different states with our FSM. We ended up writing out our state machine as one defined gesture (a fist) allowing for transition between modes, and then in each mode there were some gestures that would be different actions like one finger down represented a trumpet, etc.\n\n4. Audio felt laggy Initial playback/recording felt sluggish. We removed a couple delays that were affecting this and it was slightly better but there's still a little bit of delay that seems inevitable.\n\n5. Integration We knew from the start this would be the most challenging portion of this hackathon for us, with trying to find a way to get everything to connect nicely without too much lag or anything breaking. We tackled this by creating a pretty indepth map / plan on how everything was going to connect between the ultrasonic sensor, camera, the main controller, and the daw. We found ways to send information (OSC, loopMIDI), moved components around that would be able to send data faster (camera to laptop instead of on pi) to optimize, and we thoroughly discussed the gesture state machine. We did get pretty lucky sometimes with some integrations or data transfer systems working almost perfectly on the first try, but figuring it all out and actually implementing it took a lol of work."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud that: we were able to incorporate hardware knowledge we previously learned in an actionable way, we were able to adapt to many challenges we faced both in hardware and software, we got to work with computer vision and have it work well for us, and last but not least that we were able to create not only a challenging project for us but one that remained incredibly fun to work on together incorporating music and technology!"},{"heading":"What we learned","content":"We learned a lot about how ports work whether it be for the OSC or loopMIDI port system we had for transferring data, more than we probably need to know about how Reaper DAW works, and about how to actually implement a custom voltage divider in a real system and not just learn it from a lecture or ideal lab. We got to work with libraries we hadn‚Äôt necessarily got to before, like the Open CV for hand stuff and got to slowly implement stuff one connection at a time to make sure nothing would just collapse on us."},{"heading":"What's next for Interactive DAW","content":"There's definitely a lot that could be added to this. More instrument states being the first. We only had time to implement 4 states and only give some basic, but the most helpful, control to the user. However, more control can be given to the user, like mute/clear/undo, volume control, reverb/slow. We could definitely look into some cleanup in code, hardware, and gui and make some quality of life improvements for the system. Ideally being able to set this system up separate from a laptop and integrate with any DAW pretty easily is a huge goal. There's also plenty more potential to make this more than just hand controlled, being able to make music with dances or body movements is definitely a future possibility for this system."},{"heading":"Built With","content":"loop-midi mediapipe-hands opencv python raspberry-pi reaper ultrasonic-sensor"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Cropit","project_url":"https://devpost.com/software/cropit","tagline":"Cropit empowers farmers to future-proof their land while growing profits by using AI to guide decisions instantly revealing the impact of every choice.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/953/750/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Practical AI Innovation by Amazon"}],"team_members":[],"built_with":[{"name":"amazon","url":"https://devpost.com/software/built-with/amazon"},{"name":"capital-one","url":"https://devpost.com/software/built-with/capital-one"},{"name":"dedalus","url":null},{"name":"elevenlabs","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"knot","url":null},{"name":"next.js","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwind.css","url":null},{"name":"usda-national-farmers-market-directory","url":"https://devpost.com/software/built-with/usda-national-farmers-market-directory"},{"name":"usda-soil-data-access","url":"https://devpost.com/software/built-with/usda-soil-data-access"}],"external_links":[{"label":"cropit.tech","url":"https://cropit.tech/"},{"label":"github.com","url":"https://github.com/swetha-ganeshbabu/crop"}],"description_sections":[{"heading":"üå± Inspiration","content":"Our journey started with a love for food, climate action, and the powerful stories of Gabe Brown, Russell Hedrick, and real working farms. Watching Nature's Balance: The Art of Regenerative Farming and Chef‚Äôs Table, we saw firsthand that regenerative agriculture is not only possible, it‚Äôs the future economically and ecologically.\n\nFor years, climate targets have fallen short often because ‚Äúsustainability‚Äù felt like a cost, not an opportunity. Cropit is built to flip that script by showing how regenerative agriculture can be a profitable path for farms and food businesses.\n\nWhat really grabbed us:\n\nGabe Brown‚Äôs 6 Principles context, least disturbance, soil armor, diversity, living root, animal integration‚Äîare real-world wisdom, not just theory. Russell Hedrick‚Äôs data: over \\$62,000 saved in a year with numbers to prove it, not just hope! The relentless challenge of monocropping in the US: most row crop farms plant just 2‚Äì3 crops, nowhere near the diversity that regenerative science recommends. Our team‚Äôs foodie spirit: believing every great meal starts with soil health, and every farmer deserves recognition (and reward!)."},{"heading":"ü§ñ What It Does","content":"Cropit is your farm‚Äôs collaborative dashboard and ‚Äúhelping hand‚Äù for all things regenerative. Here‚Äôs the magic:\n\nIntegrates real-world data (USDA, OpenWeather, live web scraping via Gemini API, satellite sources) to power actionable farm analytics. Tracks profit, diversity, and resilience for every field. See the ‚ÄúEco-Wallet‚Äù: money saved, risks avoided, new revenue streams (like carbon credits). Gives proactive insights how to boost soil health, manage crop rotations, and prepare for weather or market changes. Visualizes advanced metrics: Fungal:Bacterial Ratio, real-time Brix (sap) readings, crop rotation diversity, water-holding capacity, and more. Not just a dashboard. Cropit is a digital partner, helping you make informed, profitable, sustainable choices, not just handing down ‚Äúadvice.‚Äù"},{"heading":"üõ†Ô∏è How We Built It","content":"Stack: Next.js, Python, Gemini API (web scraping/insights), ElevenLabs (audio alerts), OpenWeather, USDA agricultural data, Amazon Nova (contextual AI insights), Knot (transaction analytics), Capital One API (financial tools). UI/UX: Crafted with (lots of!) Figma iterations, prioritizing clarity for high-stakes decisions and making data approachable. Data scraping: Leveraged Gemini‚Äôs API to routinely pull fresh web/crop/soil/weather data, keeping insights grounded in what's happening on the ground right now. Analytics: Developed ‚ÄúEco-Wallet‚Äù cost models, leveraging real farm data running calculations like: $$ \\text{Water Infiltration Rate} = \\frac{\\text{Total Rain}}{\\text{Time}} $$ Voice & contextual insights: ElevenLabs reads out key alerts and recommendations so farmers can keep their hands free. Amazon Nova automates deep-dive research, surfacing actionable advice from a world of ag, climate, and science reports. Financials & transactions: Knot's API tracks crucial farm and supply-chain transactions, while Capital One's API enables in-dashboard loan offers and financial benchmarking, helping farms easily discover, plan, and finance regenerative upgrades.\n\nAll this comes together in Cropit‚Äôs dashboard making sense of a lot of moving pieces for a clear, rewarding, and enjoyable user experience."},{"heading":"üöß Challenges We Ran Into","content":"API integration: Combining many data streams (USDA, weather, web scraping) presented tons of hurdles‚Äîrate limits, inconsistent data schemas, and lots of ‚Äúwhy won‚Äôt this connect?‚Äù moments. Data overload: Modern farming generates mountains of data. Our toughest task was making this simple and actionable for real decisions. Too much info? It paralyzes. Not enough? It misguides. Communicating complexity: Regenerative ag is science + creativity. Making advanced analytics enjoyable and not overwhelming was a constant balance. Climate variability: Farming data is at the mercy of the weather global warming brings chaos. We had to design not for ‚Äúaverage‚Äù but for the wild, unpredictable future."},{"heading":"üèÖ Accomplishments That We‚Äôre Proud Of","content":"Live dashboard: Working, demo-ready, and totally flexible ready to plug in any farmer‚Äôs data. Dynamic \"Eco-Wallet\": Every cost-saving, every new revenue source, visible at a glance. Multi-source data blending: USDA, web, weather unified for actionable insights. Designed with empathy: Not ‚Äúdictating‚Äù to farmers, but listening to the real-world constraints that fields, markets, and nature impose."},{"heading":"üìö What We Learned","content":"Diversity is rare but essential. US farms average just 2.1 crops per rotation our dashboard makes expanding that not just a goal, but a reward. Profit isn‚Äôt yield alone. Sometimes less is more: like Russell Hedrick found, spending \\$108 for a \\$36 gain isn‚Äôt smart business. Let data serve, not rule, the user. Our goal shifted from ‚Äúmore data‚Äù to ‚Äúright insights, right moment.‚Äù Collaboration beats command. Farmers are experts tech should be a partner, not a boss."},{"heading":"üîÆ What‚Äôs Next for Cropit","content":"Deeper weather/soil mapping powered by AI agents predict droughts, pest threats, and yield well in advance. More cross-platform features: text or voice insight feeds, simple export to accounting or supply chain platforms. Expand Cropit as a ‚Äúregenerative social network‚Äù for sharing across farms, researchers, and chefs. Continue blending passion for great food, resilient ecosystems, and real farmer prosperity‚Äî the operating system for the agricultural revolution .\n\nThanks to our community of visionary growers, leaders, innovators, and everyday people. Cropit is built for everyone‚Äîfrom farmers to business leaders‚Äîby technologists who believe the smartest future is regenerative, profitable, and shared."},{"heading":"Built With","content":"amazon capital-one dedalus elevenlabs gemini knot next.js react tailwind.css usda-national-farmers-market-directory usda-soil-data-access"},{"heading":"Try it out","content":"cropit.tech github.com"}]},{"project_title":"ViralWave.ai","project_url":"https://devpost.com/software/viralwave-ai","tagline":"AI workflows for creator economy ‚Äî transforming trending insights into lyrics, beats, and videos in minutes","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/955/527/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Practical AI Innovation by Amazon"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Most Impactful Use of the X API by X"}],"team_members":[],"built_with":[{"name":"amazonnova","url":null},{"name":"dedalus","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"grokai","url":null},{"name":"next.js","url":null},{"name":"nova","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"suno","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"x","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/rajashekarcs2023/hack-princeton"},{"label":"x.com","url":"https://x.com/rajashekarphy/status/1987534061749895600?s=20"}],"description_sections":[{"heading":"Inspiration","content":"We watched talented creators burn out from the same exhausting cycle: spending 6-12 hours scrolling through TikTok, Twitter, Reddit, and Instagram trying to identify what's trending, manually researching viral moments across different communities, then using FIVE different fragmented tools to create one piece of content. By the time they finished production, the trend had already passed.\n\nThe breaking point came when we realized creators were spending 80% of their time on research and production logistics, leaving only 20% for actual creativity. Meanwhile, the creator economy is worth $104B+ with millions of creators desperate for a systematic approach to viral content creation.\n\nThe key insight : What if we could give creators an AI-powered trend intelligence system that doesn't just find what's viral, but instantly transforms those insights into contextual content? What if the entire pipeline from \"what's trending?\" to \"content published\" could happen in minutes instead of hours?"},{"heading":"What it does","content":"ViralWave.ai provides the first end-to-end trend-to-viral-content pipeline through four intelligent workflows:\n\n1) Discover Trends\n\nReal-time trend analysis across SIX major domains (AI/Tech, Crypto, Entertainment, Sports, Politics, Memes) using X API and Grok AI. Our Dedalus Labs agents continuously monitor viral conversations, building comprehensive context around trending topics, personalities, and cultural moments. Creators get a living, breathing trend intelligence system that understands not just what's viral, but why it's viral.\n\n2) Create Content\n\nAI-powered lyrics and music generation that weaves trending insights directly into creative content. Using Grok AI for contextual lyrics generation and Suno for professional beat creation, creators can generate multiple rap styles (Trap, Melodic, Battle) with customizable tempo and energy. Voice recording integration allows creators to add their personal touch while maintaining trend relevance.\n\n3) Produce Media\n\nRevolutionary video production pipeline that generates 15 contextual video clips using Veo AI, based on trending personalities and cultural references (e.g., Elon Musk content automatically includes Cybertruck and SpaceX elements). Drag-and-drop clip selection, image integration, ElevenLabs voice cloning for celebrity voices, and professional effects create viral-ready videos in minutes.\n\n4) Launch & Share :\n\nMulti-platform distribution optimized for TikTok, Instagram, and YouTube with performance analytics and viral prediction scoring. Content automatically adapts to platform-specific requirements and best practices."},{"heading":"How we built it","content":"Tech Stack\n\nFrontend : Next.js 16 + TypeScript + Tailwind CSS + shadcn/ui AI Services : Amazon Nova Act for intelligent browser based tasks orchestration Dedalus Labs for autonomous AI agent creation X API for real-time trend data ingestion Grok AI for contextual trend analysis and content generation Veo for AI video clip generation (15 clips per session) Suno for professional music and beat creation ElevenLabs for voice cloning and synthesis\n\nArchitecture\n\nAgent-Based System : Dedalus Labs agents handle trend discovery and content coordination Real-time Pipeline : X API ‚Üí Grok analysis ‚Üí Nova Act orchestration ‚Üí content generation Multi-AI Orchestration : Custom pipeline managing 6+ AI services simultaneously State Management : Persistent workflows across 4-step content creation process"},{"heading":"Challenges we ran into","content":"AI Orchestration : Coordinating 6 different AI APIs with varying response times and rate limits Real-time Trend Data : Managing X API limitations while maintaining fresh trend insights Context-Aware Generation : Making AI understand trending context for relevant content creation Agent Coordination : Using Dedalus Labs to create autonomous agents that work seamlessly together"},{"heading":"Accomplishments that we're proud of","content":"End-to-End AI Workflow : First platform connecting real-time trends to instant content generation Multi-AI Integration : Successfully orchestrated Amazon Nova Act, Grok, Veo, Suno, and ElevenLabs Agent-Based Innovation : Leveraged Dedalus Labs for intelligent workflow automation Productivity : Cut content creation from 12 hours to 12 minutes Context-Aware Content : AI that generates trending-relevant content, not generic output"},{"heading":"What we learned","content":"AI Agent Orchestration : Dedalus Labs agents can handle complex multi-step workflows autonomously Real-time Data Integration : X API provides rich trend data when properly managed Context : Grok AI excels at understanding cultural context for viral content Multimodality : Combining text (Grok), music (Suno), and video (Veo) creates powerful workflows"},{"heading":"What's next for ViralWave.ai","content":"Enhanced Agent Intelligence : Expand Dedalus Labs agent capabilities for predictive trend analysis Advanced Video Generation : Integrate latest Veo models for higher quality clips Voice Personality Training : Custom ElevenLabs models for individual creator voices Cross-Platform Optimization : Platform-specific content variants (TikTok vs YouTube) Creator Monetization : Direct integration with social platform creator funds"},{"heading":"Built With","content":"amazonnova dedalus gemini grokai next.js nova python suno typescript x"},{"heading":"Try it out","content":"github.com x.com"}]},{"project_title":"edgecart.","project_url":"https://devpost.com/software/edgecart","tagline":"grocery store mass surveillance for risk-adjusted target liquidation.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/954/585/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Financial Hack by Capital One"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"YC x HackPrinceton Challenge by Y Combinator"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Build on the Knot TransactionLink API by Knot API"}],"team_members":[],"built_with":[{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"knot","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"resnet18","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"websocket","url":null},{"name":"xai","url":null},{"name":"yolov8","url":null}],"external_links":[{"label":"edgecart.tech","url":"https://edgecart.tech"},{"label":"github.com","url":"https://github.com/AntoDono/edgecart"}],"description_sections":[{"heading":"The Problem","content":"Every year, 40% of food in America goes to waste ‚Äîthat's $408 billion worth of perfectly edible food thrown into landfills (USDA, 2023).\n\nMeanwhile:\n\nGrocery stores lose billions on expired produce they can't sell Customers miss deals on perfectly good food nearing peak ripeness Our planet suffers from unnecessary methane emissions and wasted resources\n\nThe current approach to preventing waste?\n\nRandom discounts.\n\nGeneric clearance sales.\n\nHoping someone‚Äîanyone‚Äîbuys it.\n\nIt doesn't work.\n\nWhy? Because discounts are either:\n\nToo late (applied when food is already unsellable) Too broad (blasting everyone with irrelevant spam notifications) Too random (no connection between what's discounted and who actually wants it)\n\nThe result? Stores throw away inventory that could have been sold. Customers never see deals on items they actually buy. And 133 billion pounds of food ends up in landfills annually‚Äîwasting the water, energy, and labor used to produce it.\n\nThe stakes are enormous.\n\nFood waste isn't just an economic problem‚Äîit's an environmental crisis. When organic matter decomposes in landfills, it produces methane, a greenhouse gas 25 times more potent than carbon dioxide. Meanwhile, 10% of global greenhouse gas emissions come from food that's never eaten (Project Drawdown, 2020).\n\nWe don't have a food scarcity problem. We have a food intelligence problem.\n\nThat's where EdgeCart comes in."},{"heading":"The Solution","content":"EdgeCart is the world's first predictive waste intelligence system that connects real-time produce decay detection with actual customer purchasing behavior. Using Markov Chain analysis, we project our solution causing a 19.5% reduction in emissions from grocery store food waste and ~180 million tons globally.\n\nImagine this scenario:\n\n9:00 AM - A camera spots bananas on the shelf at Store X. 12:00 PM - AI detects browning spots: freshness drops to 70%. 12:01 PM - System calculates a 35% discount to move inventory. 12:02 PM - AI identifies Sarah, who buys bananas every Tuesday, prefers ripe ones, and shops at Store X. 12:03 PM - Sarah's phone buzzes: \"Your favorite bananas now 35% off at Store X‚Äîperfect ripeness for banana bread tonight!\" 2:30 PM - Sarah visits the store, buys the bananas, saves $2.50. Result - Store recovers revenue on inventory that would've expired. Sarah saves money on groceries she was going to buy anyway. Zero waste.\n\nHere's what makes it revolutionary:\n\n1. Real-Time Visual Intelligence\n\nCameras monitor produce shelves 24/7, using:\n\nYOLO object detection to identify what's on the shelf ResNet freshness scoring (0-100 scale based on visual decay) Google Gemini Robotics (gemini-robotics-er-1.5-preview) for precise blemish detection and quality assessment\n\nOur AI watches bananas brown, tomatoes soften, and lettuce wilt‚Äîcreating a live decay map of inventory with predictive expiration timestamps.\n\n2. Deep Customer Intelligence (Knot API)\n\nCustomers connect their bank accounts through Knot API , revealing:\n\nComplete purchase history across ALL grocery stores What they buy, how often, at what price points Shopping patterns, preferences, and price sensitivity\n\nThe system learns: \"Sarah buys organic avocados 2x per week, always spends $3-4 each\" and \"Marcus bought strawberries 5 times last month, only when under $5.\"\n\n3. AI-Powered Smart Matching (xAI Grok)\n\nWhen produce hits the \"risk zone\" (70% freshness, 12 hours until spoilage):\n\nAI calculates dynamic discounts (lower freshness = deeper discount) System identifies customers who actually buy that specific item xAI Grok analyzes match quality across multiple dimensions: Purchase Pattern Analysis - When are they due for their next shopping trip? Timing Relevance - Weekend bulk buyer vs. weekday shopper? Value Perception - Does the discount exceed their usual threshold? Behavioral Triggers - Seasonal preferences, health choices, new varieties? Urgency Factors - Limited quantity, time sensitivity, expiration proximity? Sends targeted notifications ONLY to high-priority matches (80+ score)\n\nNo spam. No random deals. Only relevant offers for groceries you were already going to buy.\n\n4. Predictive Analytics for Stores\n\nStore dashboard provides actionable insights:\n\n\"Based on current decay rates and customer buying patterns, reduce next banana order by 30%\" \"Your avocado customers also shop at Whole Foods‚Äîstock more organic to compete\" \"50 customers notified about strawberries but only 10 bought‚Äîdiscount wasn't deep enough\"\n\n5. Zero-Waste Fallback\n\nFor items that won't sell even with targeted discounts:\n\nSystem auto-schedules food bank donations 12 hours before critical decay Customers who referred food banks earn \"waste warrior\" points Community impact tracking shows pounds of food saved\n\n6. Natural Language Interface (xAI Grok)\n\nEverything is queryable:\n\nStores ask: \"Which products have the worst sell-through rate at 60% freshness?\" Customers ask: \"How much could I save monthly based on my shopping patterns?\" Instant AI-powered insights with full context"},{"heading":"How We Built It","content":"Backend (Python)\n\nFlask - REST API & WebSocket server for real-time updates OpenCV + YOLOv8 - Real-time object detection and tracking PyTorch + ResNet18 - Custom-trained freshness classification model achieving 90% accuracy on fresh/rotten produce dataset through transfer learning Google Gemini (gemini-robotics-er-1.5-preview) - High-precision blemish segmentation and quality assessment Knot API - Customer purchase data integration across multiple merchants xAI Grok - Natural language recommendation engine with multi-dimensional analysis SQLite - Database for inventory, customers, and recommendations\n\nFrontend (React + TypeScript)\n\nReact - Modern component-based UI with responsive design WebSocket Client - Real-time inventory and notification updates Framer Motion - Smooth animations and transitions Custom Terminal UI - Cyberpunk-inspired admin dashboard\n\nAI/ML Pipeline\n\nYOLO detects produce ‚Üí crops objects ‚Üí passes to next stage ResNet scores freshness (0-100) ‚Üí triggers discount calculation Gemini Robotics detects blemishes ‚Üí adjusts quality assessment Grok matches customers ‚Üí generates personalized recommendations with reasoning\n\nThe Technical Challenge: Building a system that processes video frames in real-time, evaluates freshness with computer vision, matches thousands of customer profiles against hundreds of inventory items, and generates contextually-aware AI recommendations‚Äîall within 2-3 seconds from detection to notification."},{"heading":"Challenges We Ran Into","content":"1. Real-Time Computer Vision at Scale Processing video feeds from multiple cameras while running YOLO + ResNet + Gemini sequentially threatened to bottleneck the system. We optimized by batching detections, caching non-changing frames, and running models asynchronously.\n\n2. Knot API Integration Complexity Fetching and syncing purchase history across multiple merchants required careful rate limiting and data normalization. We built a robust caching layer and fallback system with demo users for development.\n\n3. AI Recommendation Quality vs. Cost xAI Grok API calls are expensive. We implemented intelligent rate limiting (10s between calls), batch processing, and priority scoring to only generate recommendations for high-value matches (80+ priority score).\n\n4. Dynamic Discount Calculation Balancing \"deep enough to move inventory\" with \"not too deep to hurt margins\" required iterative testing. We settled on a formula: discount = (100 - freshness_score) * 0.6 with minimum 20% threshold.\n\n5. WebSocket State Management Keeping admin dashboard and customer portals synchronized across real-time inventory changes, freshness updates, and new recommendations required careful event design and conflict resolution.\n\n6. Freshness Model Training Limited datasets for produce decay across multiple fruit types. We augmented existing datasets with synthetic aging transformations and transfer learning from ImageNet."},{"heading":"Accomplishments That We're Proud Of","content":"Created the first end-to-end waste prevention system that connects visual decay detection with actual consumer behavior\n\nIntegrated 4 different AI systems (YOLO, ResNet, Gemini Robotics, Grok) into a cohesive real-time pipeline\n\nTrained a custom ResNet18 freshness classifier locally achieving 90% accuracy on produce decay detection across multiple fruit types\n\nAchieved sub-3-second latency from produce detection to customer notification\n\nBuilt a working Knot API integration that successfully syncs multi-merchant purchase history\n\nDeveloped AI reasoning engine that explains why each recommendation was made (transparency in AI decisions)\n\nDesigned beautiful dual-interface system (admin dashboard + customer portal) with real-time WebSocket updates\n\nCreated demo system with realistic data that showcases the full customer journey from detection to purchase\n\nProved the concept works - Our system identified 15 \"at-risk\" inventory items and successfully matched them to 8 customers with 90+ priority scores during testing"},{"heading":"What We Learned","content":"Computer vision is powerful, but context is everything. A banana at 65% freshness means different things to different customers. Some want perfectly ripe fruit for immediate eating. Others want slightly underripe for meal prep. The AI needs to understand intent , not just state .\n\nReal-time doesn't mean instantaneous. We learned that 2-3 seconds from detection to notification is actually better than instantaneous. It gives the system time to calculate optimal discounts, match multiple customers, and batch API calls‚Äîresulting in higher quality recommendations.\n\nTraining our own freshness model was essential. Pre-trained models couldn't distinguish subtle decay patterns in produce. By collecting our own dataset and fine-tuning ResNet18 locally, we achieved 90% accuracy‚Äîhigh enough for production use while keeping the model lightweight for real-time inference.\n\nThe hardest part isn't the ML‚Äîit's the integration. Getting YOLO, ResNet, Gemini Robotics, Grok, Knot API, WebSockets, and a React frontend to work together seamlessly required more debugging than any individual model. Systems engineering beats algorithm optimization every time.\n\nCustomers want transparency in AI decisions. When we added the \"AI Reasoning\" section showing why xAI Grok recommended a deal, trust increased dramatically. People want to understand the logic, not just see a black box discount.\n\nOn the technical side: We mastered real-time video processing pipelines, transfer learning for custom datasets, multi-API orchestration under rate limits, and WebSocket state synchronization across distributed clients.\n\nMost importantly: We proved that waste prevention doesn't require behavior change ‚Äîit requires intelligence at the edge of the supply chain. When you match the right product (visual AI) with the right customer (purchase data) at the right time (predictive expiry), waste disappears naturally.\n\nThe Vision: A world where no edible food goes to waste because the supply chain is intelligent enough to match every item with someone who wants it, at a price that makes economic sense, before it spoils."},{"heading":"The Impact","content":"By the numbers: Using an Absorbing Markov Chain (AMC) to approximate the lifetimes and end states of each of the items in our inventory, we predict that adoption of EdgeCart would result in:\n\n19.5% reduction in emissions by 83.7 million tons of CO2 ~180 million tons less food waste annually\n\nEdgeCart: Intelligence at the edge of the supply chain.\n\nBecause the best way to prevent waste isn't to change behavior‚Äîit's to make the system smarter."},{"heading":"Built With","content":"flask gemini knot python pytorch react resnet18 typescript websocket xai yolov8"},{"heading":"Try it out","content":"edgecart.tech github.com"}]},{"project_title":"Protein Architect","project_url":"https://devpost.com/software/protein-architect","tagline":"AI-Powered Molecular Discovery","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/952/670/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"YC x HackPrinceton Challenge by Y Combinator"}],"team_members":[],"built_with":[{"name":"alphafold","url":null},{"name":"dedaluslabs","url":null},{"name":"elevenlabs","url":null},{"name":"esm2","url":null},{"name":"fastapi","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"googleveo","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"sagemaker","url":"https://devpost.com/software/built-with/sagemaker"}],"external_links":[{"label":"github.com","url":"https://github.com/rsingh135/ProteinArchitect"},{"label":"www.proteinarchi.tech","url":"https://www.proteinarchi.tech/"}],"description_sections":[{"heading":"Inspiration","content":"The pharmaceutical industry loses $1.4 billion and over a decade developing each new drug, with 90% failing in clinical trials, often because we fundamentally misunderstand how proteins interact. Traditional experimental methods like X-ray crystallography can take months to years, while computational approaches like AlphaFold require expensive GPU infrastructure that remains out of reach for most researchers.\n\nWe were inspired by the recent convergence of breakthrough AI models: AlphaFold 3 for structure prediction, Meta's ESM2 for protein language modeling, and Google's Gemini for scientific reasoning. We asked ourselves: what if we could combine these cutting-edge technologies into a single, accessible platform? What if a researcher could simply type \"human insulin,\" instantly visualize its 3D structure, predict its binding partners, analyze interaction dynamics, and even generate molecular videos‚Äîall in under three minutes?\n\nProtein Architect was born from this vision: to democratize computational structural biology by building an end-to-end platform that brings together neural network prediction, real-time 3D visualization, AI-powered research synthesis, and voice-enabled accessibility."},{"heading":"What it does","content":"Protein Architect transforms protein interaction discovery from a months-long experimental process into an interactive, AI-guided experience.\n\nAt its core, the platform enables researchers to search for any protein using natural language queries powered by Gemini 2.5 Flash. Behind the scenes, autonomous research agents built on the Dedalus Labs framework immediately spring into action, fetching and synthesizing data from PubMed, AlphaFold Database, and UniProt. Within 30 seconds, researchers receive a comprehensive research overview complete with 15+ recent academic papers, functional annotations, and markdown-rendered summaries with LaTeX equations.\n\nThe real innovation lies in our custom-trained neural network for protein-protein interaction (PPI) prediction. Using Meta's ESM2-650M to generate 1024-dimensional sequence embeddings, our model predicts whether two proteins interact in just 2-3 seconds - compared to the 6+ hours required by traditional molecular dynamics simulations. The model achieves a 77% F1 score on benchmark datasets, competitive with state-of-the-art methods while running over 5,000 times faster .\n\nOnce interactions are predicted, researchers can explore them through our WebGL-based dual molecular viewer, which renders both proteins side-by-side at 60 FPS even for structures containing 10,000+ atoms. The visualization highlights critical interaction features: hydrogen bonds appear as blue dotted lines, disulfide bridges in yellow, and binding sites with residue-level detail. Users can switch between cartoon, surface, and ball-and-stick representations to understand different structural aspects.\n\nFor drug discovery applications, we integrated multiple molecular docking tools including AutoDock Vina and DiffDock, an AI-based docking method that completes in 30 seconds to 2 minutes. The platform automatically detects binding sites and exports results in standard formats.\n\nPerhaps most innovative is our integration of Google's Veo 3.1 API for generating molecular dynamics videos. Rather than running expensive simulations, researchers can now generate physics-based videos showing the complete interaction pathway‚Äîfrom initial separated proteins through approach, orientation search, binding, and final complex formation.\n\nFinally, we built comprehensive accessibility features using ElevenLabs conversational AI integrated with Gemini 2.5 Flash. Researchers can have real-time voice conversations about protein structures, asking questions about specific residues, confidence scores, or functional domains‚Äîall hands-free, enabling analysis while conducting laboratory experiments."},{"heading":"How we built it","content":"Our architecture combines a Python/FastAPI microservices backend with a React 18 frontend, connected through extensive AI and ML pipelines.\n\nBackend Architecture\n\nThe backend leverages asynchronous Python with asyncio for concurrent processing across multiple services. We implemented a Dedalus Labs agentic framework that orchestrates autonomous research agents using Model Context Protocol (MCP) servers. These agents query the NCBI E-utilities API (handling up to 10 requests per second with our API key), the AlphaFold Database API, and UniProt REST endpoints, aggregating data in real-time.\n\nFor PPI prediction, we deployed models to AWS SageMaker endpoints, though we also support local inference for development. The service layer handles connection pooling through httpx.AsyncClient , implements exponential backoff for rate-limited APIs, and maintains a Redis cache with 7-day TTL to minimize redundant requests.\n\nFrontend Stack\n\nThe frontend uses React 18 with Vite for instant hot module replacement during development. For 3D molecular visualization, we integrated NGL Viewer, a WebGL-based library that efficiently renders protein structures in multiple representations. We built a custom dual-viewer component that synchronizes navigation between two protein structures, enabling side-by-side comparison of binding partners.\n\nThe UI uses TailwindCSS for styling, Framer Motion for fluid animations, and react-markdown with remark-gfm for rendering scientific content with LaTeX support. Voice interaction is handled through ElevenLabs' WebRTC streaming, maintaining persistent WebSocket connections for real-time audio exchange.\n\nMachine Learning Pipeline\n\nOur ML pipeline consists of three stages:\n\nStage 1: Sequence Embedding with ESM2\n\nfrom esm import pretrained model, alphabet = pretrained.esm2_t33_650M_UR50D() with torch.no_grad(): results = model(tokens, repr_layers=[33]) embeddings = results[\"representations\"][33] # 1024-dim vectors\n\nStage 2: Interaction Prediction\n\nWe designed a lightweight neural network that takes concatenated ESM2 embeddings and their element-wise product as input:\n\n$$P(\\text{interact} | A, B) = \\sigma(W_3 \\cdot \\text{ReLU}(W_2 \\cdot \\text{ReLU}(W_1 \\cdot [e_A; e_B; e_A \\odot e_B])))$$\n\nwhere e_A and e_B are the 1024-dimensional ESM2 embeddings, e_A ‚äô e_B represents interaction features captured through element-wise multiplication, and the network uses three fully-connected layers with dimensions 3072 ‚Üí 1024 ‚Üí 512 ‚Üí 2.\n\nStage 3: Structure Generation\n\nFor novel sequences without AlphaFold structures, we implemented an AlphaFold-inspired approach that predicts secondary structure propensity and generates PDB files with proper bond geometry. The algorithm analyzes amino acid composition to determine helix and sheet formation tendencies, then constructs three-dimensional coordinates following known structural constraints.\n\nAPI Integration Strategy\n\nWe integrated five major AI services: Google Gemini 2.5 Flash (with 1 million token context for research synthesis), Google Veo 3.1 (for video generation from protein structures), ElevenLabs (real-time conversational AI), Meta ESM2 (protein embeddings), and the AlphaFold Database (structure retrieval). Each integration required careful handling of rate limits, authentication flows, and error recovery strategies."},{"heading":"Challenges we ran into","content":"Neural Network Performance Crisis\n\nOur initial AlphaFold-inspired architecture faced a critical performance problem: 20 hours of training per epoch and 6 hours per interaction prediction . This made the system completely impractical for real-time use.\n\nThe root cause was our attempt to replicate AlphaFold-Multimer's full architecture, which contains approximately 93 million parameters and requires Multiple Sequence Alignment (MSA) generation taking 2-4 hours per protein pair. The attention mechanisms introduced O(N¬≤) complexity that became prohibitive for sequences longer than 500 residues.\n\nWe solved this through a multi-stage optimization approach. First, we leveraged transfer learning from ESM2, which had already been trained on millions of protein sequences from UniRef90. This eliminated the MSA generation step entirely. ESM2 generates high-quality 1024-dimensional embeddings in just 2-3 seconds, capturing evolutionary information without expensive alignment calculations.\n\nSecond, we dramatically simplified the architecture. Instead of a 93-million parameter transformer, we built a lightweight 3-layer MLP with only 4 million parameters , a 95% reduction. This prediction head operates on pre-computed ESM2 embeddings rather than raw sequences.\n\nThird, we implemented mixed precision training (FP16) using PyTorch's automatic mixed precision:\n\nfrom torch.cuda.amp import autocast, GradScaler scaler = GradScaler() with autocast(): outputs = model(embeddings) loss = criterion(outputs, labels) scaler.scale(loss).backward()\n\nThis gave us a 2.3x speedup and reduced memory usage by 40%.\n\nFinally, we used gradient accumulation to achieve an effective batch size of 256 on a single GPU:\n\nfor i, batch in enumerate(dataloader): loss = loss / 8 loss.backward() if (i + 1) % 8 == 0: optimizer.step() optimizer.zero_grad()\n\nThe results were dramatic: training time dropped from 20 hours to 45 minutes per epoch , and inference speed improved from 6 hours to 2.3 seconds (over 5,000 times faster ) while maintaining competitive accuracy with an F1 score of 0.77.\n\nSevere Class Imbalance Problem\n\nThe second major challenge emerged from the fundamental biology of protein interactions: most protein pairs don't interact . Our training dataset contained 12,847 positive examples (interacting pairs) but 11,953,201 negative examples (non-interacting pairs), a ratio of 1:930, or 99.9% negative labels .\n\nA naive model achieved 99.87% accuracy simply by predicting \"no interaction\" for every pair. The precision for the positive class was exactly zero:\n\n$$\\text{Precision}_{\\text{positive}} = \\frac{TP}{TP + FP} = \\frac{0}{0 + 12847} = 0\\%$$\n\nWe addressed this through four complementary strategies:\n\n1. SMOTE (Synthetic Minority Oversampling) to generate synthetic positive examples in the embedding space:\n\nfrom imblearn.over_sampling import SMOTE smote = SMOTE(sampling_strategy=0.05) X_resampled, y_resampled = smote.fit_resample(embeddings, labels)\n\n2. Weighted binary cross-entropy loss that penalizes false negatives 930 times more heavily than false positives:\n\npos_weight = torch.tensor([930.0]) criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\n3. Focal loss (inspired by the RetinaNet object detection paper) to down-weight easy negative examples: $$FL(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t)$$\n\nWith Œ≥ = 2, this forced the model to focus on hard-to-classify examples rather than simply learning to predict the majority class.\n\n4. Ensemble voting across five models trained on different random subsets of negative examples, reducing variance and improving robustness.\n\nThese interventions transformed our metrics: precision jumped to 0.73, recall to 0.81, F1 score to 0.77, and AUC-ROC to 0.91.\n\nAdditional Technical Challenges\n\nWe encountered rate limiting on the AlphaFold Database API (approximately 100 requests per minute), which we solved through Redis caching with a 97% hit rate, batched requests using asyncio.gather() , and exponential backoff retry logic.\n\nThe ElevenLabs voice integration required careful handling of context updates; we needed to update protein information when users selected different residues without interrupting ongoing conversations. We solved this using the sendContextualUpdate() API with a 500ms debounce and explicit instructions in the context telling the model not to ask for information already loaded in the viewer.\n\nFinally, rendering markdown content in React proved tricky when we tried to use ReactMarkdown inline within list elements. The solution was switching from inline to block-level rendering with proper div wrappers."},{"heading":"Accomplishments that we're proud of","content":"We successfully trained and deployed a production-ready neural network that achieves 77% F1 score on protein-protein interaction prediction‚Äîcompetitive with state-of-the-art methods while running over 5,000 times faster than traditional approaches. The optimization journey from 6-hour predictions to 2.3 seconds represents a fundamental breakthrough in making PPI prediction practical for real-time interactive use.\n\nThe real-time 3D visualization system renders complex molecular structures at 60 FPS even with 10,000+ atoms, providing an intuitive interface for exploring protein interactions. Our autonomous research agent successfully synthesizes information from multiple scientific databases, automatically fetching and formatting 15+ recent papers with proper citations in under 30 seconds.\n\nPerhaps most significantly, we built comprehensive accessibility features through voice integration. Researchers can now analyze protein structures hands-free, enabling new workflows like querying structural information while conducting laboratory experiments. The platform is production-ready with AWS SageMaker integration, auto-scaling FastAPI backend, and comprehensive error handling."},{"heading":"What we learned","content":"The technical journey taught us that transfer learning fundamentally changes what's possible with limited computational resources. By leveraging ESM2's pre-trained protein knowledge rather than training from scratch, we avoided what would have been approximately $50,000 in GPU costs and months of training time. The protein language model had already learned the essential patterns from millions of sequences.\n\nWe discovered that evaluation metrics tell very different stories. A model with 99.9% accuracy can be completely useless if it never predicts the minority class. Understanding the trade-offs between precision, recall, and F1 score (and choosing the right metric for the biological problem) proved crucial. Focal loss and SMOTE weren't just theoretical techniques from papers; they were essential tools that transformed our model from non-functional to production-ready.\n\nModel quantization delivered almost free performance gains: converting our PyTorch model to INT8 quantization gave us a 2.7x inference speedup with only 0.3% accuracy loss. Similarly, implementing proper caching strategies for API calls (achieving 97% cache hit rates) taught us that architectural optimization often matters more than algorithmic improvements.\n\nFrom a biological perspective, we learned that hydrophobic interactions dominate protein-protein binding. Our model discovered that binding sites with 30%+ hydrophobic residues (alanine, valine, isoleucine, leucine, methionine, phenylalanine, tryptophan, tyrosine) showed 4.2 times higher interaction probability. Charge complementarity also emerged as a key pattern: proteins with opposing charge distributions exhibited 2.8 times more interactions.\n\nThe predicted confidence scores we generated showed a Spearman correlation of 0.78 with experimental binding affinities from the PDBbind database, validating that our model was learning meaningful physical chemistry rather than simply fitting statistical patterns."},{"heading":"What's next for Protein Architect","content":"In the immediate term, we plan to enhance our PPI model by integrating AlphaFold 3's diffusion architecture for more accurate complex structure prediction and expanding training data to include approximately 500,000 additional examples from BioGRID and STRING databases. We're targeting an F1 score above 0.85 with improved confidence calibration.\n\nFor drug discovery applications, we'll implement AutoDock GPU integration for virtual screening against large compound libraries like ChEMBL (2.3 million compounds), add ADMET prediction capabilities using Chemprop models, and develop reinforcement learning algorithms for automated lead optimization.\n\nThe protein design module will incorporate RFdiffusion for scaffold generation and ProteinMPNN for sequence design, enabling researchers to design novel proteins with specific binding properties or catalytic functions from scratch.\n\nOur long-term vision is to create a fully automated drug discovery pipeline where researchers can input a disease target (like \"Alzheimer's amyloid-beta aggregation\") and receive, within 24 hours, a ranked list of 150 candidate molecules with predicted IC50 values, toxicity profiles, and manufacturing protocols. We're committed to democratizing structural biology by offering the platform for free and eventually open-sourcing of model weights trained on public data. As the platform matures, we may pursue FDA Digital Health pre-certification and HIPAA compliance to enable clinical applications.\n\nProtein Architect represents a paradigm shift in how we approach computational biology, transforming protein interaction discovery from an expensive, time-consuming process requiring specialized expertise into an accessible, interactive experience available to researchers worldwide."},{"heading":"Built With","content":"alphafold dedaluslabs elevenlabs esm2 fastapi gemini googleveo python pytorch sagemaker"},{"heading":"Try it out","content":"github.com www.proteinarchi.tech"}]},{"project_title":"Cortex","project_url":"https://devpost.com/software/cortex-3a7u2e","tagline":"An AI clinical insight engine that makes patient data instantly searchable and useful. By applying semantic search and pattern recognition, it cuts down chart review time so doctors can focus on care!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/956/744/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"YC x HackPrinceton Challenge by Y Combinator"}],"team_members":[],"built_with":[{"name":"next.js","url":null},{"name":"openai","url":null},{"name":"pinecone","url":null},{"name":"playwright","url":null},{"name":"retell-ai","url":null},{"name":"supabase","url":null},{"name":"tailwind-css","url":null},{"name":"vercel","url":null},{"name":"vertex-ai","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/VisH317/cortex"},{"label":"cortex-rust.vercel.app","url":"https://cortex-rust.vercel.app/"}],"description_sections":[{"heading":"Inspiration","content":"Our inspiration came from witnessing the real struggles of doctors working in low-resource environments and understanding a harsh truth: in healthcare, every second matters . Physicians spend nearly half of their time (which is around 16 minutes of every 30) on electronic health records and desk work, time that could otherwise be spent with patients. This administrative burden slows down care, increases patient wait times, and induces anxiety. 20% of patients have even left providers due to delays. When someone‚Äôs health, or even their life, is on the line, those minutes can make all the difference. Every minute lost to paperwork is a minute a patient doesn‚Äôt get care.\n\nWe also recognized that rare diseases, affecting millions worldwide, are often overlooked because the data needed to study them is scattered and hard to access. Researchers and clinicians struggle to find meaningful patterns without comprehensive, organized datasets. We wanted to build a solution that didn‚Äôt just store patient data, but made it instantly accessible and actionable, giving doctors the tools they need to provide faster, more informed care, and empowering researchers to discover insights that could improve countless lives. Cortex was born from the desire to save time, reduce anxiety, and ultimately make healthcare better for both patients and the people dedicated to caring for them."},{"heading":"What it does","content":"Cortex is an AI-powered assistant designed to make patient data instantly accessible and actionable . Doctors can upload records to a secure, centralized database, enabling lightning-fast searches and pattern discovery across individual patients. With patient consent, anonymized data can flow into a crowdsourced research database, unlocking insights across populations and helping researchers spot trends that would otherwise go unnoticed. Powered by AI, Cortex not only finds the right patient records‚Äîit surfaces relevant studies, medical articles, and journals, bridging the gap between clinical care and cutting-edge research. It‚Äôs like giving doctors and researchers a supercharged memory and insight engine, so they can focus on what truly matters: saving lives and advancing medicine."},{"heading":"How we built it","content":"We built Cortex using a modern web stack centered around Next.js for our frontend framework, which gave us server-side rendering capabilities and seamless API integration. The core architecture consists of: Frontend & Styling: We used Next.js with Tailwind CSS for rapid UI development, creating a clean and responsive interface that doctors and researchers can navigate efficiently. The combination allowed us to build a professional medical data platform quickly during the hackathon.\n\nBackend Infrastructure: Our API routes are handled through Next.js server functions, providing a unified codebase for both frontend and backend logic. We integrated Supabase for authentication and as our primary database, leveraging its real-time capabilities for instant data updates when doctors upload patient information or researchers access the crowdsourced database.\n\nAI Integration: We implemented multiple AI services to power our intelligent agent. OpenAI handles natural language processing for the conversational interface, while Vertex AI and Retell AI provide additional capabilities for pattern recognition in medical data and voice-based interactions. The AI agent helps doctors query patient data using natural language and assists researchers in finding relevant patterns across the anonymized dataset.\n\nVector Database: Pinecone serves as our vector database, enabling semantic search across patient records and medical literature. This allows our AI agent to find similar cases and relevant research papers based on meaning rather than just keyword matching.\n\nTesting & Deployment: We used Playwright for end-to-end testing to ensure reliability in this critical healthcare application. The entire application is deployed on Vercel, taking advantage of its seamless integration with Next.js for automatic deployments and edge functions."},{"heading":"Challenges we ran into","content":"One major challenge was pivoting mid-competition. Initially, we aimed to improve file management and summaries for a Dropbox-like application, but Dropbox had already implemented similar features. This forced us to quickly pivot to healthcare, which required learning about EHRs, patient privacy, and medical research workflows. We also faced technical hurdles, such as switching between different APIs and rebuilding core features to ensure that file embedding worked correctly."},{"heading":"Accomplishments that we're proud of","content":"For most of our team, this was our first hackathon experience, which made completing a fully functional project feel like a huge victory. We're incredibly proud that we not only finished but managed to successfully integrate multiple complex APIs - from OpenAI to Vertex AI to Pinecone - and got them all working together seamlessly under intense time pressure. Learning how to navigate so many different technologies, troubleshooting integration issues, and figuring out how to make everything communicate properly was a massive learning curve that we conquered together. We also invested significant time researching the healthcare ecosystem to ensure we were building something meaningful rather than just a technical demo."},{"heading":"What we learned","content":"We learned how critical adaptability is in the development process, as well as the importance of understanding the end-users‚Äô workflow‚Äîin this case, both doctors and researchers. We also gained hands-on experience with AI data indexing, privacy-aware data handling, and rapid prototyping in a high-stakes environment. Along the way, we learned a lot about EHRs, doctors, and their stories with patients, giving us valuable perspective on real-world healthcare challenges. We also gained experience using a variety of APIs, including Retell AI, Vertex AI, and Pinecone. Most importantly, we learned how to navigate difficulties such as pivoting ideas when one approach didn‚Äôt work out, reinforcing the importance of flexibility and resilience in innovation!"},{"heading":"What's next for Cortex","content":"Next, we‚Äôre incredibly excited to take Cortex to the next level. Our immediate focus is on expanding the AI capabilities to provide predictive insights and early warnings based on patient data trends. Imagine a system that doesn‚Äôt just store and organize data, but actively helps doctors anticipate complications, identify rare patterns earlier, and make faster, more informed decisions that could save lives. We‚Äôre also exploring deeper integration with hospital EHR systems, aiming to make Cortex a seamless part of the doctors‚Äô workflow rather than an additional tool. By connecting directly to existing systems, we can minimize administrative burdens and give clinicians more time to focus on what really matters: patient care.\n\nOn the research side, we‚Äôre working to expand our crowdsourced database to include anonymized data from multiple institutions, creating a rich ecosystem of medical information. With this, researchers will be able to uncover patterns, identify correlations, and accelerate discoveries across rare diseases and complex conditions. Our vision is a world where no disease is ‚Äúleft behind‚Äù and no patient‚Äôs data goes underutilized. Ultimately, we see Cortex becoming indispensable for both clinicians and researchers. We want it to be the go-to platform for understanding patient data, driving medical insights, and transforming healthcare workflows. This is just the beginning‚Äîour team is passionate about pushing the boundaries of what‚Äôs possible with AI in healthcare, and we‚Äôre determined to make a tangible, lasting impact on patient outcomes and medical discovery worldwide."},{"heading":"Built With","content":"next.js openai pinecone playwright retell-ai supabase tailwind-css vercel vertex-ai"},{"heading":"Try it out","content":"github.com cortex-rust.vercel.app"}]},{"project_title":"Discer.io","project_url":"https://devpost.com/software/discer-io","tagline":"Learn Agentic AI through play. Discer.io is a MMO sandbox where you build and deploy agentic AI workflows using drag-and-drop blocks‚Äîlike Scratch, but for AI agents.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/946/438/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"YC x HackPrinceton Challenge by Y Combinator"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Dedalus by Dedalus Labs"}],"team_members":[],"built_with":[{"name":"bun","url":null},{"name":"dedalus","url":null},{"name":"digitalocean","url":"https://devpost.com/software/built-with/digitalocean"},{"name":"grok","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"nextjs","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"snowflake","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"www.discerio.tech","url":"https://www.discerio.tech/"},{"label":"github.com","url":"https://github.com/RomanSlack/Discerio"}],"description_sections":[{"heading":"\"Discere\" - to learn","content":"Agentic AI literacy is broken. Most people have heard of agents but few actually understand how to build them. There‚Äôs no accessible, game-like way to learn how multi-step reasoning, tool orchestration, and feedback loops come together to form a working agentic system. Current resources are either text-heavy or code-intensive, leaving beginners overwhelmed and disengaged."},{"heading":"Our Solution","content":"We built Discer.io, an educational MMO sandbox that lets players design, orchestrate, and deploy agentic AI workflows using drag-and-drop programming blocks and prompt-based commands. Think Scratch, but for agentic AI systems.\n\nIt turns abstract AI workflows into tangible, interactive experiences. So Instead of just reading about agents or watching demos, you‚Äôll build your own, connect tools, set reasoning steps, and see the workflow come alive ‚Äî all without writing a single line of code."},{"heading":"How We Built It","content":"We combined Next.js for the frontend, Python for the backend, and a custom tick-based simulation environment built using bun, to bring agent logic to life. The visual programming was powered by modular blocks linked to custom built AI reasoning modules. Also, we utilized SnowflakeSQL for robust log and data extraction, and deployed the services using Digital Ocean. We used Dedalus Labs for our agentic capabilities and MCP server hosting. Our agents may use any of a variety of models, including Grok, Gemini, Claude, and GPT."},{"heading":"Challenges We Faced","content":"Balancing educational clarity with open-ended creativity was tough. We had to design a workflow system that feels like play yet mirrors real agentic reasoning. Furthermore, building an entire video game as one small component of a larger product, pushed us to think outside the box and solve problems with maximal efficiency."},{"heading":"What We Learned","content":"We learned how to visualize multi-step reasoning in real time, turning invisible thought chains into real, interactive systems. Thinking from the lens of an educational product also presented a unique opportunity to design an engaging curriculum and develop a service for people of all ages and backgrounds."},{"heading":"What‚Äôs Next","content":"We plan on expanding multiplayer features, classroom integrations, and open-source ‚Äúagent packs‚Äù so anyone can remix and learn from others‚Äô designs. Additionally, we would love to see a wider array of scenarios, that push the learners and agents in creative and fun ways."},{"heading":"Built With","content":"bun dedalus digitalocean grok javascript nextjs openai python react snowflake typescript vite"},{"heading":"Try it out","content":"www.discerio.tech github.com"}]},{"project_title":"New Roots","project_url":"https://devpost.com/software/new-roots","tagline":"xAI-powered immigration platform connecting migrants with global opportunities. Smart scraping, cultural fit checks, and document management -- all in one place.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/960/004/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Most Impactful Use of the X API by X"}],"team_members":[],"built_with":[{"name":"beautiful-soup","url":"https://devpost.com/software/built-with/beautiful-soup"},{"name":"django","url":"https://devpost.com/software/built-with/django"},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"firestore","url":null},{"name":"grok","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"selenium","url":"https://devpost.com/software/built-with/selenium"},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null},{"name":"xai","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/afperry12/New_Roots"},{"label":"newroots-eosin.vercel.app","url":"https://newroots-eosin.vercel.app/"}],"description_sections":[{"heading":"The Problem","content":"Annually, 18 million individuals attempt to immigrate to new countries, yet over 70% of these attempts fail. This failure rate is frequently not due to a lack of qualifications, but rather the prohibitive complexity of navigating global immigration systems. Government websites present information fragmented across dozens of pages, eligibility criteria are buried in dense legal jargon, and applicants often waste months of time and thousands of dollars only to discover they do not qualify.\n\nThis challenge was validated through direct experience assisting a family member with a skilled worker visa application. The official government website had information scattered across more than 15 different pages, lacked a clear eligibility calculator, and provided conflicting requirements. After observing the necessity of spending $2,000 on an immigration consultant for basic guidance, it became clear that a more efficient solution was required.\n\nNew Roots was conceptualized to address this gap by leveraging artificial intelligence to read, synthesize, and centralize real-time government immigration data, making this critical information accessible and actionable for everyone."},{"heading":"Product Overview","content":"New Roots is an AI-powered immigration platform designed to make global mobility accessible. The platform's core functionalities include:\n\nIntelligent Program Discovery\n\nUsing xAI's Grok-3 API , our proprietary scraper analyzes government immigration websites in real-time, automatically discovering and extracting comprehensive program data. Unlike traditional scrapers, this system understands semantic context. It identifies and aggregates related pages (eligibility, requirements, FAQs, application processes) and merges them intelligently into a single, coherent program profile.\n\nInstant Eligibility Matching\n\nUsers create a detailed profile outlining their education, work experience, language skills, and nationality. Our matching algorithm instantly calculates eligibility scores across all available programs, showing precisely where they qualify and identifying any gaps in their qualifications.\n\nSecure Document Vault\n\nApplicants can store all necessary documents (passports, diplomas, work certificates) in a Firebase-backed vault, enabling reusability across multiple applications without redundant uploads.\n\nApplication Workflow Automation\n\nUsers can track application status, receive deadline reminders, and manage multiple immigration programs from a centralized dashboard. This eliminates the need to navigate numerous disparate government portals across different countries.\n\nGovernment Portal (A Future Feature)\n\nA planned feature includes a portal for immigration officials to review applications, request documents, and update applicant statuses directly within the platform."},{"heading":"Technical Architecture","content":"Frontend (React + TypeScript + Firebase)\n\nReact 18 with TypeScript for type-safe, maintainable code TailwindCSS for rapid, responsive UI development TanStack Query for efficient data caching and real-time updates Firebase Authentication for secure user management Firebase Storage for document management with signed URLs\n\nBackend (Django + Firebase Admin SDK)\n\nDjango REST Framework providing RESTful API endpoints Firebase Firestore as our NoSQL database, streamlining development Firebase Admin SDK for server-side authentication verification Pydantic for robust data validation Custom eligibility scoring algorithm weighing 8+ factors\n\nSmart Scraper (Python + xAI Grok-3)\n\nThis is the core technological innovation of the platform:\n\nMulti-Page Discovery : For each program, Grok analyzes the main page and intelligently discovers related pages (eligibility criteria, document requirements, application steps, FAQs). Deep Extraction : Each page is fed to Grok-3 with a comprehensive prompt asking for maximum detail extraction, including 15+ FAQs, 7+ application stages, 10+ requirements, fees, processing times, and contact info. Intelligent Merging : Grok merges data from all related pages, resolving conflicts and creating one comprehensive program profile, often exceeding 120,000 characters of information per program. Quality Validation : A 70-point scoring system ensures only comprehensive programs (defined by 10+ FAQs, 7+ stages, 8+ benefits) are saved to Firebase. Automated Updates : GitHub Actions runs the scraper daily, keeping all program data current.\n\nKey Technical Innovation : Traditional scrapers are brittle and break when website layouts change. By leveraging Grok's natural language understanding, our scraper adapts automatically. It understands the query \"What documents do I need?\" regardless of how different governments phrase it.\n\nInfrastructure\n\nDocker Compose for local development (reducing the stack to 2 containers from a traditional 9!). GitHub Actions for CI/CD and automated scraping. Firebase integration eliminates approximately 80% of typical DevOps complexity (removing the need for PostgreSQL, Redis, or an S3 alternative)."},{"heading":"Development Challenges and Resolutions","content":"1. Schema Inconsistency in NoSQL Database\n\nA schema mismatch occurred where the frontend expected applicationProcess.steps[] while the scraper saved stages[] . This inconsistency led to a critical data loss incident during a cleanup operation, as the validation logic was referencing an incorrect field name.\n\nResolution : A data validation script was implemented to enforce schema consistency across all field mappings. The data restore script was updated with createdAt and updatedAt timestamps to enable proper backend querying.\n\n2. API Timeout and Performance\n\nInitial extractions from large, multi-page government websites (e.g., Canada's Express Entry) exceeded API timeout limits, with processes failing after 20+ minutes.\n\nResolution : Timeouts were extended from 60s to 180s, max_tokens were increased from 4000 to 6000, and a smart fallback logic was implemented. If multi-page merging fails, the system ingests the main page data to ensure service continuity. Retry logic with exponential backoff was also added.\n\n3. Dynamic URL and Source Instability\n\nGovernment websites reorganize frequently, leading to URL decay. Of our initial 18 program URLs, 8 returned 404 errors during scraping.\n\nResolution : Graceful error handling was implemented. The scraper now logs failures, continues to the next program, and generates a report at the end. This allows for manual updates to broken URLs in sources.yaml without halting the entire process.\n\n4. Backend Cache Invalidation Issues\n\nAfter restoring programs to Firebase, the data was not appearing on the frontend. This was traced to a stale backend cache, as the Django application had been running for over 3 hours without a restart.\n\nResolution : Health checks and a proper cache invalidation strategy were implemented. A simple Docker restart resolved the immediate issue.\n\n5. Upstream API Deprecation\n\nDuring development, we received a 404 error indicating the grok-beta model was deprecated, which broke the entire scraping pipeline.\n\nResolution : A one-line fix changing the model dependency to grok-3 resolved the issue. This update also improved results, as Grok-3 extracts even greater detail (16,728 chars vs. 15,851 for one Australian program)."},{"heading":"Key Accomplishments","content":"Scalable, Real-Time AI Data Extraction : Successfully scraped 6 comprehensive immigration programs from 6 countries, each with 15 FAQs, 7 application stages, and 10+ benefits‚Äîall extracted intelligently by xAI Grok-3. Intelligent Multi-Source Data Fusion : Our scraper discovers up to 9 related pages per program and merges over 120,000 characters of data into coherent profiles. The Canada Express Entry profile combines 8 distinct government pages into one. Streamlined, Production-Ready Architecture : A Firebase-first design eliminated 80% of typical backend complexity. No PostgreSQL, Redis, or MinIO were required, enabling deployment with just 2 Docker containers. High-Fidelity Data Assurance : Our 70-point validation system ensures every program profile is comprehensive, prioritizing data quality and completeness over sheer volume. Rapid Prototyping : A full-stack platform with intelligent scraping, user authentication, document management, and application workflow was developed in 36 hours."},{"heading":"Key Learnings","content":"Technical Lessons\n\nEfficacy of LLMs for Unstructured Data : xAI Grok is incredibly powerful for parsing unstructured web data, offering superior adaptability compared to traditional, brittle regex-based scrapers. Firebase for Rapid Development : Firebase significantly accelerated the development lifecycle by abstracting database setup, authentication, and file storage implementation. NoSQL Schema Discipline : The flexibility of Firestore requires strict, application-level schema validation to prevent data corruption. Value of Type Safety : TypeScript was instrumental in preventing dozens of bugs before runtime, especially when managing complex, nested data structures.\n\nProduct Lessons\n\nMarket Validation : The $30B immigration services market confirms the difficulty of the problem, indicating a strong user willingness to pay for a high-quality solution. Data Comprehensiveness is Key : Users require comprehensive, all-in-one data. Six complete program profiles are more valuable than 100 incomplete ones. AI as a Tool, Not a Panacea : Grok failed on approximately 50% of program URLs due to broken links, confirming that human-in-the-loop oversight is still necessary.\n\nTeam Lessons\n\nSystem Resilience and Recovery : A critical data deletion incident 90 minutes before a deadline underscored the importance of calm, systematic recovery procedures. Importance of Internal Documentation : Comprehensive logging was essential for tracing every scraper decision and debugging issues quickly."},{"heading":"Future Roadmap","content":"Immediate Term\n\nData Expansion : Correct the 8 failed program URLs and re-scrape to achieve 14+ total programs. Geographic Expansion : Expand to 10+ new countries, including France, Spain, Portugal, Japan, and the UAE. Feature Enhancement : Implement the smart eligibility calculator to provide users with actionable feedback (e.g., \"Requires 1 more year of work experience\"). Automation : Integrate Document OCR to extract data automatically from uploaded diplomas and certificates.\n\nMedium Term (6 Months) - B2B Pivot\n\nWe will target immigration law firms as a primary B2B channel:\n\nOffering : A white-label SaaS platform for firms to manage their clients. Pricing Model : $500/month per attorney plus a $50/client fee. Market Analysis : The 15,000 immigration attorneys in the US alone represent a $90M ARR potential.\n\nLong-Term Vision (1-2 Years)\n\nGovernment Partnerships : Evolve into the official application portal for smaller countries. AI Application Generation : Develop an AI assistant to generate entire visa applications from user profiles. Predictive Analytics : Build an ML model to predict application approval likelihood based on historical data. Ecosystem Marketplace : Connect users with vetted attorneys, translators, and medical exam providers.\n\nNew Roots is positioned to become a foundational platform for the future of global mobility.\n\n*I am looking for the video of the recording on my laptop!! I can't find it - Adel"},{"heading":"Built With","content":"beautiful-soup django docker firebase firestore grok python react selenium tailwindcss typescript vite xai"},{"heading":"Try it out","content":"github.com newroots-eosin.vercel.app"}]},{"project_title":"XChange - Where Market Chatter Becomes Market Insight","project_url":"https://devpost.com/software/xchange-34cvdw","tagline":"XChange turns social media sentiment into real-time trading insight using Grok AI. It empowers modern traders to predict market moves, uncover trends, and make smarter, faster investment decisions.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/947/627/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Most Impactful Use of the X API by X"}],"team_members":[],"built_with":[{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sql","url":"https://devpost.com/software/built-with/sql"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null},{"name":"x","url":null},{"name":"xai","url":null},{"name":"xapi","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/BinayakJha/Xchange"},{"label":"x-change.tech","url":"http://x-change.tech"}],"description_sections":[{"heading":"Built With","content":"github javascript react sql tailwind typescript vite x xai xapi"},{"heading":"Try it out","content":"github.com x-change.tech"}]},{"project_title":"Recall","project_url":"https://devpost.com/software/recall-cf0dp9","tagline":"Imagine waking up surrounded by strangers - only they‚Äôre your family. For 55 million people with Dementia, this is reality. Recall is here to bring memories, faces, and your identity back to life.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/956/786/datas/medium.jpg","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Grok for Real-Time Data/Signal Analysis by xAI"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Arm by MLH"}],"team_members":[],"built_with":[{"name":"grok","url":null},{"name":"nextjs","url":null},{"name":"ngrok","url":null},{"name":"openai","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"raspberrypi","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/Christinetrr/tbd"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAG4LuocB3M/uhWuKpZSxoB3ShXV_kWqwA/edit?utm_content=DAG4LuocB3M&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"}],"description_sections":[{"heading":"Inspiration","content":"Memory loss affects millions of people with Alzheimer's and Dementia , creating a gap between their daily experiences and what they can recall. We were inspired to build a solution that acts as a digital memory assistant - capturing live events in real time, helping you remember the ones you love, and never having to question your identity or livelihood again. Our goal was to help individuals maintain their sense of identity and independence by giving them another memory system and another chance at autonomy, connection, and meaning."},{"heading":"What it does","content":"Recall acts as a memory assistant that passively translates frames of significant events captured throughout your day into contextually relevant summarizations to paint a timeline of your day.\n\nRecall also helps you never forget the ones you love. Running a facial recognition software, we detect if your loved ones are nearby and create live-streamed, audible transcriptions of the conversation into structured conversation summaries linked to individual profiles\n\nWe are aimed to integrate as seamlessly and unobtrusively as possible into a user's life. Dementia should not strip you of your independence and dignity, so we eliminate the burden of manual note-taking and constant reminders, and act as a unique, personalized memory journal that helps you and your loved ones never have to answer the question \"What did I do today?\" or \"Who are you?\" again."},{"heading":"How we built it","content":"Recall was built using two main hardware components, a Raspberry Pi v 3 Model B and a Logitech Brio web-camera. We flashed a new image of a linux OS onto the Raspberry Pi and due to the tiny nature of the device, we ensured to offload heavy processing by creating our own custom deployed endpoints (using ngrok), for rigorous facial detection and environment awareness. For speech understanding, we utilize the built-in microphone from the Logitech camera and have an algorithm that understands when a user is talking with a significant person. We then use OpenAI‚Äôs whisper for transcription and grok-3 for summarization. Furthermore, we use wired earbuds in order to send audio messages to the user. Finally, all created timelines and events are stored and displayed on a NextJS app (deployed on Vercel). This allows users to go through detailed, informative timelines of a day‚Äôs events and help recall important details from surroundings and/or interactions."},{"heading":"Challenges we ran into","content":"Since this was all of our first times working with hardware, it took us a long time to get the Raspberry Pi set up. We needed to replace the SD card (from 8GB to 32GB) because we ran out of memory when installing heavier machine-learning python libraries. We also needed to re-flash the OS and enable SSH so that our project could work wirelessly. There was also an issue with wifi that made the SSH connection unstable, so we had to rely on a hotspot for all programming on the Raspberry Pi. Additionally, we didn‚Äôt want to save every image and audio files due to privacy concerns. We successfully mitigated this by using captioning conversation summaries which do not require any long-term storage of data. Even through all these situations, we were able to work together and build a meaningful project that delivers real value."},{"heading":"Accomplishments that we're proud of","content":"* Recall has the impact to change the lives of millions. *\n\nFully autonomous operation : The system can run 24/7 without user intervention, intelligently deciding when to record based on visual cues and audio cues. No buttons to press, no apps to open, Recall works silently in the background, so users can live their lives without thinking about their memory loss.\n\nPrioritized facial recognition : Our system doesn't just detect faces - it recognizes familiar faces. Recall distinguishes between strangers and loved ones, only initiating conversation recording when someone meaningful enters the frame. We capture interactions with family members and close friends (people who you choose are important to you) while respecting the privacy of passersby or delivery workers. By building individual profiles for each recognized person, we create a rich relational context: users can see not just what happened, but who they spent time with, helping them maintain connections even when faces become hard to remember.\n\nSmart audio capture : Our VAD implementation with silence detection ensures we capture complete conversations without wasting storage on insignificant\n\nScalable Architecture : Direct MongoDB integration and efficient frame processing make this viable to handle massive amounts of users\n\nPrivacy-conscious design : All video processing happens in temporary batches - none of your livestream data is saved, only transcribed and processed. This ensures your privacy, and those around you are respected at all times."},{"heading":"What we learned","content":"Throughout this project, we built a complete multi-modal AI assistive memory system integrating Raspberry Pi 3 hardware with a Logitech webcam for real-time facial recognition, Flask REST APIs for backend services, MongoDB for storing 128-dimensional face embeddings and timeline events, and AI services including OpenAI Whisper for transcription, Grok for video/audio summarization, and ElevenLabs for text-to-speech with the Matilda voice. We mastered end-to-end system architecture - from edge computing (offloading embedding extraction to the Pi) to API orchestration (coordinating 5 different services) to implementing cosine similarity search for face matching. Key technical skills gained include handling multipart file uploads in Flask, designing MongoDB schemas for ML applications, prompt engineering for concise AI outputs, managing API keys securely with .env files, debugging platform-specific issues (Python 3.14 + ARM Mac compatibility), and building modular codebases that separate concerns across hardware integration, database operations, and AI service calls"},{"heading":"What's next for Recall","content":"Moving forward, we plan to make Recall more seamless, intelligent, and scalable. Our next steps include integrating lightweight on-device models optimized for the Raspberry Pi to reduce dependency on remote servers and improve offline reliability. Another focus is expanding multimodal understanding and enabling Recall to interpret not just speech, but emotional tone and contextual cues, helping it respond more compassionately and naturally. Finally, with access to better hardware, we hope to reduce the form factor of Recall to make it more convenient to use in day-to-day life."},{"heading":"Built With","content":"grok nextjs ngrok openai opencv python raspberrypi typescript"},{"heading":"Try it out","content":"github.com www.canva.com"}]},{"project_title":"terrar.ai","project_url":"https://devpost.com/software/terrar-ai","tagline":"AI agents in Terraria to assist with building, mining, and boss fights. Share your health with them more agents, more risk. AI adapts to every situation, making every choice crucial.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/956/702/datas/medium.jpg","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Grok for Real-Time Data/Signal Analysis by xAI"}],"team_members":[],"built_with":[{"name":"c#","url":"https://devpost.com/software/built-with/c--2"},{"name":"grok","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/SlothfulDreams/terrar.ai"}],"description_sections":[{"heading":"What Drove Us","content":"This was largely an uncharted territory for us. Neither had ever modded a game, let alone any experience making games. We wanted to push the boundaries of what's possible in a sandbox game, and Terraria was the perfect avenue for it.\n\nAt the same time, prior to this hackathon, we had seen many success stories about AI agent integration in other games, namely Chess, Poker, and Minecraft, which inspired us to do the same for an arguably more complex game, Terraria. And we were very happy to do so. For the past few decades, pre-programmed NPCs have ruled over the game dev scene. We're firm believers that AI game agents will cause a big shift in an otherwise constant landscape. When that happens, we'll be overjoyed to see terrar.ai as the first step into that giant leap."},{"heading":"What We Learned","content":"We quickly learned that building real-time, context-aware agents require only the FASTEST inference, and no large amount of latency will do if we aim for a smooth AI experience. Further, without a background in video games nor C#, we were very glad to leverage the SDKs available to us: first, tModLoader , which enabled us to \"speak\" to Terraria, and second, xAI for inference. Learning the ropes became easy once we learned to reference the documentation closely. We also learned that taking breaks is both efficient and healthy . Coming back to a hard problem with a fresh set of eyes is what allowed us to stay on our A game. :)"},{"heading":"How We Built It","content":"tModLoader : We used tModLoader , an open-source framework that allows for modding Terraria using C#. This provided the foundation for integrating custom game agents. AI Backend - Grok by xAI : We chose Grok for its low-latency, high-speed inference, ensuring our agents could make decisions quickly and maintain a smooth gameplay experience. ReAct Framework : The agents were built using the ReAct framework, which allows them to reason , act , observe , and replan . This made our agents adaptive and able to respond intelligently to player actions and game dynamics."},{"heading":"Challenges We Faced","content":"No Native LangChain Support for C# : There was no dedicated Agents SDK for C# in the context of Terraria modding, so we had to create our own solution from scratch, which was admittedly very hacky. Unfamiliar Terrain : One of us had never even played Terraria, which made understanding the game mechanics and how to best integrate the agents a significant challenge. LLM Inconsistency & Latency Issues : We faced problems with inconsistent outputs from large language models (LLMs) and high latency, especially during intense gameplay moments like boss fights. Ensuring that agents made decisions quickly enough without disrupting the flow of the game was a constant balancing act."},{"heading":"Conclusion","content":"Despite these obstacles, we succeeded in creating the first dynamic AI agents for Terraria, bringing new strategic depth to the game. Terrar.ai gives players the ability to deploy AI companions who adapt to the situation, making every decision a calculated risk. Every summon, every move, and every agent deployed has a direct impact on gameplay transforming Terraria into a cooperative, AI-enhanced experience.\n\nSlides: https://gamma.app/docs/terrarai-9s4xii0ndqb3aa8"},{"heading":"Built With","content":"c# grok"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Dielectric","project_url":"https://devpost.com/software/dielectric","tagline":"Dielectric uses computational geometry and xAI Api and multimodal agentic ai to automate PCB workfllows","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Grok for Real-Time Data/Signal Analysis by xAI"}],"team_members":[],"built_with":[{"name":"kicad","url":null},{"name":"mcp","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"xai","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"I've been designing PCBs for years and worked on novel ML for automating computer architecture design over the summer, but have not came across good thermal management tools for automating PCB design with AI. Also saw the YC batch 2018 company JITX and wanted to design better PCB automation software than them using modern AI and reasoning tools."},{"heading":"What it does","content":"Dielectric uses computational geometry algorithms (Voronoi diagrams, Minimum Spanning Trees, Convex Hull analysis) combined with xAI reasoning to automate PCB design from natural language to production-ready KiCad files. The system analyzes component distribution, estimates optimal trace routing, detects thermal hotspots, and optimizes placement using a multi-agent architecture. Engineers can describe their PCB in plain English (e.g., \"Design a multi-module audio amplifier with thermal management\"), and the system automatically generates optimized layouts that are 2,000x faster than manual design."},{"heading":"How we built it","content":"Backend: FastAPI with Python 3.12+, using NumPy, SciPy, and Shapely for computational geometry \\ AI Integration: xAI Grok API for natural language understanding and reasoning over geometric data structures \\ Optimization Engine: Simulated annealing with incremental scoring for real-time performance (<500ms for interactive optimization) \\ Geometry Pipeline: Voronoi diagrams for component distribution analysis, MST for trace length estimation, Convex Hull for board utilization, and Gaussian thermal models for hotspot detection Knowledge Graph: Component relationship database that automatically identifies modules and applies design patterns \\ Export: Production-ready KiCad format with proper net connections and multi-layer support"},{"heading":"Challenges we ran into","content":"Integrating computational geometry with AI: Feeding geometric data structures (Voronoi, MST) into xAI required careful prompt engineering to make the AI understand spatial relationships and optimization trade-offs. Scaling to large PCBs: Handling 100+ component designs required hierarchical abstraction‚Äîwe implemented automatic module identification using Voronoi clustering and hierarchical optimization (modules ‚Üí components). Real-time performance: Making optimization fast enough for interactive UI (<500ms) while maintaining quality required incremental scoring, caching, and a fast-path/slow-path architecture. Deterministic optimization: Ensuring same input always produces same output required seeding random number generators from user intent hashes. Visualization complexity: Plotly subplot errors when displaying multiple computational geometry visualizations simultaneously‚Äîfixed by properly structuring trace additions. Fabrication constraints: Implementing real-world PCB manufacturing limits (trace width, spacing, via sizes) and validating against industry standards."},{"heading":"Accomplishments that we're proud of","content":"First computational geometry ‚Üí xAI pipeline: First system to feed Voronoi diagrams, MST, and Convex Hull data directly into AI reasoning for PCB optimization. \\ Multi-agent architecture: Built 5 specialized agents (IntentAgent, LocalPlacerAgent, VerifierAgent, ErrorFixerAgent, DesignGeneratorAgent) that work together like a team of engineers. \\ Production-ready export: Generates KiCad files with proper net connections, multi-layer support, and manufacturing-ready output."},{"heading":"What we learned","content":"Computational geometry provides structure for AI: Geometric algorithms (Voronoi, MST) create interpretable data structures that AI can reason over, bridging symbolic and neural approaches. \\ Natural language + geometry = powerful: Combining human intent (natural language) with rigorous mathematical analysis (computational geometry) creates a system that's both intuitive and technically sound. \\"},{"heading":"What's next for Dielectric","content":"Enhanced thermal modeling: Full 3D thermal simulation with ANSYS/COMSOL integration for accurate temperature prediction and heatsink optimization. \\ Signal integrity constraints: Add high-speed signal analysis (impedance matching, length matching, crosstalk) to the computational geometry pipeline. \\ Automated simulation integration: Direct integration with thermal and signal integrity simulators for closed-loop optimization."},{"heading":"Built With","content":"kicad mcp python xai"}]},{"project_title":"Better","project_url":"https://devpost.com/software/bettr-9rb71p","tagline":"Bet on a better you. Turn your goals into reality by staking money on your commitments. Let friends support your journey and prove you can achieve anything.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/961/257/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Build on the Knot TransactionLink API by Knot API"}],"team_members":[],"built_with":[{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"knotapi","url":null},{"name":"nessieapi","url":null},{"name":"next.js","url":null},{"name":"swiftui","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"xcode","url":"https://devpost.com/software/built-with/xcode"}],"external_links":[{"label":"github.com","url":"https://github.com/mravaloarison/Better-Princeton-version.git"},{"label":"github.com","url":"https://github.com/mravaloarison/Bettr-ios-princeton-version/tree/main/Better"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAG4KeLjbec/-uARXZyH5gOHSPWcNiFCiQ/edit?utm_content=DAG4KeLjbec&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"}],"description_sections":[{"heading":"Inspiration","content":"As college students, we have many things that we want to do, but we may lack the motivation to do them. What if there was an app that encouraged you to finish your goals? Better was created to bridge that gap between intention and action by introducing accountability, community, and financial incentives."},{"heading":"What it does","content":"Better is both a mobile app and website that encourages users to accomplish their goals by allowing users to place financial stakes on the goals they want to complete. Friends can support each other by financially contributing to these goals, capping out at the amount the user puts up with their goal. When a user creates a goal, their objective is to complete it within the deadline they set.\n\nIf a user is successful : They win back the amount they staked, plus the money contributed by their friends. If a user is unsuccessful : Friends get their donated money refunded back to them, plus another 100% of what they donated (paid out by the stake from the user). Any remaining funds go toward a charity they selected.\n\nOur mission is to promote accountability, both toward personal goals and financial responsibility, to ultimately increase follow-through and long-term compliance."},{"heading":"How we built it","content":"Frontend:\n\niOS app: Built using SwiftUI . Web app: Built using TypeScript with Next.js . Handles the user interface for creating and viewing goals, making contributions, and interacting with friends.\n\nBackend:\n\nNessie API: Simulates payments for staking on goals or contributing to friends‚Äô goals. Knot API: Allows users to sign in to their preferred merchants for purchase-related goals to ensure accountability. Firebase: Stores all posts made on both platforms. Updates user feeds in real time. Tracks and manages users‚Äô network of friends."},{"heading":"Challenges we ran into","content":"We encountered several challenges along the way. One of our main concerns was ensuring that our explanation of the product wasn‚Äôt overly complex, given how nuanced the idea is.\n\nAdditionally, we wanted to provide a consistent UX between all our features between IOS and the web. This created challenges in delegation and integration, as we had to create both a native IOS app and a web app, forcing us to be realistic about which features prioritize."},{"heading":"Accomplishments that we're proud of","content":"We are proud that we were able to build a functional and cohesive product in a short timeframe. We successfully integrated multiple technologies and languages that most of us have never used before. In addition to its functionality, we were able to keep the design, UI, and UX relatively consistent and appealing."},{"heading":"What we learned","content":"We learned how important clarity is when communicating a multi-layered idea like Better. We practiced simplifying complex workflows into digestible, compartmentalized pieces. This allowing us to gained experience in full-stack development and collaborative Git workflows. Most specifically, we were able to gain a lot of experience from integrating Knot API, Nessie API , and Firebase."},{"heading":"What's next for Better","content":"Moving forward, we want to expand Better in several directions:\n\nAdding social features such as comments, streaks, and progress feeds Enhancing analytics so users can visualize their growth and financial patterns Introducing AI-driven goal suggestions and progress tracking Continue developing ways to verify completion of a goal"},{"heading":"Built With","content":"firebase knotapi nessieapi next.js swiftui typescript xcode"},{"heading":"Try it out","content":"github.com github.com www.canva.com"}]},{"project_title":"PiggyBank","project_url":"https://devpost.com/software/tbd-9clz1k","tagline":"Money that talks","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/948/742/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Build on the Knot TransactionLink API by Knot API"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Exploring Hybrid Intelligence by Photon"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of DigitalOcean Gradient AI by MLH"}],"team_members":[],"built_with":[{"name":"capital-one","url":"https://devpost.com/software/built-with/capital-one"},{"name":"chatbot","url":null},{"name":"clerk","url":"https://devpost.com/software/built-with/clerk"},{"name":"dedalus","url":null},{"name":"digitalocean","url":"https://devpost.com/software/built-with/digitalocean"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"heart","url":null},{"name":"knot","url":null},{"name":"llama","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"oauth","url":"https://devpost.com/software/built-with/oauth"},{"name":"openai","url":null},{"name":"photon","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"snowflake","url":null},{"name":"sql","url":"https://devpost.com/software/built-with/sql"}],"external_links":[{"label":"github.com","url":"https://github.com/HackPrincetonQANT/backend-frontned-agent-alltogether"}],"description_sections":[{"heading":"üí° Inspiration: The Invisible Spending Problem","content":"We built PiggyBank because personal finance has quietly become one of the biggest sources of everyday stress.\n\nMost people don‚Äôt struggle because of big, one-time purchases. They struggle because of the tiny, invisible habits ‚Äî a $6 coffee here, a $12 delivery there ‚Äî that quietly drain financial confidence and compound stress over time.\n\nThe Financial Anxiety Data\n\n65% of Americans live paycheck to paycheck. (LendingClub, 2024) 77% of adults feel anxious about money. (APA, 2023) 59% of Gen Z and Millennials admit to impulse purchases. (Credit Karma)"},{"heading":"üéØ Use Case: Awareness in the Moment","content":"We built Piggy to do more than just track spending ‚Äî it‚Äôs an agent quietly working in the background, learning your financial habits and helping you make smarter choices.\n\nImagine this: you tap your card at Starbucks, and Piggy takes note. Over time, it learns that you grab coffee every day around 8 a.m. Since Piggy is designed to understand your behavioral patterns, it predicts when your next purchase is coming ‚Äî and before you buy(say at 7.30), it sends a friendly iMessage nudge:\n\n‚ÄúHey, maybe try a cheaper alternative like Wawa today? You ould be a day closer to your new bike that you are saving for.‚Äù\n\nYou reply, and Piggy keeps learning. Soon, it‚Äôs not just tracking your spending ‚Äî it‚Äôs helping you visualize how small choices add up. Instead of cutting out your morning coffee entirely, Piggy helps you see how redirecting those savings could make your new $250 bike a reality faster than you thought.\n\nPiggy doesn‚Äôt guilt-trip you ‚Äî it guides you, helping you reflect at the moment when awareness matters most.\n\nAlso, to reduce user friction, if you do an in-person purchase AKA have receipts, just text them to piggy, and he'll handle the rest! Super Simple!"},{"heading":"‚ú® What It Does: A Real-Time Financial Conscience","content":"PiggyBank is a real-time spending coach powered by a feedback loop that connects your transactions to a conversational agent.\n\nCore Functionality\n\nItem-Level Transaction Ingestion: Uses the Knot ** Production **TransactionLink API to ingest granular, item-level purchase data into Snowflake securely.\n\nReal-Time Classification & Feedback: Each purchase triggers a real-time loop:\n\nThe backend uses Dedalus to classify the item (Need/Want). Sends a personalized message via Photon to your iMessage for quick feedback. Your reply fine-tunes Piggy‚Äôs predictions.\n\nProactive Prediction: Detects recurring spends and sends nudges before they happen.\n\nMultimodal Receipt Processing: Powered by Gemini 2.5 Flash ‚Äî users can snap a photo of a receipt, and Piggy instantly extracts structured data via OCR.\n\n‚ÄúOink oink! I‚Äôve analyzed your receipt from Courtyard by Marriott. Total: $23.67. Saved to your tracker!‚Äù\n\nContextual Chat Assistant: A GPT-4‚Äìpowered chat assistant that reads live Snowflake history to answer:\n\n‚ÄúHow much did I spend on coffee this month?‚Äù or ‚ÄúWhat could I cut to save $50 next week?‚Äù"},{"heading":"üß† How Our Algorithm is Made (Deployed on DigitalOcean)","content":"Our predictive and conversational intelligence layer runs on a modular, serverless architecture using DigitalOcean Gradient AI .\n\n1. Data Foundation & Feature Store (Snowflake)\n\nAll transaction data and user feedback are stored in Snowflake, serving as the feature store where SQL queries and vector search aggregate behavioral patterns.\n\n2. Predictive Behavior Model (DigitalOcean Gradient AI)\n\nLlama 3.1 is deployed to intelligently ingest these datapoints and predict when the next purchase is likely to occur, allowing the agent to proactively trigger timely recommendations. With the help of Python data processing and Snowflake time-series model analyzes each user‚Äôs purchase history, computes typical intervals between repeat buys, and produces a numeric next-purchase timestamp plus confidence. Piggy analyzes factors such as the size of previous orders (e.g., whether a grocery trip typically covers a week or a month) and historical spending frequency to forecast upcoming transactions with high accuracy.\n\n3. Classification & Logic (Dedalus Labs)\n\nDedalus handles initial transaction classification and confidence scoring before engaging users via Photon.\n\n4. Multimodal Processing (Gemini API)\n\nReceipt image processing via Gemini 2.5 Flash enables OCR and JSON extraction before saving structured data to Snowflake."},{"heading":"üõ†Ô∏è Tech Stack","content":"Layer Technologies Key Use Backend / API FastAPI (Python), Flask, Node.js Microservices, RESTful endpoints, Core Analytics Data Warehouse Snowflake Central time-series storage and analytics Integrations Knot API, Clerk Auth Secure item-level data ingestion, Auth Conversational AI Photon, iMessage SDK Real-time chat, proactive alerts Intelligence Gemini 2.5 Flash, Dedalus, GPT4, Llama 3.1, DO Gradient AI OCR, Classification, Prediction Frontend React (Vite), Clerk Auth Dashboard and visualization"},{"heading":"üèÜ Special Tracks and Prizes","content":"Prize Name what we did for every track Best Practical AI Innovation by Amazon Practical AI agent that improves real-world financial outcomes. Best Financial Hack by Capital One Provides actionable coaching that translates abstract numbers into savings goals. Build on the Knot TransactionLink API by Knot API Uses Knot for secure, item-level data granularity. Exploring Hybrid Intelligence by Photon True Hybrid Agent integrating Node.js front-end and Python backend. Best Use of Dedalus by Dedalus Labs Powers classification and confidence scoring for precise messaging. Best Predictive Intelligence by Chestnut Forty Forecasts future spends to power core agent functionality. Best Use of Gemini API by MLH Uses Gemini 2.5 Flash for accurate OCR-based receipt parsing. Best Use of DigitalOcean Gradient AI by MLH Deploys predictive model on Gradient AI platform. Best Use of Snowflake API by MLH Snowflake serves as the high-performance data backbone."},{"heading":"üöÄ Accomplishments We‚Äôre Proud Of","content":"Achieved a fully functional MVP with real-time classification, messaging, and prediction. Developed a predictive commerce layer that forecasts recurring purchases. Integrated a dynamic multimodal conversational interface (Photon + Gemini). Built a scalable architecture ready for fintech deployment."},{"heading":"‚è≠Ô∏è What‚Äôs Next: From Nudger to Navigator","content":"Piggy will evolve from a coach into a proactive financial navigator:\n\nForesight Meets Automation: Detect savings patterns and reallocate funds automatically. Money Duolingo: Gamifies savings habits through streaks and literacy levels. Embeddable Coach: Offered as a plug-in for banks and fintechs via secure APIs.\n\noink oink!"},{"heading":"Built With","content":"capital-one chatbot clerk dedalus digitalocean flask gemini heart knot llama node.js oauth openai photon python snowflake sql"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Wings","project_url":"https://devpost.com/software/wingpay","tagline":"Finance is a dynamic equilibrium. Our credit and spending advisory layer supports sustainable borrowing and proactive guidance - so you feel supported, not stretched or stressed.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/955/868/datas/medium.jpg","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Exploring Hybrid Intelligence by Photon"}],"team_members":[],"built_with":[{"name":"dedalus","url":null},{"name":"imessagekit","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"knot","url":null},{"name":"nessie","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"snowflake","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/leowang2004/hackprinceton2025"}],"description_sections":[{"heading":"Inspiration","content":"Traditional credit systems exclude people without long credit histories especially new immigrants and young earners. We wanted to rethink credit as something dynamic, based on both real financial behavior and bank statements. Our goal: support people when they deserve more credits, and guide them when they‚Äôre stretched, creating healthier financial health instead of stress."},{"heading":"What it does","content":"Our platform provides real-time lending and spending guidance based on the user‚Äôs current financial capacity, not just their past credit history.\n\nWe securely aggregate financial data (bank transactions, income patterns, cash flow signals, detailed spending breakdowns), a wide data modality that most traditional bureau and institutions don‚Äôt capture. A dynamic credit model evaluates the user‚Äôs financial health and credit worthiness in real time. When the user is in a healthy financial state, the app extends credit that they can confidently afford. When spending behavior indicates risk or overspending, the app shifts to advice mode, offering tailored recommendations to help the user avoid financial stress.\n\nThe result is an experience where users feel: supported, not judged & in control, not overwhelmed\n\nAnd for lenders, we offer smarter credit allocation, reduced default risk, and deeper trust and hyper-targeted interaction and advertising with customers through our iMessage interface."},{"heading":"How we built it","content":"Our system integrates multi-source financial data with an iMessage-based AI chatbot to provide personalized credit insights and analytics.\n\nThe frontend handles user authorization and initiates authentication flows. The backend retrieves and aggregates users‚Äô transaction histories from multiple merchants via KnotAPI, while Capital One‚Äôs Nessie API verifies user identity through card-linking data and synchronizes linked accounts and transactions. After all transaction data is standardized, it is fed into a weighting model trained on large-scale datasets to generate a credit score and recommend an appropriate loan amount.\n\nAn iMessage Chatbot, implemented in Node.js with the Photon AI iMessage Kit (@photon-ai/imessage-kit), continuously monitors incoming iMessages, routes them to the chatbot backend for processing, and sends intelligent replies through the native Apple Messages app. The chatbot also retrieves each user‚Äôs transaction records from KnotAPI for real-time financial insights and query responses."},{"heading":"Challenges we ran into","content":"Idea: We began with a broad idea of building a general ‚Äúfinancial tool,‚Äù but quickly recognized a specific challenge in the BNPL space: the push for transaction volume often conflicts with vague and inconsistent credit evaluation. From there, we narrowed our focus to something both meaningful and achievable‚Äîhelping individuals improve everyday financial wellness. Our solution offers flexible credit informed by our own scoring model, which combines traditional bank statement data with detailed spending patterns. The system then provides gentle, real-time nudges to guide healthier financial decisions.\n\nTechnical friction:\n\nDedalus Labs only exposes a production-ready Python SDK, so we built a FastAPI bridge so the Node chatbot could call those GPT‚Äë5-class models and MCP servers. Nessie‚Äôs API is backed by legacy documentation, so a lot of trial-and-error was needed before we got clean bill/loan/deposit data we could pipeline. We pulled data from multiple schemas (Knot transactions, Nessie endpoints) and standardized it in Snowflake, then leaned on Cortex to generate SQL/NLP insights on top.\n\nTeam logistics: We divided up work with everyone‚Äôs hardware and technical background in mind (some people on macOS with iMessage, others focused on backend/data). Because changes were happening in parallel, we had frequent Git merges and conflict resolution to keep the branches in sync."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud of how quickly we explored, tested, and refined new ideas in real time. As the project evolved, we adapted to the APIs and data we had, staying flexible when our original plans changed. But most of all, we‚Äôre proud of the way we worked together challenging each other‚Äôs thinking, learning from one another, and genuinely enjoying the process (with plenty of matcha/coffee and laughter along the way)."},{"heading":"What we learned","content":"We learned how to plan effectively under a tight time limit‚Äîmaking deliberate choices about what to build and what to cut so we could focus on a clear flagship feature. We also learned how to collaborate efficiently, divide tasks based on strengths, and communicate openly when priorities shifted. And importantly, we learned to ask for help: talking with mentors and judges early gave us valuable insight into their APIs and helped us shape a better product in less time."},{"heading":"What's next for wingPay","content":"Our next phase focuses on bringing AI agents deeper into users‚Äô financial decision-making‚Äîwhile maintaining a human-in-the-loop as the ultimate source of trust and oversight. We plan to:\n\nCollaborate with traditional credit bureaus to refine the credit model to better reflect new financial behaviors and non-traditional income patterns (e.g., immigrants, freelancers, creators) Increase transparency so users can understand why they‚Äôre approved, advised, or warned, reducing the feeling of opaque ‚Äúcredit judgment.‚Äù Expand advisory features that guide users toward long-term financial well-being, not just short-term credit access. Our goal is to move toward more inclusive and accurate credit evaluation ecosystem - one that adapts with people‚Äôs lives instead of locking them into their past."},{"heading":"Built With","content":"dedalus imessagekit javascript knot nessie node.js openai python react snowflake"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"doeve","project_url":"https://devpost.com/software/do-eve","tagline":"use imessage to control your computer, complete tasks, and do anything you want hands-free","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/954/389/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Exploring Hybrid Intelligence by Photon"}],"team_members":[],"built_with":[{"name":"anthropic-api","url":null},{"name":"claude-3.5-sonnet","url":null},{"name":"elevenlabs","url":null},{"name":"fastapi","url":null},{"name":"httpx","url":null},{"name":"imessage-sdk","url":null},{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"photon","url":null},{"name":"pyautogui","url":null},{"name":"pydantic","url":null},{"name":"pyobjc","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"uvicorn","url":null},{"name":"websocket","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/adhvaidhsunny/doeve"}],"description_sections":[{"heading":"Built With","content":"anthropic-api claude-3.5-sonnet elevenlabs fastapi httpx imessage-sdk langchain langgraph node.js opencv photon pyautogui pydantic pyobjc python typescript uvicorn websocket"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"TextFly","project_url":"https://devpost.com/software/textfly","tagline":"Text Hey Flub to flub@textfly.tech! Flub is your AI flight agent that monitors real-time events to predict delays and cancellations before they happen","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/987/890/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Exploring Hybrid Intelligence by Photon"},{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Vibe Kanban by Vibe Kanban"}],"team_members":[],"built_with":[{"name":"ai","url":null},{"name":"anthropic","url":null},{"name":"openai","url":null},{"name":"photon","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"x","url":null}],"external_links":[{"label":"textfly.tech","url":"http://textfly.tech"},{"label":"github.com","url":"https://github.com/TextFly"},{"label":"github.com","url":"https://github.com/TextFly/flub-agent"},{"label":"github.com","url":"https://github.com/TextFly/flub-web"},{"label":"github.com","url":"https://github.com/TextFly/X-mcp"},{"label":"github.com","url":"https://github.com/TextFly/fast-flights-mcp"},{"label":"github.com","url":"https://github.com/TextFly/photon-imsg-mcp"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by recent events involving widespread flight delays and cancellations caused by the ongoing government shutdown. To address this issue, we set out to create an AI-driven solution that operates entirely through text messaging‚Äîno apps, no downloads, just seamless communication through your phone‚Äôs native messenger."},{"heading":"What it does","content":"With TextFly, you can simply message textfly@tech and get instant, accurate responses to your flight- or travel-related questions ‚Äî all through text, with no app or downloads required. TextFly goes beyond standard LLMs by using our proprietary multi-agent pipeline, which allows different AI agents to interact with specialized tools. This enables it to: Predict flight delays using real-time Twitter data, Check weather conditions across cities to help you avoid risky travel plans and Provide comprehensive travel insights, all through a simple text conversation"},{"heading":"How we built it","content":"We built TextFly using the Photon SDK, which enabled us to seamlessly handle incoming and outgoing user messages. At the core of our system is an orchestrator agent, the main controller responsible for managing the entire conversation flow. The orchestrator agent coordinates with several specialized sub-agents, each equipped with access to various MCP tools. These sub-agents can be called in parallel to handle specific tasks, such as data retrieval or analysis. When appropriate, the orchestrator can also choose to handle a request independently without invoking any sub-agents, ensuring efficient and adaptive performance."},{"heading":"Challenges we ran into","content":"We had a challenge making MCP's on Dedalus. The ones we made only functioned locally not online. Even after attempting to publish the MCP's we made, they couldn't be published."},{"heading":"Accomplishments that we're proud of","content":"The team is proud of building the MCP integration that powers the project‚Äôs backend connections. They‚Äôre also proud of designing and developing a responsive landing page that clearly communicates the product‚Äôs vision. As a team, they took initiative in leading collaboration across multiple components and ensuring all parts came together smoothly. Most of all, they‚Äôre proud of successfully completing the project from start to finish."},{"heading":"What we learned","content":"We learned how to create AI agents. We learned how to make MCP's. We learned how to make diagrams for complex agentic workflows. Specifically ones that can interact in almost real time applications, as well as deal with unpredictable inputs."},{"heading":"What's next for Textfly","content":"To explore monetization routes using targeted ads. Think how google charges companies to be placed higher in search. We want to expand over to hotel bookings and other travel bookings."},{"heading":"Built With","content":"ai anthropic openai photon python typescript x"},{"heading":"Try it out","content":"textfly.tech github.com github.com github.com github.com github.com github.com"}]},{"project_title":"Messenger AI","project_url":"https://devpost.com/software/messenger-ai","tagline":"We teach AI to use your group chat.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/959/357/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Exploring Hybrid Intelligence by Photon"}],"team_members":[],"built_with":[{"name":"dedaluslabs","url":null},{"name":"photon","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"www.messengerai.tech","url":"https://www.messengerai.tech/"}],"description_sections":[{"heading":"Inspiration","content":"What inspired us was the idea of supercharging group conversations, whether you're cramming for exams with your friends and wanna ask AI to text you summaries, answers, or create memes to send to your friends!"},{"heading":"What it does","content":"Start our agent supercharged by Photon's I-Message Kit and Dedalus Labs, and the agent automatically reads in texts, pdfs, images, etc. to enrich your conversations!"},{"heading":"How we built it","content":"We built this using Python, Dedalus Labs, and TypeScript!"},{"heading":"Challenges we ran into","content":"We ran into multiple challenges. We spent a lot of time trying to figure out how to support sending messages to group conversations and any ways we could have Photon be added to the conversation like an extra contact."},{"heading":"Accomplishments that we're proud of","content":"We're proud to be able to have our agent supercharged by the context of the conversation and be able to dynamically answer questions based on what it's seen."},{"heading":"What we learned","content":"We learned Object-Oriented-Design principles, how to use Dedalus Labs & Photon's I-Message Kit, TypeScript, and Python!"},{"heading":"What's next for Messenger AI","content":"We want to add support and let the agents do more. Hopefully when the I-Message Kit supports sending to group messages it'll be even more convenient for our users!"},{"heading":"Built With","content":"dedaluslabs photon python typescript"},{"heading":"Try it out","content":"www.messengerai.tech"}]},{"project_title":"AI BnB","project_url":"https://devpost.com/software/ai-bnb","tagline":"AI BnB: The optimal way to plan your stay.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/957/378/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Dedalus by Dedalus Labs"}],"team_members":[],"built_with":[{"name":"dedaluslabs","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"next.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"supabase","url":null},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/yoge1212/hackathon"}],"description_sections":[{"heading":"Inspiration","content":"As travelers, our group loathes planning process when it comes trips. Especially for trips that are longer in length, it takes a lot of time trying to source properties (Airbnbs) to stay in during the trip and being able to plan out exciting places to visit. We also sympathize with home renters, who have to engage in a lot of busy work in creating a listing just to make properties available. This being the case, we wanted to create AI BnB, which is an all in one AI utility that can be utilized by both travelers and home renters alike."},{"heading":"What it does","content":"AI BnB streamlines the traveling process, allowing users to speak with a chatbot about what they are looking for in a trip (ex. destinations, number of people, budgets, activities, etc.) Taking all this information, our bot will create a traveling plan with an optimal set of AI BnB properties they can rent during the duration of their trip. We streamline the process for people to list their houses as well, where a listing can be generated after pictures of each room of the property are provided to our application. We also streamline collaborative trip planning as well, allowing people to invite each other to trips, and pitch in ideas for things to do on the trip, which our bot will combine together into a trip everyone can enjoy."},{"heading":"How we built it","content":"For this application, we created these functionalities within a web application built on React + Next.js, with a Flask (Python) backend and Supabase database. In addition to these languages and frameworks, we utilized DedalusLabs very useful AI tools for streamlining usage of agentic AI and MCP servers."},{"heading":"Challenges we ran into","content":"There were many struggles that came in creating this project, especially as a group of only two hackers. But nothing worthwhile comes easy. We had to spend the last two days battling with debugging environments and incompatible library versions. We had to use technologies we were never familiar with, such as agentic AI, to implement our product. And being able to balance such a big project amongst two people was challenging in being able to delegate UI, backend, database, and AI related tasks amongst ourselves in being able to create this bigger product."},{"heading":"Accomplishments that we're proud of","content":"We are really proud that we were able to create something that is so practical and solves a real problem many face. In addition, it is a marvel that we were able to make a full-fledged application capable of creating these trips whilst having two people. The level of coordination we were able to achieve in being able to communicate, collaborate, work through adversity and ultimately achieve success was very satisfying, and we are very proud to have achieved what we did in 36 hours."},{"heading":"What we learned","content":"When going into this hackathon, we wanted to create something different that wasn't done before. And in doing so, we had to learn how to be creative and try new things. We learned more about agentic ai and how useful it is in mediating and automating tasks. We learned about user design, taking feedback from many mentors at the hackathon. The biggest thing was learning to be okay with asking for help. We"},{"heading":"What's next for AI BnB","content":"We want this to be a full-fledged application that is accessible to as many people as possible, so it can make more happy and satisfied in their trip planning. That being the case, we want this application to come to mobile, where it can be available on people's iphone and android devices."},{"heading":"Built With","content":"dedaluslabs docker flask javascript next.js python react supabase tailwindcss typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"SpatialMD","project_url":"https://devpost.com/software/spatialmd","tagline":"Surgical AR guidance system that enables remote experts to guide rural surgeons by annotating 3D reconstructions that appear as AR overlays on live video.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/955/873/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Dedalus by Dedalus Labs"}],"team_members":[],"built_with":[{"name":"canvas-api","url":null},{"name":"claude-sonnet","url":null},{"name":"dedalus-labs-ai-framework","url":null},{"name":"fastapi-(python)","url":null},{"name":"gpt-4-vision","url":null},{"name":"ibm-plex-typography","url":null},{"name":"mediapipe","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"react-18","url":null},{"name":"rest-apis","url":null},{"name":"three.js-(react-three-fiber)","url":null},{"name":"webrtc","url":"https://devpost.com/software/built-with/webrtc"},{"name":"yolov8","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Aaryaman3/FixIt"}],"description_sections":[{"heading":"Inspiration","content":"The global healthcare disparity is staggering. While urban centers have access to specialized surgical expertise, rural hospitals often lack experienced surgeons for complex procedures. This creates a critical gap: how can we bring expert surgical guidance to regions where specialists are scarce?\n\nOur inspiration came from observing that modern technology has solved similar problems in other fields:\n\nRemote collaboration works seamlessly in software development Real-time visualization powers autonomous vehicles AI-powered decision support assists in countless domains\n\nYet surgery‚Äîone of the most critical human interventions‚Äîremains largely isolated and local. We asked: What if we could bridge the expertise gap using AR, AI, and 3D reconstruction?\n\nSpatialMD was born from this vision: a surgical guidance system that transforms how surgical knowledge is shared across distances."},{"heading":"üí° What It Does","content":"SpatialMD is a real-time surgical AR guidance platform that combines three core technologies:\n\n1. 3D Reconstruction & Planning\n\nUsing computer vision and 3D Gaussian Splatting, the system:\n\nCaptures surgical scenes through standard cameras Reconstructs 3D models of anatomical structures Enables experts to identify and annotate critical structures (vessels, nerves, targets) Creates a shared 3D workspace for preoperative planning\n\n2. AI-Powered Safety Analysis\n\nA multi-factor AI safety engine evaluates surgical approaches using:\n\n$$\\text{Safety Score} = 0.40 \\times S_{\\text{vessel}} + 0.30 \\times S_{\\text{geometry}} + 0.15 \\times S_{\\text{depth}} + 0.15 \\times S_{\\text{approach}}$$\n\nWhere each factor $S_i \\in [0, 1]$ represents:\n\nVessel Proximity (40%): Distance to critical vascular structures (measured in mm) Geometric Safety (30%): Approach angle and trajectory optimization Tissue Depth (15%): Penetration depth and layered structure assessment Approach Feasibility (15%): Surgical access corridor viability\n\nThe system provides traffic-light recommendations :\n\nüü¢ Safe ($S > 0.80$): Approved for execution üü° Caution ($0.60 \\leq S \\leq 0.80$): Proceed with monitoring üî¥ Specialist Required ($S < 0.60$): Escalate to senior surgeon\n\n3. Real-Time AR Overlay\n\nThe system projects guidance directly onto the surgeon's view:\n\nLive distance measurements to targets (mm precision) Clearance monitoring from critical structures Tracking status with 30 FPS object detection Warning systems for proximity alerts"},{"heading":"üõ†Ô∏è How We Built It","content":"Architecture Overview\n\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Medical-Grade Frontend ‚îÇ ‚îÇ React 18 + Three.js + MediaPipe ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ PREOPERATIVE ‚îÇ REAL-TIME ‚îÇ AI DECISION ‚îÇ ‚îÇ PLANNING ‚îÇ GUIDANCE ‚îÇ SUPPORT ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚Ä¢ 3D Viewer ‚îÇ ‚Ä¢ AR Video Feed ‚îÇ ‚Ä¢ Safety Analysis ‚îÇ ‚îÇ ‚Ä¢ Structure ID ‚îÇ ‚Ä¢ HUD Overlay ‚îÇ ‚Ä¢ Risk Factors ‚îÇ ‚îÇ ‚Ä¢ Path Plan ‚îÇ ‚Ä¢ Distance Track ‚îÇ ‚Ä¢ Recommendations ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚Üì ‚Üì ‚Üì Three.js MediaPipe/YOLO GPT-4/Claude ‚Üì ‚Üì ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ FastAPI Backend ‚îÇ ‚îÇ Python + OpenCV + Computer Vision Pipeline ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nTechnology Stack\n\nFrontend (Medical-Grade UI)\n\nReact 18 : Modern component architecture for surgical console Three.js + React Three Fiber : Hardware-accelerated 3D rendering MediaPipe/YOLO : Real-time object detection at 30 FPS Custom Medical Design System : IBM Plex Sans/Mono typography (clinical readability) Surgical color palette (#0A0E14 background for reduced eye strain) Traffic light safety indicators (green/orange/red)\n\nBackend (AI & Processing)\n\nFastAPI : High-performance async Python framework Dedalus Labs AI Framework : Multi-model orchestration for surgical analysis GPT-4 Vision / Claude Sonnet : AI safety analysis via Dedalus OpenCV : Computer vision and image processing NumPy : Numerical computations for 3D geometry\n\nComputer Vision Pipeline\n\nDetection : YOLOv8 for real-time object tracking Segmentation : Boundary detection and structure isolation 3D Reconstruction : Point cloud generation from 2D views Annotation Mapping : Transform 3D coordinates to AR overlay positions\n\nKey Technical Innovations\n\n1. Multi-Factor Safety Scoring\n\nTraditional surgical planning relies on subjective expert judgment. We developed a quantitative safety metric combining multiple risk factors:\n\ndef calculate_safety_score(vessel_dist, geometry, depth, approach): \"\"\" Weighted safety calculation with mm-precision vessel proximity \"\"\" # Distance-based scoring (exponential decay for proximity) vessel_score = min(1.0, vessel_dist / 15.0) # <15mm is caution zone # Combine weighted factors total_score = ( 0.40 * vessel_score + 0.30 * geometry + 0.15 * depth + 0.15 * approach ) return total_score\n\nThis allows reproducible, objective safety assessments that can be validated across procedures.\n\n2. Real-Time HUD System\n\nWe built a surgical-grade heads-up display inspired by aerospace cockpits:\n\nMinimal cognitive load : Information presented only when tracking is locked Color-coded zones : Instant visual feedback on safety status Contextual warnings : Dynamic alerts based on current state Session tracking : Every action logged with timestamps\n\n3. Surgical Corridor Planning\n\nThe path planning algorithm analyzes trajectories segment-by-segment:\n\nFor a path $P = {p_0, p_1, ..., p_n}$ with $n$ waypoints, we compute:\n\n$$\\text{Path Safety} = \\frac{1}{n-1} \\sum_{i=0}^{n-1} S(p_i \\to p_{i+1})$$\n\nWhere $S(p_i \\to p_{i+1})$ is the safety score for segment $i$. This gives:\n\nPer-segment clearance measurements Color-coded visualization of risk zones Alternative path suggestions when safety thresholds aren't met"},{"heading":"üßó Challenges We Faced","content":"1. Real-Time Performance vs. Accuracy Trade-off\n\nChallenge : AI models like GPT-4 Vision provide excellent analysis but take 2-5 seconds per request‚Äîtoo slow for real-time surgical guidance.\n\nSolution : We implemented a hybrid approach using Dedalus Labs' multi-model framework :\n\nModel orchestration : Dedalus routes requests to the optimal model (GPT-4o for fast analysis, Claude Sonnet for complex reasoning) Fast tracking (30 FPS): YOLO/MediaPipe for object detection and position tracking Smart AI calls : Triggered only on user actions (annotations, path planning) Predictive caching : Pre-compute likely scenarios during idle time Fallback to geometry : Use pure computational geometry when AI is unavailable\n\nDedalus's intelligent routing reduced our average AI response time from 4s to <2s while maintaining analysis quality.\n\n2. Multi-Model AI Strategy\n\nChallenge : Different surgical analysis tasks require different AI capabilities. GPT-4 excels at quick pattern recognition, while Claude provides deeper reasoning for complex scenarios.\n\nSolution : Dedalus Labs framework enabled us to:\n\nUse 6 specialized surgical analysis tools for different tasks Automatically route requests to the best model for each scenario Fallback gracefully if a model is unavailable Aggregate insights from multiple models for critical decisions\n\nThis multi-model approach gave us the best of both worlds: speed AND accuracy.\n\n3. 3D-to-2D Projection Accuracy\n\nChallenge : Mapping 3D model coordinates to 2D AR overlay requires precise camera calibration, which varies by device and environment.\n\nSolution :\n\nBounding box normalization : Instead of absolute coordinates, we use relative positions within detected object bounds Dynamic calibration : Percentage-based mapping adapts to different scales Validation markers : User can verify accuracy before proceeding\n\nThe math behind our projection:\n\n$$ \\begin{aligned} x_{\\text{2D}} &= x_{\\text{bbox}} + (x_{\\text{norm}} \\times w_{\\text{bbox}}) \\ y_{\\text{2D}} &= y_{\\text{bbox}} + ((1 - y_{\\text{norm}}) \\times h_{\\text{bbox}}) \\end{aligned} $$\n\nWhere $(x_{\\text{norm}}, y_{\\text{norm}}) \\in [0,1]$ are normalized 3D coordinates.\n\n4. Medical-Grade UI Design\n\nChallenge : Hackathon UIs often look like... hackathon projects. We needed something a surgeon would trust in an operating room.\n\nSolution : We studied real surgical systems (da Vinci, Mako) and medical software UX principles:\n\nDark theme (#0A0E14): Reduces eye fatigue during long procedures Monospace fonts (IBM Plex Mono): Critical for reading precise measurements Traffic lights over numbers : Cognitive load reduction through color Specialist handoff protocol : Clear escalation paths for high-risk scenarios Session logging : Every action tracked with microsecond timestamps\n\nWe went through 5 complete UI redesigns to achieve production-quality polish.\n\n5. Safety-First Decision Framework\n\nChallenge : Medical software cannot simply \"suggest\" actions‚Äîit must have clear protocols for when human oversight is required.\n\nSolution : Implemented a three-tier safety system :\n\nAutomatic approval (>80%): System confident in safety Supervised execution (60-80%): Proceed with continuous monitoring Mandatory escalation (<60%): Specialist consultation required\n\nThis mimics real surgical safety protocols and ensures the system never makes autonomous decisions in high-risk scenarios."},{"heading":"What We Learned","content":"Technical Insights\n\nReal-time systems require ruthless optimization : Every millisecond counts when surgeons are waiting. We learned to profile every function call and optimize hot paths. AI is powerful but unpredictable : Large language models provide amazing insights, but their latency and occasional hallucinations mean they must be carefully integrated with deterministic fallbacks. Medical software is different : Unlike consumer apps where 99% uptime is great, medical systems need 100% reliability . This changes every architectural decision. Computer vision is still hard : Despite advances in deep learning, getting robust real-time tracking in varied lighting conditions remains challenging.\n\nDesign Lessons\n\nLess is more in critical UIs : We removed features that cluttered the interface, keeping only essential information visible. Color saves lives : Proper use of color coding (green/yellow/red) reduces cognitive load by 40% compared to text-only interfaces. Typography matters in medicine : Monospace fonts prevent misreading \"1.5mm\" as \"15mm\"‚Äîa potentially fatal error.\n\nProcess Learning\n\nIterate on UX ruthlessly : Our first UI looked like a chatbot. Our fifth looked like medical software. The difference? Listening to feedback and redesigning. Build for reliability, not just features : It's tempting to add cool AI features, but rock-solid basics matter more. Test with realistic scenarios : Using a bottle as a physical prop helped us understand spatial tracking challenges."},{"heading":"What's Next","content":"Immediate Roadmap\n\nClinical Validation : Partner with teaching hospitals to validate safety scoring accuracy Depth Sensing : Integrate stereo cameras or LiDAR for true 3D depth measurements Multi-User Collaboration : Enable multiple experts to annotate simultaneously Procedure Libraries : Build databases of common surgical approaches\n\nLong-Term Vision\n\nSpatialMD represents a step toward democratizing surgical expertise . Imagine:\n\nA rural surgeon in India receiving real-time guidance from a specialist in Boston Surgical residents practicing on 3D reconstructions before touching patients AI systems that learn from thousands of procedures to suggest optimal approaches Emergency rooms with instant access to trauma surgery expertise\n\nThe technology exists. The need is urgent. SpatialMD proves it's possible to bridge the gap."},{"heading":"Impact Potential","content":"Quantifiable Benefits\n\nReduced surgical complications : Early AI-assisted planning can reduce errors by 30-40% Expanded access : Rural hospitals gain access to specialist knowledge without specialists Faster training : Surgical residents learn on AR-guided simulations Cost reduction : Fewer complications = shorter hospital stays = lower costs\n\nGlobal Health Equity\n\nThe WHO estimates that 5 billion people lack access to safe, affordable surgical care. FixIt-style systems could:\n\nEnable remote surgical mentorship in low-resource settings Reduce preventable surgical deaths through better planning Democratize expertise by making best practices universally accessible"},{"heading":"Acknowledgments","content":"This project was built with:\n\nDedalus Labs for multi-model AI orchestration and surgical analysis tools OpenAI GPT-4 for fast AI analysis Anthropic Claude for complex reasoning MediaPipe for real-time detection Three.js for 3D visualization The open-source community for countless tools and libraries\n\nSpecial thanks to the medical professionals who provided feedback on UI design and safety protocols."},{"heading":"License","content":"MIT License - See LICENSE file for details.\n\n‚öïÔ∏è Medical Disclaimer : This system is designed for research and educational purposes. Clinical deployment requires regulatory approval (FDA/CE marking) and extensive validation.\n\nBuilt with the conviction that technology can‚Äîand should‚Äîmake world-class surgical care accessible to everyone, everywhere."},{"heading":"Built With","content":"canvas-api claude-sonnet dedalus-labs-ai-framework fastapi-(python) gpt-4-vision ibm-plex-typography mediapipe numpy opencv react-18 rest-apis three.js-(react-three-fiber) webrtc yolov8"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Brahma","project_url":"https://devpost.com/software/brahma","tagline":"Revolutionizing Preclinical Research with Synthetic Mice","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/948/668/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Vibe Kanban by Vibe Kanban"}],"team_members":[],"built_with":[{"name":"dedaluslabs","url":null},{"name":"mcp","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"shell","url":"https://devpost.com/software/built-with/shell"}],"external_links":[{"label":"github.com","url":"https://github.com/mihirchanduka/PrincetonHacks"},{"label":"github.com","url":"https://github.com/mihirchanduka/SimuMouseMCP"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration for BRAHMA came from the critical inefficiencies and ethical dilemmas in modern preclinical research. Animal testing is not only expensive and slow but also raises significant ethical concerns. We saw that researchers and AI agents lacked a scalable, ethical platform to run rapid, realistic simulations. BRAHMA, named after the creator god, was conceived to fill this void by becoming the ultimate creator of synthetic biological data, forming a new triad for research: creation (BRAHMA), preservation of data integrity, and the destruction of outdated, inefficient methods."},{"heading":"What it does","content":"BRAHMA is a platform for the on-demand generation of genetically accurate synthetic mice. It creates a complete digital twin by linking synthetic genomes, predicted phenotypes, and simulated behaviors. This enables researchers to run instant, large-scale in-silico experiments for critical applications like drug screening, genetic studies, and AI model training, all without touching a single live animal."},{"heading":"How we built it","content":"We built BRAHMA using a multi-layered computational biology and AI architecture. The core system integrates:\n\nGenome Generation Engine: Uses established genetic models and randomization to create synthetic mouse genomes complete with SNPs, copy-number variations (CNVs), and specific knockouts. Phenotype Prediction Model: A machine learning model trained on public biological datasets to predict physical traits (like obesity or tumor growth) from a given genetic profile. Behavior Simulation Module: An agent-based simulation that models mouse behavior in standard research environments like open-field tests and mazes, based on the underlying phenotype. Data Export Pipeline: Packages all outputs into standardized, researcher-ready formats including FASTQ files for sequencing data, VCF files for variants, and CSVs for phenotype and behavior logs."},{"heading":"Challenges we ran into","content":"One of the biggest challenges was accurately modeling the complex, non-linear relationships between genotypes and phenotypes. Integrating disparate biological data sources into a cohesive and realistic simulation pipeline also required significant effort. Furthermore, ensuring that our behavior simulations were both computationally efficient and biologically plausible pushed us to innovate in our agent-based modeling approach."},{"heading":"Accomplishments that we're proud of","content":"We are incredibly proud of building a fully functional, end-to-end platform that goes from a genetic specification to a rich, multi-modal dataset. We successfully created a system that can generate a synthetic mouse with a linked genome, phenotype, and behavior in minutes. Most importantly, we built a tool that has the genuine potential to save millions of dollars in research funding and countless animal lives, accelerating scientific discovery in a more ethical way."},{"heading":"What we learned","content":"Throughout this project, we deepened our understanding of computational genetics and the nuances of phenotype prediction. We learned how to better integrate different AI models to work in concert, and we gained a profound appreciation for the complexities and bottlenecks of real-world biological research. This project was a massive lesson in interdisciplinary collaboration, blending biology, computer science, and ethics."},{"heading":"What's next for BRAHMA","content":"Our vision is to democratize access to preclinical testing and transform how science is done. Next steps include:\n\nExpanding the Genetic Library: Adding more complex genetic models and disease-specific profiles. Enhancing Simulation Fidelity: Incorporating more environmental factors and social behaviors into our simulations. API Development: Creating a public API to allow researchers and AI agents to programmatically generate and access synthetic data at scale. Validation Studies: Partnering with research institutions to validate our synthetic data against real-world experimental results, further cementing BRAHMA's role as a powerful tool for the scientific community."},{"heading":"Built With","content":"dedaluslabs mcp python shell"},{"heading":"Try it out","content":"github.com github.com"}]},{"project_title":"FairFlow","project_url":"https://devpost.com/software/symbio-g2craj","tagline":"Fair Money. Real People. Honest Flow.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/954/988/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Vibe Kanban by Vibe Kanban"}],"team_members":[],"built_with":[{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"vite","url":null},{"name":"xai","url":null},{"name":"xapi","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/s-meher/fairflow"}],"description_sections":[{"heading":"Inspiration","content":"Neighbors everywhere are price-gouged by short-term credit‚Äîeven when their spending shows they‚Äôre trustworthy. We wanted to prove a small community can lend to itself if everyone sees the same story: how you spend, why you‚Äôre borrowing, and the celebration when someone gets funded."},{"heading":"What it does","content":"FairFlow lets any community turn spending transparency into shared credit. Borrowers link transaction data, Grok explains their clarity score, lenders match funds instantly, and every successful loan auto-posts to a shared X account so the whole community can cheer."},{"heading":"How we built it","content":"FastAPI + SQLite to mock user onboarding, spending summaries, risk logic, and loan matching. React (Vite, Tailwind, shadcn/ui, framer-motion) for the borrower journey and celebratory UI. xAI Grok to transform raw spending into human risk narratives. X API v2 (Bearer + OAuth1) to stream community tweets and publish loan wins."},{"heading":"Challenges we ran into","content":"Translating mock Knot data into something Grok could infer essentials from. Making OAuth1 write access behave (bearer tokens weren‚Äôt enough). Keeping the flow generic for any neighborhood while still feeling personal. ## Accomplishments that we're proud of Fully automated ‚Äúloan matched ‚Üí tweet posted‚Äù loop. Grok narratives surfaced inline with the clarity score. Community feed that blends live X updates with in-app milestones."},{"heading":"What we learned","content":"Regenerating OAuth tokens after permission changes is mandatory. Borrowers trust AI explanations when they see their own merchants in the copy. Logging external API failures (Grok/X) early makes hackathon debugging painless."},{"heading":"What's next for FairFlow","content":"Plug in real Knot connections and real lenders. Let multiple neighborhoods run their own shared X feed from the same code. Add opt-in storytelling (longer posts, donor shoutouts) so communities can rally around each success."},{"heading":"Built With","content":"react vite xai xapi"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Amelia","project_url":"https://devpost.com/software/amelia-b815hi","tagline":"Cursor for Air Traffic Controllers","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/949/604/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Vibe Kanban by Vibe Kanban"}],"team_members":[],"built_with":[{"name":"airplanes.live","url":null},{"name":"dedalus","url":null},{"name":"dedaluslabs","url":null},{"name":"elevenlabs","url":null},{"name":"fastapi","url":null},{"name":"grok","url":null},{"name":"mapbox","url":"https://devpost.com/software/built-with/mapbox"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"redis","url":"https://devpost.com/software/built-with/redis"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vibekanban","url":null},{"name":"vite","url":null},{"name":"x","url":null},{"name":"xai","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/sai-nallani/hack-princeton"}],"description_sections":[{"heading":"Inspiration","content":"Air traffic control is chronically understaffed and results in many delays, safety violations, and fatal accidents every year. This has been exacerbated by the current government shutdown during which over 40% of ATCs have stopped working (and up to 80% at some locations).\n\nThis is disastrous.\n\nIt can take up to 7 years to train an air traffic controller, so bolstering the workforce would take a concerted multi-year effort. Yet, with high churn from existing ATCs, it's likely that the workforce would reach a critical level by then.\n\nBut what if we could make every controller 10x more effective?\n\nNot by replacing them‚Äîthe human in the loop is essential for a task this critical‚Äîbut by augmenting them. We built Amelia as a second brain for ATCs: surfacing missed insights from real-time flight and weather data, automating routine communication, and reducing the cognitive load that leads to fatigue and errors. Like Cursor for air traffic controllers, we're not removing the ATC‚Äîwe're making them superhuman.\n\nWe offer Amelia as a second brain for ATCs, turning them from 1x to 10x ATCs by surfacing missed insights from real-time flight and weather data and automating controller-pilot communication. We recognize that it is essential to have a human in the loop, so we've focused on giving ATCs superpowers, not replacing them."},{"heading":"What it does","content":"Amelia aggregates data from various real-time airline, weather, and predictive data sources and identifies possible risks for all flights within a 40 nautical mile radius of a target airport. Amelia autonomously surfaces these insights directly to its air traffic controller and automates the voice communication with relevant pilots."},{"heading":"How we built it","content":"We scraped NTSA accident/incident reports from the last two years to identify the most common factors that lead to accidents/risks. Afterwards, we studied air traffic controller procedures using the NTSA ATC manual.\n\nThen, we built Amelia.\n\nOn the backend, it uses Grok, Dedalus Labs, and ElevenLabs agents to identify risks, generate insights according to standardized FAA phraseology, and swiftly alert the pilots.\n\nOn the frontend, we used React, Typescript, and Tailwind CSS."},{"heading":"Challenges we ran into","content":"Training the model to identify actual risks that ATCs identify for their pilots.\n\nIt was also a challenge to parse METAR and TAF real-time data."},{"heading":"Accomplishments that we're proud of","content":"We built Amelia in 12 hours."},{"heading":"What we learned","content":"Redis and FastAPI."},{"heading":"What's next for Amelia","content":"User interviews with ATCs."},{"heading":"Built With","content":"airplanes.live dedalus dedaluslabs elevenlabs fastapi grok mapbox python react redis tailwind typescript vibekanban vite x xai"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"SlopGuard","project_url":"https://devpost.com/software/slopguard","tagline":"Protect your brain from the natural forces of AI slop.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/947/624/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Vibe Kanban by Vibe Kanban"}],"team_members":[],"built_with":[{"name":"fastapi","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"indexeddb","url":null},{"name":"jupyternotebooks","url":null},{"name":"keras","url":null},{"name":"matplotlib","url":null},{"name":"next.js","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"openai","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tensorflow","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"slopguard.tech","url":"https://slopguard.tech/"},{"label":"github.com","url":"https://github.com/defoae/HackPrinceton25"}],"description_sections":[{"heading":"Inspiration","content":"We - Dimash (Dinmukhamed), Rasul, and Baran - were thinking about how AI affects our day-to-day life, and one thing that we agreed on is that AI is taking over our social media feeds since the dawn of OpenAI Sora and Google Veo. Nowadays you cannot even enjoy your usual brainrot memes without some AI recycling again human ingenuity, removing all its magic and straight up reducing our IQ.\n\nThat's why we wanted to provide our fellow meme connoisseurs and doomscrollers with a tool to finally pinpoint whenever they are fooled, tricked, and lied to when encountering the latest & greatest. SlopGuard is there to help."},{"heading":"What it does","content":"Slopguard has 3 distinct elements that make the tool functional and convenient to use:\n\nML Backend -> We have a custom detection model trained on public datasets and AI-Slop memes. This model can identify whether a video has certain features that are considered AI-generated, and tell us how likely the video is to have been AI-generated. Frontend -> A basic, but sloppy frontend to upload videos that our users are suspicious about. We can guarantee that our platform is AI-Slop integrated ( Õ°¬∞ Õú ñ Õ°¬∞) ‚Ñ¢"},{"heading":"How we built it","content":"We used some snake oil, magic, and human ingenuity to come up with this architecture and provide users a fun and engaging way to check whether what they consume has been made by humans or not.\n\nDimash built the ML Pipeline, Baran the extension and project architecture, and Rasul the Frontend."},{"heading":"Challenges we ran into","content":"We lost our fourth teammate to sickness, and needed to get into technologies we had never touched."},{"heading":"Accomplishments that we're proud of","content":"Dimash got himself into CNNs and came up with an amazing approach for training and testing models to detect Gen-AI videos. Rasul upped his design & frontend game, coming up with some super cool layouts and designs. And Baran tried himself out with some hidden Instagram API hacks to download videos.\n\nBut first and foremost, we stuck together as a team and pushed through to work on something fun and learn together! ‚ù§Ô∏èü´∂"},{"heading":"What we learned","content":"Coffee doesn't fix everything AI is definitely not gonna replace us We can achieve anything!"},{"heading":"Additional Feature in Developent","content":"Chrome Extension -> To allow for users to seamlessly check whether videos are AI-generated, users can just press a button on Instagram videos, so that our platform is being opened directly with the video preloaded to find out whether it has been AI-generated."},{"heading":"What's next for SlopGuard","content":"-> Deploying it to Open Web üåê -> Scaling to Stop the Slop üìà -> Although it started as a fun idea, the range of possible implementations is vast, spanning from social media to legal matters üõ†Ô∏è"},{"heading":"Built With","content":"fastapi flask indexeddb jupyternotebooks keras matplotlib next.js numpy openai opencv pandas pytorch react tensorflow typescript vercel"},{"heading":"Try it out","content":"slopguard.tech github.com"}]},{"project_title":"Evolv - Dive Deep. See Clear.","project_url":"https://devpost.com/software/kv-cache-on-this","tagline":"See the true impact of every data center before you build.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/952/953/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Predictive Intelligence by Chestnut Forty"}],"team_members":[],"built_with":[{"name":"anthropic","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"mapbox","url":"https://devpost.com/software/built-with/mapbox"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/aanyabhandari3/HackPrinceton25"},{"label":"aanyabhandari.my.canva.site","url":"https://aanyabhandari.my.canva.site/hackprinceton25"}],"description_sections":[{"heading":"Inspiration","content":"When tech giants announce new data centers, press releases celebrate job creation and economic growth. But what about the electricity bills that spike 15% for nearby residents? The aquifers drained by millions of gallons daily? The coal plants fired up to meet demand?\n\nCommunities deserve to know the real cost before breaking ground.\n\nWe were inspired by Virginia's \"Data Center Alley\", where residents discovered after construction that their electricity rates would increase to subsidize infrastructure upgrades. In Arizona, communities fought facilities consuming 1.5 million gallons daily during historic droughts. In Georgia, incoming data centers could provide millions in economic gain but have led to increased rates for residents.\n\nThe \"ah-ha\" moment: What if a high school student, a town council member, or a city planner could click on their neighborhood and see exactly what a proposed data center means for their water supply, their electric bill, their air quality? Not in a 300-page environmental impact report, but in 30 seconds.\n\nEVOLV analyzes and predicts environmental impact at scale."},{"heading":"What It Does","content":"EVOLV is an interactive geospatial platform that simulates data center impacts anywhere in the USA ‚Äî in real-time and over years.\n\nCore Innovation: Dual-Dashboard Intelligence\n\n1. Analyze Dashboard ‚Äî What happens TODAY if we build here?\n\nClick any US location ‚Üí instant impact calculation Energy : Annual consumption, household cost increases, grid strain % Carbon : CO‚ÇÇ emissions with state-specific grid mix (coal vs. renewables) Water : Daily usage adjusted for local climate + cooling system type Economics : Jobs, construction costs, tax revenue AI Insights : Claude analyzes everything and generates a narrative report answering: \"Should this community be concerned?\"\n\n2. Forecast Dashboard ‚Äî What happens over the NEXT FEW YEARS?\n\nMulti-year projections with three scenarios (best/realistic/worst case) Tipping point analysis : When does the local grid hit capacity? When does water become unsustainable? Interactive charts showing cumulative impacts compounding over time Strategic AI insights : \"In Year 5, expect water conflicts with agriculture. Here's how to mitigate...\"\n\n3. Downloadable Reports\n\nBoth dashboards generate comprehensive Markdown reports Share with community boards, regulators, or investors Complete methodology transparency ‚Äî every number explained\n\nThe Magic: Climate-Adjusted Precision\n\nNot all data centers are equal. A facility in Phoenix uses 40% more water than one in Seattle due to cooling demands. EVOLV accounts for:\n\nLocal temperatures (PUE adjustments) State grid carbon intensity (WV coal ‚â† WA hydro) Regional electricity pricing Water availability and drought risk\n\nFormula that powers water calculations: $$W_{daily} = P_{cooling} \\times f_{type} \\times (1 + 0.02 \\times (T_{avg} - 70¬∞F)) \\times 24$$\n\nWhere cooling factors range from 0.2 (air-cooled) to 1.8 (water-cooled towers).\n\nReal Example:\n\n10 MW data center in Phoenix (110¬∞F avg) vs. Seattle (65¬∞F avg):\n\nPhoenix: 151,200 gal/day (water-cooled) Seattle: 97,200 gal/day (35% less!) Impact : Phoenix = 20% of local water supply strain vs. Seattle = 2%\n\nEVOLV shows you these differences instantly."},{"heading":"How We Built It","content":"The Challenge: Making Complexity Accessible\n\nEnvironmental analysis typically requires:\n\n$50k+ consulting fees 6-12 month studies Access to proprietary databases\n\nOur solution: Automate it with open data + AI. Key Innovation: Parallel API calls + caching = 4-second analysis time (vs. industry standard months)\n\nThe Math Behind the Magic\n\nEnergy Impact: $$E_{annual} = P_{MW} \\times 8,760 \\text{ hrs} \\times 1,000 \\times PUE_{climate}$$\n\nCarbon Footprint (state-specific): $$CO_2 = E_{annual} \\times \\text{GridIntensity}_{state} \\div 2,000$$\n\nWest Virginia (coal): 1.65 lbs/kWh Washington (hydro): 0.15 lbs/kWh 11x difference!\n\nForecast Modeling: $$M_t = M_0 \\times (1 + r_{growth})^t \\times (1 - r_{efficiency})^t$$\n\nGrowth vs. efficiency improvements = realistic projections\n\nTech Stack\n\nFrontend : React 18, Mapbox GL, Chart.js, Tailwind Backend : Flask, NumPy, Pandas AI : Anthropic Claude (Sonnet 3.5) Data : 5 public APIs, all free tiers"},{"heading":"Challenges We Overcame","content":"1. Water Usage Mystery\n\nProblem: Industry data on cooling water is proprietary/inconsistent. Solution: Researched ASHRAE standards, academic papers, Google/Microsoft sustainability reports. Built parametric model validated against real facilities (Facebook Prineville, Microsoft Quincy). Result: 4 cooling types with temperature-adjusted accuracy.\n\n2. API Reliability at Scale\n\nProblem: Free APIs have rate limits; simultaneous users = throttling. Solution: Exponential backoff retry logic + 1-hour caching + fallback to national averages. Result: 99.5% uptime even under load.\n\n3. Making Numbers Meaningful\n\nProblem: \"10 million gallons/year\" means nothing to most people. Solution: Human comparisons ‚Äî \"Enough to fill 15 Olympic pools\" or \"Equal to 4,000 households.\" Result: Users understand impact viscerally.\n\n4. Carbon Intensity Variation\n\nProblem: US average CO‚ÇÇ/kWh hides 10x state differences. Solution: Integrated EIA state-level grid mix data for all 50 states. Result: Realistic emissions for each location (not generic estimates).\n\n5. Forecast Uncertainty\n\nProblem: Can't predict the future perfectly. Solution: Three scenarios (optimistic/realistic/pessimistic) with uncertainty bands. Result: Users see range of possibilities, not false precision."},{"heading":"What We Learned","content":"Technical Breakthroughs\n\nGeospatial data processing with multiple coordinate systems AI prompt engineering for consistent structured output Async API orchestration for sub-5-second response times Thermodynamics of data center cooling (PUE, evaporative losses)\n\nThe Big Insight\n\nRaw metrics are meaningless without context. When we reframed \"50 MW\" as \"enough to power 35,000 homes\" or showed household electric bills increasing $8/month, people cared .\n\nData storytelling > data dumping."},{"heading":"What's Next for EVOLV","content":"Immediate (Next 3 Months)\n\nRenewable Energy Optimizer \"If this facility runs on 80% solar/wind, impact drops by X%. Here's how to do it.\" Multi-Facility Modeling \"What if Amazon builds THREE data centers in this region?\" Community Comparison Tool \"How does this compare to Google's nearby facility?\"\n\nGoal: Make EVOLV the standard tool for data center environmental due diligence.\n\nThe Bigger Picture\n\nData centers are essential: they power AI, cloud computing, and digital infrastructure. EVOLV shifts the conversation from: ‚ùå \"Should we allow this?\" ‚úÖ \"How do we make this work for everyone?\"\n\nBecause every byte has a footprint. And every community deserves to see it.\n\nTech Stack: React, Flask, Mapbox, Claude AI, U.S. Government APIs\n\nTeam (discord): Aanya Bhandari ( snake.y), Sarvesh Gade (sastr0 ), and Pablo Leyva (pleyva)"},{"heading":"Built With","content":"anthropic flask javascript mapbox node.js python vite"},{"heading":"Try it out","content":"github.com aanyabhandari.my.canva.site"}]},{"project_title":"Forexery","project_url":"https://devpost.com/software/forexery","tagline":"An RL model that democratizes Forex trading algorithms","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/950/476/datas/medium.jpg","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Predictive Intelligence by Chestnut Forty"}],"team_members":[],"built_with":[{"name":"dedalus-labs","url":null},{"name":"gymnasium","url":null},{"name":"matplotlib","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tensorboard","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/codejvn/forexery"}],"description_sections":[{"heading":"Built With","content":"dedalus-labs gymnasium matplotlib numpy pandas python tensorboard"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"PropheSea","project_url":"https://devpost.com/software/prophesea","tagline":"A personal AI trading guide that simplifies the complex world of predictive markets with top data-backed trades in a sleek, swipeable card experience.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/949/962/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Predictive Intelligence by Chestnut Forty"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"next.js","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sql","url":"https://devpost.com/software/built-with/sql"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/maalin2/hackprinceton"}],"description_sections":[{"heading":"The Problem","content":"Prediction markets are overwhelming to new traders. There's an overload of options and mountains of potentially relevant information from every source imaginable. Traditional trading dashboards force users into reactive decision-making, drowning them in data without guidance."},{"heading":"Our Solution","content":"PropheSea transforms prediction market trading from information overload into an intuitive, personalized experience. Just as social media learns what you like, PropheSea shows you the best trading opportunities based on what you actually care about.\n\nKey Features\n\nPersonalized Interest Selection : Choose up to three interests from diverse categories including Politics, Weather, Crypto, and Sports Hybrid AI Analysis : Combines quantitative edge detection with sentiment analysis across multiple markets Swipe-Based Trading : Top trades presented in an intuitive card format Beginner-Friendly Reasoning : Complex financial analysis broken down into plain English Real-Time Market Data : Live market odds and confidence scoring via volatility, volume, and momentum analysis"},{"heading":"Architecture","content":"Frontend\n\nFramework : Next.js 14 (App Router) Language : TypeScript Styling : Tailwind CSS UI Components : Radix UI + Custom components Animations : Framer Motion\n\nBackend & Infrastructure\n\nAPI Server : FastAPI (Python) Authentication : Supabase Auth Database : PostgreSQL (via Supabase)\n\nAI & Analytics Engine\n\nDedalus Labs : MCP server deployment MCP : Tools for LLM to analyze Kalshi markets, perform analysis, and consult sources of truth\n\nQuantitative Analysis\n\nMarket Confidence Scoring : Volatility, volume, and momentum indicators Statistical Strategies : Moving averages for trend detection Statistical arbitrage identification Custom technical indicators per domain (Weather, Politics, Economics) Data Sources : Weather: NOAA, Open-Meteo, Climatology data Politics: Polling aggregators, 538 models Economics: Federal Reserve data, economic indicators\n\nSentiment Analysis\n\nLLM : xAI's Grok 4 model for real-time sentiment analysis via agentic search X (Twitter) Integration : Real-time topic-relevant tweet analysis\n\nHybrid System\n\nTwo-Stage Pipeline : Fast statistical screening filters high-edge opportunities Grok sentiment analysis verifies filtered bets Dynamic Weight Adjustment : Balances quantitative and semantic signals Arbitrage Detection : Identifies mispriced markets across platforms"},{"heading":"Getting Started","content":"Prerequisites\n\n# Node.js 18+ and Python 3.9+ node --version python --version # Environment variables required SUPABASE_URL=your_supabase_url SUPABASE_ANON_KEY=your_supabase_key XAI_API_KEY=your_grok_api_key KALSHI_API_KEY=your_kalshi_key\n\nInstallation\n\nClone the repository git clone https://github.com/maalin2/hackprinceton.git cd hackprinceton Install Python dependencies pip install -r requirements.txt pip install -r api_requirements.txt Install frontend dependencies cd dashboard npm install Set up environment variables # Create .env file in root directory cp .env.example .env # Add your API keys\n\nRunning the Application\n\nTerminal 1: Start the FastAPI backend\n\npython api_server.py --port 8000\n\nTerminal 2: Start the Next.js frontend\n\ncd dashboard npm run dev\n\nOpen http://localhost:3000 in your browser."},{"heading":"Project Structure","content":"hackprinceton/ ‚îú‚îÄ‚îÄ dashboard/ # Next.js frontend ‚îÇ ‚îú‚îÄ‚îÄ app/ # App router pages ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ dashboard/ # Main trading dashboard ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ markets/ # Market browsing ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ onboarding/ # User preference setup ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ saved/ # Saved picks ‚îÇ ‚îî‚îÄ‚îÄ components/ # React components ‚îÇ ‚îú‚îÄ‚îÄ AgentFeed.tsx # Card swipe interface ‚îÇ ‚îî‚îÄ‚îÄ ui/ # Shared UI components ‚îú‚îÄ‚îÄ strategies/ # Quantitative trading strategies ‚îÇ ‚îú‚îÄ‚îÄ moving_average.py # Trend detection ‚îÇ ‚îú‚îÄ‚îÄ statistical_arbitrage.py ‚îÇ ‚îî‚îÄ‚îÄ kalshi_data.py # Market data fetching ‚îú‚îÄ‚îÄ mcp_quantitative_agent/ # AI agent implementation ‚îÇ ‚îî‚îÄ‚îÄ server.py # Grok integration ‚îú‚îÄ‚îÄ api_server.py # FastAPI backend ‚îú‚îÄ‚îÄ hybrid_analysis.py # Combined quant + sentiment ‚îú‚îÄ‚îÄ weather_test.py # Weather market analysis ‚îú‚îÄ‚îÄ politics_test.py # Politics market analysis ‚îî‚îÄ‚îÄ economics_test.py # Economics market analysis"},{"heading":"Challenges We Overcame","content":"UX Complexity : Breaking down complex multi-factor trading decisions into an intuitive, beginner-friendly swipe interface Data Normalization : Sourcing and normalizing quantitative data to calculate accurate implied probabilities and identify arbitrage opportunities Domain-Specific Strategies : Implementing different technical indicators for different market types (weather vs. politics vs. economics) Signal Balance : Finding the optimal balance between sentiment and quantitative aspects for each trade recommendation Real-Time Performance : Managing latency challenges as market odds can shift extremely quickly"},{"heading":"What We're Proud Of","content":"Our swipe-based trading interface that makes complex decisions feel natural Dynamic weight adjustment between quantitative and semantic signals Successfully integrated diverse data sources and indicators Building a production-quality, real-time agent"},{"heading":"What We Learned","content":"Integrating multiple systems (frontend, backend, AI, databases) is far more challenging than it appears AI agents cannot be one-size-fits-all - context plays a major role when making predictions for prediction markets In prediction markets, speed is everything. Odds can change in milliseconds, making performance optimization crucial Breaking down AI reasoning into digestible explanations builds user confidence in automated recommendations"},{"heading":"What's Next for PropheSea","content":"Near-Term Goals\n\nMulti-Platform Support : Integration with Polymarket, Manifold, and other prediction markets WebSocket Implementation : Real-time bidirectional communication for instant trade execution Mobile Apps : Native iOS and Android applications for on-the-go trading\n\nLong-Term Vision\n\nAdvanced Analytics : Personal trading history, portfolio growth tracking, and risk optimization Automated Trading : Risk-adjusted automatic trading using Kalshi's native API Educational Mode : Tutorial system to teach users about prediction market mechanics On-Chain Integration : Support for decentralized prediction markets, oracles as more sources of truth and arbitrage generation, and other blockchain-based platforms Social Features : Follow successful traders, share picks, and collaborative analysis"},{"heading":"Team (Discord)","content":"Mohammed - @movisiting Sugam - @pmiozmzoa Anshul - @mrqwert. Wing - @pencilknot"},{"heading":"Acknowledgments","content":"HackPrinceton for hosting an amazing hackathon Kalshi for their prediction market API xAI for Grok 4 model access Dedalus Labs for agent infrastructure All the open-source libraries that made this possible"},{"heading":"Built With","content":"css javascript next.js node.js python react sql tailwind typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Nautilink","project_url":"https://devpost.com/software/nautilink","tagline":"Paying Fishers For Transparency And Publicizing Sustainability","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/944/810/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Solana by MLH"}],"team_members":[],"built_with":[{"name":"ais","url":null},{"name":"amazon-dynamodb","url":"https://devpost.com/software/built-with/amazon-dynamodb"},{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"apollo-server","url":null},{"name":"aws-cognito","url":null},{"name":"buckets","url":null},{"name":"cypress","url":null},{"name":"dast","url":null},{"name":"datadog","url":"https://devpost.com/software/built-with/datadog"},{"name":"eslint","url":null},{"name":"ether.js","url":null},{"name":"express-go","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"flutter","url":"https://devpost.com/software/built-with/flutter"},{"name":"gcp","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"geospatial","url":null},{"name":"grafana","url":null},{"name":"graphql","url":null},{"name":"hardhat","url":null},{"name":"hashicorp","url":null},{"name":"hugging-face","url":null},{"name":"ipfs","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"jest","url":null},{"name":"kserve","url":null},{"name":"leaflet.js","url":"https://devpost.com/software/built-with/leaflet-js"},{"name":"mapbox","url":"https://devpost.com/software/built-with/mapbox"},{"name":"native-sdks","url":null},{"name":"netifly","url":null},{"name":"next.js","url":null},{"name":"openai","url":null},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"prometheus","url":null},{"name":"prometheus-image-archive","url":"https://devpost.com/software/built-with/prometheus-image-archive"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"radix","url":null},{"name":"railway","url":null},{"name":"rainbowkit","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"redis","url":"https://devpost.com/software/built-with/redis"},{"name":"render","url":null},{"name":"rest-endpoints","url":null},{"name":"s3","url":null},{"name":"sast","url":null},{"name":"sendgrid","url":"https://devpost.com/software/built-with/sendgrid"},{"name":"sentinel","url":null},{"name":"shadcn","url":null},{"name":"sockets","url":null},{"name":"solana","url":null},{"name":"solidity","url":"https://devpost.com/software/built-with/solidity"},{"name":"spire","url":null},{"name":"stripe","url":"https://devpost.com/software/built-with/stripe"},{"name":"supabase","url":null},{"name":"tailwind","url":null},{"name":"terraform","url":null},{"name":"tls","url":null},{"name":"torchserve","url":null},{"name":"twilio","url":"https://devpost.com/software/built-with/twilio"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null},{"name":"vesselfinder","url":null},{"name":"vitest","url":null},{"name":"web3","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Ishaan-Buddharaju/Nautilink-HackPrinceton"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAG4D-U4YSM/ZBxQO0oa6M9pm5lKMcKhGQ/edit?utm_content=DAG4D-U4YSM&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"}],"description_sections":[{"heading":"Nautilink","content":"Regulating Fishing Supply Chains With Blockchain Protection"},{"heading":"60 second pitch","content":"Consumers demand high quality fish at a cheap price ‚û°Ô∏è encourages fishers to manipulate locations, fish illegally ‚û°Ô∏è destroying marine life and environments\n\n38M tons of marine life trashed from bycatch annually (WWF, 2009)\n\n3.9B acres of seafloor habitats destroyed annually by bottom trawling (F&F Lab, 2021)\n\n$50B of damage in nationally protected ecosystems annually from illegal fishing (Congress 2024)\n\nOur ocean is declining because modern fishing regulations are unverifiable\n\nSo instead of threatening fishermen with laws that we can‚Äôt even enforce\n\nWe created üåêNautilink‚öì To help fishers get what they want whilst reaching consumer‚Äôs demands\n\nHere‚Äôs how it works\n\nFishermen allow us to incorporate blockchain technology on their fishing equipment to uniquely mint transactions on a ledger IOT Devices: -Computer Vision detecting species of fish -Load Cell for weighing fish -NFC Tap for simplicity\n\nOur mobile app tracks every step along the supply chain -From where the fish was caught, to the ship it was on, to the port, fishery, storage units, processing plants(curing, deboning, cutting), wholesale hqs, retail stores, and finally to the consumer -Our NFC technology verifies the movement of fish\n\nIn the end, the consumer scans a qr code and learns about how their fish was caught -trace of supplychain -sustainability scores of each step -price markup for proven sustainability\n\nThen send these markups to the fishermen for their transparency and following regulations\n\nOn top of all that, we created a web app for regulators to track all this information on a dashboard -transaction tracking -supplychain visualization -sustainability scoring algorithm -report databases -research ai assistants -authentication methods -security roles"},{"heading":"The Problem (inspiration)","content":"Fishing on the high seas is fragmented, unverifiable, and dangerous to the environment\n\nand if unregulated, fishermen commit biblical levels of greed and harm the environment\n\nIllegal, unregulated fishing steals $20‚Äì50 billion per year from nationally protected ecosystems (Congress 2024)\n\nBottom trawler destroys ~3.9 billion acres of seafloor habitats every single year (F&F Lab 2021)\n\n*an area larger than the U.S. and China combined\n\nBycatching discards 38 million tons of marine life every year (WWF 2009)\n\n*bycatch -> unintended non-target catch\n\nAll because modern fishing regulations are unverifiable\n\nAnd the root of all evil starts from the consumer perspective, trying to hunt for the cheapest high value deals on fish.\n\nCompetitive prices create difficult conditions for fishers to operate in and make up for by cheating the law\n\nBut consumers aren't exactly happy about the environment destroyed,\n\nthey just need a way to understand how their choices affect the fishing supply chain.\n\nInstead of relying on a global seafood traceability system is built on some magical thing called trust\n\nwe decided to build a system to verify, visualize, and improve the fishing supply chain sustainability"},{"heading":"The Solution","content":"And that is why we created Nautilink is a cross-platform block chain integrated system made up of 5 parts aimed to achieve 5 things\n\nSimplicity\n\nSupport\n\nTraceability + Transparency\n\nEcocentric\n\nSecurity"},{"heading":"How it works","content":"Hardware (fishermen, supply chain etc.)\n\n‚Ä¢ Arduino-based NFC reader used to transmit sensor data from a hardware-agnostic fishing apparatus to NFC-tagged crates.\n\n‚Ä¢ Smartphone scanning of the tag logs the crate, owner, and device DIDs, along with GPS (latitude/longitude) to the blockchain.\n\n‚Ä¢ Blockchain integration provides a low-cost, verifiable link between physical assets and their digital records.\n\n‚Ä¢ Proof of concept demo: scanning the tag triggers a stepper motor (crane) to lift a cup of goldfish, simulating catch retrieval.\n\n‚Ä¢ Design goals: low-cost, small-scale, IoT-enabled hardware easily integrated into existing fishing equipment and vessels.\n\nBlock Chain Technology (transparent, verifiable)\n\nBuilt on Solana blockchain with every crate movement, mixing of fish, and split being permanently recorded on a public, immutable ledger that anyone can verify.\n\nOur smart contract program enforces transparent supply chain rules (weight validation, ownership transfers, and provenance tracking via our hardware) with novel state tracking to not only track crates but also track weighted many to many relationships.\n\n‚Ä¢ Sub-second verification - 400ms transaction finality enables real-time supply chain transparency with instant fraud detection\n\n‚Ä¢ Cryptographic integrity - SHA256 hashing and Ed25519 signatures all underlying trusted party hardware to ensure every crate record is tamper-proof and verifiable by regulators, consumers, and stakeholders\n\n‚Ä¢ Complete provenance chain - Parent-child relationships stored on-chain create an unbreakable audit trail from catch to consumer, preventing illegal fishing and supply chain fraud while creating a market for tracable fish that can align company profits with the mission of sustainability and transparency\n\nFor tobile App (consumers, fishermen, supply chain etc.) consumers would track their transactions by using QR codes and NFC tags. This interaction was depicted through a chain of nodes and edges. For the fisherman part of the app we helped them focus on fish and how they can better track their fish, which is also the main rationale behind us pursuing this idea, in tracking the fish from their inception in the oceans to their spot in our shelves we could see how efficient/inefficient certain parts of the market were and the mobile app helped in meeting this interest in the market.\n\nWeb App Dashboard/Database (Regulators)\n\nPersonal Assistant (Everyone)\n\n(hardware, mobile app tracking, block chain technology, web app dashboard)"},{"heading":"Challenges we ran into","content":"blockchain. none of us knew how to work with blockchain web3 technology ‚òπÔ∏èüëé\n\nmuch less, know how to mint, burn, transfer, freeze, thaw, delegate, create, update, CPI, BPF compile... everything... ‚òπÔ∏èüëé\n\nbut it's okay because learnt it, built it, and deployed it üòéüëç\n\nAlso our 4th teammate dropped out a third of the way in, ‚òπÔ∏èüëé\n\nbut it's okay because we met a very cool new teammate and worked well together üòéüëç"},{"heading":"Built With","content":"ais amazon-dynamodb amazon-web-services apollo-server aws-cognito buckets cypress dast datadog eslint ether.js express-go flask flutter gcp gemini geospatial grafana graphql hardhat hashicorp hugging-face ipfs javascript jest kserve leaflet.js mapbox native-sdks netifly next.js openai postgresql prometheus prometheus-image-archive python pytorch radix railway rainbowkit react redis render rest-endpoints s3 sast sendgrid sentinel shadcn sockets solana solidity spire stripe supabase tailwind terraform tls torchserve twilio typescript vercel vesselfinder vitest web3"},{"heading":"Try it out","content":"github.com www.canva.com"}]},{"project_title":"Foundaura","project_url":"https://devpost.com/software/neofoundr","tagline":"Do you have a business idea but no clue where to begin? Foundaura provides you with the intricate details of starting a business with clear steps, smart insights, and personalized guidance.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/956/503/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best Use of Snowflake API by MLH"}],"team_members":[],"built_with":[{"name":"dedalus","url":null},{"name":"fastapi","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"snowflake","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/OmNepal/HackPrinceton"}],"description_sections":[{"heading":"Inspiration","content":"61% of Americans have had an idea for starting a business, but 92% never followed through. The biggest barriers? Lack of funding (63%) and not knowing how to get started (39%). Most people want to start something meaningful, a small caf√©, a local brand, or even a tech startup, but the process feels confusing, technical, and overwhelming. Between legal registrations, financial planning, and learning how to build a business, even great ideas fade away before they begin.\n\nFoundaura was built for those people. It‚Äôs for the dreamers, creators, and professionals who have an idea but no map. We wanted to make the path from ‚ÄúI have an idea‚Äù to ‚ÄúI‚Äôm a founder‚Äù simple, structured, and guided entirely by AI."},{"heading":"What it does","content":"Foundaura is an AI-powered co-founder that helps anyone turn an idea into a launch-ready business plan. Users can simply speak or type their idea, for example, ‚ÄúI want to start a food truck in New Jersey with a $20,000 budget.‚Äù Foundaura listens, understands, and builds a complete roadmap that includes:\n\n‚Ä¢ Legal and compliance requirements specific to their location\n\n‚Ä¢ Startup costs, funding sources, and budget breakdowns\n\n‚Ä¢ Step-by-step guidance for registration and permits\n\n‚Ä¢ A professional, exportable business brief that can be shared with mentors or investors\n\nEverything happens through intelligent multi-agent reasoning, orchestrated by Snowflake Cortex and Dedalus Labs APIs."},{"heading":"How we built it","content":"Snowflake Integration & Impact\n\nFoundaura is powered end-to-end by Snowflake Cortex AI, making it a truly Snowflake-first application. Snowflake Cortex LLM handles everything from intent parsing, agent orchestration, and response synthesis to voice transcription and document generation all within the same ecosystem.\n\nHere‚Äôs what it powers:\n\n‚Ä¢ AI_TRANSCRIBE (via SQL): Converts spoken ideas into structured text in real time, enabling voice-first interaction.\n\n‚Ä¢ LLM Orchestration: Determines user intent, routes to the appropriate Dedalus agent, and merges responses.\n\n‚Ä¢ Response Formatting & Synthesis: Uses Cortex reasoning to turn multi-agent outputs into clear, structured roadmaps.\n\n‚Ä¢ Business Brief Generation: Leverages Cortex with Claude 4 Sonnet to create investor-ready, one-page summaries.\n\nDedalus Labs Integration & Impact\n\nFoundaura uses Dedalus Labs agents for real-time, specialized research. The Legal Agent uses multiple MCP servers like Brave Search, Exa Semantic Search, and GovInfo to gather location-specific requirements such as licensing, health permits, tax registration, labor laws, zoning rules, and agency contact details. The Financial Agent handles budget-aware planning: startup costs, operating expenses, funding sources (SBA loans, grants, local investor programs), and cost-saving strategies tailored to the user‚Äôs budget and location.\n\nBoth agents are orchestrated by Snowflake Cortex, which routes requests based on business type and context. Dedalus provides the factual research layer, while Snowflake manages orchestration and formatting. The result is a unified, compliance-ready business plan that feels like it was built by a real co-founder, fast, accurate, and location-aware.\n\n‚∏ª This unified workflow means we don‚Äôt rely on multiple external APIs for reasoning, transcription, and formatting, Snowflake Cortex does it all. It simplifies architecture, improves reliability, and demonstrates how Snowflake can serve as a complete AI backbone for an intelligent, multi-agent product. For hackathon judges, this highlights multi-modal Cortex use (SQL-based transcription + LLM orchestration + synthesis) in a real, working end-to-end system."},{"heading":"Challenges we ran into","content":"Integrating Dedalus Labs and Snowflake Cortex was complex. We had to manage multi-agent routing, asynchronous API calls, and schema alignment for Snowflake storage. Voice transcription in particular required fine-tuning the SQL-based AI_TRANSCRIBE workflow to ensure audio files uploaded via FastAPI were properly recognized and stored in Snowflake stages. Another major challenge was ensuring that the LLM reasoning stayed consistent and domain-relevant across legal and financial contexts. Debugging this multi-step orchestration taught us more about AI pipelines than any tutorial ever could."},{"heading":"Accomplishments that we're proud of","content":"‚Ä¢ Built a fully functional AI co-founder that converts voice to a complete startup roadmap in real time\n\n‚Ä¢ Successfully orchestrated multi-agent reasoning through Snowflake Cortex and Dedalus Labs\n\n‚Ä¢ Created an end-to-end Snowflake pipeline covering transcription, orchestration, synthesis, and document generation\n\n‚Ä¢ Designed a clean, responsive UI that makes complex data feel approachable and human\n\n‚Ä¢ Empowered people who have ideas to finally take the first step toward founding something real"},{"heading":"What we learned","content":"We learned how to combine AI reasoning, real-time research, and data infrastructure into one coherent workflow. Working with Snowflake Cortex taught us how to handle LLM orchestration entirely within SQL and integrate it seamlessly into a web app. From Dedalus Labs, we learned how multi-agent research can augment factual accuracy and context-specific guidance.\n\nMore importantly, we learned that AI tools can lower the barrier to entrepreneurship in a tangible way. It‚Äôs not just about building software, it‚Äôs about building confidence in the next generation of founders."},{"heading":"What's next for Foundaura","content":"We plan to evolve Foundaura into a full AI startup companion. Next steps include:\n\n‚Ä¢ Integrating more Snowflake Cortex functions for automatic data visualization and idea validation\n\n‚Ä¢ Expanding Dedalus agents to cover marketing, operations, and funding workflows\n\n‚Ä¢ Deploying the platform as a web app so anyone, anywhere, can start their founder journey with a conversation\n\nFoundaura+ is more than a tool. It‚Äôs a movement toward making entrepreneurship accessible to everyone."},{"heading":"Built With","content":"dedalus fastapi python react snowflake"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"WhyKnot","project_url":"https://devpost.com/software/whyknot","tagline":"WhyKnot see what your potential customers want? WhyKnot helps you see what locals are buying, and where your restaurant fits in.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/951/526/datas/medium.png","prizes":[{"hackathon_name":"HackPrinceton Fall 2025","hackathon_url":"https://hackprinceton-fall-2025.devpost.com/","prize_name":"Best .Tech Domain Name by MLH"}],"team_members":[],"built_with":[{"name":"dadelus","url":null},{"name":"fastapi","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"nextjs","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/shivvyas2/WHYKNOT"},{"label":"github.com","url":"https://github.com/vighanesh2/Restaurant-Stats"},{"label":"api.why-knot.tech","url":"https://api.why-knot.tech/"},{"label":"www.why-knot.tech","url":"https://www.why-knot.tech/"}],"description_sections":[{"heading":"Inspiration","content":"Restaurants often struggle to decide what dishes to offer and how to price them competitively when opening or expanding in new areas. During this hackathon, we noticed that while platforms like DoorDash and Uber Eats hold tons of valuable delivery data, restaurant owners rarely get direct insights from it. We wanted to make that data useful. So our idea was to build a tool where owners can simply enter a location and instantly see what‚Äôs trending nearby along with which dishes sell the most, how customers are spending, and how their pricing compares. The goal is to help small and local businesses make smarter, data-driven decisions without needing a data science team."},{"heading":"What it does","content":"WhyKnot helps restaurant owners make smarter business decisions using real-world delivery data. Simply by entering any location, they can instantly access insights from DoorDash and Uber Eats orders in that area. The app gives them a heat map of the orders and their type of food order. Also they get insights such as average order, most ordered dish, timely stats, and ask our ai about the any location they seem interested in\n\nWith WhyKnot , owners can see local demand patterns, identify potential menu gaps, and price their offerings more competitively all in one simple dashboard."},{"heading":"How we built it","content":"Our main source of the transaction data were possible due to our very friendly sponsors KnotApi and using their product we were able to fetch Doordash and Ubereats order details of costumers. We created a backend using FastApi and stored all the data into our MongoDB database. For the frontend we made use of Nextjs , and using a javascript library for generating interactive maps - Leaflet we were able to allow the businesses to visually data relevant for their business growth. To create some extra mock data we needed in a pinch we used Dedalus Labs exa-search-mcp to webscrape restaurants."},{"heading":"Challenges we ran into","content":"Knot api integrating into our prod was a challenge so we approached the sponsors and asked for advice. Also, coming up with an idea overnight made us realize that this hackathon pushed us to the maximum limit. While there were workshops and so much distractions (amazing campus and food), we had to dial in and make sure we met our deadlines."},{"heading":"Accomplishments that we're proud of","content":"We're proud that we built a functional prototype of WhyKnot within the hackathon timeframe that actually connects real data to meaningful insights. Getting reliable delivery data from multiple sources was challenging, but we managed to design an end-to-end flow that aggregates and visualizes it cleanly. Another highlight was seeing how useful the app could be during live testing. When we plugged in different city locations, the data revealed clear trends in pricing and dish popularity that matched real-world intuition. It felt great to see an idea turn into something practical that small business owners could actually use."},{"heading":"What we learned","content":"Building WhyKnot taught us how powerful raw data can be when it‚Äôs structured around a real business problem. We learned how to fetch and process location-based delivery data efficiently, deal with noisy or incomplete datasets, and use clean visualization to make insights actually understandable.\n\nWe also realized that simplicity matters. Restaurant owners don‚Äôt want complicated dashboards, they want quick, clear answers. This shaped how we designed our interface and made us focus on showing only the most relevant insights.\n\nLastly, working under hackathon time pressure reminded us how much can be achieved with teamwork, clear goals, and a good idea that solves a real-world need."},{"heading":"What's next for WhyKnot","content":"We want to grow WhyKnot into a tool that more restaurant owners can rely on, beyond the hackathon. Next steps include expanding our data sources, making the dashboard even easier to use, and adding features like recommendations for new menu items and price optimization. We‚Äôre also interested in working with restaurants directly to get feedback and test the app in real-world settings. Our long-term goal is to give every small business owner access to the same smart insights that big chains use, helping level the playing field with better data and clearer decisions."},{"heading":"Built With","content":"dadelus fastapi mongodb nextjs openai python"},{"heading":"Try it out","content":"github.com github.com api.why-knot.tech www.why-knot.tech"}]}],"generated_at":"2026-02-17T06:04:21.146845Z"}}