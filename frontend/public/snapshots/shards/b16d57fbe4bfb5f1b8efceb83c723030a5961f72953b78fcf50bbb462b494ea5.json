{"version":"v1","hackathon_url":"https://hackaichallenge.devpost.com","generated_at":"2026-02-18T16:53:42.590404Z","result":{"hackathon":{"name":"HackAI - Dell and NVIDIA Challenge","url":"https://hackaichallenge.devpost.com","gallery_url":"https://hackaichallenge.devpost.com/project-gallery","scanned_pages":5,"scanned_projects":110,"winner_count":17},"winners":[{"project_title":"Generative Art Recommendation System Tool (GARS)","project_url":"https://devpost.com/software/generative-art-recommendation-system-tool-gars","tagline":"Explore generative image creation like never before with our custom recommendation system and tool built for generative diffusion models.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"gradio","url":null},{"name":"milvus","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Prompting generative art models is critical in ensuring output aligns with what a user wants. This requires careful prompt engineering and understanding which parts of the prompt effects output. Due the vast possibilities of prompts this can be overwhelming and lead to frustration for a user. What if we can apply principles of recommendation systems to alleviate to issue and allow a user to explore generated images that are created to their preferences? This eliminates the need of careful prompt engineering at each iteration of design saving time for a user to explore more of the output space in a more efficient matter."},{"heading":"What it does","content":"Our project seeks to develops a novel integration of recommendation systems and generative art models. GARS provides a custom recommendation system that captures users preferences quickly and effectively. GARS allows a user to start a recommendation session in which fast inference SDXL Lightning models are loaded locally (works fully on consumer grade Nvidia 3070 Ti). We were able to do this by offloading parts of the diffusion model that are currently in use to the CPU. Users can optionally state their preferences to better guide the recommendation system, choose a specific step SDXL Lightning model, and an iteration count. After that a user gives a rating from (-1 to 1) for a generated image and allow the system to generate more images. A user can optionally control movements of various image characteristics through adjusting weights of each element or freezing them entirely. Once the recommendation system reaches the final iteration, all the images can be shown within a gallery."},{"heading":"How we built it","content":"For our user interface, we chose Gradio because of its seamless integration with the diffusion models we utilized. This allows for quick and efficient interactions, enabling users to easily explore and refine image generation in real time. Gradio's flexibility made it simple to display results and manage inputs, streamlining the entire user experience.\n\nFor our recommendation system, GARS uses Milvus, an open-source vector database, to manage and search through a database of embedding vectors that represent image characteristics. As users interact with the system, their preferences are adapted using the collection of vector embeddings stored by Milvus.\n\nFinally, as our recommendation system suggests new art by adjusting the prompt-based representation of the artwork, we needed a text-to-image model to generate the corresponding artwork from the prompt. It is also critical to ensure inference time is fast, as recommendations are created on the fly in real time. To achieve this, we ran SDXL Lightning and allow for user configurable option of running 2,4 and 8 steps of inference. This allows the user the option to sacrifice quality for speed."},{"heading":"Accomplishments that we're proud of","content":"Our recommendation system is able to consistently converge on a specific topic and/or style of an image by the end of a recommendation session. Achieving this level of accuracy in suggesting content that aligns well with the user‚Äôs preferences is one of the more challenging aspects of building a recommendation system. However, our system manages to do this within just a few iterations, making it both effective and enjoyable to use."},{"heading":"What we learned","content":"We learned how to take an idea and transform it into a product that people can use. We never envisioned that we could take our recommendation system and turn it into a design tool. It was initially made as a proof-of-concept that such a recommendation system could be created and function well. However, after completing this hackathon, we believe that the potential for generative recommendation systems is vast, with applications far beyond what we initially imagined. These systems could revolutionize how users discover and create content, offering personalized and innovative solutions across various fields, from design to entertainment and beyond.\n\nWe also learned that locally hosting model's provides flexibility and control that an online API does not provide. Exploring diffusion pipelines and seeing how custom ones can be built provided both a fun and fulfilling learning experience. Nvidia's AI workbench aided in the process of quickly getting the environment up and running with the possibility of quickly shifting to a remote server if we need to ever run bigger models or for training."},{"heading":"What's next for Generative Art Recommendation System Tool (GARS)","content":"The main application for GARS is still under development, but what we have developed for this hackathon will likely become a feature within our broader design tool. We aim to transform GARS into a fully functioning application within the next year. If you have any questions/concerns/suggestions or would like to try a demo of our app, please email clevergars.info@gmail.com ."},{"heading":"Built With","content":"gradio milvus python"}]},{"project_title":"RAGIS (Retrieval-Augmented Generation Incident Summary)","project_url":"https://devpost.com/software/ragis","tagline":"Project uses NVIDIA AI Workbench to easily build an assistant to help security analysts quickly identify false positives, reducing manual effort by using a RAG model for accurate predictions.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/033/619/datas/medium.jpeg","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"First Place"},{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best in Generative AI"}],"team_members":[],"built_with":[{"name":"azure","url":"https://devpost.com/software/built-with/azure"},{"name":"gradio","url":null},{"name":"langchain","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/jkuhno/ragis"}],"description_sections":[{"heading":"Inspiration","content":"Security analysts often spend significant time investigating false positives, which can lead to inefficiencies. Study shows that nearly a third of their time is spent on incidents that pose no actual threat. This creates alert fatigue and slows down response times, motivating us to create a solution that reduces this burden and helps analysts focus on real security threats."},{"heading":"What it does","content":"Our project, RAGIS (Retrieval-Augmented Generation Incident Summary), helps security analysts determine whether an incident is a false positive, or a true positive needing further investigation. It leverages generative AI and company data such as Microsoft Entra ID user details and previously closed incidents to make accurate predictions, saving valuable time and reducing the noise from false incidents."},{"heading":"How we built it","content":"We are using LangChain to build our RAG analyzer, Gradio as UI framework, and Nvidia cloud endpoints to run models. Azure queries are done with msgraph and azure.monitor.query .\n\nThe RAG part of our app starts with ChromaDB vectorstore loading, where vector embedding is done with NV-Embed-QA . We prompt meta/llama-3.1-70b-instruct chat model to act as an assistant tasked with determining if an input incident is a \"true positive\" or \"false positive\", and give the retrieved documents from ChromaDB as context. Retriever is parameterized to include some added diversity in the data, without sacrificing too much accuracy."},{"heading":"Challenges we ran into","content":"Tuning the prompt to be accurate but still allow the chat model to generalize to different use cases was a challenging task. Even more challenging was tuning the ChromaDB retriever to include relevant documents with enough diversity to allow for different use cases, without decreasing retrieval accuracy. Documentation for the Azure python packages was seemingly lackluster, we had some difficulty figuring out the queries."},{"heading":"Accomplishments that we're proud of","content":"We successfully created a functional system that automates a previously time-consuming task for analysts, increasing their efficiency by filtering out false positives and providing context-aware incident analysis."},{"heading":"What we learned","content":"We learned to utilize AI Workbench to collaborate easily with orchestration automation. Our team consisted of one security architect and one data scientist, which allowed both to learn about the other's field. By collaborating on the data integration between the AI application and Azure, we both learned how the python-AI-Azure interplay works."},{"heading":"What's next for RAGIS","content":"We plan to scale RAGIS by incorporating additional data sources, improving model accuracy, and integrating more advanced security use cases to tackle evolving cyber threats."},{"heading":"Built With","content":"azure gradio langchain python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Txt2App","project_url":"https://devpost.com/software/txt2app","tagline":"Txt2App: Turn any idea into a fully functional mobile app, powered by LLM and Nvidia AI Workbench.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/034/408/datas/medium.gif","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Second Place"},{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best in Generative AI"},{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best Written Blog Post"}],"team_members":[],"built_with":[{"name":"cuda","url":"https://devpost.com/software/built-with/cuda"},{"name":"fastapi","url":null},{"name":"llm","url":null},{"name":"nvidia-ai-workbench","url":null},{"name":"ollama","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-native","url":"https://devpost.com/software/built-with/react-native"}],"external_links":[{"label":"github.com","url":"https://github.com/altaga/Txt2App"},{"label":"github.com","url":"https://github.com/altaga/Txt2App/tree/main/Code"}],"description_sections":[{"heading":"How to run:","content":"If you wish to run the Workbench on your machine follow this: TUTORIAL HERE\n\nHi!, if you are a judge and want to review the code and the Nvidia Ai Workbench Container here are the links:\n\nBlog Post : Click here\n\nNvidia Ai Workbench Container : inside HERE\n\nVideo Demo : OPEN VIDEO\n\nIntroduction:\n\nIn an increasingly technology-driven world, the ability to develop mobile apps shouldn't be reserved for expert programmers only. Nvidia CEO Jensen Huang has highlighted the need to focus on learning prompt engineering rather than traditional programming, noting: \"It is our job to create computing technology such that nobody has to program. And that the programming language is human.\" 1\n\nLLMs provide the ability to process natural language input and text generation (not limited to natural language), which is an indispensable tool to achieve this goal. 2\n\nThe Nvidia AI Workbench offers a robust environment for the creation, training and optimization of container-based artificial intelligence models. Above all, it allows the use of resources both on the local machine and on external servers, facilitating rapid development from ready-to-work environments, thus accelerating development times. 3\n\nProblem:\n\nDeveloping mobile applications presents several challenges: 4\n\nCode Complexity : Mobile app programming involves writing and debugging code, which can be difficult without strong technical expertise. Diversity of frameworks, versions, and platforms : Ensuring that an application works optimally on different devices requires managing multiple versions and configurations, which can complicate the development process. UI/UX Design : Designing a good UI/UX that meets the expectations of users, who are already accustomed to established and current design patterns, can be an even more challenging task than developing the app's own backend.\n\nCurrent Solutions:\n\nFlutter Flow: This solution provides tools for interface design, but does not provide any AI capabilities. https://www.flutterflow.io/product Appypie: This text to app solution allows you to create applications with just a text prompt, however it requires a subscription, is closed source, and the demo provided by the page does not provide evidence of the use of AI. https://www.appypie.com/ UI Bakery: Although this page better demonstrates AI-based interface design, it does not provide any functionality to the app, only generating base designs. https://uibakery.io/\n\nSolution:\n\nIntroducing Txt2App , Huang's promise becomes a reality, accessible to everyone, democratizing application development and opening up new possibilities for technology creation thanks to Nvidia Ai Workbench and LLMs (Generative AI).\n\nDiagram and Summary:\n\nThe general diagram of our solution is as follows, this is a summary of the services, but we will detail them later.\n\nGoogle Cloud VM: We are using a Google VM with the following features. OS: Ubuntu 24.04 LTS. GPU: Nvidia Tesla T4 (16Gb). RAM: 65 Gb. HDD: 500 Gb. vCPU: 10 cores. Nvidia AI Workbench: The Nvidia toolkit is used to perform rapid development and deployment of our application. https://docs.nvidia.com/ai-workbench/user-guide/latest/overview/introduction.html Ollama Server: We use the Ollama server service to run the LLM models used in the project. LLM Model: Deepseek Coder V2. https://ollama.com/library/deepseek-coder-v2 ReactJS: This was the web framework to create the project's UI, we used pure ReactJS without any additional framework. Main UI: This is the main interface of the project where the text window and the App preview are displayed. App Preview: This interface pre-renders the app for the user to test before converting it to APK. React Native: App Builder: Android Native Build is used to convert React code into Android native code. Fastapi: We use this framework to create the complete API of our application. Static Website: This section of the API is used as a server to display the UI from the browser. API: This section communicates the UI with the generation, preview and build services."},{"heading":"Everything is fully explained step by step in our github:","content":"https://github.com/altaga/Txt2App\n\nCommentary:\n\nTxt2App is a groundbreaking solution designed to revolutionize the way mobile applications are developed. Leveraging the power of large language models (LLM) and Nvidia's AI Workbench, Txt2App enables users to turn any idea into a fully functional mobile app with ease. This innovative tool lowers the barriers to app development by automating many of the complex, technical tasks that traditionally require extensive programming knowledge. Whether you're an entrepreneur with a vision or a business looking for custom solutions, Txt2App simplifies the journey from concept to deployment.\n\nEmpowering Users with Cutting-Edge AI\n\nBy integrating Nvidia's AI Workbench, Txt2App harnesses cutting-edge machine learning models to interpret natural language inputs and generate corresponding app features. This means users can describe their ideas in plain text, and Txt2App will handle the heavy lifting of coding, UI/UX design, and backend infrastructure. This fusion of LLM and AI-driven technology drastically reduces development time, while ensuring that the final product meets high performance and functionality standards.\n\nA New Era for App Development\n\nTxt2App marks a significant shift in how applications are conceptualized, created, and delivered. It democratizes app development, making it accessible to non-technical users without compromising on the quality or complexity of the applications produced. As the world becomes increasingly mobile-centric, Txt2App opens doors for individuals and businesses to innovate and adapt swiftly, fostering a more inclusive and dynamic app ecosystem.\n\nReferences:\n\nhttps://www.forbes.com/sites/timbajarin/2024/03/20/nvidias-ceo-on-the-democratization-of-coding/ https://ai.meta.com/blog/meta-llama-3/ https://docs.nvidia.com/ai-workbench/index.html https://www.netguru.com/blog/mobile-app-challenges"},{"heading":"Built With","content":"cuda fastapi llm nvidia-ai-workbench ollama python react react-native"},{"heading":"Try it out","content":"github.com github.com"}]},{"project_title":"CaptionCraft","project_url":"https://devpost.com/software/captioncraft-5wc4b9","tagline":"Elevate Your Social Media Game.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/057/756/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Third Place"}],"team_members":[],"built_with":[{"name":"helsinki-nlp/opus-mt","url":null},{"name":"jupyter-notebook","url":null},{"name":"mistralai","url":null},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"runwayml","url":null},{"name":"salesforce-blip","url":null},{"name":"shell","url":"https://devpost.com/software/built-with/shell"},{"name":"stable-diffusion","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/yueyin22/HackAI2024_CaptionCraft.git"}],"description_sections":[{"heading":"Inspiration","content":"Social media marketing has become a vital tool for enterprises to connect with audiences, promote products, and build brand identity. The ability to drive higher interaction with posts often hinges on two key factors: an eye-catching image and a captivating caption. However, coming up with engaging captions for every post can be time-consuming. That‚Äôs where AI comes in. Inspired by the potential of AI to simplify this process, we created CaptionCraft ‚Äîa solution that not only generates captivating captions but also allows users to enhance their images by instantly removing and generating backgrounds."},{"heading":"What it does","content":"CaptionCraft is an AI-driven web application that allows users to upload a picture and automatically generate captivating captions tailored to the image. Users can customize their captions by including hashtags, emojis, and specific keywords, while also selecting the desired tone, such as playful, professional, or inspirational. This intuitive tool streamlines the captioning process, making it easier for social media enthusiasts to engage their audience effectively. Additionally, it allows users to generate custom images based on prompts. These AI-generated images can serve as backgrounds for the user‚Äôs uploaded images. The generated images can also be fed into the caption generation process, resulting in captions that are specifically tailored to both user-uploaded and AI-generated visuals. Lastly, a newly added feature enables captions to be translated into the user's desired language, breaking language barriers and allowing brands to connect with a global audience while tapping into new markets."},{"heading":"How we built it","content":"We began by identifying the core functionalities our application needed:\n\nImage-to-text conversion: We used Salesforce‚Äôs blip-image-captioning-base model to generate basic descriptive outputs for uploaded images.\n\nCaption generation: Using NVIDIA‚Äôs Mistral model, we processed these descriptions to create contextually relevant and engaging captions tailored to the image.\n\nImage generation: To expand creative possibilities, we integrated RunwayML‚Äôs stable-diffusion-v1-5 model, which allowed users to generate custom images based on prompts. These generated images could then be used as backgrounds for their uploaded photos, providing greater flexibility in content creation.\n\nText Translation: Powered by Helsinki-NLP/Opus-MT Models, we enable users to translate generated captions into multiple languages, ensuring accessibility and global reach.\n\nIntegrating the models together for user interaction, we utilized Gradio to create the easy-to-use web application. The models and API integrations were run on NVIDIA AI Workbench, and JupyterLab was used for testing and running the components during development. This integration streamlined the process of both image and caption generation while maintaining smooth user interaction."},{"heading":"Challenges we ran into","content":"One of the biggest challenges we encountered was the lack of GPU resources. Training models from scratch or running heavy computation tasks in real time required significant computing power, which we didn‚Äôt always have access to. Fortunately, we were able to overcome this by leveraging existing APIs and pre-trained models that were designed to perform efficiently with fewer resources. This allowed us to achieve our intended functionalities without the need for high-end GPUs or extensive local processing. Additionally, we spent time optimizing the application‚Äôs performance to ensure the user experience remained smooth despite the resource limitations."},{"heading":"Accomplishments that we're proud of","content":"Successfully integrated multiple advanced AI models (Salesforce blip-image-captioning-base, Nvidia‚Äôs Mistral AI, RunwayML‚Äôs stable-diffusion-v1-5 and our latest addition Helsinki-NLP/Opus-MT) into one cohesive platform. Created a seamless user experience that combines image upload, background removal, image generation, and personalized captioning. Enabled the ability to generate creative images from prompts and use them as overlays, offering new levels of customization. Optimized the solution to run efficiently despite limited GPU resources, ensuring accessibility for users with various hardware setups."},{"heading":"What we learned","content":"Through this project, we delved deeper into AI-driven solutions and how they can be applied in real-world contexts like marketing. We learned about integrating various models for different tasks, like image-to-text conversion for caption generation and background removal tools. The project reinforced our knowledge of API handling and how to balance different functionalities (like caption generation and image manipulation) within a single application. We also discovered how important it is to manage computational resources effectively, especially when working with heavy models in real-time environments."},{"heading":"What's next for CaptionCraft","content":"Enhanced User Customization: We plan to expand the customization options by adding more tone presets, allowing users to adjust captions for different audiences more precisely. Integration with Popular Social Platforms: We aim to add features for direct publishing of captions and images to popular social media platforms, further streamlining the process for users. Real-time Collaboration: Future updates might also include the ability for teams to collaborate on content creation, making it an even more powerful tool for businesses and influencers. Multilingual Support: (NEWLY INTEGRATED FEATURE) Incorporating multi-language capabilities would enable CaptionCraft to cater to a broader audience and support global social media strategies."},{"heading":"Built With","content":"helsinki-nlp/opus-mt jupyter-notebook mistralai nvidia python runwayml salesforce-blip shell stable-diffusion"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"AugmentAI","project_url":"https://devpost.com/software/data-augmentation-no-name-yet","tagline":"Supercharging your dataset images with generative AI to enhance machine learning performance.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/137/939/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"ai","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gan","url":null},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"torch","url":null},{"name":"torchserve","url":null},{"name":"workbench","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/nhvn/data-aug.git"}],"description_sections":[{"heading":"Inspiration ‚≠êÔ∏è","content":"The inspiration behind AugmentAI stems from the challenge of obtaining diverse, high-quality datasets for machine learning models. While working on various AI projects, I noticed how data scarcity often limits model performance, especially in specialized domains. This motivated me to create a tool that generates synthetic images to enhance training datasets, making quality data augmentation accessible to all developers regardless of their computational resources."},{"heading":"What it does üéÜ ‚Üí üéá","content":"AugmentAI is a data augmentation platform that generates high-quality synthetic images through the Stability AI API , with an automatic fallback to a local generative adversarial network (GAN) model. Users can:\n\nUpload individual images or entire folders Use built-in sample datasets for immediate testing Generate high-resolution augmented images Receive real-time processing feedback Download results automatically\n\nWhat makes it unique:\n\nHybrid Processing System: Combines cloud API with local processing for guaranteed availability NVIDIA AI Workbench Integration: Enables one-click deployment and simplified environment management Automated Fallback System: Seamlessly switches between services without user intervention Built-in Sample Dataset: Allows immediate testing without sourcing external images Real-time Processing Feedback: Provides continuous status updates"},{"heading":"How it's built üõ†Ô∏è","content":"The project is developed specifically for NVIDIA AI Workbench , utilizing:\n\nBackend: Python, Flask Frontend: HTML5, JavaScript, Tailwind CSS Image Processing: Stability AI API, PyTorch Deployment: NVIDIA AI Workbench environment\n\nThe architecture features:\n\nPrimary Service: Stability AI API for high-quality image generation Fallback System: Local GAN model for continuous availability User Interface: Intuitive upload system with drag-and-drop support Processing Pipeline: Automatic service switching and error handling"},{"heading":"Challenges faced üèÉ‚Äç‚ôÇÔ∏è","content":"The development journey involved several key challenges:\n\nInitial Resource Limitations CPU-based GAN training produced only 64x64px images Processing speed was impractical for real use Technical Integration Implementing seamless API integration Creating reliable fallback mechanisms Managing file uploads and downloads User Experience Designing intuitive file management Implementing real-time feedback Handling various error states"},{"heading":"Accomplishments proud of üèÜ","content":"Key achievements include:\n\nSuccessful integration with NVIDIA AI Workbench for streamlined deployment Implementation of dual processing system (API + local fallback) Creation of intuitive interface with sample dataset testing Development of robust error handling and feedback system Achievement of high-quality image generation with original dimension preservation"},{"heading":"What I learned üìö","content":"This project provided valuable experience in:\n\nNVIDIA AI Workbench environment setup and management API integration and fallback system design User interface optimization for file handling Error state management and user feedback Balancing cloud and local processing solutions\n\nImpact and Potential:\n\nSimplifies ML dataset enhancement through streamlined deployment Provides reliable service through dual processing options Enables rapid prototyping with sample dataset testing Supports both beginners and experienced users Offers scalable solution for larger projects"},{"heading":"What's next for AugmentAI ü§ñ","content":"Potential future development plans include:\n\nImage Preview System: Allow users to review generated images before downloading Advanced Image Processing Options: Provide features like style transfer, object removal, and image blending Support for Text and Tabular Data: Extend augmentation to diverse data types beyond images Batch Processing Improvements: Optimize workflows for handling large datasets efficiently Medical Imaging Applications: Explore use cases in healthcare, such as augmenting diagnostic imaging datasets Enhanced Parameter Control: Empower users to fine-tune generation parameters for precise customization"},{"heading":"Additional Information üìÑ","content":"Image Credits\n\nImage 1: \"Plant photo by Ahme12x, Stock photo ID: 2502235367, from Shutterstock.\" Image 2: \"Mountain photo by Biletskiy_Evgeniy, Stock photo ID: 591441250, from iStock.\" Image 3: \"Tree photo by LagrangeHerve, from Pixabay.\"\n\nContact: If you're a judge and need access or have questions, please reach out and I will respond as soon as possible."},{"heading":"Built With","content":"ai docker flask gan nvidia python torch torchserve workbench"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"AI Academic Feedback Assistant","project_url":"https://devpost.com/software/ai-teaching-assistant","tagline":"The all-in-one platform to quickly assess, publish, and re-evaluate students' assignments!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/057/792/datas/medium.jpg","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"gradio","url":null},{"name":"langchain","url":null},{"name":"nvidia-workbench","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/mtd-ai/aits"}],"description_sections":[{"heading":"Inspiration","content":"Recently my assignment took 5 weeks to be marked! I was so discouraged at first, but then I found out 2 graders were marking over 350 assignments! So I built this app to help them streamline the marking process! Knowing that many graders lack technical AI knowledge or computing resources, NVIDIA AI Workbench is a great solution!"},{"heading":"What it does","content":"We built AI Academic Feedback Assistant , which is an NVIDIA AI Workbench native app. It utilizes NVIDIA Workbench's ability to quickly spin up a GenAI application! You can load assessment criteria documents and student assignments, and our Assistant will give marking suggestions for you! You can also let AI generate summary or response email for you! You can either choose the local Phi-3 mini model, or use NVIDIA hosted NIMs!"},{"heading":"How we built it","content":"NVIDIA AI Workbench Gradio LangChain Phi-3 NVIDIA API Catalog NIMS\n\nI have a GPU laptop, but I mainly code on my Mac. NVIDIA AI Workbench is really convenient since I can code on my Mac and run on my GPU laptop. I don't have to worry much about building the container, and mapping ports, as those tasks are all automated for me. The ability to edit build scripts and env variables directly through a user-friendly GUI brings non-DevOps people into the game!"},{"heading":"Challenges we ran into","content":"We want our project to be compatible with low-performance GPUs, as not all graders have access to good GPUs. Therefore, we aim to minimize the model size to decrease generation time. However, the documents are usually large, and small models hallucinate a lot!\n\nSolution: RAG\n\nWe store documents in a vector database and only retrieve relevant chunks of text. For smaller models and weaker GPUs, this technique reduces inference time dramatically!"},{"heading":"Accomplishments that we're proud of","content":"We managed to provide a pretty accurate response with Phi-3-4k-mini-instruct. Its performance is on par with 7B mistral or 8B llama. We are happy that we solved a real problem, and we hope our project will positively impact AI in the education domain. We also made a great video pitching our idea! Check it out [here]("},{"heading":"What we learned","content":"We learned how NVIDIA AI Workbench automates time-consuming tasks for us!"},{"heading":"What's next for AI Academic Feedback Assistant","content":"We find out that the process of assessment, reading complaint emails, and returning formal responses is a repetitive task not only in the education domain, but in others as well, like insurance, consultant, or retails. We hope to generalize the application to many domains in the future."},{"heading":"Built With","content":"gradio langchain nvidia-workbench python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Jockbench - Revolutionary Agentic Video (AKA: Saddle Stack)","project_url":"https://devpost.com/software/workey","tagline":"Edit your videos using natural language. Jockbench isn't just a demo, it is an open source server that allows you to deploy your own agentic video production service.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/170/365/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"conda","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"fastapi","url":null},{"name":"ffmpeg","url":"https://devpost.com/software/built-with/ffmpeg"},{"name":"jockey","url":null},{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"langsmith","url":null},{"name":"nginx","url":"https://devpost.com/software/built-with/nginx"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"shadeform","url":null},{"name":"twelvelabs","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"},{"name":"yarn","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/brainwavecollective/saddle-stack/"}],"description_sections":[{"heading":"What's This All About?","content":"Imagine going from zero to having a fully functional AI video processing platform in an hour. Not just a fragile demo, but a complete, extensible framework that you can actually build upon. We've combined NVIDIA AI Workbench's powerful infrastructure management with an enhanced version of Jockey's video framework to create something unique - a platform that's both incredibly easy to start with and robust enough for serious development."},{"heading":"The Magic (In Plain English)","content":"Tell our system what kind of video you want, and it'll create it from your existing footage. For example, upload a few hours of Tour de France footage and ask for \"a 4-scene video of Jonas Vingegaard climbing, challenging Pogacar, crossing the finish line, and celebrating on the podium\" - a minute later, you've got your custom highlight reel."},{"heading":"What Makes This Special","content":"Complete Package : Everything is covered - from remote server setup to video processing to web interface Incredibly Simple Setup : Deploy and configure a GPU server with just a few clicks - no DevOps expertise needed An Eye on Production : Built with real-world usage in mind, ready for you to build upon Power Under the Hood : Leverages TwelveLabs' state-of-the-art video understanding models Developer Friendly : Extensible architecture with clean separation between UI, backend, and processing Open Source : We intend to make this entire project repository available for community use and contribution"},{"heading":"Getting Started Is Easy","content":"Complete basic prerequisites (~30 minutes) Create/configure instance and deploy the Jockey server (~20 minutes) Launch the frontend and create your first video (~10 minutes)\n\nThat's it - no previous experience with Docker, Python, or GPU setup required. This could literally be your first introduction to all of the related technologies and products and we will walk you through it all."},{"heading":"Built For Growth","content":"This isn't just another quick-start solution - it's a comprehensive platform designed to grow with your needs. Whether you're making your first AI-powered video or building a sophisticated video processing application, you'll find a solid foundation here. The architecture provides clear patterns for adding services, extending functionality, and scaling your application, making it an ideal starting point for exploring AI-powered video processing, GPU computing, or modern web architecture."},{"heading":"What's Next?","content":"While our current implementation already demonstrates the power of bringing together NVIDIA AI Workbench with enhanced video processing capabilities, we're just getting started. We're continuing to develop this into an even more robust platform while maintaining its approachability. Future plans include exploring advanced AI Workbench capabilities, expanding the front-end features, and building out additional reference implementations. We are also working with related teams to discuss how we can best give back to the open source projects that led us here."},{"heading":"Technical Foundation","content":"Built on the incredible novelty of Jockey (TwelveLabs' agentic video framework), TwelveLabs' unmatched video understanding capabilities, and NVIDIA AI Workbench's ability to abstract away complex environment configurations, we've created something that just works. Our journey involved extending Jockey for practical remote development, streamlining Workbench deployments, and creating a cohesive platform that lets you focus on building rather than configuring."},{"heading":"Challenges We Overcame","content":"Building a seamless experience meant tackling some significant technical hurdles:\n\nGetting Jockey (a \"pre-alpha\" framework) to run smoothly within containers - something it wasn't originally expected to do Learning to work within NVIDIA AI Workbench's opinionated architecture while maintaining our vision for a user-friendly platform Creating a robust interface despite neither of us being proper front-end developers Navigating the complexities of a novel real-time video processing solution"},{"heading":"Proud Accomplishments","content":"Beyond being a team of two who managed to bring this all together, we're particularly proud of:\n\nCreating a truly approachable platform for advanced AI video processing - something that typically requires significant technical expertise Successfully extending Jockey's powerful functions to a robust remote server Building a complete front-end application that showcases what's possible with this technology Wrapping complex infrastructure management into simple, automated processes Achieving our goal of making advanced AI technology accessible to more developers\n\nThe real achievement isn't just in the technical solutions we've created, but in how they come together to provide a foundation that others can build upon. We've transformed what would typically be days of painful setup and configuration into a process that can be completed in less than an hour, without sacrificing the power and flexibility that developers need for serious projects.\n\nSocials\n\nThienthanh Trinh LinkedIn: https://www.linkedin.com/in/thienthanh-trinh-71478bb0/ Twitter: @thienthanhtrinh Discord: ttrinh2306 (1295925057285263461)\n\nDaniel Ritchie LinkedIn: https://www.linkedin.com/in/danielritchie123/ Twitter: @deploydan Discord: quantumpoet (769583125579169812)\n\nhttps://brainwavecollective.ai/"},{"heading":"Built With","content":"conda docker fastapi ffmpeg jockey langchain langgraph langsmith nginx node.js nvidia openai python react shadeform twelvelabs typescript vite websockets yarn"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Personalization Aware E-Commerce Shopping Assistant","project_url":"https://devpost.com/software/personalization-aware-e-commerce-shopping-assistant","tagline":"Chatbot that lets you talk with private eCommerce data. Instead of searching for products by name, you describe what you want in natural language and see personalized results based on your query","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/057/924/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"langchain","url":null},{"name":"langgraph","url":null},{"name":"neo4j","url":"https://devpost.com/software/built-with/neo4j"},{"name":"nvidia-ai-workbench","url":null},{"name":"ollama","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"qdrant","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/QasimKhan5x/pasa"}],"description_sections":[{"heading":"Inspiration","content":"Traditional e-commerce platforms don‚Äôt offer many ways for users to interact, often requiring them to clearly state what they want using specific keywords. This can be mentally tiring. On top of that, the way products are recommended or ranked isn‚Äôt always clear, leaving users confused about why certain items show up. This can create a frustrating experience and reduce trust in the platform.\n\nToday, a successful personalized recommendation system depends on two main things: content and user experience (UX) . Content helps users find products more easily, while UX makes it easier to interact with personalized recommendations and conversations. Large Language Models (LLMs) are great for both because they can connect different ideas and objects based on their built-in knowledge."},{"heading":"How I built It","content":"Dataset Preparation\n\nThe first step was acquiring the dataset. I downloaded the Amazon Reviews'23 dataset by McAuley Lab that contained a wide range of products and reviews. For this hackathon, I focused solely on the beauty and personal care category, so I filtered the dataset to include products from this category only. Next, I sampled from the products dataset to include around 958 products only. From the reviews dataset, I included all of the reviews for the remaining products.\n\nCreating a Knowledge Graph\n\nNext, I started building a knowledge graph from the product and review data. The graph consisted of nodes and relationships representing various aspects of the dataset, such as products, users, reviews, and ratings. I used Neo4j to store and query the knowledge graph.\n\nInitially, I used the data directly from the dataset to form the basic structure, but I wanted to enrich it further. For this, I turned to a Large Language Model (LLM). The LLM was used to extract additional metadata, including:\n\nProduct Keywords : Key terms and features associated with each product. Attributes : Properties like brand, color, price range, ingredients, etc. Use-Cases : Recommended situations or needs the products were suited for. Product Summaries : Short descriptions generated from reviews.\n\nSince generating this metadata required a significant number of LLM calls, I used the Mistral-Nemo model with Ollama to handle the task locally. The GPUs that I used were Mac M3 GPUs for accelerating inference.\n\nBuilding a Vector Database\n\nOnce I had my enriched data, the next step was to build a vector database to support efficient search and retrieval. I chose Qdrant as my vector database, which allowed me to store both sparse and dense vector collections, so that I could perform Hybrid Search with reciprocal rank fusion, which is a combination of keyword-based search with vector-based search to improve accuracy and relevance.\n\nHere‚Äôs what I stored in the vector database:\n\nProduct Keywords Summaries Subcategories of Products Use Cases\n\nTo further optimize the retrieval process, I added a reranker using the Jina AI API . The reranker takes the results from the hybrid search and refines them to improve the final output by ordering the most relevant products at the top.\n\nCreating a Graph of AI Agents\n\nTo manage user queries and interact with the data, I created a network of AI agents using the LangGraph framework. Each agent had a specific role in handling different aspects of the search process.\n\nThe key components were:\n\nUser Intent Identification : I used GPT-4o to understand what the user was looking for. Query Entity Extraction : GPT-4o also helped in identifying the important entities (e.g., product name, attribute, or use-case) from the user's query. Dynamic Generation of Cypher Queries : GPT-4o generated Cypher queries on the fly based on the extracted entities to interact with the Neo4j database.\n\nThe combination of these AI agents allowed for a dynamic and conversational interaction with the knowledge graph.\n\nBuilding the Streamlit App\n\nFinally, I showcased the project in a user-friendly interface. The app allows users to enter queries and explore beauty and personal care products, retrieving results based on the enriched knowledge graph and vector-based search system."},{"heading":"NVIDIA AI Workbench","content":"Using NVIDIA AI Workbench in My Project\n\nBasic Python Image\n\nI have a MacBook, which doesn‚Äôt have NVIDIA GPUs, so I didn‚Äôt need CUDA installed in my environment. Instead, I used the basic Python image that didn‚Äôt include CUDA support. Since I mostly worked with APIs throughout the project, this setup worked perfectly for my needs. The only exception was the knowledge graph generation, which required many LLM calls. I used Ollama for local LLM calls. I was easily able to install it in workbench just by adding one line in the postBuild.bash script that adds additional software to your container that are not simply installed using pip or apt. It uses the GPUs in my Macbook, based on the Metal Performance Shaders (MPS) backend for inference acceleration. I provided the container with 4GB of RAM so that Ollama could handle relatively longer prompts.\n\nDefining Environment Requirements\n\nIn the Workbench, I started by listing all the required packages and dependencies in the environment section. This ensured that every time the container was run, all necessary libraries were installed automatically in the environment. As mentioned before, I used postBuild.bash to install Ollama . Additionally, since I was using some embedding models for vector-based retrieval, I added a python command to this script that downloads these models while the container is being built. This saved me time on repeated manual installations.\n\nMounting Cache Directory\n\nI used dense and sparse embeddings models from HuggingFace to perform hybrid search. These are large models that take a few minutes to download every time the container starts. Therefore, to avoid waiting every time, I added a Host Mount where I saved the data in /home/workbench/.cache/ to my local storage.\n\nManaging API Secrets\n\nMy project required access to multiple APIs for tasks like querying databases and reranking results. To manage these securely, I used the secrets section in the Workbench. By storing my API keys and other sensitive information in this section, I didn‚Äôt have to create or manage a separate .env file. The secrets were injected directly into the environment when needed, making the workflow smoother and more secure.\n\nServing the Streamlit App\n\nOne of the features I found really useful in NVIDIA AI Workbench was the ability to easily serve my Streamlit app. I created an app configuration in the Workbench, which allowed me to start the web server with just the click of a button. This made it simple to run and share the application, as I didn‚Äôt need to set up separate scripts to launch the app manually.\n\nEasy Reproducibility\n\nWorkbench‚Äôs environment configuration, postBuild scripts, secrets management, and app-serving capabilities, makes my project highly reproducible . Anyone can reproduce my setup by simply cloning the repository URL. Workbench also has Git built instead it and tracks all of the changes you make to your environment, scripts, secrets, variables, and code.\n\nAn all-in-one interface for these tools ensures that the project is easy to share, with all the necessary components included and readily available.\n\nLogging\n\nIn the Output tab, AI Workbench provides logs for the build process, the system APIs, and the applications that are running. For my project, I was logging responses from Streamlit, so I could see the application logs of the Chatbot application for debugging purposes.\n\nOverall, NVIDIA AI Workbench provided a streamlined environment to handle all aspects of my project, from managing dependencies and secrets to serving the final app, making it an essential tool for ensuring efficiency and reproducibility."},{"heading":"Challenges","content":"I spent the least time on the frontend, so the UI still needs some work to be done. For example, it has to stream tokens from the LLM, rather than show it only once it is completely generated. Since I only want to show formatted and structured output from the LLM, I didn't find a resource to help me accomplish this."},{"heading":"Future Work","content":"Add support for streaming Improve presentation of the UI Add support for additional categories e.g., electronics, home appliances, etc."},{"heading":"Built With","content":"langchain langgraph neo4j nvidia-ai-workbench ollama openai python qdrant"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"xShield","project_url":"https://devpost.com/software/xshield","tagline":"Introducing xShield,an AI-powered tool for easy code security and compliance analysis.Analyze entire repositories or commits for peace of mind. Fast, smart, and effortless security with a single click","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/057/574/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"aiworkbench","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"langchain","url":null},{"name":"llm","url":null},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/tenzindayoe/xshield_ai_workbench"}],"description_sections":[{"heading":"Inspiration","content":"Whether you're a solo developer, part of an enterprise, or a student, everyone deserves secure code. As a software engineering student, I aimed to streamline the development-to-deployment process by tackling code issues early on. Inspired by large language models (LLMs), this project focuses on detecting and fixing vulnerabilities, ensuring data security, and verifying regulatory compliance before staging code for deployment. This approach helps developers and reviewers catch issues early, saving time and improving productivity while ensuring software compliance. Now solo developers and small teams can also have access to advanced AI tools for Code security checks and Compliance checks usually available only to enterprises through large security teams.\n\nFor enterprises, this is especially useful since multiple software engineering projects can sometimes allow certain security issues to slip through. With this additional layer of security, companies can be more confident in their code security and compliance."},{"heading":"What it does","content":"XShield scans your repository‚Äîeither the entire codebase or just the latest commit‚Äîfor vulnerabilities and compliance issues using an LLM Infrastructure. These scan can be executed through our web interface or via API calls integrated into your CI/CD pipeline using GitHub Actions. It generates a detailed report, enabling developers and reviewers to address issues before the code is deployed. Currently XShield offers multiple LLMs such as Hermes Llama 3 and GPT4 for users to choose for their code analysis. All of this is can be simply done in the xshield website, by simply putting the github repo url and a click of a button. XShield handles all the security and compliance checks and presents the user with an easy to read and manage report.\n\nMoreover, xShield is integrated with Static Application Security Testing tool such as (Bandit for Python) making its vulnerability and security detection more robust by giving the LLMs more context and additional layers of analysis."},{"heading":"How we built it","content":"Handling large code repositories can be a challenge due to token limits in LLMs. To overcome this, we created a LangChain-based LLM pipeline where each code file is processed individually. The LLM generates a concise summary of each file‚Äôs functionality and dependencies. Once all summaries are complete, we combine them to build a compact representation of the entire repository.\n\nNext, we perform context analysis using the LangChain pipeline. The content of each file, along with its functionality and dependency map, is analyzed by the LLM to determine which other files are needed for a complete analysis. So when one file is being analyzed, all the related and dependant files are pulled by the LLM for a more comprehensive and contextual check. The LLM then provides a JSON response containing the relevant files for review.\n\nFor vulnerability detection, xShield also uses a Static Application Security Testing tool to generate a security check report, to give to the LLM more knowledge about the issues that can be detected by existing tools. This static analysis tool runs independently on the user repository container giving the users the ability to implement any tool that fits their needs. Finally, the LLM processes this refined context to check for code vulnerabilities or data compliance. This LangChain-based flow allows us to scan entire repositories with improved accuracy and context-awareness.\n\nOn the infrastructure side, we built XShield using Node.js microservices, each running in isolated containers. When a user subscribes their repository to the service, a new container is created on the fly with its own lightweight server. This ensures isolation and security for storing user code and sensitive data. The LLMs are also containerized, giving us the flexibility to use different models for security analysis based on client requirements.\n\nXShield is now developed and deployed using Nvidia AI Workbench. Since xShield is a multicontainer application we leveraged the compose feature of the AI Workbench to manage and run all of the services in different containers.\n\nTo start the entire infrastructure, users just have to click on the start button in the compose section in the Environments menu. We recommend connecting AI Workbench to a cloud server with a high performance GPU such as Nvidia H100 since the AI Service uses local LLMs."},{"heading":"Challenges we ran into & How we fixed it","content":"LLM's can sometimes be unpredictable, since we were dealing heavily with structured data, the llm's sometimes provided incorrect json response which ended breaking our web application during parsing. To encounter this issue, we used json fixing libraries and also more stable LLM's such as GPT4 to perform JSON fixing. This was a very effective solution to provide a stable and fluent experience.\n\nInitially we were manually deploying all the docker containers using shell scripts. This was a manual and tedious user experience. But through the valuable feedback of the judges, we were able to streamline this deployment by leveraging the compose feature of the AI workbench. We also had to redesign our application to support this new development and deployment using AI Workbench. Now our entire application is developed and deployed fully using Nvidia AI workbench and its compose feature."},{"heading":"Accomplishments that we're proud of","content":"We successfully developed a robust, AI-driven code security and data compliance platform that combines LLM-based analysis with Static Application Security Testing (SAST) tools. This approach creates a comprehensive, adaptable security infrastructure for identifying and fixing security and data compliance issues that can support solo developers, teams, and enterprises alike.\n\nOur major achievements include overcoming the challenge of large code files and their dependencies by designing a custom LLM pipeline. This pipeline analyzes each file independently, builds a dependency map, integrates SAST reports, and provides a full-context security assessment. This method allows XShield to accurately and efficiently assess security vulnerabilities across complex codebases.\n\nAdditionally, we‚Äôre proud of our integration with tools like Bandit, which enhances the LLM‚Äôs accuracy by adding detailed static analysis data. This fusion of SAST tools and LLM capabilities opens up exciting possibilities for improved security analysis, demonstrating a novel approach that leverages the strengths of both technologies."},{"heading":"What we learned","content":"LLMs are incredibly versatile! They can do so much more than just answer queries. We discovered the unlimited potential of LLM pipelines when integrated with other services. While this demo showcases a simple implementation, larger and more specialized LLMs can detect vulnerabilities in insecure libraries b and even design patterns.\n\nWe're proud of creating this LLM-based infrastructure, as it was a challenging yet rewarding experience. Special thanks to Docker containers and NVIDIA AI Workbench for making the deployment and setup process much easier!"},{"heading":"What's next for XShield","content":"While XShield offers robust security and compliance checks, there are several areas for improvement:\n\nEnhanced Policy Integration with RAG: We aim to integrate Retrieval-Augmented Generation (RAG) to allow more extensive policy files and handle complex security requirements. Larger Models and Fine-Tuning: We plan to incorporate larger language models and fine-tune them on Common Weakness Enumeration (CWE) datasets for deeper analysis and better-targeted security recommendations. Currently for this demo, we have integrated SAST tools to analyze python files effectively. In the future we would like to integrate multiple language SAST tools to provide a more robust security check experience or allow the users to use their SAST tool of choice. While users can modify the SAST tool by changing the containerTest repo, in the future we plan to make this process more intuitive and streamlined.\n\nDue to time constraints in the hackathon, our focus was primarily on integration and infrastructure. However, these improvements are on our roadmap to further enhance XShield‚Äôs performance and versatility."},{"heading":"Built With","content":"aiworkbench docker javascript langchain llm nvidia python tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"REALM: Reinsurance Eval & Analysis for Megaprojects","project_url":"https://devpost.com/software/realm-reinsurance-eval-analysis-for-megaprojects","tagline":"R.E.A.L.M.: AI-powered risk analysis for mega-projects. Streamlines facultative reinsurance, providing instant insights on complex risks.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/056/542/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"langchain","url":null},{"name":"openai","url":null},{"name":"perplexity","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"streamlit","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Working with Indonesia's largest reinsurance company opened my eyes to the complexities of mega-project risk assessment. The challenge of balancing qualitative and quantitative approaches in scoring these projects was particularly intriguing. We implemented a 5C approach (Character, Capacity, Capital, Collateral, and Conditions) to assess projects, but I realized there was potential for a more streamlined, tech-driven solution."},{"heading":"What We Learned","content":"Through developing R.E.A.L.M., we gained deep insights into:\n\nThe intricacies of project-based facultative reinsurance The power of combining traditional risk assessment methods with AI The importance of user-friendly interfaces in complex financial tools The challenges of integrating qualitative data into quantitative models"},{"heading":"How We Built It","content":"We built R.E.A.L.M. using a stack that includes:\n\nStreamlit for the frontend, ensuring a responsive and intuitive user interface Python for the backend, handling complex calculations and data processing Perplexity API exploring the internet SQLite for storage\n\nThe core of R.E.A.L.M. is our innovative scoring system that digitizes the 5C approach:\n\nCharacter : AI-driven analysis of the project management team's track record Capacity : Automated assessment of project feasibility and timeline Capital : Real-time financial modeling and stress testing Collateral : Smart evaluation of project assets and guarantees Conditions : AI-powered analysis of market conditions and external factors"},{"heading":"Challenges We Faced","content":"Our journey wasn't without obstacles:\n\nUser Experience : Balancing comprehensive analysis with user-friendliness was tricky. To refine our interface, we conducted multiple user testing sessions. Processing Time : A technical hurdle was ensuring quick response times while processing complex risk calculations. To address this, we optimized our backend and implemented efficient caching mechanisms.\n\nDespite these challenges, R.E.A.L.M. emerged as a powerful tool that will transform project-based facultative reinsurance assessment, making it faster, more accurate, and more accessible to underwriters worldwide."},{"heading":"Built With","content":"langchain openai perplexity python streamlit"}]},{"project_title":"Speech to Image Converter","project_url":"https://devpost.com/software/speech-to-image-converter","tagline":"See what you speak","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"api","url":null},{"name":"cuda","url":"https://devpost.com/software/built-with/cuda"},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"workbench","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Raghu-dev-pixel/Nvidia_speech_to_Image_converter.git"},{"label":"github.com","url":"https://github.com/Raghu-dev-pixel/Nvidia_speech_to_Image_converter/invitations"},{"label":"github.com","url":"https://github.com/Raghu-dev-pixel/Nvidia_speech_to_Image_converter/invitations"}],"description_sections":[{"heading":"Inspiration","content":"I am inspired to participate in this project because of my passion for AI and its potential to transform the way we interact with machines. Working on speech-to-image conversion using Nvidia's AI workbench and APIs allowed me to explore innovative solutions that can enhance accessibility and creativity in various fields, such as art and education. Additionally, it was the best way to get hands-on experience with Nvidia‚Äôs cutting-edge technologies, which I believe enhanced my understanding and skills in AI. Hackathons like these also provide an opportunity to collaborate with employees and engineers from Nvidia and tackle real-world challenges, which fueled my drive to contribute to meaningful advancements in technology and get to work with probably the best computer scientists across the globe."},{"heading":"What it does","content":"This project titled Speech-to-image Converter aims to generate images based on audio/speech as input by leveraging the benefits of Nvidia's AI workbench. The project can be used in various applications such as storytelling."},{"heading":"How we built it","content":"The Speech-to-Image Converter is an advanced generative AI system that allows users to create real-time images from spoken or audio descriptions. While existing generative AI applications such as speech-to-text and text-to-image converters are well-established, little attention has been given to the direct conversion of speech into images. This project aims to bridge that gap by developing a seamless solution using NVIDIA's AI Workbench to convert audio inputs into visual content.\n\nFor example, if a user says, Lion in a Jungle in 4K the application transcribes the audio and instantly generates a high-resolution image of a lion in the jungle. This provides an intuitive way to transform verbal ideas into visuals, offering new creative opportunities.\n\nTo achieve this use case, I made use of two existing AI architectures. One was openAI's whisper to transcribe the audio from the user into text. As part of the 2nd module a stable diffusion model was used through Nvidia's API to convert text into images and thus we get an overall application that converts speech to images. This application was created and tested on Nvidia's AI workbench."},{"heading":"Challenges we ran into","content":"Faced, with quite a lot of issues, some of the important ones can be described below: ** AI workbench installation failure* : This was the 1st issue I had to encounter and I was unable to complete the installation of the AI workbench, however, I had a debug session with colleagues from Nvidia and we found that the virtualization in the bios mode was disabled and after enabling it, I was able to install the workbench. **Availability of GPUs : As a student getting access to GPUs was difficult. We do have Google Colab that comes with inbuilt GPUs but Nvidia's AI workbench does not work with Google Colab. Additionally, LLMs like stable diffusion need GPU, to overcome this drawback I used Nvidia's inbuilt APIs from Nvidia's API catalog that in the end still makes use of stable diffusion without actually needing a GPU locally. **Huge disk space : A couple of times I encountered issues where the images of my docker were occupying more than 70 GB of my disk space and I was running out of memory, we did not have a fix for it but as a workaround, we tried reinstalling the docker after which this issue was not seen. **Compatibility issues *: I also encountered a lot of compatibility issues when installing certain libraries that were not aligned with the containers on which the libraries were to be installed."},{"heading":"Accomplishments that we're proud of","content":"1) This is my first ever hackathon and it is also a challenging hackathon, I'm proud I was able to get a working version of the application by making use of the workbench as described in the problem statement. 2) Did not give up despite many hurdles and happy to have been in contact with brilliant colleagues from Nvidia."},{"heading":"What we learned","content":"1) Ask for help when needed. 2) Never give up, your solution might just be around the corner. 3) Hands-on experience with CUDA, GPU and Nvidia workbench."},{"heading":"What's next for Speech to Image Converter","content":"The following ideas can be thought of for further improvement. 1) Currently we are using Nvidia's API from the catalog to generate an image from text, instead of doing that it would also be nice to train and use a stable diffusion model directly, with this approach we could also generate our images of ourselves. For example \"Raghu in space\" this would then give an image of me in space. 2) The idea could further be extended for videos, i.e. to generate videos based on audio inputs. 3) We could also try to create our emojis and memes as part of an extension to this project."},{"heading":"Built With","content":"api cuda nvidia python pytorch workbench"},{"heading":"Try it out","content":"github.com github.com github.com"}]},{"project_title":"Speak to Learn Japanese","project_url":"https://devpost.com/software/speak-to-learn-japanese","tagline":"You learn by saying the Japanese words","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/057/116/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"ffmpeg","url":"https://devpost.com/software/built-with/ffmpeg"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"huggingface","url":null},{"name":"whisper","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/omenking/speak-to-learn-japanese/"}],"description_sections":[{"heading":"Inspiration","content":"I'm taking Japanese lessons with a teacher and I need to practice speaking so I built this app to be used in my studies.\n\nI also had to consider what I could do handle with my Geforce RTX 3060 and and my 7th Generation Intel¬Æ Core‚Ñ¢ i5 Processor. I know my machine struggles with small LLMs, so I had to leave it LLM and RAG but I wrote what I could do with it in my Coding Challenges section."},{"heading":"What it does","content":"You have a collection of Japanese words, you record, and the app returns back the transcription so you can see how close you got."},{"heading":"How I built it","content":"Whisper + Hugging Face, I fully documented the details in Github Markdown file. I also recorded the 75% of the process. I always record everything. I thought I wasn't going to finish so I stopped recording at that 75% mark."},{"heading":"Challenges I ran into","content":"Ports configurations Limitations of JupterLabs editing files and poor terminal controls Confusion of the architecture of JupterLabs projects Lack of existing examples or too complex examples to reference from when building from the Nvidia AI Workbench example projects Specific issues with flask vague errors, and figuring out the best way to log and debug app-to-app communication, This one was the hardest. updating CUDA and installing WSL2"},{"heading":"Accomplishments that we're proud of","content":"The app works!"},{"heading":"What I learned","content":"CUDA configuration, I didn't know about how CUDA versions the featuresets avaliable for workloads CUDA monitoring, so now I know how to monitor usage via the nvidia-smi command Some Japanese words! I'm getting better everyday. I did explore NIM and NeMo offerings but since I have limited hardware I decided against an enterprise workload. I did explore the NGC Catalog but I did not see any ASR models I was familiar with for my use case, and was uncertain of my machine capabilities to experiment with available catalog models."},{"heading":"What's next for Speak to Learn Japanese","content":"I made a bunch of challenge in the Github Doc so if people wanted to know what would be next to add to the project they can read that list.\n\nI will probably developer it further for personal use. I am likely to repurpose the code for my upcoming Free Community GenAI Bootcamp in January. I say repurpose because I don't think I could stream and use Nvidia AI Workbench at the same time due to my previous generation hardware."},{"heading":"Considerations","content":"I am dyslexic, and I entered this hackathon late so I did not have time to do 2-3 passes to correct any documentation. I may fix in the future."},{"heading":"Built With","content":"ffmpeg flask huggingface whisper"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"NVIDIA NIM Factory","project_url":"https://devpost.com/software/nvidia-nim-factory","tagline":"This project is a factory for NVIDIA NIM containers in which users/businesses can quantize many models and build their own TensorRT-LLM engine for optimized inference.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/057/795/datas/medium.jpeg","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Honorable Mention"}],"team_members":[],"built_with":[{"name":"bash","url":"https://devpost.com/software/built-with/bash"},{"name":"gradio","url":null},{"name":"jupyter","url":null},{"name":"tensorrt-llm","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Rahman2001/nim-factory.git"}],"description_sections":[{"heading":"Inspiration","content":"Over the past few years Generative AI models have popped up everywhere - from creating realistic responses to complex questions, to generating images and music to impress art critics around the globe. However, there are still some users or businesses who cannot use Generative AI due to limited resources, high cost for compute power or simply overweight their business goals. In this project, we enable them to quantize almost any AI model into different sizes and build an optimized inference engine using TensorRT-LLM ."},{"heading":"What it does","content":"This project is a factory for NVIDIA NIM containers in which users/businesses can quantize many models and build their own TensorRT-LLM engine for optimized inference. This enables users/businesses with large hardware resources but smaller business goals to save compute power by quantizing LLMs into different sizes and build optimized inference engines."},{"heading":"How we built it","content":"We built with native NVIDIA libraries such as TensorRT and TensorRT-LLM . TensorRT-LLM utilizes TensorRT library for conversion and quantization of model weights to build optimized engine. Since the base container \" Python with CUDA 12.2 \" provides us with Python 3.x and CUDA 12.2 libraries, we build our project on top of that container."},{"heading":"Challenges we ran into","content":"Initially, we wanted to customize NVIDIA NIM containers from bottom to top. After long research, we discovered that it is impossible to make NIM to run quantized models because they were created with precompiled TensorRT-LLM engine which is the fundamental component of NIMs. However, it opened a new opportunity to us enable users to build their own NIMs with the use of TensorRT-LLM which gives more freedom than ever."},{"heading":"What we learned","content":"During hackathon, we gained a lot of knowledge about LLMs, experience with NVIDIA technologies like TensorRT-Model-Optimizer , TensorRT-LLM , NVIDIA NIM and more. All experiences we got from this hackathon greatly contributes to our development and opens the door to the future of technology."},{"heading":"What's next for NVIDIA NIM Factory","content":"This project has a huge potential to be used by many consumers, from small to big ones like Microsoft, OpenAI, etc. because it gives more freedom of choice than traditional NIMs in which users have to comply with the model sizes and its workflows. We plan to reveal as many features of TensorRT-LLM as possible which will increase the freedom of building their \"NIMs\" and develop advanced error handling so that users/businesses could easily interpret them."},{"heading":"Built With","content":"bash gradio jupyter tensorrt-llm"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"RetainAI - The Intelligent Solution to Keep Your Top Talent","project_url":"https://devpost.com/software/retainai","tagline":"RetainAI crafts customized employee retention strategies, empowering companies to minimize turnover, enhance engagement, and retain their top performers.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/054/592/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best in Enterprise Data Analysis"}],"team_members":[],"built_with":[{"name":"llama","url":null},{"name":"llama-index","url":null},{"name":"nvidia","url":"https://devpost.com/software/built-with/nvidia"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"scikit-learn","url":"https://devpost.com/software/built-with/scikit-learn"},{"name":"streamlit","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/arsentievalex/retain-ai"}],"description_sections":[{"heading":"Inspiration","content":"Employee turnover is a significant financial burden, with estimates suggesting that it costs U.S. businesses approximately $1 trillion annually. This staggering figure encompasses both direct and indirect costs associated with losing employees and the subsequent need to replace them. Moreover, the span of control can be up to 12-15 employees per manager, making it incredibly difficult to track employee sentiment and implement effective retention strategies.\n\nWith this problem in mind, I decided to build RetainAI."},{"heading":"What It Does","content":"RetainAI is an NVIDIA AI Workbench project with a Streamlit front-end, serving as a web app for managers. The app allows a user to upload their own data in CSV and PDF formats, or use a sample dataset. Once uploaded, the app runs ML model, and displays a dashboard with employees and their predicted attrition probability. This probability is calculated using a Random Forest Classifier model trained on uploaded employee data such as tenure, compensation, promotion frequency, performance scores, etc. As a result, a manager can see which employees on their team are at high risk of attrition.\n\nBut it doesn't end there‚Äîmanagers can also generate personalized retention strategies for individual employees. These strategies are created by GenAI and reference proprietary data in CSV, including employee details, performance reviews, benefits enrollment, engagement surveys, and unstructured PDF documents such as industry trends and company benefits. The model generates a comprehensive retention strategy, which managers can easily download as a PDF for future reference.\n\nAnother key feature of RetainAI is a chat mode. A manager can ask questions about their entire team (not just individual employees). For example, one might ask, \"Which employees are not satisfied with work-life balance?\" or \"Which employees performed poorly in the Q3 performance review?\" The chat mode is driven by llama-3.1-70b-instruct model and reference proprietary employee data."},{"heading":"How We Built It","content":"The project is built entirely in the NVIDIA AI Workbench. First, I generated fictional employee data, similar to what can be found in any modern human capital management system. Once the data was generated, I built a simple Random Forest Classifier model that predicts an employee's attrition probability based on various features. The model was tested on a new set of employees used in the demo. Employees with an attrition probability above 0.5 are considered at risk.\n\nAfterward, I developed a Llama-Index workflow that orchestrates multiple LLM calls, retrieving different pieces of information. I used local vector db to store the embeddings of sample PDF documents with industry trends and employee benefits. The model used for embeddings is NV-embed-qa-4 by NVIDIA.\n\nNext, llama-3.1-70b-instruct hosted as NVIDIA NIM is used to answer questions and retrieve relevant information.\n\nBelow is a brief overview of each step of the workflow and a shortened version of the prompts:\n\nAnalyze Compensation: How does the current salary of this employee compare to the industry benchmark? Consider the employee's starting and current salary. How does the salary growth compare to industry standards? Analyze Reviews: Based on the performance reviews, what are the employee's key strengths and areas for improvement? How do the performance reviews align with the attrition risk? Analyze Benefits: Are there any benefits that the employee is not utilizing? Are there additional benefits that could improve employee satisfaction and retention? Analyze Surveys: What are the key factors affecting employee engagement and satisfaction? Are there any areas for improvement based on the survey responses? Synthesize Responses: Based on the analysis of compensation, performance reviews, benefits enrollment, and engagement survey responses, provide a comprehensive retention recommendation for the employee.\n\nTo enhance the app and offer more flexibility, I added the ability to upload custom CSV and PDF files instead of relying solely on the sample dataset. The uploaded data must match the structure of the training data to ensure prediction accuracy. For this, I built a field-mapping interface with semi-automated fuzzy matching. For example, if a user-uploaded CSV has a column labeled \"Employee Name,\" it will automatically map to the required \"Full Name\" field. Users can also manually map fields if names differ significantly.\n\nAdditionally, I introduced a chat mode using Streamlit‚Äôs chat functionality and the llama-3.1-70b-instruct model hosted on NVIDIA‚Äôs API Catalog. I used llama-index as the LLM framework to provide context, integrating employee snapshots through ChatMessage, MessageRole, and PromptTemplate for context-aware chat experience.\n\nFinally, I built a Streamlit front-end that allows users to interact with the app and launch it directly from the AI Workbench.\n\nSee the detailed walkthrough video on YouTube - here"},{"heading":"Challenges We Ran Into","content":"One of the challenges was generating a fictional employee dataset that would make sense and reflect real-world data. I spent some time adding logic to the data generation script and refining it. The second challenge was building the prediction model. Since I had limited experience with traditional ML models, I faced difficulty in choosing the right model and verifying its accuracy."},{"heading":"Accomplishments We're Proud Of","content":"I'm proud to have built this working prototype in a relatively short time while using technologies that were new to me. With some additional work, I believe this app has the potential to become a scalable stand-alone product."},{"heading":"What We Learned","content":"I learned how to use NVIDIA AI Workbench, which was new to me. It was very easy to get up and running on my Mac. Additionally, I learned about traditional ML models such as the Random Forest Classifier and Survival Analysis. I also used NVIDIA NIM for the first time."},{"heading":"What's Next for RetainAI","content":"I have a lot of ideas for the next steps, but they will mostly be driven by feedback. Some obvious ideas include:\n\nDeployment and hosting of the app Ability to use locally hosted LLMs Adding more advanced document parser like LlamaParse for complex PDFs Providing functionality to connect to user data (e.g., Snowflake, AWS, Databricks, or popular HCM systems) Improving the accuracy of attrition predictions Enhancing the output of retention strategies, either by prompt engineering or fine-tuning the model Adding the ability to perform RAG (retrieval-augmented generation) over different user files (e.g., internal policy, industry trends, compensation benchmark reports)"},{"heading":"Built With","content":"llama llama-index nvidia python scikit-learn streamlit"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"AI Product Catalog","project_url":"https://devpost.com/software/ai-catalog-search-lb7d0v","tagline":"An AI engine to make description about product, search product by image or just describe it. Perfect fit for tailor-made product, pawnshop and ecommerce.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/058/097/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best in Enterprise Computer Vision"}],"team_members":[],"built_with":[{"name":"clip","url":null},{"name":"database","url":null},{"name":"frappe","url":null},{"name":"nvidia-ai-workbench","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"text-embedding","url":null},{"name":"vector","url":null},{"name":"vision-language-model","url":null}],"external_links":[{"label":"aiproductcatalogdemo.korenext.com","url":"https://aiproductcatalogdemo.korenext.com/"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration for AI Product Catalog (AI Catalog Search) came from observing challenges faced by pawnshop chains in Southeast Asia. When stores receive unique items like a \"ring with a dragon shape,\" they often only record basic descriptions like Gold 22K, ring, and images. This makes it difficult for stores in other locations to find such items when customer request something like \"I want to have a cool ring with dragon shape on ruby\" without manually sifting through images, which is time-consuming. With AI, we can solve this using image search. Beyond pawnshops, this solution can be applied to e-commerce and industries dealing with non-standardized, tailor-made products."},{"heading":"What It Does","content":"AI Product Catalog streamlines inventory management by enabling efficient product searches through image and text. It helps businesses quickly locate items, improving customer satisfaction and operational efficiency.\n\nInstead of only image embedding search like traditional (using CLIP), this one include high level detail of item by using Visual Large Model for incredible search result.\n\nThis application ready for end-user by API-ready for mobile apps and webapps."},{"heading":"How We Built It","content":"We built AI Product Catalog using cutting-edge technologies. We integrated high level of image captioning with VLM, natural language processing, image embedding and leveraging Visual Language Models for accurate semantic searches and simplifying the integration process without complex setups.\n\nExperimenting models is quite expensive process with trials and errors. Thanks to NVIDIA AI Workbench, I could save many efforts in setting up environment for each model."},{"heading":"Challenges We Ran Into","content":"Model Quality: Initial attempts using the CLIP model for image embedding didn't yield satisfactory results for specific descriptions like \"ring with dragon head\" even work great with image embedding search. Alternative models like BLIP also fell short until we adopted Visual Language Models paired for semantic text search. Performance: The CLIP model from Hugging Face was slow with many dependencies. I have challenge with activate CLIP model from NVIDIA NIM to switch on because of continuing error of failing to execute. Switching to CLIPP.CPP improved speed through pure C++ implementation. Stability: Building for enterprise-grade use was challenging. The initial Next.js setup wasn't stable under aggressive testing about security, authentication and audit trail. Moving to the Frappe framework improved stability but required overcoming a learning curve and limitations. Running multiple containers with NVIDIA AI Workbench: The complex permission of running docker containers by Apps features of NVIDIA Workbench (through docker deamon at /var/host-run/docker.sock) is challenging. Leading to consuming time how to set permission and discover the mechanism how Nvidia AI Workbench running an apps (from which user, from which source)."},{"heading":"Accomplishments That We're Proud Of","content":"We're proud of creating a powerful, user-friendly tool that significantly reduces search time and enhances inventory management across industries. Built on ERP platform, I will compatible with standard of security, compliance standard in enterprise. Successfully integrating advanced AI features into an enterprise-grade system is a major achievement. Furthermore, I discover new way to work with remote GPU server that is more efficient, time-saving and could create an multi-user environment for team to develop AI project without creating JupyterHub with conflicting in python environment."},{"heading":"What We Learned","content":"We learned the importance of selecting the right models for specific use cases. Furthermore, NVIDIA AI Workbench is very efficient in making a covenient environment to development. Instead of consuming build and rebuild docker container over time every updating environment, just leave it to NVIDIA AI Workbench. This approach allowed me streamlining development."},{"heading":"What's Next for AI Product Catalog","content":"Next, we plan to improve the codebase to handle more exceptional cases and deploy the system in a cluster mode for scalability. This will ensure robustness and the ability to scale with business growth."},{"heading":"Built With","content":"clip database frappe nvidia-ai-workbench python text-embedding vector vision-language-model"},{"heading":"Try it out","content":"aiproductcatalogdemo.korenext.com"}]},{"project_title":"AI Data Analysis with RAPIDS","project_url":"https://devpost.com/software/ai-data-analysis-with-rapids","tagline":"Generate custom, in-depth reports and presentations with full featured tables and visualizations powered by gpu acceleration via RAPIDS cuDF dataframes with cuML models.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/042/236/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best in Enterprise Data Analysis"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"cudf","url":null},{"name":"cuml","url":null},{"name":"dash","url":"https://devpost.com/software/built-with/dash"},{"name":"fastapi","url":null},{"name":"plotly","url":"https://devpost.com/software/built-with/plotly"},{"name":"pptx","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"rapids","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/msamylea/nvidia-alm"}],"description_sections":[{"heading":"Inspiration","content":"I was inspired by an idea I had in the past, but wasn't able to implement correctly due to speed and size limitations with data analysis. When I saw the RAPIDS suite and understood how cuDF would allow me to take advantage of GPU acceleration, I knew I would be able to do everything I wanted with this project."},{"heading":"What it does","content":"A user can upload a dataset in CSV, JSON, or Parquet format and request an analysis from an LLM (users can also choose the LLM Provider and LLM to use). The query the user gives guides the LLM through the use of a custom Data API with caching to further speed up analysis. Using the custom Data API, the LLM executes actions using cuDF dataframes to return quick results, and then finally collates the results into a coherent, actionable report that is often 20+ pages and ready for delivery. Additionally, a custom slide presentation can be created, which again uses the LLM with cuDF dataframes and the Data API to create slides with summarized data, tables, and plot visualizations. The LLM also has the option to perform cuML linear regression and output the results as a plot.\n\nFinally, users can take advantage of a chat feature to continue exploring their data in depth."},{"heading":"How we built it","content":"I chose the RAPIDS NVIDIA AI Workbench image to begin, then worked through several UI options before settling on Dash, so I could take full advantage of cuDF and visualizations.\n\nThe code is in Python, but the PDF is styled via CSS, which gave me flexibility in allowing users to upload logos and add custom company names, as well as customize the sections for the report."},{"heading":"Challenges we ran into","content":"Initially, I felt I wasn't able to allow the LLM enough access to the data without hitting token limits, and reports weren't giving me the results I was looking for with limited data access. That's when I decided to create the Data API to allow execution of functions against the cuDF dataframes, so that the LLM could make decisions about what data it needed to look at and when. This removed the limitations I had with data and brought everything together."},{"heading":"Accomplishments that we're proud of","content":"I'm extremely proud of the data caching and fuzzy matching I implemented. Data caching limits the overhead when the LLM needs to get a lot of information from the dataframes, and the fuzzy matching has greatly improved the results since often, depending on the LLM, even with strict prompts and data samples, column names were being returned incorrectly. The fuzzy matching ensures that the code can infer the correct column and produce the needed results."},{"heading":"What we learned","content":"I learned so much using the RAPIDS suite. I hadn't been aware of it before this, but I know I'll be taking advantage of it in the future, especially the full integration with pandas and polars."},{"heading":"What's next for AI Data Analysis with RAPIDS","content":"I rarely feel like any project is finished, so I'll likely continue to improve on prompts and the API in the future."},{"heading":"Built With","content":"css cudf cuml dash fastapi plotly pptx python rapids"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"VisionTrack - Smart AI Inventory Management System","project_url":"https://devpost.com/software/visiontrack-smart-inventory-management-system","tagline":"VisionTrack is designed to leverage advanced computer vision and AI technologies to handle and monitor inventory. VisionTrack automates product recognition and stock tracking.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/019/681/datas/medium.png","prizes":[{"hackathon_name":"HackAI - Dell and NVIDIA Challenge","hackathon_url":"https://hackaichallenge.devpost.com/","prize_name":"Best in Enterprise Computer Vision"}],"team_members":[],"built_with":[{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"nvidia-workbench","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/rogerkorantenng/VisionTrack"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration for VisionTrack - Smart Inventory Management System came from the need to streamline and automate inventory management processes. Traditional inventory systems often face inefficiencies and inaccuracies, especially in large-scale operations. With this in mind, we aimed to build a solution that leverages advanced image classification and machine learning to enhance the efficiency, accuracy, and scalability of inventory management."},{"heading":"What it Does","content":"VisionTrack is a state-of-the-art inventory management system designed to:\n\nAutomatically classify and categorize inventory items using cutting-edge image recognition technology. Provide real-time insights and updates on inventory status to facilitate better decision-making."},{"heading":"App Features","content":"Based on the judges' feedback, we have transformed VisionTrack into a more user-friendly and robust Inventory Management system.\n\n1. Multi Image Recognition Model Selection\n\nChoose from a range of advanced models for image recognition:\n\nGoogle ViT (Base) : A powerful vision transformer model for efficient image classification. Google ViT (Large) : A larger version of ViT, offering improved performance on complex tasks. Microsoft ResNet50 : A deep convolutional network designed for image recognition tasks, known for its efficiency. Facebook ConvNeXt Tiny : A compact model optimized for fast inference without sacrificing accuracy. Microsoft Swin : A hierarchical vision transformer model that scales well across image sizes and tasks.\n\n2. Fine-Tuning with Custom Data\n\nFine-tune the selected model to enhance its accuracy for your specific use case:\n\nAdjust hyperparameters to optimize model performance. Upload your own labeled dataset for fine-tuning, allowing the model to better understand your domain-specific images.\n\n3. Bulk Image Classification\n\nUpload multiple images at once for batch processing. Classify a large set of images in one go and retrieve results efficiently.\n\n4. Inventory Management\n\nKeep track of the images you've uploaded and their corresponding classification results:\n\nView the classification labels and associated data for each image. Monitor the inventory status of your image dataset for easy access and management.\n\n5. Forecasting using Machine Learning\n\nUse the classification results to predict future trends or behaviors. Forecast future inventory needs or category distributions based on historical classification data.\n\n6. Inventory Analytics Dashboard\n\nVisualize and analyze your inventory and classification results through various charts:\n\nBar Chart : Display the distribution of classified items across categories. Pie Chart : Visualize the proportion of categories within your dataset. Line Chart : Track trends and patterns in your inventory over time. Heatmap : Explore the relationships between various attributes in your dataset and visualize patterns."},{"heading":"How We Built It","content":"We built VisionTrack using a combination of modern technologies and frameworks:\n\nFrontend : The user interface was developed using Gradio , which allows for seamless image classification tasks through an intuitive, easy-to-use platform. Image Classification Models : Integrated a range of advanced image classification models, including: Google ViT (Base) Google ViT (Large) Microsoft ResNet50 Facebook ConvNeXt Tiny Google MobileNetV3 Inventory Database : Created a robust database to store categorized images. This database also supports forecasting, predictive analytics, and overall analytics for inventory management. Custom Fine-Tuning : To allow for product-specific customization, we implemented a custom fine-tuning feature where users can upload their own labeled product images. They can then fine-tune the model to better classify their specific products and use the fine-tuned model for further classification tasks."},{"heading":"Challenges We Ran Into","content":"Model Accuracy : Achieving high accuracy in classifying a wide variety of inventory items required fine-tuning and extensive testing of the Vision Transformer model. System Integration : Integrating the image classification model with the Gradio interface and ensuring smooth communication between components posed significant challenges. Scalability : Handling a large volume of images and ensuring system efficiency as the dataset grows was a concern. Proxy Handling : Configuring the application to work properly behind a reverse proxy required setting up the right middleware and environment variables."},{"heading":"Accomplishments We're Proud Of","content":"Automated Classification : Successfully implemented an automated image classification system using the Vision Transformer model, enabling the accurate categorization of inventory items. Enhanced User Experience : Developed an intuitive and responsive user interface with Gradio, simplifying inventory management tasks for users. Seamless Deployment : Achieved consistent and reliable deployment using Docker, ensuring the application works seamlessly across different environments."},{"heading":"What We Learned","content":"Machine Learning Integration : Gained valuable insights into integrating machine learning models with web applications, especially in handling image data for classification tasks. Effective Use of Gradio : Learned how to leverage Gradio for building user-friendly interfaces and handle middleware configurations to ensure accurate request processing. Scalability and Performance : Identified key scalability challenges and implemented solutions to ensure efficient handling of large data volumes."},{"heading":"What's Next for VisionTrack","content":"Mobile Support : Develop mobile-friendly versions of the application to expand accessibility and usability across a wider range of devices. System Integrations : Explore potential integrations with other business systems such as ERP and CRM to provide a more comprehensive inventory management solution. User Feedback : Collect and analyze user feedback to drive iterative improvements, ensuring that the system continues to meet the evolving needs of its users."},{"heading":"Built With","content":"flask nvidia-workbench python"},{"heading":"Try it out","content":"github.com"}]}],"generated_at":"2026-02-18T16:53:42.590404Z"}}