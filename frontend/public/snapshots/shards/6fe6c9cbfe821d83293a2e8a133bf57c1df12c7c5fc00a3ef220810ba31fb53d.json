{"version":"v1","hackathon_url":"https://agi-real.devpost.com","generated_at":"2026-02-18T16:41:22.576852Z","result":{"hackathon":{"name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","url":"https://agi-real.devpost.com","gallery_url":"https://agi-real.devpost.com/project-gallery","scanned_pages":2,"scanned_projects":36,"winner_count":6},"winners":[{"project_title":"REAL Hackathon Browser Agent","project_url":"https://devpost.com/software/real-hackathon-browser-agent","tagline":"A fast, reliable browser agent engineered for REAL-world tasks. Optimized for accuracy, speed, and unseen challenge variants.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/004/029/809/datas/medium.png","prizes":[{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"The REAL Agent Challenge"}],"team_members":[],"built_with":[{"name":"openrouter","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"qwen3","url":null},{"name":"real-bench","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/maxxie114/REAL-Hackathon-browser-agent-benchmark"}],"description_sections":[{"heading":"Inspiration","content":"This hack challenge pushed us to build an agent that can operate reliably under real-world constraints — fast, accurate, and versatile enough to handle practical browser tasks. The competitive setup and the REAL benchmark motivated us to push for an agent that could function like a true digital assistant."},{"heading":"What it does","content":"Our agent can autonomously perform everyday browser operations such as:\n\nApplying to jobs or filling out forms Sending emails Setting calendar events Booking hotels Navigating links and multi-page flows\n\nEssentially, it acts as a general-purpose browser automation assistant powered by vision-language reasoning."},{"heading":"How we built it","content":"We experimented with two approaches:\n\nEnhanced Prompt Engineering + Reflection Loop We began with an existing agent framework and attempted to strengthen reliability using a self-reflection feedback loop. The goal: enable the agent to critique its past actions and improve. Orchestrator-Based Architecture When reflection alone didn’t yield stable performance, we added an orchestrator model to structure tasks, guide decisions, and maintain coherence through complex multi-step interactions.\n\nThis combination gave us a more stable and efficient agent pipeline."},{"heading":"Challenges we ran into","content":"API credit limitations restricted our ability to extensively test iterations. Flow connection issues, especially when integrating multiple models. Debugging multi-agent control with a VLM was harder than expected. We spent nearly 4 hours debugging a “headless: false” issue in the browser runtime."},{"heading":"Accomplishments we’re proud of","content":"Our agent successfully completed a large variety of REAL-style tasks. Despite limited time and compute, we were able to create a pipeline that runs reliably across multiple task types. We validated that a hybrid approach (reflection + orchestrator) can significantly improve consistency."},{"heading":"What we learned","content":"Multi-agent systems with VLMs are extremely hard to synchronize — keeping track of state, screenshots, and browser feedback loops is non-trivial. Real-world agents require tight control, error recovery, and robust interface mapping. Debugging browser automation under time pressure teaches patience and resilience."},{"heading":"What’s next for the REAL Hackathon Browser Agent","content":"We plan to:\n\nPolish the agent into a long-term entrant for the 3-month REAL global leaderboard challenge. Improve error recovery, latency, and batching. Add deeper reasoning layers and stronger UI element detection. Push toward a production-grade autonomous browser assistant."},{"heading":"Built With","content":"openrouter python qwen3 real-bench"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"TwinBrowse","project_url":"https://devpost.com/software/twinbrowse","tagline":"TwinBrowse is our submission for the Real web Agent Challenge.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/004/030/622/datas/medium.png","prizes":[{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"The REAL Agent Challenge"}],"team_members":[],"built_with":[{"name":"openrouter","url":null},{"name":"playwright","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"qwen","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/bcsanto/agisdk"}],"description_sections":[{"heading":"Inspiration","content":"REAL challenged us to develop browser agents that are fast and accurate on real-life tasks. Latency was a big bottleneck. We needed to figure out which vision-language models could compete on speed while not hallucinating. I chose TwinBrowse as the name since the Mk.1 prototype was founded on Google's Gemini 3 pro."},{"heading":"What it does","content":"Twinbrowse is a web agent that completes web tasks by analyzing screenshots and executing clicks/scrolls/etc. to handle workflows across multiple web platforms (GoMail,GoCalendar,NetworkIn,Marrisuite). It will go against a list of tasks available at the agisdk repository. You can also make your own lists, by using the corresponding REAL developed webpages."},{"heading":"How I built it","content":"The agent 'sees' the screen through screenshots, it takes jpeg screenshots using Chrome DevTools Protocol, converts it to base64 URLs, it also keeps the last 4 screenshots in context. It also prunes older images to manage token usage. The screenshots are then sent to the vision language model via OpenRouter. The model analyzes the visual state, and generates tool calls (click,type,scroll) the tools executions are based on coordinates that are scaled from 0-1000 to actual viewport (1080p) dimensions. If you turn Headless to False, you can see the tools executing via Playwright."},{"heading":"Challenges I ran into","content":"The biggest challenge I faced was figuring out dropdown options, because when the native elements are open, they can't be seen in the screenshots the algorithm takes. Apart from that, latency and the text based tool extraction was a challenge to understand. I had to write Debug statements during specific tasks to see what was going on behind the scenes. I also learnt that the instruct variant of Qwen beats larger models at certain tasks. Another aspect I had to consider was navigation guidelines, and location awareness via prompt instructions of the agent. What's next for TwinBrowse Adding Retry logic for when actions fail. Develop a system that lets me see what the agent is thinking."},{"heading":"Built With","content":"openrouter playwright python qwen"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"UX AI Web Agent ","project_url":"https://devpost.com/software/ux-ai-web-agent","tagline":"UXAI Web Agent gives instant UX/UI and conversion audits from any website link, auto-researches your product, boosts revenue, and offers expert help. In a $5B market, 50K users at $20/mo hits $1M MRR.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/004/029/742/datas/medium.png","prizes":[{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"Vertical Agent Track"}],"team_members":[],"built_with":[{"name":"agi","url":null},{"name":"api","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"holo-feedback.lovable.app","url":"https://holo-feedback.lovable.app"},{"label":"github.com","url":"https://github.com/RodriguesJohn/insight-agent-ui"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration for UXAI Web Agent came from my own experience doing UX/UI audits manually for businesses. I loved helping founders improve their product clarity, usability, and conversion but the work wasn’t scalable. Each audit took hours, and many early-stage teams couldn’t afford the high cost of hiring designers, strategists, or CRO experts. I saw founders struggling to get quality feedback, not because they lacked ambition, but because expert support was too expensive, too slow, or simply unavailable.\n\nThat’s when it became clear: UX guidance needed to be democratized. Every founder should have access to expert-level insights, instantly and affordably. UXAI Web Agent was born from the belief that great UX shouldn’t be limited to companies with big budgets it should be accessible to anyone building on the internet."},{"heading":"What it does","content":"The inspiration for UXAI Web Agent came from my own experience doing UX/UI audits manually for businesses. I loved helping founders improve their product clarity, usability, and conversion but the work wasn’t scalable. Each audit took hours, and many early-stage teams couldn’t afford the high cost of hiring designers, strategists, or CRO experts. I saw founders struggling to get quality feedback, not because they lacked ambition, but because expert support was too expensive, too slow, or simply unavailable.\n\nThat’s when it became clear: UX guidance needed to be democratized. Every founder should have access to expert-level insights, instantly and affordably. UXAI Web Agent was born from the belief that great UX shouldn’t be limited to companies with big budgets it should be accessible to anyone building on the internet."},{"heading":"How we built it","content":"The inspiration for UXAI Web Agent came from my own experience doing UX/UI audits manually for businesses. I loved helping founders improve their product clarity, usability, and conversion but the work wasn’t scalable. Each audit took hours, and many early-stage teams couldn’t afford the high cost of hiring designers, strategists, or CRO experts. I saw founders struggling to get quality feedback, not because they lacked ambition, but because expert support was too expensive, too slow, or simply unavailable.\n\nThat’s when it became clear: UX guidance needed to be democratized. Every founder should have access to expert-level insights, instantly and affordably. UXAI Web Agent was born from the belief that great UX shouldn’t be limited to companies with big budgets — it should be accessible to anyone building on the internet."},{"heading":"Challenges we ran into","content":"The inspiration for UXAI Web Agent came from my own experience doing UX/UI audits manually for businesses. I loved helping founders improve their product clarity, usability, and conversion — but the work wasn’t scalable. Each audit took hours, and many early-stage teams couldn’t afford the high cost of hiring designers, strategists, or CRO experts. I saw founders struggling to get quality feedback, not because they lacked ambition, but because expert support was too expensive, too slow, or simply unavailable.\n\nThat’s when it became clear: UX guidance needed to be democratized. Every founder should have access to expert-level insights, instantly and affordably. UXAI Web Agent was born from the belief that great UX shouldn’t be limited to companies with big budgets — it should be accessible to anyone building on the internet."},{"heading":"Accomplishments that we're proud of","content":"We built an AI-powered UX engine that delivers expert-level audits in seconds, turning a once manual, expensive process into an accessible, scalable experience for every founder. We integrated AGI-driven research, real conversion psychology, and human-in-the-loop support into one seamless product. Most importantly, we created a tool that helps businesses instantly improve clarity, usability, and revenue—democratizing high-quality UX feedback for thousands of users."},{"heading":"What we learned","content":"We learned that founders don’t just want UX critiques—they want clear, actionable recommendations tied directly to revenue and conversion. We discovered that automated audits must understand product context, not just visuals, which is why AGI-level research became essential. We also realized that combining AI speed with optional human expertise creates the most trust and impact. Ultimately, we learned that democratizing high-quality UX feedback solves a real, universal problem for startups and businesses worldwide."},{"heading":"What's next for UX AI Web Agent","content":"Next, we’re expanding UXAI into a full website optimization platform. We’re adding continuous monitoring, real-time UX scoring, heatmap predictions, SEO + UX combined audits, and team dashboards for product and growth teams. We’re also releasing an API so SaaS companies, agencies, and developers can integrate UXAI audits directly into their own tools. Finally, we’ll extend human-in-the-loop support to offer full UX transformations, blending AI automation with expert insights. Our goal is simple: help every business in the world improve conversion, clarity, and revenue automatically."},{"heading":"Built With","content":"agi api react"},{"heading":"Try it out","content":"holo-feedback.lovable.app github.com"}]},{"project_title":"JobAgent","project_url":"https://devpost.com/software/applyai-19sjmz","tagline":"Job hunting is overwhelming. Our AI finds roles, tailors applications, preps interviews, and books coffee chats so you can focus on landing offers instead of grinding job boards.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/004/029/479/datas/medium.png","prizes":[{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"Vertical Agent Track"}],"team_members":[],"built_with":[{"name":"agi","url":null},{"name":"anthropic","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"telnyx","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ttokttokttok/job-application"}],"description_sections":[{"heading":"Inspiration","content":"Searching and applying for jobs is repetitive, time-consuming, and often discouraging. Candidates re-enter the same information into countless forms, manually tweak similar cover letters, and struggle to figure out where and how to stand out. We wanted to build an AI assistant that feels like a dedicated job search co-pilot — one that can handle the busywork of applications, help identify the right roles, surface networking opportunities, and even prepare users for interviews."},{"heading":"What it does","content":"JobAgent is an AI-powered job application assistant that automates the end-to-end application process using the AGI API for browser automation.\n\nHere’s the user journey:\n\nResume Upload Users start by uploading their resume into JobAgent. Resume Analysis The agent analyzes the resume to understand the user’s background, skills, and experience. Job Search on NetworkIn Using that profile, JobAgent searches for relevant jobs on NetworkIn , a LinkedIn-like platform. Job Title Recommendations It recommends job titles that align with the user’s background so the user can choose which role(s) to target. Company Selection After a job title is selected, JobAgent identifies suitable companies hiring for that role and waits for the user to pick where they want to apply. Tailored Cover Letters For each chosen company, the agent generates a tailored cover letter and returns it to the user for review and approval. Automated Application Submission Once a cover letter is approved, JobAgent uses browser automation to complete and submit the application form on the user’s behalf. Networking & Referrals The agent then searches for first- and second-degree connections at the selected company, suggesting potential contacts for coffee chats or referrals. The user chooses whom to reach out to, and JobAgent facilitates the process. Mock Interview Preparation After the application stage, users can schedule a mock interview. By entering their phone number and sending a request, a Telnyx AI agent conducts a practice interview, using the specific company and job title to ask realistic, contextual questions."},{"heading":"How we built it","content":"JobAgent is composed of several coordinated components:\n\nAGI API Browser Automation We use the AGI API to navigate job listings and application forms on NetworkIn and company career pages. It handles actions like logging in, clicking through job postings, filling in fields, and submitting applications. Resume Parsing & Profile Understanding The resume is parsed into structured data (skills, roles, experience, education). This structure powers job search queries on NetworkIn and informs the job title recommendations. Job Search & Recommendation Logic Based on the parsed profile, JobAgent constructs targeted searches on NetworkIn, filters results for relevance, and recommends job titles aligned with the user’s background and seniority level. Cover Letter Generation For each company and role, the system combines the resume content with job description context to generate a tailored cover letter that highlights relevant experience and alignment with the role. Connection Discovery JobAgent queries NetworkIn’s graph-like data to find first- and second-degree connections at the selected companies, ranking them as potential coffee chat or referral targets. Telnyx AI Integration When the user requests a mock interview, we pass the company and role context, plus key resume highlights, to a Telnyx AI agent. It then conducts a phone-based practice interview using realistic questions tied to that specific role."},{"heading":"Challenges we ran into","content":"Dynamic Job and Application Pages Job listings and application forms often change layouts, add pop-ups, or introduce new fields. Making the browser automation robust and resilient to these changes was a core challenge. High-Quality, Non-Generic Cover Letters Generating tailored cover letters that feel specific and human, rather than generic AI text, required careful prompt and context design. Connection Relevance Not every contact at a target company is equally useful. Filtering and ranking connections so that suggestions feel genuinely helpful (e.g., shared background, relevant team) was more complex than simply listing everyone. Context Synchronization for Mock Interviews Ensuring that Telnyx AI always has up-to-date context (company, job title, and user profile) so mock interviews feel realistic and targeted required thoughtful data flow between components."},{"heading":"Accomplishments that we're proud of","content":"True End-to-End Automation JobAgent doesn’t just help with one step; it covers the entire pipeline from resume upload to final application submission, with user approvals at key checkpoints. Integrated Networking Support Going beyond traditional application helpers, JobAgent actively surfaces first- and second-degree connections and helps users reach out for coffee chats and referrals. Contextual Mock Interviews The Telnyx AI integration transforms interview prep from generic Q&A into realistic, job-specific practice sessions tied directly to applications the user has just submitted. User-in-the-Loop Design Users remain in control of crucial decisions — job titles, target companies, and final cover letters — while still benefiting from heavy automation on the repetitive tasks."},{"heading":"What we learned","content":"Automation Needs Clear Approval Points Users are much more comfortable with automation when they can review and confirm important steps, like which companies to apply to and what gets sent on their behalf. Networking Multiplies the Value of Applications Automatically pairing applications with suggested contacts for coffee chats and referrals makes the assistant feel more like a career coach than just a form filler. Context Makes Practice Interviews More Valuable Mock interviews that know the job title and company are significantly more useful than generic practice sessions, leading to better preparation and confidence. Robust Web Automation Is All About Edge Cases Small changes in web layouts and application flows can break naïve automation, so handling edge cases gracefully is essential for reliability."},{"heading":"What's next for JobAgent","content":"Support for More Platforms Expand beyond NetworkIn to additional job boards and applicant tracking systems so users can apply across the wider job market. Application Tracking & Insights Add a dashboard where users can track all their applications, see statuses, and gain insight into response rates and outcomes. Deeper Personalization Incorporate user preferences like location, company size, remote vs. onsite, and industry focus even more deeply into job search and recommendations. Richer Interview Coaching Build feedback summaries and personalized prep plans from Telnyx mock interviews, helping users focus on their weak spots. Outreach Template Library Offer a growing library of customizable outreach templates for coffee chats and referrals, tuned by user feedback over time."},{"heading":"Built With","content":"agi anthropic express.js javascript node.js react telnyx typescript vite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Sentinel","project_url":"https://devpost.com/software/sentinel-23oidp","tagline":"Sentinel is a safety layer for autonomous agents that uses Sentry, Telnyx, OpenAI, AGI SDK, and Lovable to stop dangerous actions and require real human approval.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/004/030/011/datas/medium.png","prizes":[{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"Best Use of Sentry"},{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"Best Use of Telnyx"}],"team_members":[],"built_with":[{"name":"api","url":null},{"name":"context-injection","url":null},{"name":"distributed","url":null},{"name":"error-monitoring","url":null},{"name":"fastapi","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"lovable-react-components","url":null},{"name":"lovable-ui-generator","url":null},{"name":"openai-models","url":null},{"name":"performance","url":null},{"name":"postcss","url":null},{"name":"pydantic-v2","url":null},{"name":"pydantic-v2-tool-schemas","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sentry","url":null},{"name":"stats","url":null},{"name":"telnyx","url":null},{"name":"telnyx-ai-voice","url":null},{"name":"telnyx-function-calling","url":null},{"name":"telnyx-real-time-voice-assistant","url":null},{"name":"telnyx-webhook-validation","url":null},{"name":"transactions","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vite","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Preet37/Sentinel"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired to build Sentinel because enterprises are moving rapidly into the era of autonomous agents powered by OpenAI models and the AGI SDK, but they do not have reliable safeguards around what these agents can actually do. A single hallucinated API call from an OpenAI-powered system can delete customer data, send money to the wrong place, or escalate privileges. We realized that traditional prompting strategies cannot guarantee safety, which pushed us to design a true middleware layer that stands between the agent and the real world. We wanted to use sponsors like Sentry and its rich observability tooling to detect instability early and guide safer agent behavior, while using Telnyx AI Voice to involve humans when needed.\n\nOur vision came from treating Sentinel as the conscience of the agent, similar to a psychological Super-Ego. We designed it using OpenAI and the AGI SDK for model reasoning, Sentry for real-time stability and tracing, Telnyx for conversational authorization, and Lovable to help us quickly build the dashboard. Together, these sponsors shaped the core architecture. Sentinel is not a patch or a plugin. It is a safety operating system that uses OpenAI reasoning but keeps guardrails enforced through Sentry metrics and Telnyx human verification."},{"heading":"What it does","content":"Sentinel intercepts every action generated by an AGI model running through the AGI SDK and classifies the action as safe or high risk. Safe actions such as data reads pass through immediately. High-risk actions like payments, deletions, or exports are blocked until they undergo a multi-step review. The first review uses Sentry. By calling the Sentry Stats API and evaluating crash-free session rates, Sentinel ensures that no AGI-powered workflow proceeds while backend systems are unstable. This transforms Sentry observability from monitoring into active enforcement.\n\nIf an action fails a policy check, Sentinel sends the request to the human approval flow powered by Telnyx AI Voice. Through Telnyx TexML and Telnyx function-calling, the voice agent can explain the issue to the human and provide a guided authorization flow. On the frontend, the UI scaffolding generated by Lovable gives a clean, mission-control-like view of Sentry health, AGI reasoning traces, and AGI SDK tool calls. All of these sponsor technologies combine to create a seamless loop between AI autonomy, Sentry safety checks, Telnyx reaches out for admin approval and human oversight, and interactive dashboard displays the risk and reasoning and analysis of Sentinel as well as logs."},{"heading":"How we built it","content":"The core agent layer uses the AGI SDK with AGI models, but we intentionally reject open-ended tool access. Instead, we built a strict proxy called SentinelGateway that validates every tool call using typed schemas. This ensures that every payload generated by the AGI model is structured, predictable, and compliant with risk requirements. We also rely heavily on Sentry distributed tracing. Each call through the AGI SDK creates Sentry transactions and spans, which are enriched with metadata about risk scores and violated business rules. These Sentry traces help engineers see exactly how an AGI agent reached its decision.\n\nFor the human-in-the-loop flow, we built our approvals using Telnyx AI Voice. The AGI SDK triggers Telnyx calls for high-risk actions, and Telnyx webhooks send back signed responses to transition the Sentinel FSM. We also injected Sentry trace data into the Telnyx TexML script, which allows the Telnyx AI Assistant to pull real context into the conversation. Finally, Lovable helped us spin up the frontend quickly. We extended it with custom React logic to display Sentry health, Telnyx call states, and AGI task logs in real time. The result is a fully integrated stack powered by sponsor technologies at every layer."},{"heading":"Challenges we ran into","content":"One major challenge was multi-hop latency. Each action required OpenAI model inference through the AGI SDK, followed by Sentry Stats API checks and Telnyx call setup. This created moments of silence that made users think the system was stuck. We solved this using a Lovable-based frontend that streams immediate progress logs while waiting for the backend. These logs reflected the Sentry connection checks and Telnyx call initialization so the user always felt engaged. This challenge taught us how essential sponsor technologies like Sentry and Telnyx are in building responsive AI systems.\n\nAnother challenge was the Telnyx AI model not having context. Because Telnyx AI Voice runs in a different environment, it initially had no knowledge of why Sentinel blocked an action. Without context, it hallucinated generic explanations. Our fix was to inject Sentry trace metadata into the Telnyx TexML instructions. This allowed the Telnyx model to reference real Sentry metrics and logs during the call. We also had to prevent the OpenAI model from hallucinating a successful result before the human approved it. We solved this using a blocking interceptor in the AGI SDK tool logic that forces the OpenAI agent to wait for the Telnyx webhook."},{"heading":"Accomplishments that we're proud of","content":"One of our biggest accomplishments is building true human-in-the-loop security by combining OpenAI, Sentry, and Telnyx AI Voice. A human can ask the Telnyx agent questions like “Why was this blocked?” and the model will answer using Sentry trace data. This creates a transparent and auditable safety flow. The AGI SDK helped us enforce strong structural constraints, ensuring the OpenAI model only generates actions within safe bounds.\n\nAnother major accomplishment is reimagining how Sentry is used. Instead of treating Sentry as a debugging tool, we turned it into a runtime policy engine. Sentinel depends on Sentry Stats API results to allow or deny AGI actions. We also observed how seamlessly we could build clean UI experiences with Lovable, combining it with real-time Sentry logs and Telnyx states. This product would not exist without the deep technical contributions of all our sponsor tools."},{"heading":"What we learned","content":"We learned that using AGI with the AGI SDK requires deep understanding of failure modes. LLMs often hallucinate confident but unsafe actions, so architecture must be designed with strict schema enforcement. By coupling AGI reasoning with Sentry safety checks and Telnyx approval voice calls, we saw how important sponsor tools are in building real enterprise AI systems. We also learned how to enforce deterministic decision-making by forcing AGI models into Pydantic-valid schemas.\n\nWorking with Telnyx AI Voice taught us how complex voice AI actually is, especially when mixed with Sentry trace injection. We gained experience in function calling, webhook handling, and real-time context feeding. On the UI side, Lovable helped us move quickly as it gave us a good template for us to make modifications to. Combined with Sentry’s distributed tracing, we built a transparent system where engineers can see every model decision. This blend of sponsors shaped our understanding of how safety and autonomy must coexist."},{"heading":"What's next for Sentinel","content":"Our next steps include deepening our integration with Sentry to support predictive safety. We want Sentinel to use Sentry time-series metrics to identify instability before it occurs and proactively pause OpenAI agents. We also plan to expand Telnyx conversational flows so that approval calls feel more like interactive discussions. On the agent side, we aim to integrate more advanced OpenAI reasoning patterns using the AGI SDK to create stricter, more controllable tool schemas. The frontend will continue to evolve with Lovable as our base.\n\nThe most ambitious roadmap item is building self-healing automations powered by Sentry AI Autofix. Sentinel will use Sentry trace history and AGI SDK schemas to repair unsafe OpenAI actions instead of simply blocking them. For example, if an invalid Vendor ID is detected, Sentinel will query Sentry history and reconstruct the correct payload. Then, the Telnyx AI Voice system will ask the human: “Do you want to approve the corrected version that Sentinel created?” This creates a closed-loop workflow powered by Sentry, Telnyx, OpenAI, AGI SDK, and Lovable. It moves Sentinel from a passive gatekeeper to an active problem solver."},{"heading":"Built With","content":"api context-injection distributed error-monitoring fastapi github groq lovable-react-components lovable-ui-generator openai-models performance postcss pydantic-v2 pydantic-v2-tool-schemas python react sentry stats telnyx telnyx-ai-voice telnyx-function-calling telnyx-real-time-voice-assistant telnyx-webhook-validation transactions typescript vite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"warmscreen","project_url":"https://devpost.com/software/warmscreen","tagline":"Self-evolving AI recruiter that learns from every interview—using 7-agent reflexion loops, LiveKit voice, and real-time candidate proctoring to auto-optimize hiring decisions.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/004/029/749/datas/medium.jpg","prizes":[{"hackathon_name":"AGI, Inc. x OpenAI x Lovable REAL Agent Challenge","hackathon_url":"https://agi-real.devpost.com/","prize_name":"Best Use of Daytona"}],"team_members":[],"built_with":[{"name":"agiapi","url":null},{"name":"build\":-\"turbo-run-build","url":null},{"name":"clean\":-\"turbo-run-clean-&&-rm-rf-node-modules","url":null},{"name":"daytona","url":null},{"name":"db:migrate\":-\"turbo-run-db:migrate","url":null},{"name":"db:push\":-\"turbo-run-db:push","url":null},{"name":"db:studio\":-\"cd-packages/database-&&-pnpm-db:studio\"-},\"devdependencies\":-{-\"prettier\":-\"^3.1.1","url":null},{"name":"format\":-\"prettier-write-\\\"**/*.{ts,\"db:generate\":-\"turbo-run-db:generate","url":null},{"name":"lint\":-\"turbo-run-lint","url":null},{"name":"livekit","url":null},{"name":"name\":-\"warmscreen","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"npm\":-\">=9.0.0\"-}","url":null},{"name":"packages/*\"-],\"scripts\":-{-\"dev\":-\"turbo-run-dev","url":null},{"name":"private\":-true,\"description\":-\"self-evolving-ai-recruiter-with-7-agent-swarm-and-real-time-learning","url":null},{"name":"test\":-\"turbo-run-test","url":null},{"name":"turbo\":-\"^1.11.2","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"typescript\":-\"^5.3.3\"-},\"engines\":-{-\"node\":-\">=18.0.0","url":null},{"name":"version\":-\"0.1.0","url":null},{"name":"workspaces\":-[-\"apps/*","url":null}],"external_links":[{"label":"github.com","url":"http://github.com/wildhash/warmscreen"}],"description_sections":[{"heading":"What Inspired Me","content":"The inspiration behind WarmScreen stemmed from a desire to create a more intelligent and efficient utility for managing background tasks in resource-sensitive environments. I was fascinated by how modern technologies dynamically allocate limited resources, and this project was my attempt to dive into those concepts."},{"heading":"What I Learned","content":"Through building this project, I learned:\n\nThe principles of efficient multi-threaded task management. Leveraging advanced features of the primary programming language to optimize code execution. The nuances of debugging concurrency issues and improving task distribution.\n\nAdditionally, I explored the use of external libraries and frameworks to simplify certain components of the development process."},{"heading":"How I Built It","content":"I began by sketching out the architecture for WarmScreen and breaking down the overall goals into smaller milestones. I used [insert programming language/tool here] , particularly its concurrency library, to implement the core functionality. Here's a simplified structure:\n\nDesigning the Algorithm : Developed the logic for task prioritization based on resource availability. Building the Core : Connected the algorithm with modules to monitor system performance. Integrating Features : Added a user-friendly interface and logging features to track the execution of tasks.\n\nA Mathematical Approach\n\nTo ensure efficient task execution, I utilized some mathematical representations, such as cost functions:\n\n$$ C(t) = w_1 \\cdot R + w_2 \\cdot Q $$\n\nWhere:\n\n( C(t) ) is the cost at time ( t ), ( R ) represents resource usage for the task, ( Q ) is the task's priority queue, ( w_1 ) and ( w_2 ) are weights to balance resource consumption and priority.\n\nThis mathematical approach helped in optimizing task prioritization dynamically."},{"heading":"Challenges I Faced","content":"The journey wasn’t without its challenges:\n\nConcurrency Issues : Debugging race conditions and resolving deadlocks took significant effort. Performance Optimization : Striking a balance between simplicity and efficiency required iterative testing and profiling. Cross-Platform Compatibility : Making sure the project worked equally well across different environments brought up hidden bugs."},{"heading":"Conclusion","content":"WarmScreen was a challenging yet rewarding experience. It taught me to plan better, debug effectively, and innovate with limited resources. While there is always room for improvement, I'm proud of the progress I made with this project and look forward to expanding its capabilities in the future.\n\nIf you're interested in exploring the code, check out the project on GitHub . Contributions and feedback are always welcome!"},{"heading":"Acknowledgements","content":"My mentors and peers for their guidance and valuable insights. The open-source community for the vast collection of resources and tools."},{"heading":"Built With","content":"agiapi build\":-\"turbo-run-build clean\":-\"turbo-run-clean-&&-rm-rf-node-modules daytona db:migrate\":-\"turbo-run-db:migrate db:push\":-\"turbo-run-db:push db:studio\":-\"cd-packages/database-&&-pnpm-db:studio\"-},\"devdependencies\":-{-\"prettier\":-\"^3.1.1 format\":-\"prettier-write-\\\"**/*.{ts,\"db:generate\":-\"turbo-run-db:generate lint\":-\"turbo-run-lint livekit name\":-\"warmscreen node.js npm\":-\">=9.0.0\"-} packages/*\"-],\"scripts\":-{-\"dev\":-\"turbo-run-dev private\":-true,\"description\":-\"self-evolving-ai-recruiter-with-7-agent-swarm-and-real-time-learning test\":-\"turbo-run-test turbo\":-\"^1.11.2 typescript typescript\":-\"^5.3.3\"-},\"engines\":-{-\"node\":-\">=18.0.0 version\":-\"0.1.0 workspaces\":-[-\"apps/*"},{"heading":"Try it out","content":"github.com"}]}],"generated_at":"2026-02-18T16:41:22.576852Z"}}