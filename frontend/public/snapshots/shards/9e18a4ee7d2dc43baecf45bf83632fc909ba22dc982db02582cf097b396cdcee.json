{"version":"v1","hackathon_url":"https://treehacks-2017.devpost.com","generated_at":"2026-02-18T16:40:29.187060Z","result":{"hackathon":{"name":"TreeHacks 2017","url":"https://treehacks-2017.devpost.com","gallery_url":"https://treehacks-2017.devpost.com/project-gallery","scanned_pages":6,"scanned_projects":123,"winner_count":27},"winners":[{"project_title":"TrainTrax","project_url":"https://devpost.com/software/traintrax-p04tky","tagline":"TrainTrax is a music middleware, enabling speaker sharing across platforms and devices.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/478/477/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Polished"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Button in an iOS, Android, or Web App"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Linode Services"}],"team_members":[],"built_with":[{"name":"apis","url":null},{"name":"apple-music","url":null},{"name":"button","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"ios","url":"https://devpost.com/software/built-with/ios"},{"name":"love","url":"https://devpost.com/software/built-with/love"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"sketch","url":"https://devpost.com/software/built-with/sketch"},{"name":"spotify","url":"https://devpost.com/software/built-with/spotify"},{"name":"swift","url":"https://devpost.com/software/built-with/swift"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"You use Apple Music. Your friends all use Spotify. But you're all stuck in a car together on the way to Tahoe and have the perfect song to add to the road trip playlist. With TrainTrax, you can all add songs to the same playlist without passing the streaming device around or hassling with aux cords.\n\nHave you ever been out with friends on a road trip or at a party and wished there was a way to more seamlessly share music? TrainTrax is a music streaming middleware that lets cross platform users share music without pulling out the aux cord."},{"heading":"How it Works","content":"The app authenticates a “host” user sign through their Apple Music or Spotify Premium accounts and let's them create a party where they can invite friends to upload music to a shared playlist. Friends with or without those streaming service accounts can port through the host account to queue up their favorite songs. Hear a song you like? TrainTrax uses Button to deep links songs directly to your iTunes account, so that amazing song you heard is just a click away from being yours."},{"heading":"How We Built It","content":"The application is built with Swift 3 and Node.js/Express. A RESTful API let’s users create parties, invite friends, and add songs to a queue. The app integrates with Button to deep link users to songs on iTunes, letting them purchase songs directly through the application."},{"heading":"Challenges We Ran Into","content":"• The application depended a lot on third party tools, which did not always have great documentation or support. • This was the first hackathon for three of our four members, so a lot of the experience came with a learning curve. In the spirit of collaboration, our team approached this as a learning opportunity, and each member worked to develop a new skill to support the building of the application. The end result was an experience focused more on learning and less on optimization. • Rain."},{"heading":"Accomplishments that we're proud of","content":"• SDK Integrations: Successful integration with Apple Music and Spotify SDKs! • Button: Deep linking with Button • UX: There are some strange UX flows involved with adding songs to a shared playlist, but we kicked of the project with a post-it design thinking brainstorm session that set us up well for creating these complex user flows later on. • Team bonding: Most of us just met on Friday, and we built a strong fun team culture."},{"heading":"What we learned","content":"Everyone on our team learned different things."},{"heading":"What's next for TrainTrax","content":"• A web application for non-iPhone users to host and join parties • Improved UI and additional features to fine tune the user experience — we've got a lot of ideas for the next version in the pipeline, including some already designed in this prototype: TrainTrax prototype link"},{"heading":"Built With","content":"apis apple-music button express.js ios love node.js sketch spotify swift"}]},{"project_title":"Sensory","project_url":"https://devpost.com/software/sensory","tagline":"Sensory is a VR experience that visualizes and simulates various visual, auditory, and cognitive impairments.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/958/datas/medium.gif","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Creative"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Education Grand Prize"}],"team_members":[],"built_with":[{"name":"c#","url":"https://devpost.com/software/built-with/c--2"},{"name":"htc-vive","url":"https://devpost.com/software/built-with/htc-vive"},{"name":"steam-vr","url":null},{"name":"unity","url":"https://devpost.com/software/built-with/unity"},{"name":"visual-studio","url":"https://devpost.com/software/built-with/visual-studio"}],"external_links":[{"label":"github.com","url":"https://github.com/connor-a-smith/treehacks"}],"description_sections":[{"heading":"Inspiration","content":"Some things can only be understood through experience, and Virtual Reality is the perfect medium for providing new experiences. VR allows for complete control over vision, hearing, and perception in a virtual world, allowing our team to effectively alter the senses of immersed users. We wanted to manipulate vision and hearing in order to allow players to view life from the perspective of those with various disorders such as colorblindness, prosopagnosia, deafness, and other conditions that are difficult to accurately simulate in the real world. Our goal is to educate and expose users to the various names, effects, and natures of conditions that are difficult to fully comprehend without first-hand experience. Doing so can allow individuals to empathize with and learn from various different disorders."},{"heading":"What it does","content":"Sensory is an HTC Vive Virtual Reality experience that allows users to experiment with different disorders from Visual, Cognitive, or Auditory disorder categories. Upon selecting a specific impairment, the user is subjected to what someone with that disorder may experience, and can view more information on the disorder. Some examples include achromatopsia, a rare form of complete colorblindness, and prosopagnosia, the inability to recognize faces. Users can combine these effects, view their surroundings from new perspectives, and educate themselves on how various disorders work."},{"heading":"How we built it","content":"We built Sensory using the Unity Game Engine, the C# Programming Language, and the HTC Vive. We imported a rare few models from the Unity Asset Store (All free!)"},{"heading":"Challenges we ran into","content":"We chose this project because we hadn't experimented much with visual and audio effects in Unity and in VR before. Our team has done tons of VR, but never really dealt with any camera effects or postprocessing. As a result, there are many paths we attempted that ultimately led to failure (and lots of wasted time). For example, we wanted to make it so that users could only hear out of one ear - but after enough searching, we discovered it's very difficult to do this in Unity, and would've been much easier in a custom engine. As a result, we explored many aspects of Unity we'd never previously encountered in an attempt to change lots of effects."},{"heading":"What's next for Sensory","content":"There's still many more disorders we want to implement, and many categories we could potentially add. We envision this people a central hub for users, doctors, professionals, or patients to experience different disorders. Right now, it's primarily a tool for experimentation, but in the future it could be used for empathy, awareness, education and health."},{"heading":"Built With","content":"c# htc-vive steam-vr unity visual-studio"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"livegb","project_url":"https://devpost.com/software/livegb","tagline":"Edit a Game Boy game in your browser, while it's running.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/477/801/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Technically Challenging"}],"team_members":[],"built_with":[{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"z80-assembly","url":null}],"external_links":[{"label":"dev.rsnous.com","url":"http://dev.rsnous.com/livegb/"},{"label":"github.com","url":"https://github.com/osnr/livegb"}],"description_sections":[{"heading":"Inspiration","content":"There are a lot of ideas floating around about how to build more powerful programming environments.\n\nCan you edit the program while it's running?\n\nCan you have a debugger that remembers old states of your program, so you can scrub back and forth in time?\n\nCan you have the information you want at hand as you're editing and navigating the code -- runtime information, not just static source text?\n\nThe Game Boy is interesting because it has some familiar software -- Pokémon, Mario, and so on -- but it's a small enough system that you can do a lot of weird, inefficient tricks.\n\nIt has a 4 MHz processor and 8 KB of RAM.\n\nSo if we want to go back in time, we can just copy the whole computer state; it's not a big deal!"},{"heading":"How it works","content":"A code editor and emulator appear in your browser. The whole development system runs in the browser, so you can edit and play without leaving your browser window.\n\nYou edit the Game Boy assembly on the left, and it reloads the ROM pretty much instantly on the right, as you're typing."},{"heading":"What I did","content":"I wrote a completely new Game Boy assembler so it would run in the browser, so it would run fast enough to compile in real time, and so I could instrument the output properly.\n\nThe emulator is an existing JS Game Boy emulator (patched a little to support real-time ROM changes), and the demo is a small one-file demo someone wrote."},{"heading":"Future directions","content":"Smarter hot-swap (with a custom assembler and more emulator tools, we can track provenance of regions of RAM, etc). Or do input replay instead.\n\nTrack provenance of regions of display, so you click a pixel and it knows where it came from in the code.\n\nGet it working with the full Pokémon Red disassembly .\n\nShare a link to your edited game, possibly including your place in it, with other people.\n\nExport your edited game as a ROM."},{"heading":"Built With","content":"typescript z80-assembly"},{"heading":"Try it out","content":"dev.rsnous.com github.com"}]},{"project_title":"Hot Dog","project_url":"https://devpost.com/software/hot-dog","tagline":"Saving pets' lives from overheated cars","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/478/216/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of IBM Watson IoT Platform on Bluemix"}],"team_members":[],"built_with":[{"name":"android","url":"https://devpost.com/software/built-with/android"},{"name":"angular.js","url":"https://devpost.com/software/built-with/angular-js"},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"ibm-watson","url":"https://devpost.com/software/built-with/ibm-watson"},{"name":"iot","url":null},{"name":"node-red","url":"https://devpost.com/software/built-with/node-red"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"raspberry-pi","url":"https://devpost.com/software/built-with/raspberry-pi"},{"name":"twilio","url":"https://devpost.com/software/built-with/twilio"}],"external_links":[{"label":"github.com","url":"https://github.com/Raghav-Maheshwari/treehacks2017"}],"description_sections":[{"heading":"Inspiration","content":"During sweltering summer days, cars can be become very hot very fast. Many people accidentally leave their dogs, or even young children and infants, in their vehicles, while picking up groceries or shopping. Even though they expect to be gone for only 20 minutes or less, during this time, car temperatures can reach about 110 degrees within minutes. 39 children died of heat stroke in overheated cars in 2016, accumulating to hundred of child deaths since 1998. Thousands of pets die per year in these cars. We wanted to stop these tragic and preventable deaths."},{"heading":"What it does","content":"Hot Dog is an IoT application, using IBM Watson's Node-RED and the Raspberry Pi. Users place the hardware, comprised of the Raspberry Pi and a temperature sensor, near their windshield in the car. Hot Dog will keep track of the temperature within their vehicle while they are running errands. When the measured temperature is about to reach dangerously high-levels and it detects a presence in the car, the application will send a text message to the user, warning them that they are potentially putting their pet/child at risk of heat stroke. If the car does become extremely hot, the app will also call Animal Control or 911 automatically as a second resort. As another addition to the IoT capability, we have a twitter account linked that tweets from the pet's perspective calling for help on a large social scale. In addition, we have made a web application dashboard that displays the live temperature updates, grabs data from a weather api to display heat patterns, graphs the temperatures fetched through the Pi, and displays the tweets."},{"heading":"How we built it","content":"Our main platform runs on Node-RED, where we have the IoT device as the Raspberry Pi (or for demo purposes, an app that allows us to manually control the temperature). The IoT device connects to many outlet nodes, such as twitter, twilio, and http to send live data to each outlet. On the hardware side, we have the Pi connected to a temperature sensor to retrieve measures and send it to the server. Then, we have the web application created from HTML/CSS, Javascript, and Angular.js to display the live data, also using frameworks such as n3-charts and OpenWeatherMap to visualize the data and give a comprehensive insight into past and projected temperatures in and around the car. Most importantly, the web page displays the status of the car, whether it is dangerous, uncomfortable, or safe at the current moment in the car. We use Twilio to send messages to the user's phone if the car become too hot or to call the authorities in dire situations. We use Twitter to tweet live updates as well."},{"heading":"Challenges we ran into","content":"As first-time hardware hackers, we were completely new to using microprocessors and microcomputers. We went from trying to use the Raspberry Pi, to the Intel Edison, to the Arduino Uno, back to the Edison, and finally to choosing the Raspberry Pi. We were trying to figure out how to attach a temperature sensor and how to connect the device on Node-RED as an IoT device. After many installations and attempts, we finally managed to retrieve data from a Raspberry Pi. Additionally, we had to simulate the temperature, so we also used a separate IoT device to manually change the temperature. We had troubles learning how to use Node-RED and how to connect nodes and data payloads appropriately. The twitter feature had authorization issues as well. Every step felt like 3 steps back to begin with, but we finally had a product at the end."},{"heading":"Accomplishments that we're proud of","content":"We made an IoT application that works! We successfully connected the data from the Pi to multiple outlets/platforms including web, Android, and SMS tools. It was amazing to see how Node-RED could so easily send information live onto our phones and other laptops. Our idea actually solves a real-life problem that could potentially save many lives lost every year. All of us see on the news that some small child died of heat stroke while their parents were following their busy schedule and just simply forgot how hot the day was. Way too many helpless pets die from this very issue as well, and our app can work to lower the number of fatalities."},{"heading":"What we learned","content":"We expanded our horizons beyond simply software and integrated hardware into our hack. We learned of the crazy capabilities of the Raspberry Pi, how to interface the Pi with serial communication, and how to integrate peripheral senors onto the hardware. We learned about the power of Node-RED to connect everything together and more about how node modules work. As students from USC and Stanford and strangers at first, we learned how to emphasize everyone's talents yet also learn a lot about each part of the project."},{"heading":"What's next for Hot Dog","content":"Ideally, this application will be incorporated into cars across the country or encourage car manufactures to make their own implementations to monitor car temperatures. To improve the accuracy of our hardware, we will add sound sensors to detect noises such as barking or crying along with the temperatures so that users will only get notifications and warnings when the hardware is sure that the owner is out and there is life at risk in the car. The hardware will eventually have LED lights displaying warnings to passerbys when some being is threatened. We aim to educate people about the dangers of leaving lives in hot vehicles as well and raise awareness. We are improving our Android interface and tried making a Android launcher widget as well, so we definitely want to make more mobile apps for Hot Dog to supplement the mobile accessibility and provide information easily on mobile home screens like it does on our existing apps."},{"heading":"Built With","content":"android angular.js css html ibm-watson iot node-red node.js raspberry-pi twilio"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Dream.it","project_url":"https://devpost.com/software/dream-it","tagline":"If you can dream it, you can wear it.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/676/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of IBM Watson IoT Platform on Bluemix"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Overall Integration and Use of Microsoft Technology(s)"}],"team_members":[],"built_with":[{"name":"bing-image-search","url":null},{"name":"bing-search-api","url":"https://devpost.com/software/built-with/bing-search-api"},{"name":"bing-speech","url":null},{"name":"bing-vision","url":null},{"name":"css3","url":"https://devpost.com/software/built-with/css3"},{"name":"cuda","url":"https://devpost.com/software/built-with/cuda"},{"name":"cudnn","url":null},{"name":"fabric.js","url":"https://devpost.com/software/built-with/fabric-js"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"generative-adverserial-networks","url":null},{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"ibm-watson","url":"https://devpost.com/software/built-with/ibm-watson"},{"name":"linode","url":"https://devpost.com/software/built-with/linode"},{"name":"microsoft-cognitive-services","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"pixel-recursive-super-recursion","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sass","url":"https://devpost.com/software/built-with/sass"},{"name":"socket.io","url":"https://devpost.com/software/built-with/socket-io"},{"name":"super-resolution-pixel-subnets","url":null},{"name":"theano","url":null},{"name":"vue.js","url":null},{"name":"web-rtc","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/Dranithix/treehacks-client"}],"description_sections":[{"heading":"Inspiration & What it does","content":"You're walking down the road, and see a belle rocking an exquisite one-piece. \"Damn, that would look good on me (or my wife)\" .\n\nYou go home and try to look for it: \"beautiful red dress\" . Google gives you 110,000,000 results in 0.54 seconds. Well that helped a lot. You think of checking the fashion websites, but the number of these e-commerce websites makes you refrain from spending more than a few hours. \"This is impossible...\" . You perseverance only lasts so long - you give up.\n\nFast forward to 2017. We've got everything from Neural Forests to Adversarial Networks.\n\nYou go home to look for it: Launch Dream.it\n\nYou make a chicken-sketch of the dress - you just need to get the curves right. You select the pattern on the dress, a couple of estimates about the dress. Dream.it synthesizes elegant dresses based on your sketch. It then gives you search results from different stores based on similar dresses, and an option to get on custom made. You love the internet. You love Dream.it . Its a wonderful place to make your life wonderful.\n\nSketch and search for anything and everything from shoes and bracelets to dresses and jeans: all at your slightest whim. Dream.it lets you buy existing products or get a new one custom-made to fit you."},{"heading":"How we built it","content":"What the user sees\n\nDream.it uses a website as the basic entry point into the service, which is run on a linode server . It has a chatbot interface, through which users can initially input the kind of garment they are looking for with a few details. The service gives the user examples of possible products using the Bing Search API . The voice recognition for the chatbot is created using the Bing Speech to Text API . This is classified using a multiclassifier from IBM Watson Natural Language Classifier trained on custom labelled data into the clothing / accessory category. It then opens a custom drawing board for you to sketch the contours of your clothing apparel / accessories / footwear and add color to it.\n\nOnce the sketch is finalized, the image is converted to more detailed higher resolution image using Pixel Recursive Super Resolution .\n\nWe then use Google's Label Detection Vision ML and IBM Watson's Vision APIs to generate the most relevant tags for the final synthesized design which give additional textual details for the synthesized design. The tags, in addition to the image itself are used to scour the web for similar dresses available for purchase\n\nBehind the scenes\n\nWe used a Deep Convolutional Generative Adversarial Network (GAN) which runs using Theano and cuDNN on CUDA . This is connected to our web service through websockets. The brush strokes from the drawing pad on the website get sent to the GAN algorithm, which sends back the synthesized fashion design to match the user's sketch."},{"heading":"Challenges we ran into","content":"Piping all the APIs together to create a seamless user experience. It took a long time to optimize the data ( mpeg1 ) we were sending over the websocket to prevent lags and bugs. Running the Machine learning algorithm asynchronously on the GPU using CUDA. Generating a high-quality image of the synthesized design. Customizing Fabric.js to send data appropriately formatted to be processed by the machine learning algorithm."},{"heading":"Accomplishments that we're proud of","content":"We reverse engineered the Bing real-time Speech Recognition API to create a Node.js library. We also added support for partial audio frame streaming for voice recognition . We applied transfer learning from Deep Convolutional Generative Adversarial Networks and implemented constraints on its gradients and weights to customize user inputs for synthesis of fashion designs. Creating a Python-Node.js stack which works asynchronously with our machine learning pipeline"},{"heading":"What we learned","content":"This was a multi-faceted educational experience for all of us in different ways. Overall:\n\nWe learnt to asynchronously run machine learning algorithms without threading issues. Setting up API calls and other infrastructure for the app to run on. Using the IBM Watson APIs for speech recognition and label detection for images. Setting up a website domain, web server, hosting a website, deploying code to a server, connecting using web-sockets. Using pip, npm; Using Node.js for development; Customizing fabric.js to send us custom data for image generation. Explored machine learning tools learnt how to utlize them most efficiently. Setting up CUDA, cuDNN, and Theano on an Ubuntu platform to use with ML algorithm."},{"heading":"What's next for Dream.it","content":"Dream.it currently is capable of generating shoes, shirts, pants, and handbags from user sketches. We'd like to expand our training set of images and language processing to support a greater variety of clothing, materials, and other accessories. We'd like to switch to a server with GPU support to run the cuDNN-based algorithm on CUDA.\n\nThe next developmental step for Dream.it is to connect it to a 3D fabric printer which can print the designs instantly without needing the design to be sent to manufacturers. This can be supported at particular facilities in different parts of the country to enable us to be in control of the entire process."},{"heading":"Built With","content":"bing-image-search bing-search-api bing-speech bing-vision css3 cuda cudnn fabric.js flask generative-adverserial-networks html5 ibm-watson linode microsoft-cognitive-services node.js numpy pixel-recursive-super-recursion python sass socket.io super-resolution-pixel-subnets theano vue.js web-rtc"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Parentese","project_url":"https://devpost.com/software/language-learner-e2awx8","tagline":"Help kids in non-English speaking households to learn English with the assistance of an engaging conversationalist.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of IBM Watson IoT Platform on Bluemix"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Google ML"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Consumer Project"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/chzou/language-learner"}],"description_sections":[{"heading":"Inspiration","content":"Children who know English are more likely to perform better in school as they grow up, but there are often households where English is not spoken at all. We made an application that engages children in English while helping them learn about their surroundings and how to respond to certain questions in conversation."},{"heading":"What it does","content":"Parentese is an app that uses image recognition to identify objects in a child's surroundings and tell the child what the object is. Once it tells the child what the object is, it asks the child a question about the given object and waits for the child to respond, giving an appropriate return response to the child's answer."},{"heading":"How we built it","content":"We used the Google Cloud Vision API to analyze an image captured from a constant video stream and return the major object in the scene. We then used IBM Watson Text-to-Speech to tell the child what the object is and to ask an associated question about the object. Our application would listen for the child's response and then use IBM Watson Speech-to-Text to get a written form of what the child has just said. Finally, we use a trained IBM Watson Conversation service to take the child's speech and provide an appropriate response about what the child has just said about the object in question."},{"heading":"What's next for Parentese","content":"We hope to expand Parentese to engage the child in deeper conversation, likely with further training of the IBM Watson Conversation service. Parentese also has the potential to be a mobile app or an embedded application in a toy that the child could carry around and converse with on a daily basis, making it more convenient and engaging in the process of learning English."},{"heading":"Built With","content":"css html javascript python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Moonlens","project_url":"https://devpost.com/software/moonlens","tagline":"An affordable VR platform for sharing personal experiences using special camera-glasses and mobile VR devices.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/359/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"VR Grand Prize"}],"team_members":[],"built_with":[{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"css3","url":"https://devpost.com/software/built-with/css3"},{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"linode","url":"https://devpost.com/software/built-with/linode"},{"name":"php5","url":"https://devpost.com/software/built-with/php5"},{"name":"processing","url":"https://devpost.com/software/built-with/processing"},{"name":"xcode","url":"https://devpost.com/software/built-with/xcode"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"The idea addresses a very natural curiosity to live and experience the world as someone else, and out of the progress with the democratization of VR with the Cardboard, we tried to create a method for people to \"upload\" their life to others. The name is a reference to Sharon Creech's quote on empathy in Walk Two Moons: \"You can't judge a man until you've walked two moons in his moccasins\", which resonated with our mission."},{"heading":"What it does","content":"Moonlens consists of a pipeline of three aspects that connects the uploaders to the audience. Uploaders use the camera-glasses to record, and then upload the video onto the website along with the data from the camera-glasses's gyro-accelerometer data (use explained below). The website communicates with the iOS app and allows the app to playback the video in split-screen.\n\nTo prevent motion sickness, the viewer has to turn his head in the same orientation as the uploader for the video to come into view, as otherwise the experience will disturb the vestibular system. This orientation requirement warrants the use of the gyro-accelerometer in the camera-glasses to compare to the iPhone's orientation tracking data."},{"heading":"How we built it","content":"The three components of the pipeline:\n\nCamera-glasses: using the high framerate and high resolution of mini sports cameras, we took apart the camera and attached it to a pair of glasses. The camera-glasses sport a combination of gyroscope and accelerometer that start synchronously with the camera's recording, and the combination of the camera and Arduino processor for the gyro-accelerometer outputs both the video file and the orientation data to be uploaded onto the website. Website: The website is for the uploaders to transfer the individual video-orientation data pairs to the database. The website was designed with Three.js, along with the externally designed logo and buttons. It uses Linode servers to handle PHP requests for the file uploads. App: The app serves as the consumer endpoint for the pipeline, and allows consumers to view all the videos in the database. The app features automatic split-screen, and videos in the app are of similar format with 360 videos except for the difference that the video only spans a portion of the spherical projection, and the viewer has to follow the metaphorical gaze of the uploader through following the video's movements."},{"heading":"Challenges we ran into","content":"A major challenge early on was in dealing with possible motion sickness in uploaders rotating their heads while the viewers don't; this confuses the brain as the visual cortex receives the rotational cue but the inner ear, which acts as the gyro for the brain, doesn't, which is the main cause for VR sickness. We came up with the solution to have the viewer turn his or her head, and this approach focuses the viewer toward what's important (what the uploader's gaze is on) and also increases the interactivity of the video.\n\nIn building the camera, we did not have the resources for a flat surface to mount the boards and batteries for the camera. Despite this, we found that our lanyards for Treehacks, when hot-glue-gunned together, made quite a good surface, and ended up using this for our prototype.\n\nIn the process of deploying the website, we had several cases of PHP not working out, and thus spent quite a bit of time trying to deploy. We ended up learning much about the backend that we hadn't previously known through these struggles and ultimately got the right amount of help to overcome the issues."},{"heading":"Accomplishments that we're proud of","content":"We were very productive from the beginning to the end, and made consistent progress and had clear goals. We worked very well as a team, and had a great system for splitting up work based on our specialties, whether that be web, app dev, or hardware.\n\nBuilding the app was a great achievement as our app specialist JR never built an app in VR before, and he figured out the nuances of working with the gyroscope and accelerometer of the phone in great time and polished the app very well.\n\nWe're also quite proud of having built the camera on top of basic plastic glasses and our Treehacks lanyards, and Richard, who specializes in hardware, was resourceful in making the camera and hacking the camera.\n\nFor the web part, Dillon and Jerry designed the backend and frontend, which was an uphill battle due to technical complications with PHP and deploying. However, the website came together nicely as the backend finally resolved the complications and the frontend was finished with the design."},{"heading":"What we learned","content":"We learned how to build with brand new tools, such as Linode, and also relied on our own past skills in development to split up work in a reasonable and efficient manner. In addition, we learned by building around VR, which was a field that many of the team members did not have exposure before."},{"heading":"What's next for Moonlens","content":"In the future, we will make the prototype camera-glasses much more compact, and hopefully streamline a process for directly producing video to uploading with minimal assistance from the computer. As people use the app, creating a positive environment between uploaders and viewers would be necessary and having the uploaders earn money from ads would be a great way to grow the community, and hopefully given time, the world can better connect and understand each other through seeing others' experiences."},{"heading":"Built With","content":"arduino css3 html5 javascript linode php5 processing xcode"}]},{"project_title":"Audiobook Maker","project_url":"https://devpost.com/software/audiobook-maker","tagline":"Turn a physical book into an audibook in other languages.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/198/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Health Grand Prize"}],"team_members":[],"built_with":[{"name":"google-ml","url":null},{"name":"linode","url":"https://devpost.com/software/built-with/linode"},{"name":"obective-c","url":null},{"name":"ocr","url":null},{"name":"php","url":"https://devpost.com/software/built-with/php"},{"name":"swift","url":"https://devpost.com/software/built-with/swift"},{"name":"translate","url":null}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"Cliff is dyslexic, so reading is difficult and slow for him and makes school really difficult. But, he loves books and listens to 100+ audiobooks/yr. However, most books don't have an audiobook, especially not textbooks for schools, and articles that are passed out in class. This is an issue not only for the 160M people in the developed world with dyslexia but also for the 250M people with low vision acuity. After moving to the U.S. at age 13, Cliff also needed something to help him translate assignments he didn't understand in school. Most people become nearsighted as they get older, but often don't have their glasses with them. This makes it hard to read forms when needed. Being able to listen instead of reading is a really effective solution here."},{"heading":"What it does","content":"Audiobook maker allows a user to scan a physical book with their phone to produced a digital copy that can be played as an audiobook instantaneously in whatever language they choose. It also lets you read the book with text at whatever size you like to help people who have low vision acuity or are missing their glasses."},{"heading":"How we built it","content":"In Swift and iOS using Google ML and a few clever algorithms we developed to produce high-quality scanning, and high quality reading with low processing time."},{"heading":"Challenges we ran into","content":"We had to redesign a lot of the features to make the app user experience flow well and to allow the processing to happen fast enough."},{"heading":"Accomplishments that we're proud of","content":"We reduced the time it took to scan a book by 15X after one design iteration and reduced the processing time it took to OCR (Optical Character Recognition) the book from an hour plus, to instantaneously using an algorithm we built. We allow the user to have audiobooks on their phone, in multiple languages, that take up virtually no space on the phone."},{"heading":"What we learned","content":"How to work with Google ML, how to work around OCR processing time. How to suffer through git Xcode Storyboard merge conflicts, how to use Amazon's AWS/Alexa's machine learning platform."},{"heading":"What's next for Audiobook Maker","content":"Deployment and use across the world by people who have Dyslexia or Low vision acuity, who are learning a new language or who just don't have their reading glasses but still want to function. We envision our app being used primarily for education in schools - specifically schools that have low-income populations who can't afford to buy multiple of books or audiobooks in multiple languages and formats."},{"heading":"Treehack themes","content":"treehacks education Verticle > personalization > learning styles (build a learning platform, tailored to the learning styles of auditory learners) - I'm an auditory learner, I've dreamed a tool like this since the time I was 8 years old and struggling to learn to read. I'm so excited that now it exists and every student with dyslexia or a learning difference will have access to it.\n\ntreehacks education Verticle > personalization > multilingual education ( English as a second-language students often get overlooked, Are there ways to leverage technology to create more open, multilingual classrooms?) Our software allows any book to become polylingual.\n\ntreehacks education Verticle > accessibility > refugee education (What are ways technology can be used to bring content and make education accessible to refugees? How can we make the transition to education in a new country smoother?) - Make it so they can listen to material in their mother tongue if needed. or have a voice read along with them in English. Make it so that they can carry their books wherever they go by scanning a book once and then having it for life.\n\ntreehacks education Verticle >language & literacy > mobile apps for English literacy (How can you build mobile apps to increase English fluency and literacy amongst students and adults?) -One of the best ways to learn how to read is to listen to someone else doing it and to follow yourself. Audiobook maker lets you do that. From a practical perspective - learning how to read is hard and it is difficult for an adult learning a new language to achieve proficiency and a high reading speed. To bridge that gap Audiobook Maker makes sure that every person can and understand and learn from any text they encounter.\n\ntreehacks education Verticle >language & literacy > in-person learning (many people want to learn second languages) - Audiobook maker allows users to live in a foreign countrys and understand more of what is going on. It allows users to challenge themselves to read or listen to more of their daily work in the language they are trying to learn, and it can help users understand while they studying a foreign language in the case that the meaning of text in a book or elsewhere is not clear.\n\nWe worked a lot with Google ML and Amazon AWS."},{"heading":"Built With","content":"google-ml linode obective-c ocr php swift translate"}]},{"project_title":"Artemis","project_url":"https://devpost.com/software/artemis","tagline":"Track your nutrition intake using Amazon Alexa, hands-free","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/477/755/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Voice User Experience Using Amazon Alexa"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Data Visualization"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Facebook's Choice"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"php","url":"https://devpost.com/software/built-with/php"}],"external_links":[{"label":"github.com","url":"https://github.com/Mitsukizzy/TreeHacks2017"},{"label":"artemisalexa.com","url":"http://artemisalexa.com/index.html"}],"description_sections":[{"heading":"Inspiration","content":"We were sitting together as a team after dinner when our team member pulled out her phone and mentioned she needed to log her food – mentioning how she found the app she used (MyFitnessPal) to be quite tedious. This was a sentiment shared by many users we've encountered and we decided there must be a way that we could make this process simple and smooth!"},{"heading":"What it does","content":"Artemis is an Amazon Alexa experience that changes the way you engage in fitness and meal tracking. Log your food, caloric intake, and know what the breakdown of your daily diet is with a simple command. All you have to do is tell Artemis that you ate something, and she'll automatically record it for you, retrieve all pertinent nutrition information, and see how it stacks up with your daily goals. Check how you're doing at anytime by asking Artemis, \"How am I doing?\" or looking up your stats presented in a clear and digestible way at www.artemisalexa.com"},{"heading":"How we built it","content":"We took the foods processed from the language request, made a call to the Nutritionix API to get the caloric breakdown, and update the backend server which live-updates the dashboard. The smart-sensor waterbottle tracks water level by using ultrasonar waves that bounce back with distance data."},{"heading":"Challenges we ran into","content":"It's definitely difficult for us to model data beyond the two days we've been working on this project and we wanted to model a lot richer of a data set in our dashboard."},{"heading":"Accomplishments that we're proud of","content":"We're really proud of the product we've built!\n\nPolished and pleasant user experience Thorough coverage of conversation, can sustain a pertinent conversation with Artemis about healthy eating. Wide breadth of data visualization Categorical breakdown Variances for Caloric intake over the course of the day Items consumed as percentages of daily nutritional breakdown Light sensor for fluid color detection (aside from water – no cheating with soda!) Ultrasonar sensor that measures water level"},{"heading":"What's next for Artemis","content":"We're hoping to build Fitbit integration so that Alexa can directly log your food into one app."},{"heading":"Built With","content":"css html javascript node.js php"},{"heading":"Try it out","content":"github.com artemisalexa.com"}]},{"project_title":"Pet Detective","project_url":"https://devpost.com/software/pet-detective","tagline":"Pet Detective is a chatbot service and analytics platform that incentivizes people to help our animal friends.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/477/598/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Google App Engine"}],"team_members":[],"built_with":[{"name":"chatbot","url":null},{"name":"d3.js","url":"https://devpost.com/software/built-with/d3-js"},{"name":"facebook-messenger","url":"https://devpost.com/software/built-with/facebook-messenger"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"google-vision","url":null},{"name":"heroku","url":"https://devpost.com/software/built-with/heroku"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[],"description_sections":[{"heading":"Inspiration","content":"We were inspired by the story of the large and growing problem of stray, homeless, and missing pets, and the ways in which technology could be leveraged to solve it, by raising awareness, adding incentive, and exploiting data."},{"heading":"What it does","content":"Pet Detective is first and foremost a chat bot, integrated into a Facebook page via messenger. The chatbot serves two user groups: pet owners that have recently lost their pets, and good Samaritans that would like to help by reporting. Moreover, Pet Detective provides monetary incentive for such people by collecting donations from happily served users. Pet detective provides the most convenient and hassle free user experience to both user bases. A simple virtual button generated by the chatbot allows the reporter to allow the bot to collect location data. In addition, the bot asks for a photo of the pet, and runs computer vision algorithms in order to determine several attributes and match factors. The bot then places a track on the dog, and continues to alert the owner about potential matches by sending images. In the case of a match, the service sets up a rendezvous with a trusted animal care partner. Finally, Pet Detective collects data on these transactions and reports and provides a data analytics platform to pet care partners."},{"heading":"How we built it","content":"We used messenger developer integration to build the chatbot. We incorporated OpenCV to provide image segmentation in order to separate the dog from the background photo, and then used Google Cloud Vision service in order to extract features from the image. Our backends were built using Flask and Node.js, hosted on Google App Engine and Heroku, configured as microservices. For the data visualization, we used D3.js."},{"heading":"Challenges we ran into","content":"Finding the write DB for our uses was challenging, as well as setting up and employing the cloud platform. Getting the chatbot to be reliable was also challenging."},{"heading":"Accomplishments that we're proud of","content":"We are proud of a product that has real potential to do positive change, as well as the look and feel of the analytics platform (although we still need to add much more there). We are proud of balancing 4 services efficiently, and like our clever name/logo."},{"heading":"What we learned","content":"We learned a few new technologies and algorithms, including image segmentation, and some Google cloud platform instances. We also learned that NoSQL databases are the way to go for hackathons and speed prototyping."},{"heading":"What's next for Pet Detective","content":"We want to expand the capabilities of our analytics platform and partner with pet and animal businesses and providers in order to integrate the bot service into many different Facebook pages and websites."},{"heading":"Built With","content":"chatbot d3.js facebook-messenger flask google-cloud google-vision heroku node.js opencv python"}]},{"project_title":"Assist ASD","project_url":"https://devpost.com/software/assist-asd","tagline":"We empower care takers to help people with Autism through data visualization, therapy tracking and deep learning.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/477/740/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Google App Engine"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Innovative Use of Neura"}],"team_members":[],"built_with":[{"name":"google-app-engine","url":"https://devpost.com/software/built-with/google-app-engine"},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"google-visualization","url":"https://devpost.com/software/built-with/google-visualization"},{"name":"illumina","url":null},{"name":"microsoft","url":null},{"name":"neura","url":"https://devpost.com/software/built-with/neura"},{"name":"qualtric","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ewjc/Autism-Tracker"},{"label":"github.com","url":"https://github.com/Nicholas-Swift/Autism-Tracker-Server"}],"description_sections":[{"heading":"Inspiration","content":"Our inspiration were are friends who have Autism and also hearing the keynote speaker talk about her brother who is Autistic."},{"heading":"What it does","content":"Assist ASD is an application made for people with autism, their caretakers and behavioral therapists. Our mobile application allows people with autism to understand social signals through image/facial recognition. In addition, the care takers are able to track their receiver in order to know events like when entering and leaving home, sleeping schedules and physical activity. Care takers not only track these events, but have measures for recording notes based ABC assessment. Lastly, all information and data is then pushed to the behavioral therapist who is able to view the metrics and data analytics in order to make more informed decisions for their patients."},{"heading":"How I built it","content":"Using AGILE/SCRUM planning, we built it using technologies based on scope. After planning the project, we incorporated google's cloud service and facial recognition along with Microsoft's sentimental analytics. We incorporated Neura's API in order to get updates on the autistic person's movements such as physical activity, sleeping activity and entering or leaving designated points. We used Qualtrics in order to display data analytics of all behaviors tracked."},{"heading":"Challenges I ran into","content":"We ran into API issues with Microsoft services. Initially it was a very confusing setup because they only had code for objective C. However, after playing around with the curl and python aspect it became useful. We also had an interesting adventure of scoping our project more precisely and cutting out possible technologies that we could use."},{"heading":"Accomplishments that I'm proud of","content":"Well, we see our application having a big impact on the ASD community."},{"heading":"What I learned","content":"More about the problem space of ASD and new technologies and capabilities for applications."},{"heading":"What's next for Assist ASD","content":"We will user interview behavioral therapist to make sure we are solving and implementing the right features."},{"heading":"Built With","content":"google-app-engine google-cloud google-visualization illumina microsoft neura qualtric"},{"heading":"Try it out","content":"github.com github.com"}]},{"project_title":"Homeward","project_url":"https://devpost.com/software/homeward","tagline":"Foster a pet, make a friend, save a life.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/478/642/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Google ML"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"google-app-engine","url":"https://devpost.com/software/built-with/google-app-engine"},{"name":"google-ml","url":null},{"name":"jade","url":"https://devpost.com/software/built-with/jade"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"vue.js","url":null}],"external_links":[{"label":"homebound-159210.appspot-preview.com","url":"https://homebound-159210.appspot-preview.com/"}],"description_sections":[{"heading":"Inspiration","content":"More than 2.7 million pets will be killed over the next year because shelters cannot accommodate them. Many of them will be abandoned by owners who are unprepared for the real responsibilities of raising a pet, and the vast majority of them will never find a permanent home. The only sustainable solution to animal homelessness is to maximize adoptions of shelter animals by families who are equipped to care for them, so we created Homeward as a one-stop foster tool to streamline this process."},{"heading":"What it does","content":"Homeward allows shelters and pet owners to offer animals for adoption online. A simple and intuitive UI allows adopters to describe the pet they want and uses Google Cloud ML's Natural Language API to match their queries with available pets. Our feed offers quick browsing of available animals, multiple ranking options, and notifications of which pets are from shelters and which will be euthanized soon."},{"heading":"How we built it","content":"We used the Node.js framework with Express for routing and MongoDB as our database. Our front-end was built with custom CSS/Jade mixed with features from several CSS frameworks. Entries in our database were sourced from the RescueGroups API, and salient keywords for query matching were extracted using Google's Natural Language API. Our application is hosted with Google App Engine."},{"heading":"Challenges we ran into","content":"Incorporating Google's Natural Language API was challenging at first and we had to design a responsive front-end that would update the feed as the user updated their query. Some pets' descriptions had extraneous HTML and links that added noise to our extracted tags. We also found it tedious to clean and migrate the data to MongoDB."},{"heading":"Accomplishments that we're proud of","content":"We successfully leveraged Google Cloud ML to detect salient attributes in users' queries and rank animals in our feed accordingly. We also managed to utilize real animal data from the RescueGroups API. Our front-end also turned out to be cleaner and more user-friendly than we anticipated."},{"heading":"What we learned","content":"We learned first-hand about the challenges of applying natural language processing to potentially noisy user queries in real life applications. We also learned more about good javascript coding practices and robust back-end communication between our application and our database. But most importantly, we learned about the alarming state of animal homelessness and its origins."},{"heading":"What's next for Homeward","content":"We can enhance posted pet management by creating a simple account system for shelters. We would also like to create a scheduling mechanism that lets users \"book\" animals for fostering, thereby maximizing the probability of adoption. In order to scale Homeward, we need to clean and integrate more shelters' databases and adjust entries to match our schema."},{"heading":"Built With","content":"css express.js google-app-engine google-ml jade javascript mongodb node.js vue.js"},{"heading":"Try it out","content":"homebound-159210.appspot-preview.com"}]},{"project_title":"Kinesis","project_url":"https://devpost.com/software/kinesis","tagline":"Making motor rehabilitation an engaging experience for stroke patients with a virtual reality-based wearable glove.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/675/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best IoT Solution for Good"},{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Novel Use of a Physical Device"}],"team_members":[],"built_with":[{"name":"android","url":"https://devpost.com/software/built-with/android"},{"name":"android-studio","url":"https://devpost.com/software/built-with/android-studio"},{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"bluetooth","url":"https://devpost.com/software/built-with/bluetooth"},{"name":"flex-sensors","url":null},{"name":"google-cardboard","url":"https://devpost.com/software/built-with/google-cardboard"},{"name":"internet-of-things","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"unity","url":"https://devpost.com/software/built-with/unity"}],"external_links":[{"label":"https://github.com/MeeraSrinivasan/kinesis","url":"https://github.com/MeeraSrinivasan/kinesis"}],"description_sections":[{"heading":"Inspiration","content":"Stroke costs the United States an estimated $33 billion each year, reducing mobility in more than half of stroke survivors age 65 and over, or approximately 225,000 people a year. Stroke motor rehabilitation is a challenging process, both for patients and for their care providers. On the patient-side, occupational and physical therapy often involves hours of training patients to perform functional movements. This process can be mundane and tedious for patients. On the physician’s side, medical care providers need quantitative data and metrics on joint motion while stroke patients perform rehabilitative tasks.\n\nTo learn more about the stroke motor skill rehabilitation process and pertinent needs in the area, our team interviewed Dr. Kara Flavin, a physician and clinical assistant professor of Orthopaedic Surgery and Neurology & Neurological Sciences at the Stanford University School of Medicine, who helps stroke patients with recovery. We were inspired by her thoughts on the role of technology in the stroke recovery process to learn more about this area, and ultimately design our own technology to meet this need."},{"heading":"What it does","content":"Our product, Kinesis, consists of an interconnected suite of three core technologies: an Arduino-based wearable device that measures the range of motion exhibited by the joints in users’ hands and transmits the data via Bluetooth; a corresponding virtual reality experience in which patients engage with a virtual environment with their hands, during which the wearable transmits range of motion data; and a Bluetooth to Android application to MongoDB data collection and visualization mechanism to store and provide this information to health care professionals."},{"heading":"How we built it","content":"Our glove uses variable-resistance flex sensors to measure joint flexion of the fingers. We built circuits powered by the Arduino microcontroller to generate range-of-motion data from the sensor output, and transmit the information via a Bluetooth module to an external data collector (our Android application.) We sought a simple yet elegant design when mounting our hardware onto our glove. Next, we built an Android application to collect the data transmitted over Bluetooth by our wearable. The data is collected and sent to a remote server for storage using MongoDB and Node.js. Finally, we the data is saved in .csv files, which are convenient for processing and would allow for accessible and descriptive visuals for medical professionals. Our virtual-reality experience was built in the Unity engine and was constructed for Google Cardboard, deployable to any smartphone device that supports Google Cardboard."},{"heading":"Challenges","content":"Our project proved to be an exciting yet difficult journey. We quickly found that the various aspects of our project - the Arduino-based hardware, Android application, and VR with Unity/Google Cardboard - were a challenging application of internet of things (IoT) and hard to integrate. Sending data via Bluetooth from the hardware (Arduino) to the Android app and parsing that data to useful graphs was an example of how we had to combine different technologies. Another major challenge was that none of our team members had prior Unity/VR-development/Google Cardboard experience, so we had to learn these frameworks from scratch at the hackathon."},{"heading":"Accomplishments that we’re proud of","content":"We hope that our product will make motor rehabilitation a more engaging and immersive process for stroke patients while also providing insightful data and analytics for physicians. We’re proud of learning new technologies to put our hack together, building a cost-effective end-to-end suite of technologies, and blending together software as well as hardware to make a product with incredible social impact."},{"heading":"What we learned","content":"We had a very well-balanced team and were able to effectively utilize our diverse skill sets to create Kinesis. Through helping each other with coding and debugging, we familiarized ourselves with new ways of thinking. We also learned new technologies (VR/ Unity/Google Cardboard, MongoDB, Node.js), and at the same time learnt something new about the ones that we are familiar with (Android, hardware/Arduino). We learnt that the design process is crucial in bringing the right tools together to address social causes in an innovative way."},{"heading":"What's next for Kinesis","content":"We would like to have patients use Kinesis and productize our work. As more patients use Kinesis, we hope to add more interactive virtual reality games and to use machine learning to derive better analytics from the increasing amount of data on motor rehabilitation patterns. We would also like to extend the applications of this integrated model to other body parts and health tracking issues."},{"heading":"Built With","content":"android android-studio arduino bluetooth flex-sensors google-cardboard internet-of-things mongodb node.js unity"},{"heading":"Try it out","content":"https://github.com/MeeraSrinivasan/kinesis"}]},{"project_title":"Everybody Lives","project_url":"https://devpost.com/software/everybody-lives","tagline":"Me make shelter population data transparent to all shelters and coordinate animal transfers between shelters","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/478/042/datas/medium.jpg","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Hack to Save Homeless Pets"}],"team_members":[],"built_with":[{"name":"google-maps","url":"https://devpost.com/software/built-with/google-maps"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"json","url":"https://devpost.com/software/built-with/json"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"rescuegroups","url":"https://devpost.com/software/built-with/rescuegroups"}],"external_links":[{"label":"github.com","url":"https://github.com/ClassonTech/TreeHacks2017"}],"description_sections":[{"heading":"Inspiration","content":"Our inspiration for this project was to develop a new approach to how animal shelter networks function, and how the nationwide animal care and shelter systems can be improved to function more efficiently, and cost effectively. In particular, we sought out to develop a program that will help care for animals, find facilities capable of providing the care needed for a particular animal, and eradicate the use of euthanization to quell shelter overpopulation."},{"heading":"What it does","content":"Our program retrieves input data from various shelters, estimates the capacity limit of these shelters, determines which shelters are currently at capacity, or operating above capacity, and optimizes the transfer or animals capable of being moved to new facilities in the cheapest way possible. In particular, the process of optimizing transfers to different facilities based on which facilities are overpopulated was the particular goal of our hack. Our algorithm moves animals from high-population shelters to low-population shelters, while using google maps data to find the optimal routes between any two facilities. Optimization of routes takes into account the cost of traveling to a different facility, and the cost of moving any given number of animals to that facility through cost estimations. Finally, upon determining optimal transfer routes between facilities in our network, our algorithm plots the locations of a map, giving visual representations of how using this optimization scheme will redistribute the animal population over multiple shelters."},{"heading":"How we built it","content":"We built our program using a python infrastructure with json API calls and data manipulation. In particular, we used python to make json API calls to rescue groups and google maps, stored the returned json data, and used python to interpret and analyze this data. Since there are no publicly available datasets containing shelter data, we used rescue groups to generate our own test data sets to run through our program. Our program takes this data, and optimizes how to organize and distribute animals based on this data."},{"heading":"Challenges we ran into","content":"The lack of publicly available data for use was particularly difficult since we needed to generate our own datasets in order to test our system. This problem made us particularly aware of the need to generate a program that can function as a nationwide data acquisition program for shelters to input and share their animal information with neighboring shelters. Since our team didn't have significant experience working on many parts of this project, the entire process was a learning experience."},{"heading":"Accomplishments that we're proud of","content":"We're particularly proud of the time we managed to commit to building this program, given the level of experience we had going into this project as our first hackathon. Our algorithm operates efficiently, using as much information as we were able to incorporate from our limited dataset, and constraints on how we were able to access the data we had compiled. Since our algorithm can find the optimal position to send animals that are at risk due to their location in an overpopulated shelter, our program offers a solution to efficiently redistribute animals at the lowest cost, in order to prevent euthanization of animals, which was our primary goal behind this project."},{"heading":"What we learned","content":"Aside from technical skills learned in the process of working on this project, we all learned how to work as a team on a large software project while under a strict time constraint. This was particularly important since we only began working on the project on the afternoon of the second day of the hackathon. In terms of technical skills, we all learned a lot about using APIs, json calls in python, and learning python much farther in depth than any of us previously had experience in. Additionally, this hackathon was the first time one of our team members had ever coded, and by the end of the project she had written the entire front end of the project and data visualization process."},{"heading":"What's next for Everybody Lives","content":"We had a lot of other ideas that we came up with as a result of this project that we wanted to implement, but did not have the time nor resources available to work on. Specifically, there are numerous areas we would like to improve upon and we conceptualized numerous solutions to issues present in today's shelter management and systems. Overall, we envisioned a software program used by shelters across the country in order to streamline the data acquisition process, and share this data between shelters in order to coordinate animal transfers, and resource sharing to better serve animals at any shelter. The data acquisition process could be improved by developing an easy to use mobile or desktop app that allows to easily input information on new shelter arrivals which immediately is added to a nationally available dataset, which can be used to optimize transfers, resource sharing, and population distribution. Another potential contribution to our program would be to develop a type of transportation and ride-share system that would allow people traveling various distances to transport animals from shelter to shelter such that animals more suited to particular climates and regions would be likely to be adopted in these regions. This feature would be similar to an Uber pool system. Lastly, the most prominent method of improving our program would be to develop a more robust algorithm to run the optimization process, that incorporates more information on every animal, and makes more detailed optimization decisions based on larger input data sets. Additionally, a machine learning mechanism could be implemented in the algorithm in order to learn what situations warrant an animal transfer, from the perspective of the shelter, rather than only basing transfers on data alone. This would make the algorithm grow, learn and become more robust over time."},{"heading":"Built With","content":"google-maps javascript json python rescuegroups"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Doggo","project_url":"https://devpost.com/software/newdoge","tagline":"Our app aims to give a foster animal the best change of being adopted, by helping shelter staff take quality photos.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/476/099/datas/medium.PNG","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Hack to Save Homeless Pets"}],"team_members":[],"built_with":[{"name":"ruby","url":"https://devpost.com/software/built-with/ruby"},{"name":"swift","url":"https://devpost.com/software/built-with/swift"}],"external_links":[{"label":"github.com","url":"https://github.com/a-yang3/newdoge"}],"description_sections":[{"heading":"Built With","content":"ruby swift"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Pet's Palace","project_url":"https://devpost.com/software/pet-s-palace","tagline":"Smart Popup Animal Shelters","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/613/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Hack to Save Homeless Pets"}],"team_members":[],"built_with":[{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"ibm-watson","url":"https://devpost.com/software/built-with/ibm-watson"},{"name":"ios","url":"https://devpost.com/software/built-with/ios"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/sampurnabasu/PetsPalace"}],"description_sections":[{"heading":"Inspiration","content":"There are two types of pets wandering unsupervised in the streets - ones that are lost and ones that don't have a home to go to. Pet's Palace portable mini-shelters services these animals and connects them to necessary services while leveraging the power of IoT."},{"heading":"What it does","content":"The units are placed in streets and alleyways. As an animal approaches the unit, an ultrasonic sensor triggers the door to open and dispenses a pellet of food. Once inside, a live stream of the interior of the unit is sent to local animal shelters which they can then analyze and dispatch representatives accordingly. Backend analysis of the footage provides information on breed identification, custom trained data, and uploads an image to a lost and found database. A chatbot is implemented between the unit and a responder at the animal shelter."},{"heading":"How we built it","content":"Several Arduino microcontrollers distribute the hardware tasks within the unit with the aide of a wifi chip coded in Python. IBM Watson powers machine learning analysis of the video content generated in the interior of the unit. The adoption agency views the live stream and related data from a web interface coded with Javascript."},{"heading":"Challenges we ran into","content":"Integrating the various technologies/endpoints with one Firebase backend."},{"heading":"Accomplishments that we're proud of","content":"A fully functional prototype!"},{"heading":"Built With","content":"arduino firebase ibm-watson ios javascript python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Messenger Bots' Best Friends","project_url":"https://devpost.com/software/messenger-bots-best-friends-8n5haj","tagline":"Best Friends Animal Society + FB Messenger Bot = More open & connected animal shelters and current/future pet owners","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/855/datas/medium.gif","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Hack to Save Homeless Pets"}],"team_members":[],"built_with":[{"name":"best-friends","url":null},{"name":"keynote","url":"https://devpost.com/software/built-with/keynote"},{"name":"sketch","url":"https://devpost.com/software/built-with/sketch"},{"name":"uikit","url":"https://devpost.com/software/built-with/uikit"}],"external_links":[],"description_sections":[{"heading":"Introduction","content":"Best Friends Animal Society 's mission is to bring about a time when there are No More Homeless Pets\n\nThey have an ambitious goal of reducing the death of homeless pets by 4 million/year (they are doing some amazing work in our local communities and definitely deserve more support from us)"},{"heading":"How this project fits in","content":"Originally, I was only focusing on a very specific feature (adoption helper).\n\nBut after conversations with awesome folks at Best Friends came a realization that bots can fit into a much bigger picture in how the organization is being run to not only save resources , but also increase engagement level and lower the barrier of entry points for strangers to discover and become involved with the organization (volunteering, donating, etc.)\n\nThis \"design hack\" comprises of seven different features and use cases for integrating Facebook Messenger Bot to address Best Friends's organizational and operational needs with full mockups and animated demos:\n\nStreamline volunteer sign-up process Save human resource with FAQ bot Lower the barrier for pet adoption Easier donations Increase visibility and drive engagement Increase local event awareness Realtime pet lost-and-found network\n\nI also \"designed\" (this is a design hack right) the backend service architecture, which I'm happy to have discussions about too!"},{"heading":"How I built it","content":"def design_hack(): s = get_sketch() m = s.make_awesome_mockups() k = get_apple_keynote() return k.make_beautiful_presentation(m)"},{"heading":"Challenges I ran into","content":"Coming up with a meaningful set of features that can organically fit into the existing organization Resisting the urge to write code"},{"heading":"What I learned","content":"Unique organizational and operational challenges that Best Friends is facing How to use Sketch How to create quasi- prototypes with Keynote"},{"heading":"What's next for Messenger Bots' Best Friends","content":"Refine features and code :D"},{"heading":"Built With","content":"best-friends keynote sketch uikit"}]},{"project_title":"PetPlay","project_url":"https://devpost.com/software/petplay","tagline":"Find pets to play with from local shelters","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/718/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Commercially Viable Solution using Pitney Bowes APIs"}],"team_members":[],"built_with":[{"name":"button","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"heroku","url":"https://devpost.com/software/built-with/heroku"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"objective-c","url":"https://devpost.com/software/built-with/objective-c"},{"name":"petfinder","url":"https://devpost.com/software/built-with/petfinder"},{"name":"sendgrid","url":"https://devpost.com/software/built-with/sendgrid"},{"name":"socket.io","url":"https://devpost.com/software/built-with/socket-io"}],"external_links":[{"label":"playwithpets.herokuapp.com","url":"http://playwithpets.herokuapp.com/"},{"label":"github.com","url":"https://github.com/frogbandit/PlayWithPets"},{"label":"github.com","url":"https://github.com/spenciefy/Play-With-Pets/"}],"description_sections":[{"heading":"Inspiration","content":"Over 90% of pets who are sent to pet shelters are killed -- one of the major problems facing pet shelters today. Every day, nearly 5,500 dogs and cats are killed in America's shelters, just because they don't have safe places to call home. Meanwhile, many people, especially those living in urban areas, want to play with pets. In our personal experience, friends who have gone to college or are living in NYC miss spending time with their pets that they had when they were growing up."},{"heading":"What it does","content":"PetPlay matches people willing to spend time with a pet from a shelter, for activities such as hiking, walking, or watching TV on the couch. PetPlay solves the immediate need of pets at shelters that need to be taken care of. Furthermore, as pets spend more time outside of the shelter, they increase their chances of being adopted. This would increase fostering and adoption rates in the long run.\n\nPetPlay consists of a mobile iOS user-facing app , which uses a visually-appealing Tinder-like interface to allow users to swipe left or right on pets. Once a match is made, the user can specify a time and location for their activity of choice. Then, a request is made to the pet shelters and an email is sent. The pet shelters view their requests on a web application, playwithpets.herokuapp.com , where they can see all their pets as well as incoming requests. The pet shelters then follow up with the users via email or phone call, and users can leave their feedback."},{"heading":"How we built it","content":"We built the iOS mobile app in Objective-C , and the web app in Node.js with Express. We used Google Firebase to store the data. We also integrated PetFinder API to get real pet and shelter data, Sendgrid API to send the email notification to shelters, and Pitney Bowes IdentifyEmail and IdentifyAddress APIs to confirm emails and addresses. We also integrated with Button API to allow the user to easily call an Uber to the Shelter. Our shelter-side application is hosted on Heroku."},{"heading":"Challenges we ran into","content":"Coming up with the best way to meet the pet shelters' needs was the first challenge for this project, so we spent a lot of time taking to them about this project and getting feedback. Other than that, integrating the mobile and web portions through Firebase was also challenging."},{"heading":"Accomplishments that we're proud of","content":"We're proud to create the first mobile and web app for users seeking short-term pet playdates."},{"heading":"What's next for PetPlay","content":"Using Virtual Reality to make the pet swiping experience even better."},{"heading":"Built With","content":"button express.js firebase heroku node.js objective-c petfinder sendgrid socket.io"},{"heading":"Try it out","content":"playwithpets.herokuapp.com github.com github.com"}]},{"project_title":"Dandelyon","project_url":"https://devpost.com/software/dandelion-l8f4h6","tagline":"Help search and rescue team in disasters cover a larger area over a longer time","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/477/939/datas/medium.jpg","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Overall Integration and Use of Microsoft Technology(s)"}],"team_members":[],"built_with":[{"name":"azure","url":"https://devpost.com/software/built-with/azure"},{"name":"azure-event-hub","url":null},{"name":"azure-iot-hub","url":null},{"name":"azure-iot-suite","url":"https://devpost.com/software/built-with/azure-iot-suite"},{"name":"azure-stream-analytics","url":null},{"name":"documentdb","url":null},{"name":"domain.com","url":null},{"name":"electron","url":"https://devpost.com/software/built-with/electron"},{"name":"geo911","url":null},{"name":"geoenhance","url":null},{"name":"geomap","url":null},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"google-compute-engine","url":"https://devpost.com/software/built-with/google-compute-engine"},{"name":"mssql","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"nosql","url":null},{"name":"particle","url":"https://devpost.com/software/built-with/particle"},{"name":"pitneybowes","url":null},{"name":"powerbi","url":null}],"external_links":[{"label":"dandelyon.org","url":"http://dandelyon.org"},{"label":"github.com","url":"https://github.com/kaiyisg/dandelion"}],"description_sections":[{"heading":"Inspiration","content":"Coming from South-East Asia, we have seen the devastation that natural disasters can wreck havoc on urban populations\n\nWe wanted to create a probe that can assist on-site Search and Rescue team members to detect and respond to nearby survivors"},{"heading":"What it does","content":"Each Dandelyon probe detects changes in its surroundings and pushes data regularly to the backend server. Additionally, each probe has a buzzer that produces a noise if it detects changes in the environment to attract survivors. Using various services, visualise data from all probes at the same time to investigate and determine areas of interest to rescue survivors."},{"heading":"What it consists of","content":"Deployable IoT Probe Live data streams Data Visualisation on Microsoft Power BI Data Visualisation on WebApp with Pitney Bowes API(dandelyon.org)"},{"heading":"How we built it","content":"Hardware\n\nIdentified the sensors that we would be using Comprises of: Cell battery Breadboard Jumper Wires Particle Electron 2G (swapped over to our own Particle 3G as it has better connectivity) + Cellular antenna GPS + external antenna Sound detector sensor Buzzer Accelerometer Soldered pin headers onto sensors Tested the functionality of each sensor Wired each sensor alone to the Electron Downloaded the open source libraries for each sensor from GitHub Wrote a code for main function for the sensor to communicate with the Electron Read the output from each sensor and check if it's working Integrated every sensor with the Electron Tested the final functionality of the Electron\n\nSoftware\n\nInfrastructure used Azure IoT Hub Azure Stream Analytics Azure NoSQL Microsoft Power BI Google Cloud Compute Particle Cloud with Microsoft Azure IoT Hub integration Backend Development 1. Flow of live data stream from Particle devices 2. Supplement live data with simulated data 3. Data is piped from Azure IoT Hub to PowerBI and Webapp Backend 4. PowerBI used to display live dashboards with live charts 5. WebApp displays map with live data WebApp Development Deployed NodeJS server on Google Cloud Compute connected to Azure NoSQL database. Fetches live data for display on map."},{"heading":"Challenges we ran into","content":"Hardware Integration Azure IoT Stream connecting to PowerBI as well as our custom back-end Working with live data streams"},{"heading":"Accomplishments that we're proud of","content":"Integrating the Full Hardware suite Integrating Probe -> Particle Cloud -> Azure IoT -> Azure Stream Analytics -> PowerBI and Azure Stream Analytics -> Azure NoSQL -> Node.Js -> PitneyBowes/Leaflet"},{"heading":"What's next for Dandelyon","content":"Prototyping the delivery shell used to deploy Dandelyon probes from a high altitude Developing on the backend interface used to manage and assign probe response"},{"heading":"Built With","content":"azure azure-event-hub azure-iot-hub azure-iot-suite azure-stream-analytics documentdb domain.com electron geo911 geoenhance geomap google-cloud google-compute-engine mssql node.js nosql particle pitneybowes powerbi"},{"heading":"Try it out","content":"dandelyon.org github.com"}]},{"project_title":"Mira ","project_url":"https://devpost.com/software/mira","tagline":"How do you see yourself?","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/478/677/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Amazon Web Services - Best Use of AWS"}],"team_members":[],"built_with":[{"name":"d3.js","url":"https://devpost.com/software/built-with/d3-js"},{"name":"google-app-engine","url":"https://devpost.com/software/built-with/google-app-engine"},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"google-cloud-ml","url":null},{"name":"google-machine-learning","url":null},{"name":"google-vision-ai","url":null},{"name":"ibm-watson","url":"https://devpost.com/software/built-with/ibm-watson"}],"external_links":[],"description_sections":[{"heading":"Story","content":"Mental health is a major issue especially on college campuses. The two main challenges are diagnosis and treatment.\n\nDiagnosis\n\nExisting mental health apps require the use to proactively input their mood, their thoughts, and concerns. With these apps, it's easy to hide their true feelings.\n\nWe wanted to find a better solution using machine learning. Mira uses visual emotion detection and sentiment analysis to determine how they're really feeling.\n\nAt the same time, we wanted to use an everyday household object to make it accessible to everyone.\n\nTreatment\n\nMira focuses on being engaging and keeping track of their emotional state. She allows them to see their emotional state and history, and then analyze why they're feeling that way using the journal."},{"heading":"Technical Details","content":"Alexa\n\nThe user's speech is being heard by the Amazon Alexa, which parses the speech and passes it to a backend server. Alexa listens to the user's descriptions of their day, or if they have anything on their mind, and responds with encouraging responses matching the user's speech.\n\nIBM Watson/Bluemix\n\nThe speech from Alexa is being read to IBM Watson which performs sentiment analysis on the speech to see how the user is actively feeling from their text.\n\nGoogle App Engine\n\nThe backend server is being hosted entirely on Google App Engine. This facilitates the connections with the Google Cloud Vision API and makes deployment easier. We also used Google Datastore to store all of the user's journal messages so they can see their past thoughts.\n\nGoogle Vision Machine Learning\n\nWe take photos using a camera built into the mirror. The photos are then sent to the Vision ML API, which finds the user's face and gets the user's emotions from each photo. They're then stored directly into Google Datastore which integrates well with Google App Engine\n\nData Visualization\n\nEach user can visualize their mental history through a series of graphs. The graphs are each color-coded to certain emotional states (Ex. Red - Anger, Yellow - Joy). They can then follow their emotional states through those time periods and reflect on their actions, or thoughts in the mood journal."},{"heading":"Built With","content":"d3.js google-app-engine google-cloud google-cloud-ml google-machine-learning google-vision-ai ibm-watson"}]},{"project_title":"Sweet Tweetment","project_url":"https://devpost.com/software/tweethacks","tagline":"Sweet Tweetment helps you know if you should check in with any of your friends who might be feeling down!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/314/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"#HackHarrassment"}],"team_members":[],"built_with":[{"name":"alexa","url":"https://devpost.com/software/built-with/alexa"},{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"angular.js","url":"https://devpost.com/software/built-with/angular-js"},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"ibm-watson","url":"https://devpost.com/software/built-with/ibm-watson"},{"name":"machine-learning","url":"https://devpost.com/software/built-with/machine-learning"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"twitter","url":"https://devpost.com/software/built-with/twitter"}],"external_links":[{"label":"sweettweetment.com","url":"http://sweettweetment.com:3000/"},{"label":"github.com","url":"https://github.com/matthewkol186/tweethacks"}],"description_sections":[{"heading":"Inspiration","content":"Sweet Tweetment lets you check up on your friends who need it the most. We were inspired to do this to solve two major problems:\n\n1) In the digital age, we're following so many people on social media sites such as Twitter that we're unable to manually keep up with everyone we care about\n\n2) Mental health issues are on the rise (especially on college campuses and among youth), and bullying has become very prevalent on social media\n\nWe wanted to solve these problems by automating the process of checking up on your friends."},{"heading":"What it does","content":"Sweet Tweetment finds all of the people you follow, and searches for whether you should reach out to them because they've been suffering in some way or are at risk in the future. Our application uses sentiment analysis to read in your friends' tweets, classify them, and suggest a means to reach out to those in need. We use machine learning make our recommendations predictive and reactive, so you can find friends at risk based on current trends, or friends who have already experienced some traumatic events. Our app can also identify whether your friends are being bullied, and can direct you to tools to help them to #HackHarrassment. You can even create an account, and tweet your friends to check up on them right form the website!"},{"heading":"How we built it","content":"The frontend is built with AngularJS, HTML, and CSS. The user can log in to their twitter account through our site which uses the Twitter API and OAuth to return a list of all the people they are following. They can select all friends who they would like to check up on (for harassment and well-being).\n\nThe backend is built in Node Express, and uses the Twitter API to get lists of followers and recent tweets. This data is source dto IBM Watson's (Bluemix) emotional analysis platform (Alchemy API) to determine how sad or aggressive the messages were. Based on the emotional analysis, each tweet is scored and this information is fed through a machine learning linear regression framework to predict how sad their subsequent posts will be (i.e. the future emotional state of the user), and gather how sad posts have been on average previously.\n\nA similar process is used to determine online harassment. The tweets that are sent to their friends are emotionally analyzed for the anger sentiment and if an overwhelming amount of their tweets are classified as being “angry or aggressive” (based on the emotional analysis results), the friend is classified as being a target of online bullying.\n\nThe app is hosted using Linode."},{"heading":"Challenges we ran into","content":"You can run the same code and have it stop working."},{"heading":"Accomplishments that we're proud of","content":"-Empowering people to help their friends in need -Helping create new avenues to find and stop bullying"},{"heading":"What we learned","content":"You can run the same code and have it stop working!"},{"heading":"What's next for tweethacks","content":"We're hoping to have users log into the website once, and send them emails whenever any of their friends appears to be struggling in any way to make Sweet Tweetment even more user friendly!"},{"heading":"Built With","content":"alexa amazon-web-services angular.js css html ibm-watson machine-learning node.js twitter"},{"heading":"Try it out","content":"sweettweetment.com github.com"}]},{"project_title":"PhyloForest","project_url":"https://devpost.com/software/clusters-of-orthologous-groups-in-vr","tagline":"For the first time, you can see, interact with, and manipulate orthologous protein clusters in virtual reality.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/478/194/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Innovative Genomics Hack"}],"team_members":[],"built_with":[{"name":"c#","url":"https://devpost.com/software/built-with/c--2"},{"name":"ebi-ncbi-blast","url":"https://devpost.com/software/built-with/ebi-ncbi-blast"},{"name":"eggnog","url":null},{"name":"unity","url":"https://devpost.com/software/built-with/unity"}],"external_links":[{"label":"docs.google.com","url":"https://docs.google.com/presentation/d/1X-iYTfohdgmyGH1rFdEJslEiF-fKLEPrFYFk_fP32Ac/edit?usp=sharing"}],"description_sections":[{"heading":"What it does","content":"PhyloForest helps researchers and educators by improving how we see phylogenetic trees. Strong, useful data visualization is key to new discoveries and patterns. Thanks to our product, users have a greater ability to perceive depth of trees by communicating widths rather than lengths. The length between proteins is based on actual lengths scaled to size."},{"heading":"How we built it","content":"We used EggNOG to get phylogenetic trees in Newick format, then parsed them using a recursive algorithm to get the differences between the protein group in question. We connected names to IDs using the EBI (European Bioinformatics Institute) database, then took the lengths between the proteins and scaled them to size for our Unity environment. After we put together all this information, we went through an extensive integration process with Unity. We used EBI APIs for Taxon information, EggNOG gave us NCBI (National Center for Biotechnology Information) identities and structure. We could not use local NCBI lookup (as eggNOG does) due to the limitations of Virtual Reality headsets, so we used the EBI taxon lookup API instead to make the tree interactive and accurately reflect the taxon information of each species in question. Lastly, we added UI components to make the app easy to use for both educators and researchers."},{"heading":"Challenges we ran into","content":"Parsing the EggNOG Newick tree was our first challenge because there was limited documentation and data sets were very large. Therefore, it was difficult to debug results, especially with the Unity interface. We also had difficulty finding a database that could connect NCBI IDs to taxon information with our VR headset. We also had to implement a binary tree structure from scratch in C#. Lastly, we had difficulty scaling the orthologs horizontally in VR, in a way that would preserve the true relationships between the species."},{"heading":"Accomplishments that we're proud of","content":"The user experience is very clean and immersive, allowing anyone to visualize these orthologous groups. Furthermore, we think this occupies a unique space that intersects the fields of VR and genetics. Our features, such as depth and linearized length, would not be as cleanly implemented in a 2-dimensional model."},{"heading":"What we learned","content":"We learned how to parse Newick trees, how to display a binary tree with branches dependent on certain lengths, and how to create a model that relates large amounts of data on base pair differences in DNA sequences to something that highlights these differences in an innovative way."},{"heading":"What's next for PhyloForest","content":"Making the UI more intuitive so that anyone would feel comfortable using it. We would also like to display more information when you click on each ortholog in a group. We want to expand the amount of proteins people can select, and we would like to manipulate proteins by dragging branches to better identify patterns between orthologs."},{"heading":"Built With","content":"c# ebi-ncbi-blast eggnog unity"},{"heading":"Try it out","content":"docs.google.com"}]},{"project_title":"Overpupulation","project_url":"https://devpost.com/software/overpupulation","tagline":"A shelter simulation that shows the adoption process from a dog's perspective","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/476/516/datas/medium.jpg","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Domain Name from Domain.com"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"jquery","url":"https://devpost.com/software/built-with/jquery"}],"external_links":[{"label":"eights.github.io","url":"https://eights.github.io"},{"label":"github.com","url":"https://github.com/eights/eights.github.io"}],"description_sections":[{"heading":"Inspiration","content":"Our team was united in our love for animals, and our anger about the thousands of shelter killings that happen every day due to overcrowding. In order to raise awareness and educate others about the importance of adopting rather than shopping for their next pet, we framed this online web application from a dog's perspective of the process of trying to get adopted."},{"heading":"What it does","content":"In Overpupulation, users can select a dog who they will control in order to try to convince visitors to adopt them. To illustrate the realistic injustices some breeds face in shelters, different dogs in the game have different chances of getting adopted. After each rejection from a potential adoptee, we expose some of their faulty reasoning behind their choices to try to debunk false misconceptions. At the conclusion of the game, we present ways for individuals to get involved and support their local shelters."},{"heading":"How we built it","content":"This web application is built in Javascript/JQuery, HTML, and CSS."},{"heading":"Accomplishments that we're proud of","content":"For most of us, this was our first experience working in a team coding environment. We all walked away with a better understanding of git, the front-end languages we utilized, and design.\n\nWe have purchased the domain name overpupulation.com, but are still trying to work through redirecting issues. :)"},{"heading":"Built With","content":"css html javascript jquery"},{"heading":"Try it out","content":"eights.github.io github.com"}]},{"project_title":"Reaction","project_url":"https://devpost.com/software/reaction-gu9x8o","tagline":"A personal assistant who provides real-time feedback for college students and professors in the lecture hall","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/477/596/datas/medium.jpg","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Facebook's Choice"}],"team_members":[],"built_with":[{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"facebook-messenger-bots","url":null},{"name":"java","url":"https://devpost.com/software/built-with/java"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"ssl","url":null},{"name":"vps","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/FloydHorng/Reaction"},{"label":"github.com","url":"https://github.com/FloydHorng/Reaction-Lecturer"}],"description_sections":[{"heading":"Background","content":"For college students, the story is all too familiar: You're copying down Prof X's slide on thermodynamics, but halfway through your transcription, the professor jumps to the next slide. Darn! What now? Do you A) Leave your notes incomplete. B) Erase your unfinished bullet point C) Write a \"note to self\" to return to this pressing matter later. While you were contemplating this dilemma, Prof X advanced 3 more slides. Whoops.\n\nNot only does this story ring true for most students, but it's just as relevant for professors: Professors want to know if their students are internalizing their lectures; however, without sustained feedback from the entire class body, many professors end up teaching at pace that is too quick or too slow."},{"heading":"What it does","content":"Now what if there was a way to solve these issues without having to purchase expensive applications or hardware - a solution that doesn't require everyone to download an obscure app or memorize a long web URL. Enter Reaction , the Lecture Assistant and Facebook Messenger Chat Bot. Students can ask Reaction to \"show me the previous slide,\" and he will send, via messenger, an image of the previous slide. Or students can tell Reaction to \"tell prof to slow down,\" all in natural language. Meanwhile, the collection of reactions sent by students - ranging from \"I'm confused\" to \"this material is easy\" - aggregate on the Reaction Desktop Client, where a graph of \"Understanding over Time\" is displayed on the top right corner, updating in real time. This graph allows the professor to understand how well his students are grasping his material, and to adjust his pace if necessary. Reaction even logs which students have spoken with him, replacing the time consuming sign-in sheet or roll call."},{"heading":"What's next for Reaction","content":"Reaction could soon be the complete lecture solution for colleges across the globe. Students will no longer have to purchase expensive hardware clickers such as the iClicker2, since Reaction will soon support both in-class and out-of-class polling. Reaction's inner personal assistant will truly shine when professors ask him to \"remind students about Assignment 3, 1 day before it's due.\" Lastly, Reaction will soon support geofencing, to ensure that students are in the lecture hall when class begins (sorry students, no more asking a friend for the Kipin Attendance Code)."},{"heading":"Built With","content":"express.js facebook-messenger-bots java node.js ssl vps"},{"heading":"Try it out","content":"github.com github.com"}]},{"project_title":"Project #doSomething","project_url":"https://devpost.com/software/project-dosomething","tagline":"An integration to encourage nonprofit donations directly within your email","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/476/062/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of the Mixmax API"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"mixmax","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"}],"external_links":[{"label":"github.com","url":"https://github.com/infinitebattery7/mixmax-donate/"}],"description_sections":[{"heading":"Inspiration","content":"We all feel strongly about a wide variety of issues, but often fail to support organizations fighting for causes close to us. Our inspiration for this project was this feeling: we wanted to find a way to encourage donating to nonprofits in the easiest way. What better way to do this than through something we use everyday-- email."},{"heading":"What it does","content":"Project #doSomething is an email integration for a \"/donate\" command on Mixmax (an email enhancing tool). We then offer a variety of nonprofits to donate to, including the Best Friends Animal Society, various animal shelters, the ACLU, LGBTQ+ Initiative, ect."},{"heading":"How we built it","content":"We built this Mixmax integration with primarily JavaScript (Node.js), HTML/CSS, and lots of coffee."},{"heading":"Challenges we ran into","content":"We ran into a major issue where we found out that Chrome was blocking the integration, because we didn't have a valid security certificate on our local dev environment. We managed to eventually work around it by modifying Chrome. Another major challenge we ran into was discovering which nonprofits to add, but we quickly found a ton of worthy organizations."},{"heading":"Accomplishments that we're proud of","content":"We're proud of making a working email integration (with Mixmax) that can be used by anyone. We really hope people can use this to donate, and easily encourage their friends to donate."},{"heading":"What's next for Project #doSomething","content":"Stretch goal for the future: make it easy to match donations (and track how many donations to match) via a Mixmax integration."},{"heading":"Built With","content":"css html javascript mixmax node.js"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Thrive","project_url":"https://devpost.com/software/thrive-qtfc1m","tagline":"Connecting patients & doctors to create better healthcare outcomes","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/477/593/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Most Innovative Use of Neura"}],"team_members":[],"built_with":[{"name":"angular.js","url":"https://devpost.com/software/built-with/angular-js"},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"ios","url":"https://devpost.com/software/built-with/ios"},{"name":"neura-sdk","url":null},{"name":"sketch","url":"https://devpost.com/software/built-with/sketch"},{"name":"xcode","url":"https://devpost.com/software/built-with/xcode"}],"external_links":[],"description_sections":[{"heading":"Introduction","content":"Today, America's healthcare system is plagued with gaps and inefficiencies. Before visiting a new healthcare provider, patients are unable to compare various healthcare providers before choosing one that best suits them. After their visit, healthcare providers must call patients individually to check in on how they're doing and answer any questions that patients may have. There is no standard system that patients can use to give feedback and frequent non-urgent updates to their healthcare providers. That's why we made Thrive!"},{"heading":"Our solution","content":"Thrive is a platform that aims to guide patients at every step of the process of seeking and receiving care. Patients can search for healthcare providers and read reviews on them before scheduling an appointment. After visiting the doctor, Thrive will remind them to take any medications they were prescribed and leave a review for the healthcare provider they visited. Doctors and patients can easily communicate with each other through the in-app chat feature. As more and more patients submit feedback and ratings, doctors can see how they compare to their peers and what areas they can improve in.\n\nThe iOS app is geared towards patients who are on-the-go and need a simple, streamlined process of submitting daily feedback and writing reviews about their healthcare providers. The desktop app is geared towards healthcare providers, who need an easy way to monitor and communicate with many patients at once."},{"heading":"Building it","content":"Our team of three has experience across iOS development, web development, and UI/UX design. Knowing that our goal was ambitious, we scoped our goal for the hackathon to create a working prototype that demonstrates the value proposition of the idea. We took the divide and conquer approach to accomplish this - as Katy iterated on the development of UI/UX designs, Matt and Magnus developed them in the iOS and web apps (respectively)."},{"heading":"The learning experience","content":"This was our first time working with a location-based API that runs in the background and sends push notifications when a certain threshold has been reached. We struggled a bit with the data structure and setting it up with our own database / backend, but it worked out well at the end and we use it now in our notifications. We are planning to keep the API after this project and add more features, to get more data about our users. We also gained more experience working with Google's Firebase."},{"heading":"Built With","content":"angular.js firebase ios neura-sdk sketch xcode"}]},{"project_title":"Canoe","project_url":"https://devpost.com/software/canoe","tagline":"Canoe suggests spontaneous travel trips/destinations based on your interests, budget, and availability.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/478/297/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2017","hackathon_url":"https://treehacks-2017.devpost.com/","prize_name":"Best Use of Amadeus API"}],"team_members":[],"built_with":[{"name":"amadeus","url":"https://devpost.com/software/built-with/amadeus"},{"name":"azure","url":"https://devpost.com/software/built-with/azure"},{"name":"bing-apis","url":null},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"microsoft-cognitive-services","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"react-native","url":"https://devpost.com/software/built-with/react-native"}],"external_links":[{"label":"github.com","url":"https://github.com/nikhilkhanna/CanoeBackend"},{"label":"github.com","url":"https://github.com/jackswiggett/CanoeFrontend"}],"description_sections":[{"heading":"Inspiration","content":"Every one of us grew up traveling. It was something you did and not something you thought of. It was something that your parents made you do. Now, whether it's because you don't have enough time or money or can't be bothered to go through the hassle, traveling is becoming harder and harder. That's where Canoe comes in."},{"heading":"What it does","content":"Canoe is a mobile application which takes away this hassle. Given where a user has liked or would like to travel, as well as their budget, Canoe suggests a personalized list of destinations _ and _ airfares catered to their preferences. It scours the web for the best prices on flights, and generates a list that balances your potential interest in a travel destination and affordability."},{"heading":"How we built it","content":"Canoe is strictly a mobile facing application. We use Microsoft Azure to host our application backend as well as our location and user data. We leverage Microsoft Cognitive Services APIs (Recommendations, Bing Image Search) to handle destination recommenadtion and image querying, and we leverage Amadeus APIs to handle inspired (near un-parameterized) and most popular trip/destination retrieval. We use NodeJS and Express on the back end and React Native on the front end."},{"heading":"Challenges we ran into","content":"Map issues No Azure experience Testing No React Native experience Version control ## Accomplishments that we're proud of A lot of the time with short projects like these you end up with either a nice interface _ OR _ decent functionality, but I think we were able to get the right amount of both! ## What we learned We learned SO many new technologies. And also new ways to improve our workflow! Also how some of the APIs we used come up in industry and commercially. ## What's next for Canoe We're all pretty excited to be able to flesh it out a little more. It definitely needs to be more robust, and it could always use a little more customization. And of course a bit of polish."},{"heading":"Built With","content":"amadeus azure bing-apis express.js microsoft-cognitive-services mongodb node.js react-native"},{"heading":"Try it out","content":"github.com github.com"}]}],"generated_at":"2026-02-18T16:40:29.187060Z"}}