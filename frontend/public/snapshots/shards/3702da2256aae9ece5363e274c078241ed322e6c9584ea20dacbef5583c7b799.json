{"version":"v1","hackathon_url":"https://boilermake-xii.devpost.com","generated_at":"2026-02-18T16:52:16.376813Z","result":{"hackathon":{"name":"BoilerMake XII","url":"https://boilermake-xii.devpost.com","gallery_url":"https://boilermake-xii.devpost.com/project-gallery","scanned_pages":5,"scanned_projects":110,"winner_count":15},"winners":[{"project_title":"REMI","project_url":"https://devpost.com/software/remi-hbkrzs","tagline":"Ride More, Spend Less, Earn Money","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/286/225/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"1st Place Prize: iPad"},{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"College of Engineering: Most Consequential Project"}],"team_members":[],"built_with":[{"name":"android-pro-9-vanilla","url":null},{"name":"android-studio","url":"https://devpost.com/software/built-with/android-studio"},{"name":"arduino-nano-micro-controller","url":null},{"name":"ble","url":null},{"name":"bluetooth","url":"https://devpost.com/software/built-with/bluetooth"},{"name":"bluetooth-low-energy-(peripheral-and-central-peer-to-peer)","url":null},{"name":"dart","url":null},{"name":"emulators","url":null},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"firebase-backend-for-auth-and-database","url":null},{"name":"flutter","url":"https://devpost.com/software/built-with/flutter"},{"name":"geolocator","url":null},{"name":"google-maps","url":"https://devpost.com/software/built-with/google-maps"},{"name":"i2c-communication","url":null},{"name":"java","url":"https://devpost.com/software/built-with/java"},{"name":"java-sdk","url":null},{"name":"nfc-reader","url":null},{"name":"pwm-servo-control","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/mihir-chauhan/REMI"},{"label":"youtu.be","url":"https://youtu.be/GpDwoyOBtG8"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAGgosvrLWk/-t25JlMohuZ80b0P-JoCWw/edit?utm_content=DAGgosvrLWk&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"}],"description_sections":[{"heading":"Inspiration","content":"Ever since coming to Purdue, we‚Äôve loved exploring around, but most places are hard to get to by walking, or even using the bus. So, a lot of us end up using Veos or Uber to get around fast, but these are incredibly expensive and even require a startup fee. For example, a simple ride from our residence hall to the memorial union would cost up to 5 dollars. This simply isn‚Äôt sustainable for students like ourselves. In general, we can see that transportation around campus is unreliable, time-consuming, and expensive. Villainous scooter rentals can be pricey and cumbersome, and there are thousands of regular bikes sitting idle which could better serve the community when used."},{"heading":"What it does","content":"REMI is a 2 products 1 easy-to-use platform solution that combines a smart bike lock with encrypted NFC keys and an easy‚Äêto‚Äêuse mobile app, enabling owners to list their bikes and securely lend them out. Renters simply open the app, find a nearby bike, and unlock it using our NFC technology‚Äîno fuss, no hassle. And to safeguard everyone, REMI enforces guaranteed responsibility so bikes are returned safely every time. Bike owners make money by lending out unused bikes, while renters save time and money accessing convenient, affordable transportation. Best of all, the platform is designed to be seamless for both parties."},{"heading":"How we built it","content":"On our mobile app development side we utilized Android Studio to code with Flutter and Dart, allowing us to create and support users across multiple platforms. With the help of emulators we were able to test frequently and extensively on Android Pro 9 vanilla devices to make sure the user experience had a natural feel and performed exceptionally. Also, Flutter's wide variety of plugins and libraries helped us make use of Google Maps API, Apple‚Äôs modals, geolocators, and more to enable a seamless and user-friendly design that would meet the ever changing needs of Purdue University.\n\nOn the hardware side, REMI made use of the powerful Arduino Nano microcontroller which was equipped with an NFC reader to construct a secure and encrypted smart bike lock system. WIth Bluetooth Low Energy from both central and peripheral peer-to-peer communication we were able to establish strong channels of communication for reliable data transfer. We also utilized I2C communication and PWM servo control to better deliver standards of precision and responsiveness within the hardware. This allowed for our physical and digital components of our platform.\n\nTo help support our back end and database functions, we made sure to use Firebase to ensure that any data from the user and the transactions are handled with state of the art security. With firebase we played close attention to the authentication process and database functions. In the end we made sure to bring together these two dynamic and unique technologies to build a cohesive system that is for students from students within the biking transportation world. By working with these technologies we effectively optimize performance for our campus bike-sharing initiative.\n\nFor our back end, we chose Firebase to manage both authentication and database functions, ensuring that user data and bike-sharing transactions are handled securely and efficiently. This cloud-based solution provides real-time updates and robust data management, making it an ideal choice for a dynamic and scalable platform. By seamlessly integrating these technologies, we have built a cohesive system that enhances user experience, guarantees security, and optimizes performance for our campus bike-sharing initiative."},{"heading":"Challenges we ran into","content":"One of our most difficult challenges that we ran into on the technical side was managing the Gradle builds and the stability of the emulators. This would cost us a lot of time and having to also manage the dependencies, build failures, updates, and other things that would go wrong trying to repeatedly rebuild the Gradle which hurt our development progress significantly. Furthermore, the emulator would often crash on us and we had a lot of difficulty recognizing the BLE connections which would also lead to a handful of restarts during the NFC testing portion of the project. To overcome this we just had to make sure that our Gradle was configured optimally, cache the dependencies when we had the chance, and make our debugging approach more efficient to minimize downtime.\n\nAnother major challenge that was difficult to overcome was when we had to integrate the hardware with the software. We had a lot of trouble trying to establish security when it came to a reliable communication method between the NFC bike lock and the mobile app. BLE was also tricky to work around because there were inconsistent and unexpected latency + connection drops while we were working with it. Nevertheless, we pushed through and debugged without fail to fine-tune the system and create a better smart lock mechanism. In the end, these little issues would make all the difference to a difficult user experience compared to a more smooth, user-friendly experience.\n\nOverall, time was a big issue when it came to trying to take on this project. Especially when it came to the more physical component of the project. Just trying to find all the hardware was like a scavenger project, but we eventually worked quickly to go to the Bechtel center, Mechanical Engineering building, and Lamburtus to get access to the parts we needed, spare tools, and 3d-print our product."},{"heading":"Accomplishments that we're proud of","content":"As first time Boilermake participants and as freshmen, we are incredibly proud of the incredible progress we were able to make in a very short amount of time, proving to ourselves that with hard work, passion, and a clear vision, anything is possible. Our team did a fantastic job embracing the challenge of using technology unfamiliar to us, and stepped out of our comfort zones to bring our idea to life. Whether it was building the NFC hardware components, or learning how to use flutter to develop mobile apps and the Gradle build process, we ended up building a robust prototype which far surpassed our initial expectations. One of our greatest successes was coordinating our work so that each function could be pieced together and emerge as a functional system. Let‚Äôs not overlook the success of not eating our hi-chews we were using for testing!"},{"heading":"What we learned","content":"As we developed REMI, we came across different ways to push our boundaries and learn together as a team. For example, two of us came into the hackathon with experience using Flutter and Dart, while one teammate had comparatively less exposure to the library. We took this situation and made it a learning opportunity for everyone because we could leverage existing skills we‚Äôve worked with all while coming across recent libraries and dependencies we could implement. Given that this was our very first hackathon where we incorporated a hardware component, it was really interesting to see our NFC reader work alongside BLE technology to communicate with the REMI app we developed. We also got to work extremely closely with the Google Maps API to let users locate and interact with bikes using the API‚Äôs geolocation features to handle our backend logic."},{"heading":"What's next for REMI","content":"Envision a world where REMI, a pioneer of community and transportation, provides easier, cheaper, profitable, sustainable transportation to each and every location it reaches. First, REMI would work within university campuses, then expand to larger bike friendly towns and cities, and expand its range of transportation methods(skateboards, hoverboards, roller skates, etc.). REMI would help the community drive sustainable movement, bringing a community together in mutually beneficial relationships. This innovation marks an improvement in increasing the quality of life‚Äã for millions of students, and is truly the superior transportation management system dedicated to students by students."},{"heading":"Built With","content":"android-pro-9-vanilla android-studio arduino-nano-micro-controller ble bluetooth bluetooth-low-energy-(peripheral-and-central-peer-to-peer) dart emulators firebase firebase-backend-for-auth-and-database flutter geolocator google-maps i2c-communication java java-sdk nfc-reader pwm-servo-control"},{"heading":"Try it out","content":"github.com youtu.be www.canva.com"}]},{"project_title":" MockMade","project_url":"https://devpost.com/software/mockmate","tagline":"Perfect your technical and behavioral interview skills with AI.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/281/941/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"2nd Place Prize: Sony Headphone"},{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Cartesia: Best Use of Sonic"},{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Caterpillar: Best Cloud Implementation"}],"team_members":[],"built_with":[{"name":"auth0","url":null},{"name":"cartesia","url":null},{"name":"cloudinary","url":"https://devpost.com/software/built-with/cloudinary"},{"name":"magicui","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"next.js","url":null},{"name":"openai","url":null},{"name":"react.js","url":null},{"name":"render","url":null},{"name":"retell","url":null},{"name":"sync","url":"https://devpost.com/software/built-with/sync"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"demo.meriedith.com","url":"https://demo.meriedith.com/"},{"label":"github.com","url":"https://github.com/danielxies/bmakebackend"},{"label":"github.com","url":"https://github.com/danielxies/boilerdemo"},{"label":"github.com","url":"https://github.com/danielxies/boilerfrontend"}],"description_sections":[{"heading":"Inspiration","content":"As computer science students ourselves, we experienced the rigorous internship hunt season in this job market. The influx of software engineers led companies to increase their hiring bar for interviews. We wanted to help our peers land their dream jobs by using real-time human-like AI to conduct job interviews, simulating a real interview. We hope that this product can be a helpful practice tool that improves job seekers' interview skills."},{"heading":"What it does","content":"MockMade is a mock interview platform that conducts technical and behavioral interviews in real time. Choose a specific company to practice for and choose either a behavioral or technical interview. Our behavioral interview is conducted similar to a phone screen where the user would get a call and an AI would ask questions pertaining to the job. Once the user completes their interview, we process the audio and transcript to grade their interview based on various categories. While it was a phone call interview, you can watch a simulation of your interview in video form between the AI interviewer and your responses. For our technical interview, you would use a leetcode-like platform integrated with AI. While you're coding your solution, ask the interviewer for tips on how to complete the problem and keep you on the right track till you pass all the test cases instead of just searching up the solution."},{"heading":"How we built it","content":"Our behavioral interview uses Retell AI to power the real-time voice and call functionality. The post-interview analysis is conducted using multi-prompt OpenAI calls to grade each category. Our interview video simulation is powered by Sync, where we upload videos to the cloud using Cloudinary and lip sync them to the interview audios. The technical interview involves Whisper to transcribe the input audio, Cartesia Sonic to generate human-like text-to-speech audio, and OpenAI GPT 4o to parse the input transcript and code. We use Auth0 to secure our website with a robust custom log-in and sign-up page. To store the technical interview leetcode questions, we used MongoDB's noSQL database. We hosted our website and product completely on the cloud using Render for the backend and Vercel for the frontend. To build the frontend, we used Next.js, React.js, Typescript, and MagicUI."},{"heading":"Challenges we ran into","content":"We had some trouble with Retell AI and making sure that the agent was reliably asking meaningful questions to extensively quiz the interviewee. While we were developing the interview video simulation, we had some trouble getting the latency as low as possible and hosting the videos on the cloud effectively. We spent time working to connect all these technologies to work seamlessly with each other to provide a great experience for the user."},{"heading":"Accomplishments that we're proud of","content":"We are proud of creating a solution to a problem that every member of this hackathon faces. We are particularly proud of integrating a phone call to the inputted phone number and interview analysis. The integration with Sync was impressive to see since we were able to simulate the interview in video form. Lastly, we are proud of our integrated leetcode environment, which seamlessly guides a coder through a problem."},{"heading":"What we learned","content":"Throughout this project, we learned how to use and integrate countless technologies we would not have been exposed to before, including Retell AI, Sync, OpenAI, Cartesia, Auth0, MongoDB, Render, Vercel, etc. We learned how to make user-facing designs for our frontend and use clean UI components to represent our product in the best way."},{"heading":"What's next for MockMade","content":"We're looking to go public with our product and have real-world impacts on job seekers. We're looking to expand our services to all top companies by using the most frequently asked interview questions. Our phone call agent will be more robust and ask more insightful follow-ups. We plan to use a variety of leetcode questions for the technical interview portion to target more company-specific topics."},{"heading":"Built With","content":"auth0 cartesia cloudinary magicui mongodb next.js openai react.js render retell sync typescript vercel"},{"heading":"Try it out","content":"demo.meriedith.com github.com github.com github.com"}]},{"project_title":"Bear Necessities","project_url":"https://devpost.com/software/bear-necessities","tagline":"The simple bear necessities of tab management!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/287/333/datas/medium.gif","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"MLH: Best .Tech Domain Name"}],"team_members":[],"built_with":[{"name":"auth0","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini-api","url":null},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"json","url":"https://devpost.com/software/built-with/json"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"requests","url":"https://devpost.com/software/built-with/requests"},{"name":"sqlite","url":"https://devpost.com/software/built-with/sqlite"}],"external_links":[{"label":"github.com","url":"https://github.com/YohaanChokhany/teddy-tabber"}],"description_sections":[{"heading":"Inspiration","content":"The chaos of having 100+ tabs open while coding isn't just a meme - it's a real productivity killer. As students constantly on our computers, we found ourselves losing time switching between all kinds of tabs. After one too many browser crashes and lost work sessions, we decided to turn this frustration into something useful."},{"heading":"What it does","content":"Bear Necessities is a tab management extension that makes organizing your digital workspace effortless. Our AI-powered browser agent automatically groups related tabs, provides quick search across all open tabs, and includes productivity analytics to help you understand and improve your browsing habits. The unique aspect is our gamified approach - you earn points and track progress for maintaining an organized workflow, making tab management less of a chore."},{"heading":"How we built it","content":"Built as a Chrome extension using React for the frontend interface Used Chrome's tabGroups API to handle tab management and tracking Context-aware categorization engine powered by AI Implemented database storage for maintaining user preferences and scores Created a lightweight scoring algorithm that rewards good tab management habits"},{"heading":"Challenges we ran into","content":"API-related troubleshooting, dependency installation Balancing automated tab organization with user control Optimizing performance when handling hundreds of tabs"},{"heading":"Accomplishments that we're proud of","content":"Developed a scoring algorithm that actually makes tab management engaging Built a fully functional product that we ourselves will use daily Maintained good performance and created an engaging interface Followed through with the layout we had in mind for the hackathon"},{"heading":"What we learned","content":"Installation and dependency best practices How to stay within scope efficiently for a hackathon Division of labor and constant communication builds healthy collaboration"},{"heading":"What's next for Bear Necessities","content":"Friend features allowing you to compete in real time Productivity utilities such as Pomodoro Timers Blacklist features allowing you to block a website while studying"},{"heading":"Built With","content":"auth0 css flask gemini-api html javascript json python react requests sqlite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"SmithAI","project_url":"https://devpost.com/software/smithai","tagline":"The vast majority of the population won't open a command line or run a program to use AI. We simplify this process by letting anyone make custom AI Agents on demand without any technical experience.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/284/506/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Caterpillar: Best Cloud Implementation"},{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"MLH: Best Use of Gen AI"},{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Purdue Innovates: Most Likely to Become a Business"}],"team_members":[],"built_with":[{"name":"amazon-ec2","url":"https://devpost.com/software/built-with/amazon-ec2"},{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"beanstalk","url":"https://devpost.com/software/built-with/beanstalk"},{"name":"chatgpt","url":null},{"name":"claude","url":null},{"name":"deepseek","url":null},{"name":"ec2","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"llama","url":null},{"name":"markdown","url":"https://devpost.com/software/built-with/markdown"},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"ollama","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-native","url":"https://devpost.com/software/built-with/react-native"},{"name":"redis","url":"https://devpost.com/software/built-with/redis"},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/ShayManor/BoilerMake.git"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by an idea from Y Combinator that challenged us to make AI more accessible for everyone. Rather than limiting powerful AI tools to those who can navigate a terminal or write code, we saw an opportunity to democratize AI. Our project extends that mission by allowing anyone‚Äîeven complete beginners‚Äîto harness AI for complex tasks on demand, opening up possibilities that were once reserved for highly technical users."},{"heading":"What It Does","content":"SmithAI enables you to create and deploy AI ‚Äúagents‚Äù tailored to your specific needs‚Äîbe it answering questions, automating tasks, or analyzing data. Under the hood, SmithAI features an intelligent algorithm that determines which large language model (LLM) is best suited for your task and seamlessly routes your request there. This makes the process effortless for users: no more second-guessing which AI tool is the right fit, as SmithAI handles the complexity behind the scenes."},{"heading":"How We Built It","content":"Full-Stack: We developed a frontend using HTML, JavaScript, and Tailwind CSS, and integrated it with ChatGPT, Ollama, Deepseek, and Claude on the backend. Smart Routing Algorithm: We created a core logic that evaluates multiple LLMs and dynamically chooses which one to use for a given query. App Store & Hosting: We set up our own app store on MongoDB and host each app on AWS EC2, utilizing Elastic Beanstalk for orchestration and S3 for storage. Scalable AI: We also run smaller AI models directly on EC2 instances, balancing performance with cost-effectiveness."},{"heading":"Challenges We Ran Into","content":"One of our biggest hurdles was orchestrating multiple AI models with varying strengths and limitations. Ensuring each model could be invoked reliably‚Äîwithout bottlenecks or conflicts‚Äîrequired careful infrastructure planning and robust fallback mechanisms. Another challenge was building a user interface intuitive enough for non-technical users while still providing advanced features for power users."},{"heading":"Accomplishments That We're Proud Of","content":"On-Demand AI Agents: We successfully built a system that allows anyone to spin up AI-driven agents without writing a single line of code. Seamless Model Switching: Our intelligent routing algorithm is a testament to our team‚Äôs engineering prowess‚Äîsmoothly switching between different AI models to deliver the best results. Infrastructure Mastery: We‚Äôre thrilled with how we utilized AWS EC2, Elastic Beanstalk, and S3 in a cohesive way that scales as user demand grows."},{"heading":"What We Learned","content":"We learned that integrating multiple AI models is as much about orchestration and engineering as it is about algorithmic intelligence. We discovered how to leverage the strengths of each model‚Äîlike ChatGPT for natural language understanding or Claude for complex reasoning‚Äîand fuse them into a unified experience. We also honed our skills in full-stack development, AWS infrastructure management, and dynamic model selection based on performance metrics."},{"heading":"What's Next for SmithAI","content":"We plan to:\n\nExpand Model Library: Incorporate even more specialized AI models for tasks like code generation, image recognition, and data analytics. User-Friendly Interface: Continue refining our UI/UX so that anyone can deploy advanced AI without feeling overwhelmed. Enhanced Collaboration: Introduce collaborative features that allow teams to build and share AI agents seamlessly. Global Accessibility: Pursue partnerships and multi-language support so our platform can serve diverse communities around the world. By lowering the barrier to entry for AI, we believe SmithAI can spark a new wave of innovation across industries and empower people of all backgrounds. The possibilities are limitless, and we‚Äôre excited to see how this technology will shape the future."},{"heading":"Built With","content":"amazon-ec2 amazon-web-services beanstalk chatgpt claude deepseek ec2 flask html javascript llama markdown mongodb ollama openai python react react-native redis tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"getmemoria.tech","project_url":"https://devpost.com/software/getmemoria-tech","tagline":"A verbal journal. Capture your thoughts and hear them echo, any time or any place.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/281/783/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"MLH: Best Use of MongoDB Atlas"}],"team_members":[],"built_with":[{"name":"expo.io","url":"https://devpost.com/software/built-with/expo-io"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"nextjs","url":null},{"name":"tailwind","url":null},{"name":"whisper","url":null}],"external_links":[{"label":"getmemoria.tech","url":"http://getmemoria.tech"},{"label":"api.getmemoria.tech","url":"http://api.getmemoria.tech"},{"label":"boilerexpress.onrender.com","url":"http://boilerexpress.onrender.com/sentiment"},{"label":"boilerexpress.onrender.com","url":"http://boilerexpress.onrender.com/whisper"},{"label":"github.com","url":"https://github.com/rayhanadev/memoria-app"}],"description_sections":[{"heading":"Inspiration","content":"We were inspired by Retro, the app, a private social photo sharing app. We thought, with all these sound related technologies, that we could build an even better sound bite social experience."},{"heading":"What it does","content":"You, and your friends can create a small personal group, where you can share as frequently as you want, sounds or thoughts from your life, where you can all reflect, enjoy, and laugh together week by week, with subtle AI enhanced quality of life features such as mood analysis, activity trackers, and transcriptions."},{"heading":"How we built it","content":"We utilized Expo to port our React App to mobile, developing a cross platform capable app for iPhone and Android. We utilized MongoDB for our database, Groq API / Whisper for Speech to Text, Next.JS and React for our fullstack development."},{"heading":"Challenges we ran into","content":"We dealt with Nativewind issues related to Expo's updates which hindered our progress in building the expo version of the app. We overcame this by utilizing alternative approaches to the problem, and probing for different solutions."},{"heading":"Accomplishments that we're proud of","content":"We're proud of a robust demo and deployment of our project."},{"heading":"What we learned","content":"We all learned more about fullstack development and collaborating as a team with a variety of skills."},{"heading":"What's next for getmemoria.tech","content":"We hope to continue maintaining the project for friends and family."},{"heading":"Built With","content":"expo.io groq javascript mongodb nextjs tailwind whisper"},{"heading":"Try it out","content":"getmemoria.tech api.getmemoria.tech boilerexpress.onrender.com boilerexpress.onrender.com github.com"}]},{"project_title":"Fluention","project_url":"https://devpost.com/software/fluention","tagline":"For speech-impaired individuals, Fluention offers AI-driven therapy and real-time translation, ensuring clear, confident communication with personalized correction.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/283/154/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"3rd Place Prize: JBL Speaker"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"fastapi","url":null},{"name":"figma","url":null},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"gpt-4","url":null},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"lipsync-api","url":null},{"name":"mediapipe","url":null},{"name":"next.js","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"openai","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytt","url":null},{"name":"tensorflow","url":null},{"name":"time","url":null},{"name":"vscode","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/jihwimin/fluention"}],"description_sections":[{"heading":"Inspiration","content":"At Fluention, we believe that everyone deserves to be heard and understood . Inspired by personal experiences with loved ones who have developmental and speech disorders , we saw firsthand the frustration of being unable to express thoughts clearly . Individuals with conditions such as autism, dysarthria, aphasia, and apraxia of speech often face significant barriers in pronunciation, articulation, and verbal expression . While traditional speech therapy is essential , it can be expensive, time-consuming, and difficult to access .\n\nDespite advancements in AI, there is no comprehensive tool that both enhances speech clarity and simplifies communication for those with speech impairments . Many individuals struggle with verbal communication daily , affecting their social interactions, education, and career opportunities . The lack of accessible, structured training options forces many to rely on limited therapy sessions or struggle alone.\n\nThat‚Äôs why we built Fluention ‚Äîan AI-powered platform designed to assist individuals in training their pronunciation, articulation, and speech clarity . By combining neuroscience-backed methods and cutting-edge AI , Fluention provides a personalized, structured approach to speech training, helping individuals express themselves with confidence in everyday life. Our goal is to bridge the gap between thought and communication , making verbal expression more natural, accessible, and empowering for everyone."},{"heading":"What it does","content":"We offer two primary functionalities that work together to enhance speech clarity and aid communication :\n\n1. AI Speech Language Pathologist Assistant\n\nInspired by clinically validated research from top university hospitals , this module offers structured pronunciation training using AI-powered lip movement tracking, speech recognition, and interactive correction methods . It is designed to help users train their pronunciation, articulation, and speech clarity through a science-backed, structured approach that mimics professional speech therapy sessions .\n\nSub-functions:\n\nOral & Breath Control Training Lip and Tongue Analyzer Lip Training: Users follow three different lip shapes , each requiring them to hold the shape for two seconds and repeat it three times before progressing. Tongue Training: Users mimic three tongue positions , maintaining each for two seconds and repeating three times before moving to the next position. Receptive & Expressive Language Development Trains both listening and speaking abilities using AI-driven speech analysis . Users describe an image, and the AI converts speech to text, analyzes grammar, pronunciation, and sentence structure , and provides feedback. Vocabulary Enhancement A gamified approach to expand word recognition and usage skills . AI provides synonym recommendations and alternative word choices to improve linguistic diversity. Contextual Communication Skills Fluention offers a voice-enabled AI conversation partner that engages users in natural dialogues . Users can practice real-life conversations , receive real-time pronunciation and fluency corrections , and develop confidence in social interactions .\n\n2. AI-Powered Language Disorder Translator\n\nAI-powered speech assistance system designed to help individuals with speech disorders by accurately converting their spoken language into clear, understandable text and speech. It leverages state-of-the-art AI models for Speech-to-Text (STT), Text Normalization, and Text-to-Speech (TTS).\n\nSpeech-to-Text (STT) with OpenAI Whisper\n\nConverts speech into text, even for individuals with speech impairments.\n\nGPT-4-Based Text Normalization\n\nEnhances the readability and structure of transcribed speech.\n\nText-to-Speech (TTS) with Google Cloud\n\nConverts normalized text back into clear and natural speech.\n\nReal-time Speech Recording & Processing\n\nUsers can record speech directly on the website for instant conversion."},{"heading":"How we built it","content":"To create a seamless AI-powered speech therapy experience , we integrated multiple technologies across different components:\n\nLip and Tongue Analyzer Development\n\nLip Analysis: Mediapipe‚Äôs Face Mesh for real-time lip landmark detection . Lip height-to-width ratio tracking to recognize \"oooo\" and \"eeeee\" shapes . A progress bar system ensures the user holds the correct shape for a fixed duration . Real-time visual feedback overlays green tracking points for accuracy. Tongue Analysis: HSV color filtering to isolate the tongue from the video feed. Contour detection to find the largest tongue shape . Movement tracking of the tongue tip to classify left, right, and downward positions . Real-time overlays and labels for immediate feedback. AI Speech Analysis (Receptive & Expressive Language Development) Speech-to-Text AI models to transcribe, analyze, and correct pronunciation, grammar, and fluency . Pronunciation Game (Vocabulary Enhancement) Designed using interactive gamification techniques to keep users engaged. AI Voice Assistant Friend (Contextual Communication Skills) A voice-interactive AI assistant using Voice API to simulate real-life conversations .\n\nAI Language Disorder Translator\n\nUser Records Speech The user presses the \"Start Recording\" button on the web interface. The recorded audio is sent to the backend for processing. Speech-to-Text (STT) Processing OpenAI Whisper transcribes the speech into text. The transcribed text is extracted and checked for accuracy. Text Normalization with GPT-4 The transcribed text is sent to GPT-4 for grammatical and structural improvements. The AI enhances clarity while preserving the speaker's original intent. Text-to-Speech (TTS) Conversion The final, normalized text is converted into natural speech using Google TTS. The user receives an audio output that is easier to understand."},{"heading":"Challenges we ran into","content":"Lack of extensive audio datasets for speech impairments made AI training difficult. Fine-tuning AI to detect subtle pronunciation errors was challenging. Ensuring real-time feedback without lag while handling multiple AI processes . API integration difficulties for seamless real-time speech processing. Securing API keys and managing sensitive speech data responsibly ."},{"heading":"Accomplishments that we're proud of","content":"Successfully built an AI-powered lip-sync pronunciation trainer . Integrated estimated five APIs for real-time speech analysis and voice interactions . Developed a fully functional AI-driven speech therapy assistant in under 36 hours ."},{"heading":"What we learned","content":"How to train AI for speech recognition and pronunciation assessment . Challenges faced by individuals with speech impairments and how AI can assist them. Best practices for AI-powered speech rehabilitation tools ."},{"heading":"What's next for Fluention","content":"Enhancing accuracy by implementing machine learning-based lip analysis instead of relying solely on ratio tracking. Improving tongue analysis by refining contour detection and integrating machine learning for better classification . Expanding AI training with larger and more diverse speech datasets . Enhancing real-time speech analysis for more personalized feedback . Adding character-based AI voice assistants for interactive learning. Developing a competitive pronunciation game with rewards . Implementing slow-motion mouth movement analysis for users to visualize pronunciation in detail."},{"heading":"Built With","content":"css fastapi figma google-cloud gpt-4 groq html javascript lipsync-api mediapipe next.js numpy openai opencv python pytt tensorflow time vscode"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"SignBridge","project_url":"https://devpost.com/software/signbridge-69v0fc","tagline":"Giving Every Voice the Power to Be Heard!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/287/073/datas/medium.jpeg","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"MLH: Best Use of Auth0"}],"team_members":[],"built_with":[{"name":"auth0","url":null},{"name":"beautiful-soup","url":"https://devpost.com/software/built-with/beautiful-soup"},{"name":"bert","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"google-drive","url":"https://devpost.com/software/built-with/google-drive"},{"name":"mediapipe","url":null},{"name":"next.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sync","url":"https://devpost.com/software/built-with/sync"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/AakashSriram/BoilermakeXII-SignBridge"}],"description_sections":[{"heading":"Inspiration","content":"Imagine sitting in a job interview. You‚Äôre the perfect candidate - your resume is impressive, the interviewers seem excited, and you know exactly what to say.\n\nBut when you try to speak, nothing comes out.\n\nYou gesture, trying to explain, but they don‚Äôt understand. The opportunity slips away - not because you aren‚Äôt qualified, but because the world cannot hear you.\n\nNow, imagine a world where that barrier doesn‚Äôt exist. Where your thoughts and ideas are heard, no matter how you express them. That‚Äôs the future we‚Äôre building."},{"heading":"What it does","content":"SignBridge is an AI-powered tool that translates American Sign Language (ASL) into both text and speech in real time, breaking down communication barriers for the deaf and non-verbal community.\n\nUsing computer vision , SignBridge captures hand gestures and movements, processes them through a Convolutional Neural Network (CNN) , and converts them into readable text. Then, to make interactions more natural, we go a step further‚Äî syncing the generated speech with a video of the person signing , making it appear as though they are actually speaking.\n\nThis is achieved using Sync , an AI-powered lip-syncing tool that animates the signer‚Äôs lips to match the spoken output. Additionally, SignBridge considers the signer‚Äôs gender and race to generate an appropriate AI voice, ensuring a more authentic and personalized communication experience.\n\nWith its ability to provide instant translation and realistic speech synchronization , SignBridge can be used in everyday conversations, workplaces, educational settings, and beyond‚Äîhelping to create a world where communication is truly inclusive."},{"heading":"How we built it","content":"SignBridge: Technical Overview\n\n1) ASL to Speech\n\nOur system leverages a Transformer-based Neural Network to recognize hand gestures made by the user and translate them into spoken language. The model is trained on a dataset of American Sign Language (ASL) gestures and is implemented using MediaPipe for real-time hand tracking and gesture recognition. The trained model processes ASL inputs efficiently, ensuring accurate and seamless translation to speech.\n\n2) User Authentication with Auth0\n\nWe integrate Auth0 for secure user authentication. This is crucial as our system utilizes facial recognition and lip-syncing techniques to enhance the accuracy and personalization of speech generation from ASL gestures. By mapping users' facial movements and lip sync patterns, we create a more natural and context-aware speech output, making interactions more lifelike and engaging.\n\n3) Lip-Sync Audio Generation\n\nTo ensure that the generated speech is synchronized with realistic lip movements, our system makes API calls to specialized lip-syncing services . This feature improves the visual realism and inclusivity of our ASL-to-speech conversion by mapping audio to corresponding lip movements.\n\n4) Generative AI for Word Prediction\n\nA Generative AI model is employed to enhance word prediction and context interpretation. By analyzing sequential ASL inputs, the AI model can predict probable next words, improving the fluency and coherence of the generated speech.\n\n5) Ethnicity and Gender Prediction Using BERT\n\nWe integrate BERT (Bidirectional Encoder Representations from Transformers) to infer the ethnicity and gender of the user based on their name. This information helps tailor the speech synthesis to better match cultural and linguistic nuances, contributing to a more personalized and contextually aware translation.\n\n6) Speech to ASL\n\nThe Speech-to-ASL module follows these steps:\n\nSpeech Collection in the Frontend: The system records speech input from users directly within the web application. Mapping Speech to Hand Motions: To convert speech into ASL gestures, we require a comprehensive dataset of sign language videos that correspond to spoken words. These videos are web-scraped from reliable ASL datasets and repositories, ensuring a diverse and accurate representation of gestures. The processed video segments are then mapped to hand motion sequences and dynamically displayed on the frontend to provide users with an ASL visualization of the spoken input.\n\nBy combining machine learning, natural language processing, and computer vision , SignBridge creates an efficient and accessible communication bridge between ASL and spoken language. üöÄ"},{"heading":"Challenges We Encountered","content":"Throughout the development of SignBridge , we faced several technical challenges that required iterative problem-solving and optimization. Below is a breakdown of the key issues and how we addressed them:\n\nStep 1: Gesture Recognition Accuracy & Word Buffering\n\nOne of the primary challenges in ASL-to-speech translation was buffer misclassification ‚Äîwhen users repeated a gesture, the model sometimes predicted incorrect words due to lingering buffer data. To resolve this, we implemented a buffer filtering mechanism that dynamically removes incorrect predictions and stabilizes the output, ensuring accuracy in translation. Additionally, our dataset was limited to 249 recognized words , and while we had access to a larger dataset, retraining the model on time was impractical. We had to develop an alternative approach to balance dataset limitations with real-time usability.\n\nStep 2: Gender-Neutral Speech Generation\n\nWhen generating speech from ASL, we found that most available text-to-speech (TTS) models defaulted to female voices . To introduce gender diversity in voice synthesis, we designed a mathematical approach to alter pitch and frequency dynamically , allowing us to modify existing voice outputs instead of sourcing additional models.\n\nStep 3: Real-Time Lip-Sync Optimization\n\nSynchronizing generated speech with lip movements was computationally intensive, causing latency issues . We evaluated multiple lip-syncing models to determine the fastest and most efficient approach for real-time performance. Ultimately, we selected an optimized model that significantly reduced sync time , ensuring fluid and natural lip synchronization.\n\nStep 4: Prompt Engineering for Phrase Generation\n\nTo improve ASL-to-text conversion accuracy, we needed to extract the most contextually relevant phrase from multiple predicted words. Using prompt engineering , we refined the model‚Äôs ability to select the phrase with the highest contextual weightage from the five most likely word predictions, improving the fluency of translated sentences.\n\nStep 5: Handling Unrecognized Words via Fingerspelling\n\nSince the entire application relied on gesture recognition, there was always a possibility that a word was not present in our dataset . In such cases, we implemented fingerspelling (letter-by-letter spelling of words using ASL hand signs) instead of generating incorrect words, ensuring continued communication."},{"heading":"Accomplishments that we're proud of","content":"One of our biggest accomplishments is creating a tool that has the potential to improve communication and accessibility for people with hearing and speech impairments. By successfully translating American Sign Language (ASL) into text and speech in real time , we‚Äôre helping bridge a gap that has long been a barrier for many.\n\nWe‚Äôre also proud of the technical achievements behind SignBridge . From training a computer vision model to recognize ASL gestures to fine-tuning real-time text and speech output , we tackled complex challenges in deep learning, natural language processing, and synchronization .\n\nBeyond the technology, we‚Äôre proud of the impact SignBridge can have . It‚Äôs more than just a project‚Äîit‚Äôs a step toward a more inclusive world where everyone, regardless of how they communicate, has a voice."},{"heading":"What we learned","content":"1) Computer Vision Model Implementation with Limited Data\n\nWe learned how to train and optimize computer vision models with a constrained dataset. By leveraging data augmentation and transfer learning , we improved recognition accuracy despite the limited availability of ASL gesture datasets .\n\n2) Real-Time Synchronization Challenges\n\nAchieving real-time synchronization between ASL gestures, speech output, and lip movements was a significant challenge. We optimized our neural network inference speed and reduced latency in video processing to ensure a seamless user experience.\n\n3) Prompt Engineering for Improved Predictions\n\nWe explored prompt engineering techniques to generate contextually accurate phrases from multiple ASL-to-text predictions. This significantly improved the fluency and accuracy of ASL translations , making communication more natural and effective."},{"heading":"What's next for SignBridge","content":"SignBridge is just the beginning of a much larger vision. While it currently translates American Sign Language (ASL) into text and speech , we want to take it even further. We aim to expand its capabilities to include more sign languages from around the world , ensuring accessibility for a global audience.\n\nWe also aim to improve translation accuracy by incorporating more advanced deep learning models , enabling smoother, more natural conversations.\n\nBeyond language expansion, we‚Äôre working on improving the user experience by making SignBridge accessible across multiple platforms , including mobile and web applications . Our goal is to integrate it into everyday environments‚Äî customer service, classrooms, workplaces ‚Äîanywhere communication barriers exist.\n\nUltimately, we envision SignBridge as more than just a tool‚Äîit‚Äôs a step toward a more inclusive world where communication is truly universal ."},{"heading":"Built With","content":"auth0 beautiful-soup bert flask google-drive mediapipe next.js python sync typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"slynk","project_url":"https://devpost.com/software/slynk","tagline":"reimagining ads with interactive AR avatars. meet and talk with your favorite celebrities with sylnk, our AR app offering a new personalized immersive experience for discovering advertisements.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/283/045/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Sync: Best Lipsync Hack"}],"team_members":[],"built_with":[{"name":"ar","url":null},{"name":"elevenlabs","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"groq","url":"https://devpost.com/software/built-with/groq"},{"name":"llama","url":null},{"name":"mediapipe","url":null},{"name":"ngrok","url":null},{"name":"openai-whisper","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"swift","url":"https://devpost.com/software/built-with/swift"},{"name":"sync","url":"https://devpost.com/software/built-with/sync"},{"name":"xcode","url":"https://devpost.com/software/built-with/xcode"}],"external_links":[{"label":"github.com","url":"https://github.com/AnanyaJajoo/boilermake2025"}],"description_sections":[{"heading":"Inspiration:","content":"In a world saturated with intrusive advertising, we want to transform ads from annoying interruptions into delightful, engaging experiences . Research shows that consumers respond significantly better to positive, emotionally appealing content than to neutral or information-heavy ads.\n\nThat‚Äôs why we created slynk , an augmented reality (AR) app that‚Äôs bringing sci‚Äëfi to life, revolutionizing the way we interact with ads and shop. By crafting immersive, interactive experiences with novel technology, we‚Äôre creating ads that resonate with people long after the interaction ends. With slynk, scanning an ad transforms it into an immersive, personalized experience. The celebrity or spokesperson comes to life in real‚Äëtime, walking you through the product‚Äôs features, answering questions, and showing you exactly how it would look or work in your own life. It‚Äôs not just another static image or video‚Äîslynk lets you engage and interact with the products you want to see, right in front of you.\n\nFor consumers, this means shopping that‚Äôs more than just a transaction‚Äîit‚Äôs an interactive, engaging experience. You can visualize products in your space, ask questions, and get real‚Äëtime, personalized information that helps you make better decisions faster . No more scrolling endlessly through product pages; with slynk, you have everything you need to make informed, confident choices‚Äîall while saving time.\n\nFor businesses, big or small, slynk is a game‚Äëchanger. It doesn‚Äôt matter if you're a startup with limited resources or a large corporation with a vast product catalog. By boosting engagement and increasing conversion rates by 94% (market.us) on product pages, slynk helps businesses connect with consumers in a more meaningful way. It gives small businesses the tools they need to create personalized, memorable experiences that compete with the biggest names in the industry. Larger businesses, on the other hand, can leverage slynk‚Äôs analytics to refine their marketing strategies and deliver the kind of targeted, immersive advertising that drives results."},{"heading":"What it does:","content":"slynk brings a whole new level of interactivity to ads. When you come across an ad that catches your attention, simply open the slynk app and point your phone at the ad. Instantly, the celebrity or spokesperson will appear on your screen, lip-syncing an AI-generated script that showcases the product in a way that aligns with your personal preferences. You can then interact with the product itself by resizing it‚Äîmaking it larger or smaller‚Äîallowing you to get a closer look and explore the product in more detail. If you like what you see, you can easily add it to your \"Liked Items\" list. From there, you can revisit your liked products, click through to their websites, and make a purchase directly. This creates a seamless, personalized shopping experience that allows you to interact with ads like never before."},{"heading":"How we built it:","content":"AR: XCode\n\nWe used XCode's ARKit, RealityKit, UIKit, Vision, AVfoundation packages.\n\nARKit handles the core augmented reality functionality by providing motion tracking and scene understanding for placing virtual content in the real world. RealityKit builds upon ARKit to deliver high-fidelity 3D rendering, physics simulation, and advanced visual effects for our AR experiences UIKit manages the app‚Äôs user interface components and provides the basic application development environment. AVFoundation handles all audio-visual media processing including video playback, audio recording, and media file management for our ad content.\n\nTogether, these frameworks create a comprehensive stack that enables us to build an immersive AR advertising platform with sophisticated UI, realistic 3D content, and seamless media handling capabilities.\n\nSoftware:\n\nGroqCloud (LLama3.2-90b-vision), Sync (lipsyncing static video of ad promoter person), ElevenLabs (tts for fine-tuned ad promoter audio), ngrok tunneling (hosting public videos for APIs), OpenAI Whisper (stt for user prompt & interaction), CV prompt-based object detection (Grounding DINO 1.5), removal, and inpaint/fill (inpaint anything - segment anything (SAM-2 ViT-b) and LaMA (big-lama)), face mesh and smooth mapping (MediaPipe), FileStack + ngrok tunneling (public file upload and host api).\n\nInput Processing\n\nSpeech input converted to text via OpenAI Whisper Video/image input processed through MediaPipe face mesh for 3D landmark detection Object detection and segmentation performed using Grounding DINO 1.5, SAM2 ViT-b Captured static video hosted through ngrok tunneling for API access\n\nCore Processing\n\nLLama 3.2 11B Vision model processes visual content and generates ad-related content Face mesh coordinates mapped and smoothed using MediaPipe‚Äôs 468 3D landmarks\n\nVisual Enhancement\n\nLip movements synchronized with generated audio and static video input from ngrok using Sync.so technology Generated text converted to speech using ElevenLabs voice synthesis integration into Sync using specified voice ID Background inpainting and filling where needed with LoMA\n\nDistribution\n\nSync.so output video mapped onto detected object with MediaPipe Repeat the loop from Core processing for further user interaction and prompts about ad product IoS App has ‚ÄúLike‚Äù feature, saves the ad URL into local storage database for future viewing"},{"heading":"Challenges we ran into:","content":"Our original goal was to implement our app on the Meta Quest 3 so that ads come to life by creating interactive VR avatars from recognr-ized adboards who would advertise products and answer questions about their product. However, due to compatibility issues with Meta Quest Link needing Windows systems with NVIDIA discrete graphics, we had to pivot our idea to be more realistic while still immersive. We transitioned to a new AR stack using XCode (Swift) libraries and had to learn how to combine ARKit with all the apis."},{"heading":"Accomplishments that we‚Äôre proud of:","content":"Going into this project, we knew it would be quite ambitious. Building out a AR/VR platform and augmenting images into animated talking personas with as low latency as possible is not just an issue we are addressing in this hackathon, startups and companies are developing their own reality swapping and mixed reality solutions to manipulate media for content creation, distribution, and consumption. Understanding two completely new platforms (Unity + Quest 3, XCode + ARKit) and having to scrap one was not only a big planning hurdle we had to overcome, but also a significant mental hurdle. Coming up with creative ways to actually implement parts of our ambitious idea was something we were quite proud of, researching and trying out different models for applications (stability ai‚Äôs stable diffusion2, GLIGEN for generative filling and inpainting, Grounding-DINO for scene-aware object detection, Grounded SAM for detailed segmentation, vespa.ai VLM for vision language understanding) . After trying out multiple approaches and consulting with our team, we came up with the most optimized solution that balanced performance and speed for our application."},{"heading":"What we learned:","content":"Ananya : I learned a lot about how to do AR on Swift and was able to do a lot more in a short amount of time in addition to having to learn the platform and language. I have had previous experience developing AR apps but this is my first experience with Swift, I liked its feature robustness while staying simple.\n\nManav : Learned a completely new language with Swift, got a lot of experience with API paradigms which are quite helpful for future development.\n\nKathleen : Team synergy is very important and I am glad that we had a lot of that. I really valued learning a new development language and platform through Swift and XCode as well.\n\nRobert : I got to learn so much with dynamic video manipulation and extraction with novel advanced models that definitely help me understand the variety of models available, the emerging areas of R&D in capable, low-latency computer vision and generative media, familiarity with developing with new models and libraries, and integrating dynamic CV and media into a meaningful app."},{"heading":"What‚Äôs next for slynk:","content":"slynk is just getting started. We wanted to make ads a positive, immersive interaction rather than the dull, nagging presence they have right now. Once we acquire the required hardware, we will boot our app and features into virtual reality with Apple Vision Pro. With this, our recognition 2D image to interactive 3D virtual avatar system can be used to create real virtual assistants that users can talk to and physically interact with for a more immersive experience . We will expand the virtual avatar to become full body. This virtual avatar generation can also be applied to other applications such as virtual shopping and fitting for clothes and furniture, personalized sports broadcasting, and VR presentation generation."},{"heading":"Built With","content":"ar elevenlabs flask groq llama mediapipe ngrok openai-whisper python swift sync xcode"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Pizza Buddy","project_url":"https://devpost.com/software/pizza-buddy-ynpfh4","tagline":"This app is a first step into revolutionizing online food orders. Using LLMs and storing user preferences, this app enables users to order Pizza using natural language w/o having to navigate the UI.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/285/967/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Blip: Best Browser Agent Hack"}],"team_members":[],"built_with":[{"name":"chatgpt","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"fastapi","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/william-parodi/Pizza-Buddy"}],"description_sections":[{"heading":"Inspiration","content":"The idea for Pizza Buddy came from our own experiences of ordering food online. We often found ourselves scrolling through endless menus, trying to decide what to order, only to end up overwhelmed by choices. What if there was a way to simplify this process? What if you could just chat with someone (or something) about what you or the rest of your party are craving, and they would take care of the rest? That‚Äôs when we thought of creating an extension that acts as your personal pizza assistant‚Äîstreamlining the ordering process by understanding your preferences through natural conversation.\n\nWe wanted to make ordering pizza as easy as chatting with a friend. With the rise of conversational AI, we saw an opportunity to leverage LLMs like ChatGPT to create a seamless user experience. Thus, Pizza Buddy was born."},{"heading":"What it does","content":"Pizza Buddy is a browser extension that allows users to chat with a bot to place their pizza orders. Here's how it works:\n\nConversation-based Ordering : Users can simply start a conversation with the bot, describing what they want in their pizza (e.g., \"I want a large pepperoni pizza with extra cheese\"). Cart Filling : Based on the conversation, the bot automatically fills the user's cart with the appropriate items from the pizza restaurant's menu. Confirmation : Once the cart is filled, the user is then able to purchase the items in the cart, or remove them to try again."},{"heading":"How we built it","content":"Building Pizza Buddy was a multi-step process that involved several technologies and frameworks:\n\nFrontend : We used Javascript and HTML to build the user interface for the browser extension. The chat interface was designed to be intuitive and responsive, ensuring a smooth user experience. Backend : The backend was built using FastAPI . This handled the logic for processing user input, interacting with APIs, and managing the state of the conversation. Autoclicking Scripts : We developed scripts that allowed us to navigate Domino's webpage in order to automatically add the items the LLM selected to the cart Database : We used a locally hosted database that allowed us to store memories that the LLM can refer back and write to in order to make decisions on what to order and store those decisions for the future."},{"heading":"Challenges we ran into","content":"Building Pizza Buddy was not without its challenges:\n\nUnderstanding Ambiguous Input : One of the biggest challenges was handling ambiguous or incomplete user input. For example, if a user says, \"I want a medium pizza,\" but doesn't specify toppings, we had to design the bot to ask follow-up questions to clarify their order. API Limitations : Some pizza delivery services had limited or poorly documented APIs, which made it difficult to integrate certain features. We had to work around these limitations by building automated scripts that added items to the cart for us. Error Handling : Handling errors gracefully was another challenge. If the bot misunderstood a user's request or if there was an issue with the API, we needed to provide clear feedback to the user and allow them to correct their order."},{"heading":"Accomplishments that we're proud of","content":"Despite the challenges, we‚Äôre incredibly proud of what we‚Äôve accomplished with Pizza Buddy :\n\nSeamless User Experience : We managed to create a conversational interface that feels natural and intuitive. Users can place orders without ever leaving the chat window. Personalization : By storing user preferences and past orders, we were able to offer personalized recommendations, making the ordering process even faster for returning users. Scalability : The architecture we built is scalable, meaning we can easily add support for more restaurants or cuisines in the future."},{"heading":"What we learned","content":"Building Pizza Buddy taught us a lot about both technical and non-technical aspects of software development:\n\nImplementing Memory for LLM APIs : Working through this project taught us valuable skills in this more niche area of AI. By implementing mechanisms for AI models to remember certain things, the applications can become endless for many future projects down the line. User-Centric Design : We learned that the key to a successful product is focusing on the user experience. Every feature we added was driven by the goal of making the process easier and more enjoyable for the user. Error Handling : We realized that robust error handling is crucial for maintaining user trust. Even if something goes wrong, the user should always feel in control and informed."},{"heading":"What's next for Pizza Buddy","content":"We have big plans for Pizza Buddy moving forward:\n\nExpand Cuisine Options : While we started with Dominos pizza restaurants, this project will be expand to be able to provide similar service to other restaurants, Amazon shopping, Walmart, and more. Voice Integration : We‚Äôre exploring the possibility of adding voice commands, allowing users to place orders hands-free. Multi-language Support : To reach a broader audience, we plan to add support for multiple languages, making the bot accessible to non-English speakers. AI Enhancements : We want to continue improving the bot‚Äôs AI capabilities, making it smarter and more context-aware. This includes better handling of complex orders and more accurate predictions of user preferences. Mobile App : In addition to the browser extension, we‚Äôre considering developing a standalone mobile app for Pizza Buddy , offering even more convenience for users on the go."},{"heading":"Built With","content":"chatgpt css fastapi javascript openai python tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Site Sentinel","project_url":"https://devpost.com/software/site-sentinel","tagline":"Site Sentinel is an AI-powered Industrial Safety Monitoring System that enforces real-time PPE compliance and posture monitoring using AI and cloud analytics.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/285/190/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Caterpillar: Best Cloud Implementation"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"mediapipe","url":null},{"name":"pycharm","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"roboflow","url":"https://devpost.com/software/built-with/roboflow"},{"name":"vscode","url":null},{"name":"yolov8","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/smchoi24/Boilermake2025"},{"label":"smchoi24.github.io","url":"https://smchoi24.github.io/Boilermake2025/templates/"}],"description_sections":[{"heading":"Inspiration","content":"Purdue University is constantly evolving, with ongoing construction projects ranging from new apartment buildings to academic renovations. Seeing these frequent construction sites, we became concerned about potential workplace accidents . Since safety hazards can arise suddenly, we wanted to create a solution that proactively prevents accidents before they happen ."},{"heading":"What it does","content":"Site Sentinel is an AI-powered Industrial Safety Monitoring System that enhances workplace safety through:\n\nPPE compliance detection using Roboflow to ensure workers wear helmets, gloves, vests, and goggles. Posture monitoring with MediaPipe , identifying unsafe lifting techniques in real time. Cloud-based analytics dashboard for tracking safety trends, generating reports, and ensuring OSHA compliance."},{"heading":"How we built it","content":"YOLOv8 , trained with Roboflow , was used for detecting missing PPE such as helmets, gloves, and vests. MediaPipe was implemented for real-time pose estimation , identifying unsafe lifting techniques. Edge AI processing with YOLOv8 enables low-latency detection on-site, minimizing cloud dependency. AWS services manage cloud storage, data analysis, and compliance tracking . A cloud-based analytics dashboard provides insights into safety trends and violations."},{"heading":"Challenges we ran into","content":"Every technology we used‚Äî Roboflow, MediaPipe, YOLO, and some of AWS services ‚Äîwas new to us. Learning them within a short timeframe was challenging. Integrating local detection functions with AWS services required precise handling of outputs to ensure stable cloud communication. Balancing real-time processing with accuracy and efficiency required extensive testing and optimization."},{"heading":"Accomplishments that we're proud of","content":"Successfully integrating AI-powered PPE detection and pose estimation into a real-time safety system. Deploying AI for low-latency processing , making our system efficient and scalable . Creating a cloud-based analytics dashboard that provides valuable safety insights for managers. Overcoming steep learning curves with new technologies and building a working prototype within a hackathon timeframe."},{"heading":"What we learned","content":"How to train and deploy object detection models with Roboflow . Real-time pose estimation using MediaPipe to track worker movements. The complexities of integrating AI with cloud-based analytics . Best practices for AWS services , ensuring stable cloud communication. The importance of real-time processing for workplace safety applications."},{"heading":"What's next for Site Sentinel","content":"Featuring hazard detection to include falling objects, gas leaks, and slippery surfaces for a more comprehensive safety solution. Improving the efficiency and accuracy of YOLOv8 PPE detection and MediaPipe posture analysis to reduce false positives and enhance reliability. Developing a mobile app for instant safety alerts, compliance tracking, and on-the-go monitoring . Enhancing dashboard functionalities with AI-driven predictive safety insights , allowing managers to anticipate and prevent potential risks. Exploring partnerships with industry leaders to bring Site Sentinel into real-world industrial and construction environments."},{"heading":"Built With","content":"amazon-web-services mediapipe pycharm python roboflow vscode yolov8"},{"heading":"Try it out","content":"github.com smchoi24.github.io"}]},{"project_title":"SignaSure","project_url":"https://devpost.com/software/signasure","tagline":"Signatures are the cornerstone of identity verification, from banking to national elections. SignaSure is a B2B API powered by a 92% accurate model to authenticate signatures with ease and precision.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/294/173/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"RCAC: Best Use of HPC/AI"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"neural-network","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tensorflow","url":null}],"external_links":[{"label":"SignaSure.net","url":"http://SignaSure.net"},{"label":"github.com","url":"https://github.com/Gjensen140/SignaSure"}],"description_sections":[{"heading":"Inspiration","content":"With two members in the group being closely connected to the banking industry, check fraud was on our radar as a problem that needed to be addressed. It costs the financial industry billions annually, so we sought to improve on existing signature verification technologies."},{"heading":"What it does","content":"It reads in a real signature and a signature the user is unsure of, then returns whether it thinks the signature is genuine or fraudulent."},{"heading":"How we built it","content":"We trained a CNN on a kaggle data set of genuine and forged signatures, then integrated it with an API to a react frontend where users can demo the product."},{"heading":"Challenges we ran into","content":"The first model we used employed a siamese neural network, but was ultimately too small architecture-wise for our intended purpose. Another significant setback was the struggle to host the api on AWS EC2, which timed out for seemingly no reason."},{"heading":"Accomplishments that we're proud of","content":"We also were able to train a 92% accurate model. We learned react, tensorflow, and flask despite having no previous experience in any of the three."},{"heading":"What we learned","content":"Learning new web development, Machine learning, and front end."},{"heading":"What's next for SignaSure","content":"Learning how to host the API and create a distributable api for users to employ locally. We would also like to fix the Siamese neural network to improve accuracy."},{"heading":"Built With","content":"amazon-web-services docker flask neural-network python react tensorflow"},{"heading":"Try it out","content":"SignaSure.net github.com"}]},{"project_title":"EyeDentify","project_url":"https://devpost.com/software/eyedentify-3leky5","tagline":"Staring at screens all day? Your eyes are paying the price. EyeDentify uses AI to track eye strain in real time, helping you prevent fatigue before it starts. Stay sharp, stay healthy!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/282/140/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Roboflow: Best Use of Roboflow Workflows"}],"team_members":[],"built_with":[{"name":"coco","url":null},{"name":"face-api.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react.js","url":null},{"name":"roboflow","url":"https://devpost.com/software/built-with/roboflow"}],"external_links":[{"label":"github.com","url":"https://github.com/archakamk/EyeDentify"}],"description_sections":[{"heading":"Inspiration","content":"The average screen time for teens hovers around 7 hours per day. In today's digital world, prolonged computer use has become a daily norm, leading to eye strain and related visual discomfort for millions. Our team was driven by the need to address this growing issue and enhance overall eye health in the digital age. Recognizing that most people aren't aware of the subtle signs of eye strain until it becomes a bigger problem, we developed EyeDentify. Our goal is to create a tool that actively monitors and detects eye strain, empowering users to take proactive steps to maintain eye comfort and well-being during computer use."},{"heading":"What it does","content":"EyeDentify is an eye strain detection web application designed to monitor users' eye movements and detect signs of eye strain or related conditions like redness, watering, or fatigue. By attempting to combine both a trained machine learning model from Roboflow and a blink detection system, EyeDentify analyzes the user‚Äôs eye movements and visual patterns, alerting them with popup notifications when it detects strain or discomfort. The application runs seamlessly in the background, sending users real-time notifications, ensuring they take necessary breaks to maintain eye health."},{"heading":"How we built it","content":"Our application is designed to process real-time data from the user‚Äôs webcam to detect signs of eye strain. The first step in our process was to gather a large dataset from Kaggle to train a custom model using Roboflow to identify patterns like redness, eye bags, and watery eyes. We were able to develop our model through implementing a workflow that divided the large scale project into smaller steps, making it easier for development. On the other hand, the front end was built with React.js, featuring a live webcam feed that will eventually integrate with our model. User authentication was implemented with Auth0 to ensure privacy to each user. While we weren‚Äôt able to fully implement the model into the website during this hackathon, that‚Äôs our next step."},{"heading":"Challenges we ran into","content":"Attempting to implement our original idea, a vein detection model, proved quite challenging as we weren't able to acquire enough data to train the model. So, we decided to pivot to another solution to medical issues -- helping reduce eye strain. For this project, one of the biggest challenges we faced was gathering enough data to train our model. We initially struggled to find enough labeled data for Roboflow, which meant we had to change our approach and focus on detecting specific patterns such as redness and bagginess. Another tough part was integrating the model with our React website; we had to figure out how to make the API calls work seamlessly without messing with the rest of the website. However, we learned a lot about how to make things work despite these hurdles!"},{"heading":"Accomplishments that we're proud of","content":"We are really proud of creating a tool that tackles a growing problem‚Äîeye strain from too much screen time. By building a model that can track and detect eye strain in real time, we‚Äôre giving users a practical, easy-to-use solution. What makes it even more exciting is that it works entirely through the web, with no need for extra hardware, making it accessible and convenient. It helps hackers like ourselves stay informed on when to take breaks especially in hackathons like Boilermake!"},{"heading":"What we learned","content":"Throughout the project, we sharpened our debugging skills to make sure our model performed accurately across all the parameters we set. There were plenty of moments where things didn‚Äôt work as expected, but taking the time to troubleshoot and refine our approach helped us push through. We also found that regularly checking in on each other's progress kept us aligned with our goals and made collaboration much more efficient. By working together and staying organized, we were able to tackle challenges more effectively and keep the project moving forward."},{"heading":"What's next for EyeDentify","content":"As we move forward, we plan to combine our blink tracking system with the strain detection model in the future. We‚Äôre also focused on improving the model‚Äôs accuracy by collecting more diverse data to better capture a wider range of eye strain indicators. Additionally, we plan to add features such as implementing MongoDB, so we can track more in-depth data for our users. Finally, another key goal is optimizing the app‚Äôs performance across different devices, especially for mobile users who want to keep tabs on their eye health while on the go."},{"heading":"Built With","content":"coco face-api.js python react.js roboflow"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Circuit Court","project_url":"https://devpost.com/software/circuit-court","tagline":"Battle as Prosecutor or Defense in AI-generated legal cases! Present arguments across 3 rounds, adapt to the AI judge‚Äôs live feedback, and sway its verdict.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/287/196/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Modal: \"But I'm Not A Wrapper\" for Best Self-Hosted LLM"}],"team_members":[],"built_with":[{"name":"blender","url":"https://devpost.com/software/built-with/blender"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"llama","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"}],"external_links":[{"label":"github.com","url":"https://github.com/jaxsonp/circuit-court"}],"description_sections":[{"heading":"Inspiration","content":"We enjoy party games like Jackbox and the drama of courtroom shows, and wanted to join the two in our project. Brainstorming led to Circuit Court, a fun game that harnesses generative AI to act as a dynamic ‚Äújudge,‚Äù where players argue not just against each other, but against an LLM‚Äôs logic."},{"heading":"What It Does","content":"Players join from their mobile devices as Prosecutor or Defense in AI-generated legal battles. Over three rounds, they present arguments to sway the AI judge, which reacts with live feedback before delivering a verdict."},{"heading":"How We Built It","content":"Frontend: Host screen built with React and Babylon.js for real-time visuals, 3d graphics, and animations. Backend: A Python Flask server handles game logic and player connections. AI Core: A self-hosted Llama model generates scenarios, evaluates arguments, and writes feedback. Multiplayer: WebSockets sync inputs and game state between the server, host, and players."},{"heading":"Challenges We Ran Into","content":"Protocol design: Syncing game state between the server, host, and players was surprisingly tricky to design efficiently. React Rendering: Mixing rendering logic with dynamic game state in React was difficult to get working. Hosting: Hosting the LLM on Modal and the server on Google Cloud introduced complexity in managing cross-platform communication."},{"heading":"Accomplishments We‚Äôre Proud Of","content":"Dynamic Scenarios: No two cases are alike. The AI crafts everything from stolen cupcakes to robot rebellions, keeping gameplay fresh and unpredictable. Interesting Graphics: Using a 3D scene for the visuals was very challenging in the relatively short time constraints, so we were proud to produce graphics we are happy with."},{"heading":"What We Learned","content":"Networking is Hard: Syncing multiple clients in real-time requires mindfulness of various errors React Best Practices: Separating rendering logic from game state management is crucial for performance and maintainability. Using Modal and Google Cloud required us to keep things consistent across multiple platforms."},{"heading":"What‚Äôs Next for Circuit Court","content":"Additional roles: Spectators can join as jurors and give their input. Objections: Players can interrupt and object to their opponent's arguments Custom Scenarios: Let players input their own conflicts (e.g., ‚ÄúRoommate ate my pizza‚Äù). Mobile App: Scan a QR to jump into the courtroom!"},{"heading":"Built With","content":"blender flask google-cloud javascript llama python react websockets"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"ArisTalkle","project_url":"https://devpost.com/software/aristalkle","tagline":"AI-powered debates. Smarter discourse. Stronger voices.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/287/200/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Purdue Innovates: Most Likely to Become a Business"}],"team_members":[],"built_with":[{"name":"cartesia-api","url":null},{"name":"clerk","url":"https://devpost.com/software/built-with/clerk"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"gemini-api","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"local-hosting","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"next.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"shadcn/ui","url":null},{"name":"supabase","url":null},{"name":"sync-ai","url":null},{"name":"tailwind-css","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/AaravMohanty/BoilerMakeXII"}],"description_sections":[{"heading":"Inspiration","content":"In today's digital world, meaningful discourse is often lost in text-based communication, leading to misinterpretation and polarization. Inspired by Aristotle‚Äôs belief in the power of thoughtful debate, we wanted to create a platform that fosters structured, engaging, and AI-driven discussions. Our goal was to help people refine their argumentation skills while making debates more accessible and interactive to make everyone more confident in their speaking abilities."},{"heading":"What it does","content":"ArisTalkle is an AI-powered debate platform that enables users to engage in video debates with a human-like AI opponent. You argue, and Aristotle responds! It provides:\n\nPersonalized scoring and feedback to help users improve. A practice mode for refining presentation and argumentation skills. A personal dashboard to track past performance, scores, and areas for improvement. By combining AI-driven interaction with structured discourse, ArisTalkle enhances critical thinking and communication skills."},{"heading":"How we built it","content":"AI Model: We use the Gemini API to analyze the user's video file and generate a text-based argument . The generated text is then passed to Cartesia API , which converts it into realistic speech. The Sync AI model then synchronizes the generated audio with a virtual AI video speaker, creating a lifelike debate experience . Backend: Interacted with MongoDB using Next.js Server Actions to add and manipulate data in the database. Built AI server using Python and Flask to manage AI model interactions and user data. Stores debate history, scores, and personalized feedback. Supabase was used to host .wav files , making them publicly accessible for Sync AI. Frontend: Developed using Next.js for a fast, server-rendered experience . Styled with Tailwind CSS for a modern, responsive UI . Utilized shadcn/UI for an accessible and aesthetic component library. Handles video uploads, real-time feedback, and debate tracking seamlessly. Database: We used MongoDB to manage user accounts, track improvement metrics, and store debate performance."},{"heading":"Challenges we ran into","content":"Getting the Gemini API to work consistently Initially, we faced issues with response delays and inconsistencies in AI-generated arguments. We optimized API calls and implemented error-handling mechanisms to ensure smooth performance. Generating a publicly accessible .wav file for Sync AI Sync AI required public URLs for the AI-generated speech files, but the output was locally stored by default. We solved this by integrating Supabase to host and serve .wav files via public links . Integration between back-end and front-end Since we were dealing with multiple data types (PDF, video, audio, text), ensuring smooth communication between the AI models, front-end UI, and Flask server was complex. We developed a structured API endpoint system to handle the flow of data across the different components."},{"heading":"Accomplishments that we're proud of","content":"Successfully integrated multi-step AI processing to create a realistic debate experience . Developed real-time speech analysis and feedback to help users improve argumentation. Solved the file hosting challenge with Supabase , enabling a smooth AI-driven debate process. Built a modern, user-friendly UI with Next.js, Tailwind CSS, and shadcn/UI for an intuitive debate experience. We were able to make a solution that analyzes a user's video logically and outputs a video in about the same time as the video generation AI Sora (sometimes even faster!)."},{"heading":"What we learned","content":"How to effectively integrate multiple AI models (Gemini API, Cartesia API, Sync AI) into a single pipeline. The importance of reliable file hosting solutions for AI-generated content. Best practices for back-end and front-end integration when handling multimedia data (video, audio, text, PDF). How to fine-tune AI-generated responses to create structured and engaging debates. Leveraging Next.js for server-rendered performance and shadcn/UI for accessible UI components ."},{"heading":"What's next for Aristalkle","content":"Expanding AI capabilities to support multi-person debates and different argumentation styles. Integrating multilingual support to make debates accessible worldwide. Enhancing feedback systems with deeper insights into argument strength. Introducing debate tournaments where users can compete and track their progress. Building partnerships with schools and workplaces to promote structured discourse and critical thinking.\n\nAristalkle is just the beginning‚Äîour vision is to create a world where meaningful debate is accessible to everyone! üöÄ"},{"heading":"Built With","content":"cartesia-api clerk flask gemini-api github javascript local-hosting mongodb next.js python shadcn/ui supabase sync-ai tailwind-css typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Story Sage","project_url":"https://devpost.com/software/story-sage-bqiszj","tagline":"Our project takes in a pdf of a story which is used to create an audio file which is voiced by multiple characters based on who is speaking in the story.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/282/533/datas/medium.png","prizes":[{"hackathon_name":"BoilerMake XII","hackathon_url":"https://boilermake-xii.devpost.com/","prize_name":"Purdue Innovates: Most Likely to Become a Business"}],"team_members":[],"built_with":[{"name":"cartesia","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"fastapi","url":null},{"name":"gemini","url":"https://devpost.com/software/built-with/gemini"},{"name":"genai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"websockets","url":"https://devpost.com/software/built-with/websockets"}],"external_links":[{"label":"github.com","url":"https://github.com/ansh-gangapurkar/story-sage.git"}],"description_sections":[{"heading":"Inspiration","content":"The reason we chose this project was the fact that many Audiobooks currently use one voice for every character or when they have different voices they have to hire voice actors which can become expensive. So seeing the work that Cartesia does with voices inspired us to try and solve this problem by using different voices for each character which speaks in stories."},{"heading":"What it does","content":"What our project does is it takes in input as a pdf and uses the Gemini API to parse through the text as well as selecting unique voices for each character depending on what the character is like. Then the Cartesia API generates audio files using each voice which we splice together. We present the audio file to the user at the end of the process so it can be listened to."},{"heading":"How we built it","content":"We did extensive research into how exactly the Cartesia API works as well as finding out how we could incorporate Gemini into our project as that was the GenAI we wanted to use. We built the backend using python websockets and the frontend was built using react and typescript using next.js as a framework."},{"heading":"Challenges we ran into","content":"We ran into quite a few problems while trying to use the Cartesia API as it was unfamiliar technology and none of us had ever worked with AI voices before. Also we ran into issues splicing the audios together as it was difficult getting the audios to retain the same quality."},{"heading":"Accomplishments that we're proud of","content":"We are proud of learning how to use a new technology in this short time period as none of us were familiar with how it worked. We are also proud about rising to the challenge of finding different libraries to use in order to splice audios together as well as using Gemini effectively to select the correct voices for specific characters."},{"heading":"What's next for Story Sage","content":"Our main short term goal is to deploy Story Sage as a web application. Our long term goals would be to implement smoother audio files, include more file types as input, and get Story Sage on mobile app stores to enable further access."},{"heading":"Built With","content":"cartesia css fastapi gemini genai python typescript websockets"},{"heading":"Try it out","content":"github.com"}]}],"generated_at":"2026-02-18T16:52:16.376813Z"}}