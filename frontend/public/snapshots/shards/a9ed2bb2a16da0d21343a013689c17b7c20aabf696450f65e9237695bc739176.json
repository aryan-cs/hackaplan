{"version":"v1","hackathon_url":"https://treehacks-2023.devpost.com","generated_at":"2026-02-18T16:40:22.763538Z","result":{"hackathon":{"name":"TreeHacks 2023","url":"https://treehacks-2023.devpost.com","gallery_url":"https://treehacks-2023.devpost.com/project-gallery","scanned_pages":13,"scanned_projects":293,"winner_count":50},"winners":[{"project_title":"Smart Shoe","project_url":"https://devpost.com/software/smart-shoe-module","tagline":"A modular shoe attachment clipped to the wearer's shoe to help people adjusting to new blindness, eye injury, or retinal degeneration by vibrating when it detects an approaching obstacle.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/735/datas/medium.PNG","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Hardware Hack: 4 x Monoprice Maker Select 3D Printer v2"}],"team_members":[],"built_with":[{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"imu","url":null},{"name":"irsensor","url":null},{"name":"mpu","url":null},{"name":"soldering","url":null},{"name":"ultrasound","url":null}],"external_links":[{"label":"drive.google.com","url":"https://drive.google.com/file/d/1o2mxJXDgxnnhsT8eL4pCnbk_yFVVWiNM/view?usp=share_link"}],"description_sections":[{"heading":"Inspiration","content":"Retinal degeneration affects 1 in 3000 people, slowly robbing them of vision over the course of their mid-life. The need to adjust to life without vision, often after decades of relying on it for daily life, presents a unique challenge to individuals facing genetic disease or ocular injury, one which our teammate saw firsthand in his family, and inspired our group to work on a modular, affordable solution. Current technologies which provide similar proximity awareness often cost many thousands of dollars, and require a niche replacement in the user's environment; (shoes with active proximity sensing similar to our system often cost $3-4k for a single pair of shoes). Instead, our group has worked to create a versatile module which can be attached to any shoe, walker, or wheelchair, to provide situational awareness to the thousands of people adjusting to their loss of vision."},{"heading":"What it does (Higher quality demo on google drive link!: https://drive.google.com/file/d/1o2mxJXDgxnnhsT8eL4pCnbk_yFVVWiNM/view?usp=share_link )","content":"The module is constantly pinging its surroundings through a combination of IR and ultrasonic sensors. These are readily visible on the prototype, with the ultrasound device looking forward, and the IR sensor looking to the outward flank. These readings are referenced, alongside measurements from an Inertial Measurement Unit (IMU), to tell when the user is nearing an obstacle. The combination of sensors allows detection of a wide gamut of materials, including those of room walls, furniture, and people. The device is powered by a 7.4v LiPo cell, which displays a charging port on the front of the module. The device has a three hour battery life, but with more compact PCB-based electronics, it could easily be doubled. While the primary use case is envisioned to be clipped onto the top surface of a shoe, the device, roughly the size of a wallet, can be attached to a wide range of mobility devices.\n\nThe internal logic uses IMU data to determine when the shoe is on the bottom of a step 'cycle', and touching the ground. The Arduino Nano MCU polls the IMU's gyroscope to check that the shoe's angular speed is close to zero, and that the module is not accelerating significantly. After the MCU has established that the shoe is on the ground, it will then compare ultrasonic and IR proximity sensor readings to see if an obstacle is within a configurable range (in our case, 75cm front, 10cm side).\n\nIf the shoe detects an obstacle, it will activate a pager motor which vibrates the wearer's shoe (or other device). The pager motor will continue vibrating until the wearer takes a step which encounters no obstacles, thus acting as a toggle flip-flop.\n\nAn RGB LED is added for our debugging of the prototype: RED - Shoe is moving - In the middle of a step GREEN - Shoe is at bottom of step and sees an obstacle BLUE - Shoe is at bottom of step and sees no obstacles\n\nWhile our group's concept is to package these electronics into a sleek, clip-on plastic case, for now the electronics have simply been folded into a wearable form factor for demonstration."},{"heading":"How we built it","content":"Our group used an Arduino Nano, batteries, voltage regulators, and proximity sensors from the venue, and supplied our own IMU, kapton tape, and zip ties. (yay zip ties!)\n\nI2C code for basic communication and calibration was taken from a user's guide of the IMU sensor. Code used for logic, sensor polling, and all other functions of the shoe was custom. All electronics were custom.\n\nTesting was done on the circuits by first assembling the Arduino Microcontroller Unit (MCU) and sensors on a breadboard, powered by laptop. We used this setup to test our code and fine tune our sensors, so that the module would behave how we wanted. We tested and wrote the code for the ultrasonic sensor, the IR sensor, and the gyro separately, before integrating as a system.\n\nNext, we assembled a second breadboard with LiPo cells and a 5v regulator. The two 3.7v cells are wired in series to produce a single 7.4v 2S battery, which is then regulated back down to 5v by an LM7805 regulator chip. One by one, we switched all the MCU/sensor components off of laptop power, and onto our power supply unit. Unfortunately, this took a few tries, and resulted in a lot of debugging.\n\n. After a circuit was finalized, we moved all of the breadboard circuitry to harnessing only, then folded the harnessing and PCB components into a wearable shape for the user."},{"heading":"Challenges we ran into","content":"The largest challenge we ran into was designing the power supply circuitry, as the combined load of the sensor DAQ package exceeds amp limits on the MCU. This took a few tries (and smoked components) to get right. The rest of the build went fairly smoothly, with the other main pain points being the calibration and stabilization of the IMU readings (this simply necessitated more trials) and the complex folding of the harnessing, which took many hours to arrange into its final shape."},{"heading":"Accomplishments that we're proud of","content":"We're proud to find a good solution to balance the sensibility of the sensors. We're also proud of integrating all the parts together, supplying them with appropriate power, and assembling the final product as small as possible all in one day."},{"heading":"What we learned","content":"Power was the largest challenge, both in terms of the electrical engineering, and the product design- ensuring that enough power can be supplied for long enough, while not compromising on the wearability of the product, as it is designed to be a versatile solution for many different shoes. Currently the design has a 3 hour battery life, and is easily rechargeable through a pair of front ports. The challenges with the power system really taught us firsthand how picking the right power source for a product can determine its usability. We were also forced to consider hard questions about our product, such as if there was really a need for such a solution, and what kind of form factor would be needed for a real impact to be made. Likely the biggest thing we learned from our hackathon project was the importance of the end user, and of the impact that engineering decisions have on the daily life of people who use your solution. For example, one of our primary goals was making our solution modular and affordable. Solutions in this space already exist, but their high price and uni-functional design mean that they are unable to have the impact they could. Our modular design hopes to allow for greater flexibility, acting as a more general tool for situational awareness."},{"heading":"What's next for Smart Shoe Module","content":"Our original idea was to use a combination of miniaturized LiDAR and ultrasound, so our next steps would likely involve the integration of these higher quality sensors, as well as a switch to custom PCBs, allowing for a much more compact sensing package, which could better fit into the sleek, usable clip on design our group envisions.\n\nAdditional features might include the use of different vibration modes to signal directional obstacles and paths, and indeed expanding our group's concept of modular assistive devices to other solution types.\n\nWe would also look forward to making a more professional demo video Current example clip of the prototype module taking measurements:( https://youtube.com/shorts/ECUF5daD5pU?feature=share )"},{"heading":"Built With","content":"arduino imu irsensor mpu soldering ultrasound"},{"heading":"Try it out","content":"drive.google.com"}]},{"project_title":"Aqua Shot","project_url":"https://devpost.com/software/aquashot","tagline":"Spray your friends, and make NFT's that we'll send! Interact with and cherish memories with creators through physical interactions that turn into NFTs.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/390/521/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Creative Hack: 4 x Sonos Roam"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Aptos: $1000"}],"team_members":[],"built_with":[{"name":"aptos","url":null},{"name":"c++","url":"https://devpost.com/software/built-with/c--3"},{"name":"ipfs","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pinata","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"teensy","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"aquashot.tech","url":"https://aquashot.tech/"},{"label":"cad.onshape.com","url":"https://cad.onshape.com/documents/03805a9bbe24ba5ad9c62b00/w/7cfb6b459d202ef476449828/e/e7fc0acb00867afb99c004e1?renderMode=0&uiState=63f23341dc3584418755d9df"},{"label":"youtu.be","url":"https://youtu.be/kSxTMCTiuvo"},{"label":"github.com","url":"https://github.com/FourSauces/TheWaterboarders"}],"description_sections":[{"heading":"Inspiration","content":"This project was inspired by our curious na√Øvet√© in integrating interdisciplinary technologies‚Ä¶ and the desperate need to wake up a certain friend incapable of waking up to any traditional alarm. Every Thursday at 5am, everyone but him within a 2 room radius would wake up to his alarm. We were drawn to the use of water as a potential alternative to a traditional alarm.\n\nThinking beyond an alarm, we found an opportunity to use robots to augment livestreams and strengthen the bond between content creators and consumers. As users donate to control the robot and interact with a creator, they receive NFTs of moments that can be cherished far into the future.\n\nWe came to see a use case in the realm of virtual human interactions. Particularly, we focused on how to foster a more meaningful connection between streamers and their audience, which platforms such as Twitch are constantly trying to find innovations in. By getting people more involved in the moments, we are able to create not only those interactions, but also create an in-person anchor point for the people, representing key components streaming sites have yet to utilize: the warmth and intimacy that real-world interactions and memories can provide."},{"heading":"What it does","content":"Users pay using Aptos for a water turret to spray water at somebody‚Äôs face. The user interacts with the website we made, which has integration for Aptos' Petra wallet, as well as a livestream showing what a creator is doing. We mounted a separate webcam on a turret, which uses facial recognition to track people, and aims the water nozzle at their face. When someone donates through the site, the pump activates, and a recording of the moment is made into an NFT and sent back to the user's wallet. Overall, the interaction between our hardware and software (Web3 integration, CV, motor controls) is what drives the user experience."},{"heading":"How we built it","content":"We designed and fabricated the aqua shooter (our water-spraying turret-targeting robot) using 3D printing, laser cutting, soldering, and manual fabrication using various other tools. We used many libraries and programming languages to program the various parts of our project. We used Typescript, HTML, Python, and C++ programming languages, along with the most notable packages we used being React for the website, Aptos SDK for Aptos integration, OpenCV alongside the face_recognition package for face tracking, and Pinata-python for uploading videos to IPFS."},{"heading":"Challenges we ran into","content":"The biggest challenge was integrating the software and hardware. With complex software and hardware components, we had to find ways to bring them all together at the last moment. Some of these included the installing of different software packages, the design of complex small parts, and finally the integration of everything after we had tested each individual component of the project and needed to tune it. Overall, the unpredictable results, or lack thereof, from these different components interacting was stress-test for communication, planning, and technical precision."},{"heading":"Accomplishments that we're proud of","content":"In a project with so many different parts, we are proud that we could integrate many different disciplines together and successfully come up with this unique system that brings both joy and utility to its users."},{"heading":"What we learned","content":"We learned many aspects in Aptos, OpenCV, and robotics through this compiled fun project! In addition, we learned how to integrate these very different disciplines into a complete project, ensuring precision on all fronts before piecing together the puzzle."},{"heading":"What's next for AquaShot","content":"Although we were only able to create one new avenue of physical interaction, we hope to continue expanding the ways that meaningful physical interactions can be included in virtual interactions. While this project‚Äôs goal was a mix of futuristic technologies for fun shenanigans, we look to bring these tools forward for the purpose of bridging the connectivity gap between the physical and virtual worlds. Indeed, the Aqua Shot should not be seen as a standalone, but rather an example feature of what the product could include.\n\nIn addition, there remains the possibility for an entirely new type of investment/trade market. On one hand, streamers will opt in on these technologies due to promises of higher donation revenue. On the other, viewers will be actively placing bets on moments and memories that will stand as valuable to the community, making them active entertainers as well. As a result, we envision an entirely new type of engagement in entertainment and human relationships."},{"heading":"Built With","content":"aptos c++ ipfs opencv pinata python react teensy typescript"},{"heading":"Try it out","content":"aquashot.tech cad.onshape.com youtu.be github.com"}]},{"project_title":"Proactive Refresh","project_url":"https://devpost.com/software/proactive-refresh","tagline":"The first implementation of accountable threshold signatures with proactive refresh. We are the safest way to secure funds and protect what's most important to your organization.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/388/072/datas/medium.gif","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Technically Complex Hack: 4 x Mac Minis"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Omnichain Smart Contract Application by Zetachain: $2500"}],"team_members":[],"built_with":[{"name":"circom","url":null},{"name":"elliptic-curve-cryptography","url":null},{"name":"nextjs","url":null},{"name":"rust","url":"https://devpost.com/software/built-with/rust"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"zero-knowledge","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/lyronctk/ats-pr-bls"},{"label":"github.com","url":"https://github.com/nathanhleung/ats-pr-bls-frontend"},{"label":"proactive-refresh.vercel.app","url":"https://proactive-refresh.vercel.app/"},{"label":"github.com","url":"https://github.com/nathanhleung/ats-pr-bls-contracts"}],"description_sections":[{"heading":"Inspiration","content":"Threshold signatures secure billions in assets across crypto and traditional finance. They're meant to increase vault security by splitting up a digital signature across N parties, requiring at least T of them to sign off before any action (e.g. \"liquidate funds\" or \"pay contractor\") is taken. Though adversaries now need to compromise at least T parties to exploit, vanilla schemes come with a significant drawback. Signature shares are stagnant, so adversaries can target the T parties over the course of months, eventually resulting in a hack regardless of the threshold parameter.\n\nIt's a common occurrence. The Ronin Bridge was secured by a 5-of-7 multisig. Adversaries compromised keys one at a time to drain the contract of $650M. The Harmony Bridge was secured by a 2-of-5 multisig. Again, adversaries compromised two keys separately for a $100M exploit."},{"heading":"What it does","content":"Proactive refresh is a promising solution to these vulnerabilities. It's a way to renew signature shares every 30 seconds. Think of it as Google Authenticator for threshold signatures. Adversaries would then need to compromise all T keys (eg. all 5 keys for Ronin) within the span of 30 seconds- a much harder task.\n\nA simple concept, but building it to be cryptographically secure is fairly challenging. So much so that a valid construction was only recently proposed in a 2022 theory paper coming out of the Boneh laboratory. It satisfied many challenging requirements, namely: 1) having no central point of failure, 2) preserving the original vault, and 3) tracing back to signers. The scheme does so while providing security guarantees of unforgeability and accountability.\n\nWe built out this primitive from scratch (first team to do so, to our knowledge). To demonstrate how powerful it is, we deployed a cross-chain vault on ZetaChain that's secured by a 5-of-7 threshold signature. Any adversary that wishes to drain the vault must compromise 5 signature shares in the span of 30 seconds. We think this would be unlikely."},{"heading":"How we built it","content":"The scheme is instantiated by sampling N secret keys from the base field of the BLS12-381 curve. One key is handed to each party via a secure communication channel. T parties can then come together, with each individually signing the message to create T signatures. We use lagrange interpolation to find the lowest degree polynomial that \"fits\" to these signatures, with f(0) on the polynomial set as the collective signature. Notice that each set of T signers has a unique collective signature, allowing us trace back to who signed. Accountability! A big deal when dealing with mission-critical requests.\n\nTo verify these signatures, we can again fit the lowest degree polynomial over the public keys for these parties. Due to the handy linearity property of BLS signatures (tracing back to the linearity of pairings over elliptic curves), this collective public key verifies the signature as expected.\n\nThat's how we implement accountable threshold BLS signatures. Now for proactive refresh. Every 30 seconds, all N parties are required to sample a new T-1 degree polynomial that passes through the origin. Every party then needs to add the corresponding point from all N polynomials to their local secret key. This completely changes what their secret key is. But, since all the new polynomials pass through the origin, all collective signatures at f(0) are still the same (read: vault kept intact). What's more, each party contributed equally to the update process, so there's no single point of failure.\n\nA key that is compromised in one update round by an adversary is now useless in the following update round since the joint polynomial is completely different. Mission accomplished.\n\nTo demonstrate how powerful this primitive is, we deployed an asset vault on ZetaChain based on a custom fork of Gnosis Safe . We modified the isValidSignature function and the signature verification logic in the execTransaction method of the Safe to instead rely on an on-chain ZK proof of a valid BLS signature generated using this signature scheme. Beyond modifying the signature scheme, we also took advantage of ZetaChain's zEVM features: the vault can accept messages from any blockchain supported by ZetaChain. To demonstrate this capability, we wrote a GnosisSafeZetaChainClient contract which we deployed to Goerli. A call to execTransaction on this Goerli contract which contains a valid signature parameter will trigger a transaction on the main ZetaChain vault using ZetaChain's cross-chain messaging. This simplifies multisig management as now there is a single source of truth for managing the assets and signature verification of the vault ‚Äî the Safe instance on ZetaChain."},{"heading":"Challenges we ran into","content":"Implementing the scheme was pretty difficult. It's elegant and doable to understand from a high level, but the nitty gritty lost us a good bit of sleep:\n\n1) Existing libraries with components we needed had group elements that didn't play well together, so we had to implement the primitive from scratch. Our rust implementation included BLS signatures (elliptic curve pairings and group operations on BLS12-381), accountability (variant of Shamir's secret sharing scheme with lagrange interpolation), and proactive refresh (sampling these strategic polynomials).\n\n2) Needed zkSNARKs. ZetaChain (& EVM) doesn't have the BLS precompile, so verifying the signature on-chain would've costed an ungodly amount of gas. We remedied this with a SNARK. Instead of checking the BLS signature on chain, we check it in a circuit and verify just the proof on chain. This was a hefty engineering lift since the computational model in a circuit is fairly different from what we dealt with in rust. It was especially difficult because we needed to do complex field arithmetic (pairings) that doesn't play well with the field that bn128 (the main zkSNARK elliptic curve) provides. We built this on the circom/snarkjs stack and used groth16 as our proving system. NOTE: The correct circuit is still compiling here, so the vault we have live right now can be spoofed by a well-informed adversary.\n\n3) The default Gnosis Safe deployment process recommended by the Gnosis Safe team relies on presigned transactions generated from a key that only the Gnosis Safe team controls. These presigned transactions only work for deployment on certain whitelisted chains. Unfortunately, ZetaChain was not on the whitelist, so we had to make significant modifications to the Safe's constructor and deployment scripts in order to get a working Safe instance on ZetaChain. After getting the Safe working on ZetaChain, we spent extensive time digging into Solidity abi-coding and memory vs. calldata nuances to make sure data was passed in the correct encoding and format from Goerli to ZetaChain (e.g. we needed to calculate the correct offset to slice a calldata byte array by to get calldata bytes instead of memory bytes). We also ran into some contract size ceilings that we ended up mitigating by deleting legacy signature verification code used by the default Gnosis Safe verification algorithm that wasn't necessary under the new BLS signature scheme."},{"heading":"Accomplishments that we're proud of","content":"1) Rust crate that's the first working example of proactive refresh for accountable threshold signatures.\n\n2) Cross-chain vault on ZetaChain that we're willing to put money on (maybe?).\n\n3) ZK proofs that solidified the end-to-end implementation from primitive to dapp."},{"heading":"What we learned","content":"Though our team had some cryptography / ZK background going into this, this was still massively difficult. We're much more comfortable with all types of threshold signatures and circuit work."},{"heading":"What's next for Proactive Refresh","content":"Increased security for vaults is one among many threshold-related use cases such as bridging, timelock encryption, and commitment pools. We're excited to see what projects spawn from accountable threshold signatures with proactive refresh. Cleaning up the code now and fleshing out tests, then will make the crate available for the open source community!"},{"heading":"Built With","content":"circom elliptic-curve-cryptography nextjs rust typescript zero-knowledge"},{"heading":"Try it out","content":"github.com github.com proactive-refresh.vercel.app github.com"}]},{"project_title":"DroneFormer","project_url":"https://devpost.com/software/droneformer","tagline":"Controlling UAVs with natural language!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/388/969/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Moonshot Prize: 4 x Segway - G30Max Electric Kick Scooter"}],"team_members":[],"built_with":[{"name":"ml","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/brianwu568/DroneFormer"},{"label":"medium.com","url":"https://medium.com/@sidhantbendre22/hacking-the-moonshot-stanford-treehacks-2023-9166865d4899"}],"description_sections":[{"heading":"Inspiration","content":"Building domain-specific automated systems in the real world is painstaking, requiring massive codebases for exception handling and robust testing of behavior for all kinds of contingencies ‚Äî automated packaging, drone delivery, home surveillance, and search and rescue are all enormously complex and result in highly specialized industries and products that take thousands of engineering hours to prototype.\n\nBut it doesn‚Äôt have to be this way! Large language models have made groundbreaking strides towards helping out with the similarly tedious task of writing, giving novelists, marketing agents, and researchers alike a tool to iterate quickly and produce high-quality writing exhibiting both semantic precision and masterful high-level planning.\n\nLet‚Äôs bring this into the real world. What if asking ‚Äúfind the child in the blue shirt and lead them to the dinner table‚Äù was all it took to create that domain-specific application?\n\nTaking the first steps towards generally intelligent embodied AI, DroneFormer turns high-level natural language commands into long scripts of low-level drone control code leveraging advances in language and visual modeling. The interface is the simplest imaginable, yet the applications and end result can adapt to the most complex real-world tasks."},{"heading":"What it does","content":"DroneFormer offers a no-code way to program a drone via generative AI. You can easily control your drone with simple written high-level instructions. Simply type up the command you want and the drone will execute it ‚Äî flying in spirals, exploring caves to locate lost people with depth-first search, or even capturing stunning aerial footage to map out terrain. The drone receives a natural language instruction from the user (e.g. \"find my keys\") and explores the room until it finds the object."},{"heading":"How we built it","content":"Our prototype compiles natural language instructions down into atomic actions for DJI Tello via in-context learning using the OpenAI GPT-3 API. These actions include primitive actions from the DJI SDK (e.g. forward, back, clockwise turn) as well as custom object detection and visual language model query actions we built leveraging zero-shot image and multimodels models such as YOLOv5 and image processing frameworks such as OpenCV. We include a demo for searching for and locating objects using the onboard Tello camera and object detection."},{"heading":"Challenges we ran into","content":"One significant challenge was deciding on a ML model that best fit our needs of performant real-time object detection. We experimented with state-of-the-art models such as BLIP and GLIP which either were too slow at inference time, or were not performing as expected in terms of accuracy. Ultimately, we settled on YOLOv5 as having a good balance between latency and ability to collect knowledge about an image. We were also limited by the lack of powerful onboard compute, which meant the drone needs to connect to an external laptop (which needed to serve both the drone and internet networks, which we resolved using Ethernet and wireless at the same time) which in turn connects to the internet for OpenAI API inference."},{"heading":"Accomplishments that we're proud of","content":"We were able to create an MVP! DroneFormer successfully generates complex 20+ line instructions to detect and navigate to arbitrary objects given a simple natural language instruction to do so (e.g. ‚Äúexplore, find the bottle, and land next to it‚Äù)."},{"heading":"What we learned","content":"Hardware is a game changer! Embodied ML is a completely different beast than even a simulated reinforcement learning environment, and working with noisy control systems adds many sources of error on top of long-term language planning. To deal with this, we iterated much more frequently and added functionality to deal with new corner cases and ambiguity as necessary over the course of the project, rewriting as necessary. Additionally, connectivity issues arose often due to the three-tiered nature of the system between the drone, laptop, and cloud backends."},{"heading":"What's next for DroneFormer","content":"We were constrained by the physical confines of the TreeHacks drone room and obstacles available in the vicinity, as well as the short battery life of the Tello drone. Expanding to larger and more complex hardware, environments, and tasks, we expect the DroneFormer framework to handily adapt, given a bit of prompt engineering, to emergent sophisticated behaviors such as:\n\nWatching over a child wandering around the house and reporting any unexpected behavior according to a fine-tuned classifier Finding that red jacket that you could swear was on the hanger but which has suddenly disappeared Checking in ‚Äúperson‚Äù if the small coffee shop down the street is still open despite the out-of-date Google Maps schedule Sending you a picture of the grocery list you forgot at home\n\nDroneFormer will be a new type of personal assistant ‚Äî one that always has your back and can bring the magic of complex language model planning to the embodied real world. We‚Äôre excited!\n\nhttps://medium.com/@sidhantbendre22/hacking-the-moonshot-stanford-treehacks-2023-9166865d4899"},{"heading":"Built With","content":"ml openai python"},{"heading":"Try it out","content":"github.com medium.com"}]},{"project_title":"CityGO","project_url":"https://devpost.com/software/pedestrian-flow-analysis","tagline":"Instantly transform an unwalkable street. ü™Ñ","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/391/006/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Impactful Hack: 4 x Apple TV Wi-Fi + Ethernet (128 GB)"}],"team_members":[],"built_with":[{"name":"api","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"mapbox","url":"https://devpost.com/software/built-with/mapbox"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwind","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/chloecookie/citygo"}],"description_sections":[{"heading":"Inspiration","content":"It‚Äôs insane how the majority of the U.S. still looks like endless freeways and suburban sprawl. The majority of Americans can‚Äôt get a cup of coffee or go to the grocery store without a car.\n\nWhat would America look like with cleaner air, walkable cities, green spaces, and effective routing from place to place that builds on infrastructure for active transport and micro mobility? This is the question we answer, and show, to urban planners, at an extremely granular street level.\n\nCompared to most of Europe and Asia (where there are public transportation options, human-scale streets, and dense neighborhoods) the United States is light-years away ... but urban planners don‚Äôt have the tools right now to easily assess a specific area‚Äôs walkability.\n\nHere's why this is an urgent problem: Current tools for urban planners don‚Äôt provide location-specific information ‚Äîthey only provide arbitrary, high-level data overviews over a 50-mile or so radius about population density. Even though consumers see new tools, like Google Maps‚Äô area busyness bars, it is only bits and pieces of all the data an urban planner needs, like data on bike paths, bus stops, and the relationships between traffic and pedestrians.\n\nAs a result, there‚Äôs very few actionable improvements that urban planners can make. Moreover, because cities are physical spaces, planners cannot easily visualize what an improvement (e.g. adding a bike/bus lane, parks, open spaces) would look like in the existing context of that specific road. Many urban planners don‚Äôt have the resources or capability to fully immerse themselves in a new city, live like a resident, and understand the problems that residents face on a daily basis that prevent them from accessing public transport, active commutes, or even safe outdoor spaces.\n\nThere‚Äôs also been a significant rise in micro-mobility‚Äîusage of e-bikes (e.g. CityBike rental services) and scooters (especially on college campuses) are growing. Research studies have shown that access to public transport, safe walking areas, and micro mobility all contribute to greater access of opportunity and successful mixed income neighborhoods, which can raise entire generations out of poverty. To continue this movement and translate this into economic mobility, we have to ensure urban developers are making space for car-alternatives in their city planning. This means bike lanes, bus stops, plaza‚Äôs, well-lit sidewalks, and green space in the city.\n\nThese reasons are why our team created CityGO‚Äîa tool that helps urban planners understand their region‚Äôs walkability scores down to the granular street intersection level and instantly visualize what a street would look like if it was actually walkable using Open AI's CLIP and DALL-E image generation tools (e.g. ‚ÄúWhat would the street in front of Painted Ladies look like if there were 2 bike lanes installed?)‚Äù\n\nWe are extremely intentional about the unseen effects of walkability on social structures, the environments, and public health and we are ecstatic to see the results: 1.Car-alternatives provide economic mobility as they give Americans alternatives to purchasing and maintaining cars that are cumbersome, unreliable, and extremely costly to maintain in dense urban areas. Having lower upfront costs also enables handicapped people, people that can‚Äôt drive, and extremely young/old people to have the same access to opportunity and continue living high quality lives. This disproportionately benefits people in poverty, as children with access to public transport or farther walking routes also gain access to better education, food sources, and can meet friends/share the resources of other neighborhoods which can have the huge impact of pulling communities out of poverty.\n\nPlacing bicycle lanes and barriers that protect cyclists from side traffic will encourage people to utilize micro mobility and active transport options. This is not possible if urban planners don‚Äôt know where existing transport is or even recognize the outsized impact of increased bike lanes.\n\nFinally, it‚Äôs no surprise that transportation as a sector alone leads to 27% of carbon emissions (US EPA) and is a massive safety issue that all citizens face everyday. Our country‚Äôs dependence on cars has been leading to deeper issues that affect basic safety, climate change, and economic mobility. The faster that we take steps to mitigate this dependence, the more sustainable our lifestyles and Earth can be."},{"heading":"What it does","content":"TLDR: 1) Map that pulls together data on car traffic and congestion, pedestrian foot traffic, and bike parking opportunities. Heat maps that represent the density of foot traffic and location-specific interactive markers. 2) Google Map Street View API enables urban planners to see and move through live imagery of their site. 3) OpenAI CLIP and DALL-E are used to incorporate an uploaded image (taken from StreetView) and descriptor text embeddings to accurately provide a hyper location-specific augmented image .\n\nThe exact street venues that are unwalkable in a city are extremely difficult to pinpoint. There‚Äôs an insane amount of data that you have to consolidate to get a cohesive image of a city‚Äôs walkability state at every point‚Äîfrom car traffic congestion, pedestrian foot traffic, bike parking, and more.\n\nBecause cohesive data collection is extremely important to produce a well-nuanced understanding of a place‚Äôs walkability, our team incorporated a mix of geoJSON data formats and vector tiles (specific to MapBox API). There was a significant amount of unexpected ‚Äúdata wrangling‚Äù that came from this project since multiple formats from various sources had to be integrated with existing mapping software‚Äîhowever, it was a great exposure to real issues data analysts and urban planners have when trying to work with data.\n\nThere are three primary layers to our mapping software: traffic congestion, pedestrian traffic, and bicycle parking.\n\nIn order to get the exact traffic congestion per street, avenue, and boulevard in San Francisco, we utilized a data layer in MapBox API. We specified all possible locations within SF and made requests for geoJSON data that is represented through each Marker. Green stands for low congestion, yellow stands for average congestion, and red stands for high congestion. This data layer was classified as a vector tile in MapBox API.\n\nConsolidating pedestrian foot traffic data was an interesting task to handle since this data is heavily locked in enterprise software tools. There are existing open source data sets that are posted by regional governments, but none of them are specific enough that they can produce 20+ or so heat maps of high foot traffic areas in a 15 mile radius. Thus, we utilized Best Time API to index for a diverse range of locations (e.g. restaurants, bars, activities, tourist spots, etc.) so our heat maps would not be biased towards a certain style of venue to capture information relevant to all audiences. We then cross-validated that data with Walk Score (the most trusted site for gaining walkability scores on specific addresses). We then ranked these areas and rendered heat maps on MapBox to showcase density.\n\nSan Francisco‚Äôs government open sources extremely useful data on all of the locations for bike parking installed in the past few years. We ensured that the data has been well maintained and preserved its quality over the past few years so we don‚Äôt over/underrepresent certain areas more than others. This was enforced by recent updates in the past 2 months that deemed the data accurate, so we added the geographic data as a new layer on our app. Each bike parking spot installed by the SF government is represented by a little bike icon on the map!\n\nThe most valuable feature is the user can navigate to any location and prompt CityGo to produce a hyper realistic augmented image resembling that location with added infrastructure improvements to make the area more walkable. Seeing the StreetView of that location, which you can move around and see real time information, and being able to envision the end product is the final bridge to an urban developer‚Äôs planning process, ensuring that walkability is within our near future."},{"heading":"How we built it","content":"We utilized the React framework to organize our project‚Äôs state variables, components, and state transfer. We also used it to build custom components, like the one that conditionally renders a live panoramic street view of the given location or render information retrieved from various data entry points.\n\nTo create the map on the left, our team used MapBox‚Äôs API to style the map and integrate the heat map visualizations with existing data sources. In order to create the markers that corresponded to specific geometric coordinates, we utilized Mapbox GL JS (their specific Javascript library) and third-party React libraries.\n\nTo create the Google Maps Panoramic Street View, we integrated our backend geometric coordinates to Google Maps‚Äô API so there could be an individual rendering of each location. We supplemented this with third party React libraries for better error handling, feasibility, and visual appeal. The panoramic street view was extremely important for us to include this because urban planners need context on spatial configurations to develop designs that integrate well into the existing communities.\n\nWe created a custom function and used the required HTTP route (in PHP) to grab data from the Walk Score API with our JSON server so it could provide specific Walkability Scores for every marker in our map.\n\nText Generation from OpenAI‚Äôs text completion API was used to produce location-specific suggestions on walkability. Whatever marker a user clicked, the address was plugged in as a variable to a prompt that lists out 5 suggestions that are specific to that place within a 500-feet radius. This process opened us to the difficulties and rewarding aspects of prompt engineering, enabling us to get more actionable and location-specific than the generic alternative.\n\nAdditionally, we give the user the option to generate a potential view of the area with optimal walkability conditions using a variety of OpenAI models. We have created our own API using the Flask API development framework for Google Street View analysis and optimal scene generation.\n\nHere‚Äôs how we were able to get true image generation to work: When the user prompts the website for a more walkable version of the current location, we grab an image of the Google Street View and implement our own architecture using OpenAI contrastive language-image pre-training (CLIP) image and text encoders to encode both the image and a variety of potential descriptions describing the traffic, use of public transport, and pedestrian walkways present within the image. The outputted embeddings for both the image and the bodies of text were then compared with each other using scaled cosine similarity to output similarity scores. We then tag the image with the necessary descriptors, like classifiers,‚Äîthis is our way of making the system understand the semantic meaning behind the image and prompt potential changes based on very specific street views (e.g. the Painted Ladies in San Francisco might have a high walkability score via the Walk Score API, but could potentially need larger sidewalks to further improve transport and the ability to travel in that region of SF). This is significantly more accurate than simply using DALL-E‚Äôs set image generation parameters with an unspecific prompt based purely on the walkability score because we are incorporating both the uploaded image for context and descriptor text embeddings to accurately provide a hyper location-specific augmented image.\n\nA descriptive prompt is constructed from this semantic image analysis and fed into DALLE, a diffusion based image generation model conditioned on textual descriptors. The resulting images are higher quality, as they preserve structural integrity to resemble the real world, and effectively implement the necessary changes to make specific locations optimal for travel.\n\nWe used Tailwind CSS to style our components."},{"heading":"Challenges we ran into","content":"There were existing data bottlenecks, especially with getting accurate, granular, pedestrian foot traffic data.\n\nThe main challenge we ran into was integrating the necessary Open AI models + API routes. Creating a fast, seamless pipeline that provided the user with as much mobility and autonomy as possible required that we make use of not just the Walk Score API, but also map and geographical information from maps + google street view.\n\nProcessing both image and textual information pushed us to explore using the CLIP pre-trained text and image encoders to create semantically rich embeddings which can be used to relate ideas and objects present within the image to textual descriptions."},{"heading":"Accomplishments that we're proud of","content":"We could have done just normal image generation but we were able to detect car, people, and public transit concentration existing in an image, assign that to a numerical score, and then match that with a hyper-specific prompt that was generating an image based off of that information. This enabled us to make our own metrics for a given scene; we wonder how this model can be used in the real world to speed up or completely automate the data collection pipeline for local governments."},{"heading":"What we learned and what's next for CityGO","content":"Utilizing multiple data formats and sources to cohesively show up in the map + provide accurate suggestions for walkability improvement was important to us because data is the backbone for this idea. Properly processing the right pieces of data at the right step in the system process and presenting the proper results to the user was of utmost importance. We definitely learned a lot about keeping data lightweight, easily transferring between third-party softwares, and finding relationships between different types of data to synthesize a proper output.\n\nWe also learned quite a bit by implementing Open AI‚Äôs CLIP image and text encoders for semantic tagging of images with specific textual descriptions describing car, public transit, and people/people crosswalk concentrations. It was important for us to plan out a system architecture that effectively utilized advanced technologies for a seamless end-to-end pipeline. We learned about how information abstraction (i.e. converting between images and text and finding relationships between them via embeddings) can play to our advantage and utilizing different artificially intelligent models for intermediate processing.\n\nIn the future, we plan on integrating a better visualization tool to produce more realistic renders and introduce an inpainting feature so that users have the freedom to select a specific view on street view and be given recommendations + implement very specific changes incrementally. We hope that this will allow urban planners to more effectively implement design changes to urban spaces by receiving an immediate visual + seeing how a specific change seamlessly integrates with the rest of the environment.\n\nAdditionally we hope to do a neural radiance field (NERF) integration with the produced ‚Äúoptimal‚Äù scenes to give the user the freedom to navigate through the environment within the NERF to visualize the change (e.g. adding a bike lane or expanding a sidewalk or shifting the build site for a building). A potential virtual reality platform would provide an immersive experience for urban planners to effectively receive AI-powered layout recommendations and instantly visualize them.\n\nOur ultimate goal is to integrate an asset library and use NERF-based 3D asset generation to allow planners to generate realistic and interactive 3D renders of locations with AI-assisted changes to improve walkability. One end-to-end pipeline for visualizing an area, identifying potential changes, visualizing said changes using image generation + 3D scene editing/construction, and quickly iterating through different design cycles to create an optimal solution for a specific locations‚Äô walkability as efficiently as possible!"},{"heading":"Built With","content":"api flask mapbox openai python react tailwind"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Fluent.ly","project_url":"https://devpost.com/software/j-jzktbg","tagline":"Fluent.ly revolutionizes the ability to refine language ability. The synergy between our mission and financial support cements our ethically driven approach to bettering the education of the world.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/390/902/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Beginner Hack: 4 x Audio Technica MX50 Headphones"}],"team_members":[],"built_with":[{"name":"auth0","url":null},{"name":"convex","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"microsoft-azure-cognitive-services","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"}],"external_links":[{"label":"github.com","url":"https://github.com/SherveenMehrvarzan/Fluent.ly"}],"description_sections":[{"heading":"Inspiration","content":"We were motivated to tackle linguistic challenges in the educational sector after juxtaposing our personal experience with current news.\n\nThere are currently over 70 million asylum seekers, refugees, or internally-displaced people around the globe, and this statistic highlights the problem of individuals from different linguistic backgrounds being forced to assimilate into a culture and language different than theirs. As one of our teammates was an individual seeking a new home in a new country, we had first hand perspective at how difficult this transition was. In addition, our other team members had volunteered extensively within the educational system in developing communities, both locally and globally, and saw a similar need with individuals being unable to meet the community‚Äôs linguistics standards.\n\nWe also iterated upon our idea to ensure that we are holistically supporting our communities by making sure we consider the financial implications of taking the time to refine your language skills instead of working."},{"heading":"What it does","content":"Fluently‚Äôs main purpose is to provide equitable education worldwide. By providing a user customized curriculum and linguistic practice, students can further develop their understanding of their language. It can help students focus on areas where they need the most improvement. This can help them make progress at their own pace and feel more confident in their language skills while also practicing comprehension skills. By using artificial intelligence to analyze pronunciation, our site provides feedback that is both personalized and objective."},{"heading":"How we built it","content":"Developing the web application was no easy feat.\n\nAs we were searching for an AI model to help us through our journey we stumbled upon OpenAI, specifically Microsoft Azure‚Äôs cognitive systems that utilize OpenAI‚Äôs comprehensive abilities in language processing. This API gave us the ability to analyze voice patterns and fluency and transcribe passages that are mentioned in the application. Figuring out the documentation as well as how the AI will be interacting with the user was most important for us to execute properly since the AI would be acting as the tutor/mentor for the students in these cases. We developed a diagram that would break down the passages read to the student phonetically and give them a score of 100 for how well each word was pronounced based on the API‚Äôs internal grading system. As it is our first iteration of the web app, we wanted to explore how much information we could extract from the user to see what is most valuable to display to them in the future.\n\nIntegrating the API with the web host was a new feat for us as a young team. We were confident in our python abilities to host the AI services and found a library by the name of Flask that would help us write html and javascript code to help support the front end of the application through python. By using Flask, we were able to host our AI services with python while also continuously managing our front end through python scripts.\n\nThis gave room for the development of our backend systems which are Convex and Auth0. Auth0 was utilized to give members coming into the application a unique experience by having them sign into a personalized account. The account is then sent into the Convex database to be used as a storage base for their progress in learning and their development of skills over time. All in all, each component of the application from the AI learning models, generating custom passages for the user, to the backend that communicated between the Javascript and Python server host that streamlines the process of storing user data, came with its own challenges but came together seamlessly as we guide the user from our simple login system to the passage generator and speech analyzer to give the audience constructive feedback on their fluency and pronunciation."},{"heading":"Challenges we ran into","content":"As a majority beginning team, this was our first time working with many of the different technologies, especially with AI APIs. We need to be patient working with key codes and going through an experiment process of trying different mini tests out to then head to the major goal that we were headed towards. One major issue that we faced was the visualization of data to the user. We found it hard to synthesize the analysis that was done by the AI to translate to the user to make sure they are confident in what they need to improve on. To solve this problem we first sought out how much information we could extract from the AI and then in future iterations we would simply display the output of feedback.\n\nAnother issue we ran into was the application of convex into the application. The major difficulty came from developing javascript functions that would communicate back to the python server hosting the site. This was resolved thankfully; we are grateful for the Convex mentors at the conference that helped us develop personalized javascript functions that work seamlessly with our Auth0 authentication and the rest of the application to record users that come and go."},{"heading":"Accomplishments that we're proud of:","content":"One accomplishment that we are proud of was the implementation of Convex and Auth0 with Flask and Python. As python is a rare language to host web servers in and isn't the primary target language for either service, we managed to piece together a way to fit both services into our project by collaboration with the team at Convex to help us out. This gave way to a strong authentication platform for our web application and for helping us start a database to store user data onto.\n\nAnother accomplishment was the transition of using a React Native application to using Flask with Python. As none of the group has seen Flask before or worked for it for that matter, we really had to hone in our abilities to learn on the fly and apply what we knew prior about python to make the web app work with this system.\n\nAdditionally, we take pride in our work with OpenAI, specifically Azure. We researched our roadblocks in finding a voice recognition AI to implement our natural language processing vision. We are proud of how we were able to display resilience and conviction to our overall mission for education to use new technology to build a better tool."},{"heading":"What we learned","content":"As beginners at our first hackathon, not only did we learn about the technical side of building a project, we were also able to hone our teamwork skills as we dove headfirst into a project with individuals we had never worked with before.\n\nAs a group, we collectively learned about every aspect of coding a project, from refining our terminal skills to working with unique technology like Microsoft Azure Cognitive Services. We also were able to better our skillset with new cutting edge technologies like Convex and OpenAI.\n\nWe were able to come out of this experience not only growing as programmers but also as individuals who are confident they can take on the real world challenges of today to build a better tomorrow."},{"heading":"What's next?","content":"We hope to continue to build out the natural language processing applications to offer the technology in other languages. In addition, we hope to hone to integrate other educational resources, such as videos or quizzes to continue to build other linguistic and reading skill sets. We would also love to explore the cross section with gaming and natural language processing to see if we can make it a more engaging experience for the user. In addition, we hope to expand the ethical considerations by building a donation platform that allows users to donate money to the developing community and pay forward the generosity to ensure that others are able to benefit from refining their linguistic abilities. The money would then go to a prominent community in need that uses our platform to fund further educational resources in their community."},{"heading":"Bibliography","content":"United Nations High Commissioner for Refugees. ‚ÄúGlobal Forced Displacement Tops 70 Million.‚Äù UNHCR, UNHCR, The UN Refugee Agency, https://www.unhcr.org/en-us/news/stories/2019/6/5d08b6614/global-forced-displacement-tops-70-million.html ."},{"heading":"Built With","content":"auth0 convex css html javascript microsoft-azure-cognitive-services openai python"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Health Story","project_url":"https://devpost.com/software/health-story","tagline":"Introducing Health Story, our revolutionary app for hypertension management - a game-changer for doctors and patients alike. Say goodbye to piles of notes and medical errors!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/390/578/datas/medium.jpeg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Healthcare GrandPrize: 4 x Apple Watch SE"}],"team_members":[],"built_with":[{"name":"amazon-web-services","url":"https://devpost.com/software/built-with/amazon-web-services"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"vue","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/rajas1998/HealthStoryBackend"},{"label":"github.com","url":"https://github.com/DhruvaBansal00/Frontend-TreeHacks"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration behind building this app was to address the critical issue of medical errors in healthcare. According to a study by Johns Hopkins, medical errors are the third leading cause of death in the United States, after heart disease and cancer, with an estimated 250,000 deaths per year. These errors can occur due to various factors, including miscommunication and lack of complete patient information. Doctors have to go through piles of notes and patient histories, leading to time-consuming processes and increased risk of medical errors. By streamlining the conversation between doctors and patients and providing a clear overview of the patient's health status other relevant diagnosis information, Health Story aims to reduce the risk of medical errors and ultimately improve patient outcomes. Our mission is to make health management more efficient, effective, and safe for both doctors and patients.\n\nThe following are the facts that show how extreme this problem is:\n\nHaving hypertension puts you at risk for heart disease and stroke, which are leading causes of death in the United States. In 2020, more than 670,000 deaths in the United States had hypertension as a primary or contributing cause Only about 1 in 4 adults (24%) with hypertension have their condition under control."},{"heading":"What It Does","content":"We built Health Story, a web app that combines cutting-edge tech with a human-centered approach to address the common challenges faced by doctors by providing a comprehensive overview of a patient's medical history in one place. Our app consists of multiple features as outlined below.\n\nSpeech2SOAP\n\nDoctors and nurses spend countless hours in writing medical notes, and summarizing them into the SOAP format (S-Subjective, O-Objective, A-Assessment, P-Plan). With a live transcription feature, doctors can now focus on their patients instead of taking notes. This feature not only transcribes the conversation, but also converts the conversation into a medical SOAP format which summarizes the patient's history over the last few visits, providing doctors with a quick and clear understanding of the patient's health status. We are different from existing solutions as we help the doctors find correlations and information that they need but cant find easily. We solve the 'tell me something I didn't know' problem.\n\nHealth Analyzer\n\nWe also integrate an analytics dashboard into our app which depicts a trend in vital health metrics (blood pressure, heart rate, etc), and provide \"smart\" comments on the inflection points in the patient's health trend over time. This enables the doctors to make more informed decisions and improve patient outcomes without having to sift through countless pages of notes.\n\nDrugs\n\nIt is crucial for the doctors to assess whether the patient is taking the right kind of medication in the right amount and at regular intervals. To help doctors make this assessment, we build a tracker which displays whether or not they have been taking the medications as prescribed based on the patient doctor conversation.\n\nTests\n\nIn this component, we display information regarding diagnostic tests that were conducted on the patient by different medical providers. Along with displaying test results, we also extract the reason behind why a test was ordered, when was the test conducted, or why wasn't the test performed in spite of being ordered."},{"heading":"How We Built It","content":"Our application consists of a main front end built with Vue and a backend built with Python, with Flask as our server. We used AWS Transcribe to convert speech to text, while for summarizing the doctor patient conversation into a medical SOAP format, we used OpenAI's GPT-3 to extract meaningful and relevant insights from the dialogue."},{"heading":"Challenges we ran into","content":"The main challenge for us was to learn deeply about the medical industry and specifically about hypertension. We spent a lot of time talking to the organizers, sponsors, doctors and nurses around the world and listened to their opinions on our ideas. Secondly, we also found it difficult to come to a conclusion regarding what specific features we wanted in our final product. To do so, we talked to doctors and nurses to get feedback on our proposal, learn about their actual needs, and finally refine the scope of our idea."},{"heading":"Accomplishments that we're proud of","content":"We are proud of our idea and commitment - the amount of energy and passion that we put into this project to solve a real-world problem was something special and close to our hearts. The accomplishment that we are most proud about is the impact that this product could have on elevating the efficiency of the healthcare system and thereby saving more lives."},{"heading":"What we learned","content":"Building this app for the hackathon has been a tremendous learning experience for us. We learned how to work under tight deadlines, collaborate effectively with a team, and solve problems creatively. Specifically, we learned about the challenges faced by doctors and how extracting relevant information from medical conversations and presenting them in a meaningful manner can help reduce medical errors.\n\nThrough this hackathon, we also had the opportunity to learn from other developers and mentors, who provided valuable feedback and insights on our app. We learned about the latest trends and best practices in the field, as well as strategies for improving the user experience and increasing the app's value proposition. Overall, this hackathon has been an enriching learning experience, and we look forward to applying the lessons and skills we gained to future projects."},{"heading":"References and Sources","content":"Centers for Disease Control and Prevention, National Center for Health Statistics. About Multiple Cause of Death, 1999‚Äì2020. CDC WONDER Online Database website. Atlanta, GA: Centers for Disease Control and Prevention; 2022. Accessed February 21, 2022. Whelton PK, Carey RM, Aronow WS, Casey DE, Collins KJ, Dennison C, et al. 2017 ACC/AHA/AAPA/ABC/ACPM/AGS/APhA/ASH/ASPC/NMA/PCNA Guideline for the prevention, detection, evaluation, and management of high blood pressure in adults. Hypertension. 2018;71(19):e13‚Äì115. Centers for Disease Control and Prevention. Hypertension Cascade: Hypertension Prevalence, Treatment and Control Estimates Among U.S. Adults Aged 18 Years and Older Applying the Criteria from the American College of Cardiology and American Heart Association‚Äôs 2017 Hypertension Guideline‚ÄîNHANES 2015‚Äì2018. Atlanta, GA: U.S. Department of Health and Human Services; 2021. Accessed March 12, 2021. Farley TA, Dalal MA, Mostashari F, Frieden TR. Deaths preventable in the U.S. by improvements in the use of clinical preventive services. Am J Prev Med. 2010;38(6):600‚Äì609 https://www.corhealthontario.ca/HTN-Follow-Up-Protocol-(2018).pdf"},{"heading":"Built With","content":"amazon-web-services flask python vue"},{"heading":"Try it out","content":"github.com github.com"}]},{"project_title":"ShipSense.app (+ novel AI-powered data augmentation method)","project_url":"https://devpost.com/software/shipsense-ai-novel-data-augmentation-protocol","tagline":"Mitigating overfishing through AI-augmented satellite imagery and data viz dashboard. Novel few-shot synthetic image data augmentation method using fine-tuned Stable Diffusion for any object.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/386/478/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Sustainability Grand Prize: 4 x Apeman M4 DLP Projector 1080P"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Innovative Hack by Meta: 4 x Meta Swag - Backpack & Blankets & Sweatshirts & T-Shirts & Beanies"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Data Hack by HRT: 4 x Access to online HRT VIP Swag Store & $150 Amazon Gift Card"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Replit's Choice Award: 3000 Replit Cycles + 3 mo of Hacker Subscription (1st Place) & 2000 Replit Cycles + 2 mo of Hacker Subscription (2nd Place) & 1000 Replit Cycles + 1 mo of Hacker Subscription (3rd Place)"}],"team_members":[],"built_with":[{"name":"chakra","url":null},{"name":"folium","url":null},{"name":"keras","url":null},{"name":"multiprocessing","url":null},{"name":"nextjs","url":null},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"openai","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"pillow","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"stablediffusion","url":null},{"name":"tensorflow","url":null}],"external_links":[{"label":"shipsense.app","url":"https://shipsense.app/"},{"label":"github.com","url":"https://github.com/SohamGovande/treehacks-2023"},{"label":"docs.google.com","url":"https://docs.google.com/document/d/1HXQFVR9KneeYJkby3gI7vXaiBwKuPViMJpXMb-mG0sQ/edit?usp=sharing"}],"description_sections":[{"heading":"TL; DR","content":"Illegal overfishing is a massive issue ( >200 billion fish /year), disrupting global ecosystems and placing hundreds of species at risk of extinction. Satellite imagery can detect fishing ships but there's little positive data to train a good ML model. To get synthetic data: we fine-tuned Stable Diffusion on 1/1000ths of the data of a typical GAN (and 10x training speed) on images of satellite pictures of ships and achieved comparable quality to SOTA. We only used 68 original images! We trained a neural network using our real and synthetic data that detected ships with 96% accuracy. Built a global map and hotspot dashboard that lets governments view realtime satellite images, analyze suspicious activity hotspots, & take action. Created a custom polygon renderer on top of ArcGIS Our novel Stable Diffusion data augmentation method has potential for many other low-data applications.\n\nGot you hooked? Keep reading!"},{"heading":"Let's get reel...","content":"Did you know global fish supply has decreased by 49% since 1970?\n\nWhile topics like deforestation and melting ice dominate sustainability headlines, overfishing is a seriously overlooked issue. After thoroughly researching sustainability, we realized that this was an important but under-addressed challenge.\n\nWe were shocked to learn that 90% of fisheries are over-exploited or collapsing. What's more, around 1 trillion (1,000,000,000,000) fish are caught yearly.\n\nHailing from San Diego, Boston, and other cities known for seafood, we were shocked to hear about this problem. Research indicates that despite many verbal commitments to fish sustainably, one in five fish is illegally caught . What a load of carp!\n\nPeople are shellfish...\n\nAround the world, governments and NGOs have been trying to reel in overfishing, but economic incentives and self-interest mean that many ships continue to exploit resources secretly. It's hard to detect small ships on the world's 140 million square miles of ocean."},{"heading":"What we're shipping","content":"In short (we won't keep you on the hook): we used custom Stable Diffusion to create realistic synthetic image data of ships and trained a convolutional neural networks (CNNs) to detect and locate ships from satellite imagery. We also built a data visualization platform for stakeholders to monitor overfishing. To enhance this platform, we identified several hotspots of suspicious dark vessel activity by digging into 55,000+ AIS radar records.\n\nWhile people have tried to build AI models to detect overfishing before, accuracy was poor due to high class imbalance. There are few positive examples of ships on water compared to the infinite negative examples of patches of water without ships. Researchers have used GANs to generate synthetic data for other purposes. However, it takes around 50,000 sample images to train a decent GAN. The largest satellite ship dataset only has ~2,000 samples.\n\nWe realized that Stable Diffusion (SD), a popular text-to-image AI model, could be repurposed to generate unlimited synthetic image data of ships based on relatively few inputs. We were able to achieve highly realistic synthetic images using only 68 original images."},{"heading":"How we shipped it","content":"First, we read scientific literature and news articles about overfishing, methods to detect overfishing, and object detection models (and limitations). We identified a specific challenge: class imbalance in satellite imagery.\n\nNext, we split into teams. Molly and Soham worked on the front-end, developing a geographical analysis portal with React and creating a custom polygon renderer on top of existing geospatial libraries. Andrew and Sayak worked on curating satellite imagery from a variety of datasets, performing classical image transformations (rotations, flips, crops), fine-tuning Stable Diffusion models and GANs (to compare quality), and finally using a combo of real and synthetic data to train an CNN. Andrew also worked on design, graphics, and AIS data analysis. We explored Leap ML and Runway fine-tuning methods."},{"heading":"Challenges we tackled","content":"Building Earth visualization portals are always quite challenging, but we could never have predicted the waves we would face. Among animations, rotations, longitude, latitude, country and ocean lines, and the most-feared WebGL, we had a lot to learn. For ocean lines, we made an API call to a submarine transmissions library and recorded features to feed into a JSON. Inspired by the beautiful animated globes of Stripe's and CoPilot's landing pages alike, we challengingly but succeedingly wrote our own.\n\nAdditionally, the synthesis between globe to 3D map was difficult, as it required building a new scroll effect compatible with the globe. These challenges, although significant at the time, were ultimately surmountable, as we navigated through their waters unforgivingly. This enabled the series of accomplishments that ensued.\n\nIt was challenging to build a visual data analysis layer on top of the ArcGIS library. The library was extremely granular, requiring us to assimilate the meshes of each individual polygon to display. To overcome this, we built our own component-based layer that enabled us to draw on top of a preexisting map."},{"heading":"Making waves (accomplishments)","content":"Text-to-image models are really cool but have failed to find that many real-world use cases besides art and profile pics. We identified and validated a relevant application for Stable Diffusion that has far-reaching effects for agricultural, industry, medicine, defense, and more.\n\nWe also made a sleek and refined web portal to display our results, in just a short amount of time. We also trained a CNN to detect ships using the real and synthetic data that achieved 96% accuracy."},{"heading":"What we learned","content":"How to tackle overfishing:\n\nWe learned a lot about existing methods to combat overfishing that we didn't know about. We really became more educated on ocean sustainability practices and the pressing nature of the situation. We schooled ourselves on AIS, satellite imagery, dark vessels, and other relevant topics.\n\nDon't cast a wide net. And don't go overboard.\n\nOriginally, we were super ambitious with what we wanted to do, such as implementing Monte Carlo particle tracking algorithms to build probabilistic models of ship trajectories. We realized that we should really focus on a couple of ideas at max because of time constraints.\n\nDivide and conquer\n\nWe also realized that splitting into sub-teams of two to work on specific tasks and being clear about responsibilities made things go very smoothly.\n\nGeographic data visualization\n\nBuilding platforms that enable interactions with maps and location data."},{"heading":"What's on the horizon (implications + next steps)","content":"Our Stable Diffusion data augmentation protocol has implications for few-shot learning of any object for agricultural, defense, medical and other applications. For instance, you could use our method to generate synthetic lung CT-Scan data to train cancer detection models or fine-tune a model to detect a specific diseased fruit not covered by existing general-purpose models.\n\nWe plan to create an API that allows anyone to upload a few photos of a specific object. We will build a large synthetic image dataset based off of those objects and train a plug-and-play CNN API that performs object location, classification, and counting.\n\nWhile general purpose object detection models like YOLO work well for popular and broad categories like \"bike\" or \"dog\", they aren't feasible for specific detection purposes. For instance, if you are a farmer trying to use computer vision to detect diseased lychees. Or a medical researcher trying to detect cancerous cells from a microscope slide. Our method allows anyone to obtain an accurate task-specific object detection model. Because one-size-fits-all doesn't cut it.\n\nWe're excited to turn the tide with our fin-tech!\n\nHow many fish/ocean-related puns did you find?"},{"heading":"Built With","content":"chakra folium keras multiprocessing nextjs numpy openai opencv pandas pillow python react stablediffusion tensorflow"},{"heading":"Try it out","content":"shipsense.app github.com docs.google.com"}]},{"project_title":"ControlDB","project_url":"https://devpost.com/software/controldb","tagline":"Accelerating access to web3 data storage at scale. 100X cheaper, more secure, more persistent than existing cloud data providers. Easier to use, faster to implement than competing Web3 solutions.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/387/390/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Estuary: 4 x iPad 10th Gen (1st Place) & 4 x Mechanical Gaming Keyboards (2nd Place)"}],"team_members":[],"built_with":[{"name":"b+tree","url":null},{"name":"caching","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"estuary","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"golang","url":"https://devpost.com/software/built-with/golang"},{"name":"ipfs","url":null},{"name":"nextjs","url":null},{"name":"solidity","url":"https://devpost.com/software/built-with/solidity"},{"name":"tailwindcss","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"controldb.carrd.co","url":"https://controldb.carrd.co/"},{"label":"github.com","url":"https://github.com/ControlDb"},{"label":"tinyurl.com","url":"https://tinyurl.com/controldb-slides"}],"description_sections":[{"heading":"TLDR","content":"We are a developer toolkit which provides a decentralized database as a service where users can use our endpoints as well as NoCode tool where users can upload their data in a decentralised manner."},{"heading":"Inspiration","content":"üëãüèª With the advent of Web3, there are now decentralized ways to store data that are a hundred times cheaper than Web2 solutions . Such methods are equally, if not more secure, dependable and scalable.\n\nüò© However, using them remains vastly more technically challenging and time consuming than traditional alternatives.\n\nü§ì As Web3 developers, even as we've sought to push the envelope with frontier blockchain technology, we've run into limitations with Web2 solutions time and time again ."},{"heading":"What it does","content":"ü´° ControlDB‚Äôs mission is to bridge this gap between cost and performance , allowing developers to use exponentially cheaper IPFS distributed file storage, while circumventing much of the complexity and limitations that normally come with it.\n\nüöÄ IPFS, the InterPlanetary File System, is a peer-to-peer file sharing network. Files are sharded across multiple nodes. Building on this protocol allows ControlDB to fundamentally ensure user data remains decentralized, preventing a single source of failure because of IPFS' distributed nature.\n\n‚ùå A limitation of IPFS, however, is that shards of files are made public.\n\n‚úÖ To overcome this, ControlDB adds an additional layer of encryption to further increase user privacy. In the event that a user's IPFS hash is intercepted, an attacker will still have to circumvent the additional layer of advanced encryption, keeping users' data safe.\n\n‚ùå IPFS also has no inherent read or write controls, necessary for handling sensitive data across multiple agents, for example in healthcare.\n\n‚úÖ Here ControlDB introduces a permission layer onto files, allowing admins to designate different levels of file access across multiple stakeholders with varied roles.\n\n‚ùå IPFS is also accessed through command line interface, making it hard to debug and understand.\n\n‚úÖ In contrast ControlDB adds a user-friendly GUI on top of IPFS‚Äô command line based function, allowing non-technical users to access its features. A simplified API makes it easy and quick for developers to implement ControlDB‚Äôs file storage into their programs. Doing so circumvents the need for developers to build a new IPFS pipeline, reducing the barrier to entry for smaller and/or less experienced teams.\n\n‚úÖ Our architecture is designed to be plug-and-play, which means that you can easily switch between different storage endpoints, such as IPFS or Estuary or any other option where you just need to add a configuration file, depending on your needs. This provides you with the flexibility to use the database of your choice, while still taking advantage of our platform's powerful features.\n\nüî•üî•üî• Altogether ControlDB will save developers significant amounts of time, money and technical headache, allowing them to scale usage from simple to complex use cases as their software grows.\n\nüòåüòåüòå It will also improve the availability of files, reduce privacy concerns, and grant users increased control over their data."},{"heading":"How we built it","content":"üõ†Ô∏è ControlDB was built with TypeScript and Golang. Its MVP consists of a fully functional backend with full encryption, decryption and sharding across multiple nodes implemented, as well as a fully functional frontend with login, file upload and retrieval. We even built a working user interface.\n\nü§ùüèª Yes, everything is fully working . ü´°ü´°ü´°\n\nTechnical Architecture\n\nOverall Architecture\n\nWe have an API Server which interacts with the Node Cluster which is a wrapper to any decentralised storage system. We spun up 3 IPFS nodes locally which are used as the decentralised storage engine.\n\nNo code frontend tool Our front end allows users to easily upload their data onto decentralised file storage quickly without any hassle or code.\n\nAPI Server\n\nAPI Server: This layer accepts user requests via our Frontend as well as the HTTP API requests. The permissions are fetched out of payload which user sent and then the main data is used for the further part.\n\nMiddleware Node Cluster\n\nMiddleware Node: A search engine is developed in this layer using B+ Trees for faster retrieval of data and lookup. As the data is received from the user, we encrypt it using AES-256 and generate the encryption key. A unique id is also generated in this node which will be used as a key for insertion in the B+ Tree. The package of permissions, encryption key and IPFS Hash is generated for the insertion in B+ Trees.\n\nIPFS Nodes We have started 3 IPFS nodes which interacts with our middleware node.\n\nFirstly, IPFS is installed on the operating system by following the official IPFS documentation. This step provides the necessary software to create and manage the IPFS cluster.\n\nNext, IPFS is initialized on each node using the ipfs init command, which creates configuration files for ipfs-cluster-ctl to interact with the nodes. This step is essential to ensure that the IPFS nodes are ready to be managed by the cluster.\n\nA configuration file is created using the default docker-compose.yml file, or a custom configuration file can be used to set up the cluster. The configuration file specifies how many IPFS cluster nodes and Kubo nodes are to be created, which determines the cluster's capacity and the method of interaction with the nodes.\n\nThe Kubo nodes sit on top of the IPFS cluster nodes and provide a way for users to interact with the cluster via HTTP API or IPFS client. This interaction enables users to manage and control the IPFS cluster by creating endpoints that allow various actions to be performed on the nodes.\n\nOnce the cluster is set up, users can create endpoints to perform various actions on the cluster nodes. These endpoints can be migrated as necessary, enabling the cluster to be flexible and adaptable to changing requirements."},{"heading":"Challenges we ran into","content":"üßê At first, the team struggled with ideation, and considered a broad spectrum of potential pathways. There was a struggle to find consensus. We also had little to no experience with IPFS, and no idea how to architect or scope it down. This was overcome with much discussion and research.\n\nChallenges we ran into:\n\nDeveloping the ACL and integrating it with the IPFS. Starting the local IPFS architecture. As we were running the local IPFS server, we faced the CORS issue in the IPFS nodes which prevented us to access from different origins. Developing B+ search tree as per our use case of adding multiple values. Integration of different components we built. Integration with Estuary APIs for using them as the storage engine along with IPFS."},{"heading":"Accomplishments that we're proud of","content":"üôèüèª We are incredibly proud to achieve a fully functional MVP within 36 hours. Integrating IPFS from zero experience, as well as permission and encryption layers, ensuring everything runs stably, has been a huge accomplishment within the short time we've had."},{"heading":"What we learned","content":"üíØ This was a great deep dive into the world of decentralized data storage, IPFS and building permission layers. We also learnt to build synergy as a team, and how to build a strong team together, leveraging each individual's unique strengths."},{"heading":"What's next for ControlDB","content":"ü•≥ We'd like to change encryption keys over time, reducing vulnerabilities to attacks."},{"heading":"Built With","content":"b+tree caching docker estuary github golang ipfs nextjs solidity tailwindcss typescript"},{"heading":"Try it out","content":"controldb.carrd.co github.com tinyurl.com"}]},{"project_title":"Domi Rental Companion","project_url":"https://devpost.com/software/domi-rental-companion","tagline":"We are enhancing the experience of private properties for landlords and tenants while increasing convenience, transparency, and satisfaction.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/818/datas/medium.PNG","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Web 3.0 & Fintech Grand Prize: 4 x Airline Gift Card for Crypto Conference"}],"team_members":[],"built_with":[{"name":"convex","url":null},{"name":"modal","url":null},{"name":"openai","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"reactnative","url":null},{"name":"stripe","url":"https://devpost.com/software/built-with/stripe"}],"external_links":[{"label":"github.com","url":"https://github.com/punnkam/domi"}],"description_sections":[{"heading":"Inspiration","content":"From our experience renting properties from private landlords, we think the rental experience is broken. Payments and communication are fragmented for both landlords and tenants. As tenants, we have to pay landlords through various payment channels, and that process is even more frustrating if you have roommates. On the other hand, landlords have trouble reconciling payments coming from these several sources.\n\nWe wanted to build a rental companion that initially tackles this problem of payments, but extends to saving time and headaches in other aspects of the rental experience. As we are improving convenience for landlords and tenants, we focused solely on a mobile application."},{"heading":"What it does","content":"Allows tenants to make payments quickly in less than three clicks Chatbot interface that has information about the property's lease and state-specific rental regulation Landlords monitor the cash flow of their properties transparently and granularly"},{"heading":"How we built it","content":"Full stack React Native app Convex backend and storage Stripe credit card integration Python backend for Modal & GPT3 integration"},{"heading":"Challenges we ran into","content":"Choosing a payment method that is reliable and fast to implement Parsing lease agreements and training GPT3 models Deploying and running modal.com for the first time Ensuring transaction integrity and idempotency on Convex"},{"heading":"Accomplishments that we're proud of","content":"Shipped chat bot although we didn't plan to Pleased about the UI design"},{"heading":"What we learned","content":"Mobile apps are tough for hackathons Payment integrations have become very accessible"},{"heading":"What's next for Domi Rental Companion","content":"See if we provide value for target customers"},{"heading":"Built With","content":"convex modal openai react reactnative stripe"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Zazu: AI Teaching Assistant","project_url":"https://devpost.com/software/zazu-8j6vg5","tagline":"An AI TA built into a video call app to help teachers with live lectures.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/414/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Education Grand Prize: 4 x Nintendo Switch"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Dolby.io: $1000 in GiftCards"}],"team_members":[],"built_with":[{"name":"dolby.io","url":null},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"github.com","url":"https://github.com/jtcheng26/treehacks"}],"description_sections":[{"heading":"Inspiration","content":"The main inspiration of the idea was in our own personal experience when we are in the middle of a live lecture or watching a pre recorded zoom lecture, and we had a question regarding the topic. The process of googling a result one the side while the lecture is going on is usually a herculean task that involves managing multiple tabs and usually always falling behind on the notes. Our website solves this problem."},{"heading":"What it does","content":"Zazu is a video call platform designed for teachers and students. It allows students to have access to an AI TA right in their video call so that they can ask questions to the TA while not disturbing the teacher and the flow of the lecture. The teacher can also use a slew of AI powered features, such as generating quiz questions on demand to ask the students to check engagement. The teacher can also generate polls in lecture simply by asking Zazu to \"generate poll\" and a poll will be sent to all students instantly. At the end of the lecture once a student leaves call, a summary is created of the lecture with bullet point notes for the student, basically eliminating the need for students to manually take notes. The video call platform also supports all the features of Zoom and has AI features built on top of it."},{"heading":"How we built it","content":"The front end of the website was built using the Dolby.io framework and React which allowed us to quickly implement most of the video call features. The backend is powered by Flask where we make multiple open ai requests to their Davinci model to get our results. We use Firebase Cloud Firestore to store our data and socket.io to communicate data between our server and client. We hosted our server on [server]. Most of the development revolved around building out features in React for the front end and building out API endpoints in Python on the backend. We heavily use OpenAI's Davinci LLM and a lot of time was spent prompt engineering to get the data that we require for each of our different features."},{"heading":"Challenges we ran into","content":"The main challenge we ran into was getting the data from the Davinci LLM in a format that was consistent with every API call. We had to spend a large part of our time designing specific prompts for the LLM so that we get the response in the same format every time regardless of the topic of the lecture. We also had to spend a decent chunk of time on parsing the transcript of the lecture and filtering out meaningless remarks and noise in the data. To solve this, we had to use NLP filters in the backend and models to periodically summarize the transcript which makes it easier to send to the LLM to get results."},{"heading":"Accomplishments that we're proud of","content":"We are extremely proud of the verbal speech-to-text commands that we built to help support teachers during their lecture. By simply invoking the command, \"generate quiz\", a multiple choice question about the topic of the lecture is generated by the Davinci LLM and instantly sent to all the students on call. This is powered by a slew of APIs and frameworks which is extremely impressive since our team is made up of mostly beginner hackers and this is most of our's first hackathon."},{"heading":"What we learned","content":"The main concept we learned was how to build an end-to-end application with a complete feature set. We also got a significant amount of experience in using OpenAI's APIs and Dolby.io framework to create a front end video call app. Large portion of the time was dedicated to bug fixing and we learned a lot about version control and how to build a large project in parallel with different members contributing to different features."},{"heading":"What's next for Zazu","content":"Zazu has the potential to become a great tool for educators around the world. The immediate next steps are to expand the feature set and make it complete with all the features of Zoom. We would also want to add support for using our feature set not only on video calls but also on pre-recorded lectures. Then we would ideally publish the app and market it to teachers, specifically college professors where this would largely come into play."},{"heading":"Built With","content":"dolby.io firebase flask openai python react"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Ally","project_url":"https://devpost.com/software/ally-kmoagt","tagline":"Ally makes drone data management simple, giving non-technical people easy access to automated workflows for their drone data. Our drag-and-drop platform gives users critical time back to save lives.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/388/281/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Privacy & Safety Grand Prize: 4 x Mark VII + AC Tactical WiFi Pineapples"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"next","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"dripdrones.vercel.app","url":"https://dripdrones.vercel.app/"},{"label":"github.com","url":"https://github.com/AllenWang314/drones_go_burr"}],"description_sections":[{"heading":"Inspiration","content":"Tens of thousands of people are dying every year in natural disasters due to poor infrastructure.\n\nMonths after the devastating 2008 earthquake in Sichuan, China, Mindy visited the region and witnessed the horrific consequences of lacking up-to-code infrastructure. She spoke with locals, meeting a grandmother carrying a baby whose father was lost in the rubble when she was only 10 days old. Fast forward to today, the death tolls are now in the tens of thousands due to the Turkey-Syria earthquakes, with at least 20,000 victims still lying beneath the rubble. More than 6,000 buildings collapsed in the region, but a lot of the damage could have been prevented with better infrastructure monitoring.\n\nThese earthquakes were extremely deadly because these cities did not enforce building codes or treat safe housing as a human right (Vox News). Construction companies have been cutting corners and ignoring building codes for decades, and the government often just lets it slide.\n\nThrough researching current processes rescue teams use to help on-site, we started piecing together how impactful drones can be in this space. Specifically, we decided to create automated workflows because we‚Äôve worked with drone data before and know that it‚Äôs a lot to take on as a first-time user."},{"heading":"What it does","content":"Ally makes drone data management simple, giving non-technical people easy access to automated workflows for their drone data. Commercial uses of drone technology have been most prevalent in fields such as agriculture, forestry management, urban planning, and disaster relief, where most users are not technically familiar with image processing. Our end-to-end platform allows users to drag-and-drop tasks (i.e. for our current focus of disaster management: locate people stranded under rubble; map 3D reconstructions of high-priority areas; annotate imagery and send to relevant teams) into a custom workflow. For example, a search-and-rescue official‚Äôs workflow could be [search(‚Äùpeople in rubble‚Äù), map/locate() results]. Our goal is to eliminate overhead and allow any users to efficiently comb through drone image data to make informed decisions.\n\nDuring the hackathon, we focused on connecting drone images to semantic search, using OpenAI‚Äôs Clip neural network that brings together text and images. Users can upload drone images, search for keywords to resurface important timeframes, and sort images based on how close their query is."},{"heading":"What we learned","content":"Drones : Though we‚Äôve worked with drones before, Treehacks was the first time we had access to such high-tech drones from Skydio and Parrot. It was super inspiring to learn about how fast the industry is advancing and see how passionate their teams were about their technology. Disaster Management : We learned so much about the problems surrounding disaster management and narrowed down one of the major pain points‚Äì bad infrastructure. It was disappointing to hear that many of the lives lost in these natural disasters were very preventable if all parties acted ethically from the start. OpenAI CLIP Model : Most models like ChatGPT use only one form of input: text. OpenAI‚Äôs CLIP model is one of the first to effectively connect images and text by embedding them in the same vector space. This allows us to basically map out not only how close images are to each other in meaning, but also how close they are to words and phrases. Treehacks was the first time we‚Äôve worked with an existing ML model with pre-trained weights‚Äîsetting up was definitely a challenge. Image search : We learned that image search is hard to do. We considered alternative image search approaches, like using keywords, or other current AI methods. However, the CLIP model seemed to be the highest performing one. At the moment, CLIP performs well out-of-the-box without fine tuning. In the future, we see ways to improve the search by training CLIP further."},{"heading":"Future","content":"There are lots of interesting possibilities for the future. After we create the automated workflow platform, we can expand to different customer bases. Farmers can create workflows to monitor their land (identify areas with pests, monitor soil moisture, track movement and health of livestock) and alert relevant teams. City planners can create workflows to monitor urban growth, detect poor infrastructure, and report any damage. Construction workers can create workflows to send their drones on routine checkups, inspect infrastructure for potential problems, and send alerts to intervening teams.\n\nBusiness Model\n\nThe current plan is a freemium approach, where we give away free 1GB accounts and charge for # of users, additional storage, number of integrations, and/or computer power. We plan on first giving our platform for free out to disaster managers so they can setup their workflows and start using it for prevention methods. This way they are setup for success in the case that disaster strikes.\n\nThe global disaster management market is expected to grow to 5.2 billion by 2027. The global agricultural drone market is expected to reach USD 1.7 billion by 2025, and the global market for urban planning is expected to reach USD 7.6 billion by 2027. In addition, with the rise of extreme climate events, the need for disaster relief software and tools will only grow.\n\nAutomating workflows for the current existing manual processes in these fields will save immense time that is currently being used to do mundane, repetitive, logistical tasks, giving back time to spend on growth and innovation. Though money is important to run a business, we‚Äôre currently focused on saving critical time from disaster managers who will in turn be able to save more lives."},{"heading":"Ethics","content":"We strongly believe that governments should treat safe housing as a human right. After doing a lot of research into the space, we learned that construction companies have been cutting corners and ignoring building codes for decades, and the government often just lets it slide. This was one of the biggest reasons for the high death count after the recent earthquake in Turkey and Syria.\n\nIt‚Äôs ethically wrong for us as a society to allow people living in bad infrastructure to constantly be in worry about their livelihood. Or worse, not even realize how dangerous their living situation is. Thus, for this hackathon, we focused on safety because it was the most high-impact in saving lives.\n\nThe first step we took was building out the drone image search, giving disaster managers a quick way to sort through their large datasets. Not only will this be extremely useful post-disaster to filter out data, but also to help identify bad infrastructure areas and notify those in the area before it‚Äôs too late.\n\nAlly makes drone data management simple and easily accessible for non-technical users. With such a high-impact space, there exist many ethical issues to further explore:\n\nPrivacy is an especially important consideration when using drones for data collection. The data collected by drones can be used to monitor people without their knowledge or consent, or to gain access to sensitive information. To ensure privacy, drones should only be used with explicit consent and with appropriate oversight or regulation. Additionally, all data collected should be treated with the utmost respect for the rights and privacy of the people involved. Accuracy is also a key ethical concern when using drones for data collection. If the data and images collected are not accurate, then decisions made based on this data could be wrong or misguided. To ensure accuracy, the designers of the drones must ensure that the automated workflows and algorithms used are reliable and effective. Safety and security are also important ethical considerations when using drones for data collection. If the data is used for disaster relief, for example, then there is the potential for drones to crash or malfunction, endangering the people in the area. Additionally, drone data is vulnerable to hacking, potentially leading to a breach of confidential information. To ensure safety and security, designers must ensure that the drones are equipped with appropriate safeguards and that the data collected is encrypted. Reliability is a major ethical consideration when using drones for data collection. If the automated workflows are not reliable, then the data collected could be inaccurate and ineffective for decision making. To ensure reliability, designers must ensure that the drones are equipped with reliable and accurate sensors and that the data is stored securely.\n\nBy taking these ethical considerations into account when designing our product, Ally, we will ensure that the data is used responsibly and in the best interest of the public.\n\nResources\n\nApplications of drone in disaster management: A scoping review Vox News: How these buildings made the Turkey and Syria earthquakes so deadly"},{"heading":"Built With","content":"css javascript next openai python react typescript"},{"heading":"Try it out","content":"dripdrones.vercel.app github.com"}]},{"project_title":"ArticuLab","project_url":"https://devpost.com/software/clear-speech","tagline":"Perfect your public speaking with ArticuLab! Want to ace the upcoming presentation? Need to practice your debate skills? Receive constructive realtime feedback in our unique, immersive VR experience.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/386/854/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"New Frontiers Grand Prize: 4 x Quest 2"}],"team_members":[],"built_with":[{"name":"c#","url":"https://devpost.com/software/built-with/c--2"},{"name":"chatgpt","url":null},{"name":"oculus","url":"https://devpost.com/software/built-with/oculus"},{"name":"unity","url":"https://devpost.com/software/built-with/unity"},{"name":"wit.ai","url":"https://devpost.com/software/built-with/wit-ai"}],"external_links":[{"label":"github.com","url":"https://github.com/RyanBoomer30/TreeHack2023"}],"description_sections":[{"heading":"Inspiration","content":"Public speaking is an incredibly important skill that many seek but few master. This is in part due to the high level of individualized attention and feedback needed to improve when practicing. Therefore, we want to solve this with AI! We have created a VR application that allows you to get constructive feedback as you present, debate, or perform by analyzing your arguments and speaking patterns. While this was our starting motivation for ArticuLab, we quickly noticed the expansive applications and social impact opportunities for it. ArticuLab could be used by people suffering from social anxiety to help improve their confidence in speaking in front of crowds and responding to contrasting opinions. It could also be used by people trying to become more fluent in a language, since it corrects pronunciation and word choice."},{"heading":"What it does","content":"ArticuLab uses AI in a VR environment to recommend changes to your pace, argument structure, clarity, and boy language when speaking. It holds the key to individualized public speaking practice. In ArticuLab you also have the opportunity to debate directly against AI, who'll point out all the flaws in your arguments and make counterarguments so you can make your defense rock-solid."},{"heading":"How we built it","content":"For our prototype, we used Meta's Wit.AI natural language processing software for speech recognition, built a VR environment on Unity, and used OpenAI's powerful ChatGPT to base our feedback system on argument construction and presenting ability. Embedding this into an integrated VR App results in a seamless, consumer-ready experience."},{"heading":"Challenges we ran into","content":"The biggest challenge we ran into is using the VR headset microphone as input for the speech recognition software, and then directly inputting that to our AI system. What made this so difficult was adapting the formatting from each API onto the next. Within the same thread, we ran into an issue where the microphone input would only last for a few seconds, limiting the dialogue between the user and the AI in a debate. These issues were also difficult to test because of the loud environment we were working in. Additionally, we had to create a VR environment from scratch, since there were no free assets to fit our needs."},{"heading":"Accomplishments that we're proud of","content":"We're especially proud of accomplishing such an ambitious project with a team that is majority beginners! Treehacks is three of our integrants' first hackathon, so everyone had to step up and do more work or learn more new skills to implement in our project."},{"heading":"What we learned","content":"We learned a lot about speech to text software, designing an environment and programming in Unity, adapting the powerful ChatGPT to our needs, and integrating a full-stack VR application."},{"heading":"What's next for ArticuLab","content":"Naturally, there would be lots more polishing of the cosmetics and user interface of the program, which are currently restricted by financial resources and the time available. Among these, would be making the environment a higher definition with better quality assets, crowd responses, ChatGPT responses with ChatGPT plus, etc. ArticuLab could be useful both academically and professionally in a variety of fields, education, project pitches like Treehacks, company meetings, event organizers‚Ä¶ the list goes on! We would also seek to expand the project to alternate versions adapted for the comfort of the users, for example, a simplified iOS version could be used by public speakers to keep notes on their speech and let them know if they're speaking too fast, too slow, or articulating correctly live! Similarly, such a feature would be integrated into the VR version, so a presenter could have notes on their podium and media to present behind them (powerpoint, video, etc.), simulating an even more realistic presenting experience. Another idea is adding a multiplayer version that would exponentially expand the uses for ArticuLab. Our program could allow debate teams to practice live in front of a mix of AI and real crowds, similarly, ArticuLab could host online live debates between public figures and politicians in the VR environment."},{"heading":"Built With","content":"c# chatgpt oculus unity wit.ai"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"mimi","project_url":"https://devpost.com/software/jarbls","tagline":"a new kind of personal AI.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/529/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Natural Language Hack by Mem: 4 x AirPods Max (1st Place) & 4 x JBL Flip 6 (2nd Place) & 4 x Mini Projectors (3rd Place)"}],"team_members":[],"built_with":[{"name":"google","url":"https://devpost.com/software/built-with/google--2"},{"name":"openai","url":null},{"name":"twilio","url":"https://devpost.com/software/built-with/twilio"}],"external_links":[{"label":"github.com","url":"https://github.com/bryanhpchiang/mimi"}],"description_sections":[{"heading":"Inspiration","content":"it's really fucking cool that big LLMs (ChatGPT) are able to figure out on their own how to use various tools to accomplish tasks.\n\nfor example, see Toolformer: Language Models Can Teach Themselves to Use Tools ( https://arxiv.org/abs/2302.04761 )\n\nthis enables a new paradigm self-assembling software: machines controlling machines.\n\nwhat if we could harness this to make our own lives better -- a lil LLM that works for you?"},{"heading":"What it does","content":"i made an AI assistant (SMS) using GPT-3 that's able to access various online services (calendar, email, google maps) to do things on your behalf.\n\nit's just like talking to your friend and asking them to help you out."},{"heading":"How we built it","content":"a lot of prompt engineering + few shot prompting."},{"heading":"What's next for jarbls","content":"shopping, logistics, research, etc -- possibilities are endless\n\nmore integrations !!! the capabilities explode exponentially with the number of integrations added long term memory\n\ncome by and i can give you a demo"},{"heading":"Built With","content":"google openai twilio"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"CommuniPute","project_url":"https://devpost.com/software/communipute","tagline":"Share compute power throughout your community when you're not using it through our distributed compute sharing platform.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/218/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Convex: 5 ft Massive Lego Eiffel Tower + 2m RC Airplane kit E-flite DRACO + Arduino Robot - Lynxmotion SQ3U"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Developer Tool by Warp: 4 x Xbox Series S"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Hack for a Real World Use Case by Pear: $1000 & up to $100000 uncapped SAFE"}],"team_members":[],"built_with":[{"name":"compute","url":null},{"name":"containerization","url":null},{"name":"convex","url":null},{"name":"css3","url":"https://devpost.com/software/built-with/css3"},{"name":"distributed-computing","url":null},{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"jsx","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"github.com","url":"https://github.com/AbhishekMarda/CommuniPute/tree/main"}],"description_sections":[{"heading":"Inspiration","content":"No matter how much you use your computer, it's likely you're not using your computing power to 24/7. That being said, it always feels like when you need power, you can never seem to have enough. Imagine being able to utilize your computer's compute power around the clock. With increasingly powerful machines entering the market (such as Apple's 96 GB RAM M2 MacBook Pro), we're beginning to see an underutilization of these compute resources. On the other hand, we see more and more compute heavy workloads - such as deep learning models - becoming more prevalent. What if there was a way for someone across the world to use your machine's resources while you sleep? Or if you could supercharge your own programs by using the resources of someone that's off their laptop? Noticing this discrepancy, our team decided to address this problem by creating a platform that connects some user's underutilized compute power to other user's compute needs."},{"heading":"What it does","content":"CommuniPute allows users to make their compute power available to the community and make money off of their computer's utilization. Users who need compute can request this underutilized compute power for their own innovations. A user can request compute power by browsing the catalog of available compute resources and selecting the compute resource of their choice. The script is run on the selected compute platform.\n\nAdvantages\n\nRun on a more powerful machine Utilize a more powerful network Run your code on the compute architecture of your choice Distribute your workloads"},{"heading":"Technical details","content":"Used semaphores for multiple connections working at once Used websocket technology using Convex Used containerization using Docker to prevent elevation of privilege, along with limiting available RAM memory React.js in the frontend with dynamic updates A web based IDE to execute code Being able to run python code with required libraries being downloaded into docker container with user specifications\n\nFuture Goals\n\nWe wanted to create a system that's able to take a compute heavy workload and intelligently distribute the workload to available compute resources. This allows requesting users to utilize the combined power of available compute resources for their innovation needs. Given constrained by time constraints of the hackathon, we implemented a proof-of-concept of the distributed computation model-- with parallelization being a future goal.\n\nPlease see the \"What's next\" section for a more elaborate set of future goals"},{"heading":"How this applies to Sustainability","content":"One of the greatest challenges in the current tech sustainability space is the heavy resource demands of significant compute systems. Furthermore, old compute systems are typically trashed - therefore, negatively impacting the reduce, recycle, and reuse sustainability model. Our platform can utilize older compute systems to fulfill the industry's every growing compute power demand. By leveraging these underutilized compute platforms, we reduce the need to aggressively extract materials for compute systems thus facilitating the reduce, reuse, recycle cycle."},{"heading":"How this applies to Education","content":"Education within the computer science or technology related space often implies the presence of powerful compute systems. However, for underprivileged students, the lack of compute capacity often serves as a handicap. Giving access to unused hardware for cheap allows greater access to education, equitability, and potential for innovation.\n\nThis platform also allows an easier entry into heavy compute fields. Users no longer need to get up to speed on platforms cloud compute providers such as AWS, Azure, or Google Cloud. Users can simply write their functions and hit run without worrying about the overhead about where their compute will run.\n\nFurthermore, academic institutions often have many compute systems which are underutilized or outright not used. Our platform will allow for the utilization of these compute platforms by students, researchers, academics, and professors within the institution."},{"heading":"How this applies to New Frontiers (ML/AI)","content":"Deep learning is becoming the new game changing innovation within the Machine Learning and Artificial Intelligence space. However, the creation of deep learning models requires the modeling of neural networks which require significant amounts of compute. Using our platform can alleviate these challenges by providing readily available compute for very cheap. A real world use case where our platform may have been used is during COVID-19. During COVID-19 research, scientists at IBM created a \"grid computing\" platform which asked users to offer their machines to scientists for running compute heavy workloads. We hope to make this level of compute readily, and cheaply available to any ML/AI innovator.\n\nFurthermore, as mentioned within the \"How this applies to Education\", our platforms allow ML/AI engineers to only focus on their innovation rather than worrying about setting up compute systems on AWS/Azure/Google Cloud to support their compute heavy workloads. This not only allows innovators access to cheap compute power, but also reduces the barriers of entry to ML/AI innovation space."},{"heading":"How this applies to Healthcare","content":"One of the greatest challenges in healthcare relates to patient safety. Typically, patient data is regulated to not leave the healthcare institutions network. Therefore, the cloud is not an option to offload heavy Machine Learning workloads. Our platform can provide a solution in this space by allowing healthcare institutions to utilize all their compute systems for running compute heavy workloads."},{"heading":"How this applies to Web 3.0/Blockchain","content":"Coin mining requires compute resources. A big challenge for coins is the lack of compute power to mine these coins. Leveraging underutilized compute resources will allow for the mining of such coins."},{"heading":"How this helps Developers","content":"Our platform serves as a tool that developers can utilize in multiple ways:\n\nDevelopers have an ever increasing need for compute power. Our platform makes immense compute power readily accessible to developers. For example, for developers working on machine learning workloads can utilize our platforms to run their workloads and get results without worrying about overhead related to setting up a cloud platform for their compute needs. Developers want to test their products on multiple compute architectures and through various operating systems. Our platform allows users to choose which available machine they want to run their work on. Ex. a developer may want to ensure that their app works on x86 architecture. Our platform provides information about the available compute platform. So a developer can choose the appropriate x86 machine with the host OS of their choice."},{"heading":"How we built it","content":"We created 3 separate modules for this project. The three modules are as follows:\n\nHost-side Client: The host-side client features a python application. The host-side client communicates its availability to the server, receives requests Backend Solution: We leveraged Convex's backend capabilities and web sockets solution. The backend solution allows the connection of available compute resource to a requesting user. Since convex uses web sockets under the hood, we were able to leverage real-time reactive updates. This also allowed a two-way communication from the server to the client and the client to the server. It was imperative to send updates from the backend side to the client. Convex simplified the necessary logic and infrastructure that would've been required to make this possible - the web sockets solution was a game-changing asset. Web App: The web app allowed requesting users an interface for viewing available compute platforms and requesting the compute platforms.\n\nPlease see uploaded images for architecture diagram"},{"heading":"Challenges we ran into","content":"Security Considerations\n\nBeing a compute sharing platform, the foremost challenge we considered was being able to run code within a containerized platform. We wanted to ensure security for both the host machine and the requesting machine. The code being run on the host machine shouldn't harm the host machine. Likewise, we wanted to provide a level of security for the requesting machine's code so that it isn't readily observed by the host machine.\n\nWe addressed these challenges by using a novel containerization technology in order to separate executing of the code. Anytime a request is made to compute, we spin up a separate compute container that allows execution of code in a complete silo\n\nNew Technologies\n\nOur team came in with strong backend knowledge but a limited working knowledge of front end. We ended up using Convex which simplified the backend logic but placed the brunt of the workload on the frontend technologies. Therefore, coming up to speed with our front end framework (React), JavaScript, and integrating with Convex was the biggest challenge that our team faced."},{"heading":"Accomplishments that we're proud of","content":"We were able to create a working minimal viable product within a short period of time. The product we created has a vast application within almost every industry that utilizes technology. So our team is most proud of creating a product that makes a difference in every industry and potentially revolutionizes the way we use hardware."},{"heading":"What we learned","content":"3/4 of the teammates were first time hackers. Furthermore, our entire team came in with limited working knowledge of Convex, JavaScript, React, and front end technologies. Our team was able to quickly come up to speed with these technologies. Furthermore, we learnt how to work with containerization technologies. We learnt an incredible amount during this project and had a great time working as a team!"},{"heading":"What's next for CommuniPute","content":"There's multiple next iterations for our community compute platform:\n\nCreate an orchestration system which allows one compute job to be orchestrated over multiple compute systems. This will provide utility for functions such as deep learning and larger work loads. Create a service which allows for compute sharing within a local edge network using peer-to-peer connections without sending compute data to a backend server. This has a significant application within the healthcare industry as regulation prevents patient information from leaving the origin healthcare entity. Therefore, healthcare entities will now be able to perform compute on their under utilized compute platforms within their network edge then send out computed data for centralized processing Implement paying mechanism and back a coin using credits Allow for uploading files rather than using the text editor to write code."},{"heading":"Built With","content":"compute containerization convex css3 distributed-computing docker html5 javascript jsx python react"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Course Connection","project_url":"https://devpost.com/software/course-connection","tagline":"Ever meet another student, seemingly a stranger, only to realize you were in 12 classes together? See who you have taken classes with and form meaningful connections!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/390/108/datas/medium.jpeg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Estuary: 4 x iPad 10th Gen (1st Place) & 4 x Mechanical Gaming Keyboards (2nd Place)"}],"team_members":[],"built_with":[{"name":"estuary","url":null},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"networkx","url":null},{"name":"next.js","url":null},{"name":"nginx","url":"https://devpost.com/software/built-with/nginx"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"vercel","url":null}],"external_links":[{"label":"treehacks.siwiec.us","url":"https://treehacks.siwiec.us/"}],"description_sections":[{"heading":"Inspiration","content":"College is often heralded as a defining time period to explore interests, define beliefs, and establish lifelong friendships. However the vibrant campus life has recently become endangered as it is becoming easier than ever for students to become disconnected. The previously guaranteed notion of discovering friends while exploring interests in courses is also becoming a rarity as classes adopt hybrid and online formats. The loss became abundantly clear when two of our members, who became roommates this year, discovered that they had taken the majority of the same courses despite never meeting before this year. We built our project to combat this problem and preserve the zeitgeist of campus life."},{"heading":"What it does","content":"Our project provides a seamless tool for a student to enter their courses by uploading their transcript. We then automatically convert their transcript into structured data stored in Firebase. With all uploaded transcript data, we create a graph of people they took classes with, the classes they have taken, and when they took each class. Using a Graph Attention Network and domain-specific heuristics, we calculate the student‚Äôs similarity to other students. The user is instantly presented with a stunning graph visualization of their previous courses and the course connections to their most similar students.\n\nFrom a commercial perspective, our app provides businesses the ability to utilize CheckBook in order to purchase access to course enrollment data."},{"heading":"High-Level Tech Stack","content":"Our project is built on top of a couple key technologies, including React (front end), Express.js/Next.js (backend), Firestore (real time graph cache), Estuary.tech (transcript and graph storage), and Checkbook.io (payment processing)."},{"heading":"How we built it","content":"Initial Setup\n\nOur first task was to provide a method for students to upload their courses. We elected to utilize the ubiquitous nature of transcripts. Utilizing python we parse a transcript, sending the data to a node.js server which serves as a REST api point for our front end. We chose Vercel to deploy our website. It was necessary to generate a large number of sample users in order to test our project. To generate the users, we needed to scrape the Stanford course library to build a wide variety of classes to assign to our generated users. In order to provide more robust tests, we built our generator to pick a certain major or category of classes, while randomly assigning different category classes for a probabilistic percentage of classes. Using this python library, we are able to generate robust and dense networks to test our graph connection score and visualization.\n\nBackend Infrastructure\n\nWe needed a robust database infrastructure in order to handle the thousands of nodes. We elected to explore two options for storing our graphs and files: Firebase and Estuary. We utilized the Estuary API to store transcripts and the graph ‚Äúfingerprints‚Äù that represented a students course identity. We wanted to take advantage of the web3 storage as this would allow students to permanently store their course identity to be easily accessed. We also made use of Firebase to store the dynamic nodes and connections between courses and classes.\n\nWe distributed our workload across several servers. We utilized Nginx to deploy a production level python server that would perform the graph operations described below and a development level python server. We also had a Node.js server to serve as a proxy serving as a REST api endpoint, and Vercel hosted our front-end.\n\nGraph Construction\n\nTreating the firebase database as the source of truth, we query it to get all user data, namely their usernames and which classes they took in which quarters. Taking this data, we constructed a graph in Python using networkX, in which each person and course is a node with a type label ‚Äúuser‚Äù or ‚Äúcourse‚Äù respectively. In this graph, we then added edges between every person and every course they took, with the edge weight corresponding to the recency of their having taken it.\n\nSince we have thousands of nodes, building this graph is an expensive operation. Hence, we leverage Firebase‚Äôs key-value storage format to cache this base graph in a JSON representation, for quick and easy I/O. When we add a user, we read in the cached graph, add the user, and update the graph. For all graph operations, the cache reduces latency from ~15 seconds to less than 1.\n\nWe compute similarity scores between all users based on their course history. We do so as the sum of two components: node embeddings and domain-specific heuristics. To get robust, informative, and inductive node embeddings, we periodically train a Graph Attention Network (GAT) using PyG (PyTorch Geometric). This training is unsupervised as the GAT aims to classify positive and negative edges. While we experimented with more classical approaches such as Node2Vec, we ultimately use a GAT as it is inductive, i.e. it can generalize to and embed new nodes without retraining. Additionally, with their attention mechanism, we better account for structural differences in nodes by learning more dynamic importance weighting in neighborhood aggregation. We augment the cosine similarity between two users‚Äô node embeddings with some more interpretable heuristics, namely a recency-weighted sum of classes in common over a recency-weighted sum over the union of classes taken.\n\nWith this rich graph representation, when a user queries, we return the induced subgraph of the user, their neighbors, and the top k most people most similar to them, who they likely have a lot in common with, and whom they may want to meet!"},{"heading":"Challenges we ran into","content":"We chose a somewhat complicated stack with multiple servers. We therefore had some challenges with iterating quickly for development as we had to manage all the necessary servers. In terms of graph management, the biggest challenges were in integrating the GAT and in maintaining synchronization between the Firebase and cached graph."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre very proud of the graph component both in its data structure and in its visual representation."},{"heading":"What we learned","content":"It was very exciting to work with new tools and libraries. It was impressive to work with Estuary and see the surprisingly low latency. None of us had worked with next.js. We were able to quickly ramp up to using it as we had react experience and were very happy with how easily it integrated with Vercel."},{"heading":"What's next for Course Connections","content":"There are several different storyboards we would be interested in implementing for Course Connections. One would be a course recommendation. We discovered that chatGPT gave excellent course recommendations given previous courses. We developed some functionality but ran out of time for a full implementation."},{"heading":"Built With","content":"estuary firebase networkx next.js nginx node.js python react vercel"},{"heading":"Try it out","content":"treehacks.siwiec.us"}]},{"project_title":"Eddy","project_url":"https://devpost.com/software/eddy-zx9uto","tagline":"The autopilot for ideas‚ÄîEddy semantically maps your thoughts into an alluring, explorable map, helping you sail your stream of consciousness.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/902/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Natural Language Hack by Mem: 4 x AirPods Max (1st Place) & 4 x JBL Flip 6 (2nd Place) & 4 x Mini Projectors (3rd Place)"}],"team_members":[],"built_with":[{"name":"chakra-ui","url":null},{"name":"fastapi","url":null},{"name":"figma","url":null},{"name":"huggingface","url":null},{"name":"nltk","url":"https://devpost.com/software/built-with/nltk"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"react-flow","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/joyliu-q/treehacks"}],"description_sections":[{"heading":"Inspiration","content":"Imagine you're sitting in your favorite coffee shop and a unicorn startup idea pops into your head. You open your laptop and choose from a myriad selection of productivity tools to jot your idea down. It‚Äôs so fresh in your brain, you don‚Äôt want to waste any time so, fervently you type, thinking of your new idea and its tangential components. After a rush of pure ideation, you take a breath to admire your work, but disappointment. Unfortunately, now the hard work begins, you go back though your work, excavating key ideas and organizing them.\n\nEddy is a brainstorming tool that brings autopilot to ideation. Sit down. Speak. And watch Eddy organize your ideas for you."},{"heading":"Learnings","content":"Melding speech recognition and natural language processing tools required us to learn how to transcribe live audio, determine sentences from a corpus of text, and calculate the similarity of each sentence. Using complex and novel technology, each team-member took a holistic approach and learned news implementation skills on all sides of the stack."},{"heading":"Features","content":"Live mindmap ‚ÄîAutomatically organize your stream of consciousness by simply talking. Using semantic search, Eddy organizes your ideas into coherent groups to help you find the signal through the noise. Summary Generation ‚ÄîHelpful for live note taking, our summary feature converts the graph into a Markdown-like format. One-click UI ‚ÄîSimply hit the record button and let your ideas do the talking. Team Meetings ‚ÄîNo more notetakers: facilitate team discussions through visualizations and generated notes in the background."},{"heading":"Challenges","content":"Live Speech Chunking - To extract coherent ideas from a user‚Äôs speech, while processing the audio live, we had to design a paradigm that parses overlapping intervals of speech, creates a disjoint union of the sentences, and then sends these two distinct groups to our NLP model for similarity. API Rate Limits ‚ÄîOpenAI rate-limits required a more efficient processing mechanism for the audio and fewer round trip requests keyword extraction and embeddings. Filler Sentences ‚ÄîNot every sentence contains a concrete and distinct idea. Some sentences go nowhere and these can clog up the graph visually. Visualization ‚ÄîForce graph is a premium feature of React Flow. To mimic this intuitive design as much as possible, we added some randomness of placement; however, building a better node placement system could help declutter and prettify the graph."},{"heading":"Future Directions","content":"AI Inspiration Enhancement ‚ÄîUsing generative AI, it would be straightforward to add enhancement capabilities such as generating images for coherent ideas, or business plans. Live Notes ‚ÄîEddy can be a helpful tool for transcribing and organizing meeting and lecture notes. With improvements to our summary feature, Eddy will be able to create detailed notes from a live recording of a meeting."},{"heading":"Built with","content":"UI: React, Chakra UI, React Flow, Figma AI: HuggingFace, OpenAI Whisper, OpenAI GPT-3, OpenAI Embeddings, NLTK API: FastAPI\n\nSupplementary Material"},{"heading":"Built With","content":"chakra-ui fastapi figma huggingface nltk openai python react react-flow"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"PCOS Pal ","project_url":"https://devpost.com/software/pcos-pal","tagline":"Using machine-learning to aid in pcos diagnosis and awareness","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/542/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of InterSystems IntegratedML: $2000 (1st Place) & $1500 (2nd Place) & $1000 (3rd Place)"}],"team_members":[],"built_with":[{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"intersystems","url":null},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"sqlalchemy","url":"https://devpost.com/software/built-with/sqlalchemy"}],"external_links":[{"label":"github.com","url":"https://github.com/reaganrazon/pcospal"}],"description_sections":[{"heading":"Inspiration","content":"Polycystic Ovary Syndrome, or PCOS, is a chronic condition known as the most prevalent endocrine‚Äìmetabolic disorder, affecting around 6‚Äì10% of reproductive-aged women across the world. The exact cause is unknown and there is no direct cure, but the symptoms can be treatable.\n\nWhile there is not a specific test to diagnose PCOS, a diagnosis would commonly require at least 2 of the 3 following features: polycystic appearing ovaries, hyperandrogenism, and amenorrhea. An internal ultrasound is a common method of examination; however, they are not recommended for women younger than 20 years, thus making PCOS difficult to spot in early adulthood.\n\nThe reality is that many people go undiagnosed. In a study done by Monash Centre for Health Research and Implementation, researchers found that people who have PCOS commonly reported that they were unsatisfied with their overall diagnosis experience, including the information provided about the condition, the number of health professionals they had to see, and the wait time for diagnosis. PCOS affects physical health and mental well-being over the life span, and a delay in diagnosis can exacerbate these effects and even lead to more long-term health complications.\n\nAs someone who is experiencing the difficulties associated with PCOS, I wanted to come up with an application that could assist in the diagnosis process."},{"heading":"What it does","content":"Anyone can have access to a questionnaire that will calculate the risk or likelihood of having PCOS, there is a log-in feature using authentication and logged in users will have access to other parts of the website."},{"heading":"How I built it","content":"I utilized a dataset that has different fields containing symptoms or conditions that could be useful to predict PCOS, such as ovarian follicle size, cycle length, and whether the patient has an irregular cycle. I did pre-processing and then learned how to use Intersystems IntegratedML to train and validate models."},{"heading":"Challenges I ran into","content":"Connecting the database to my application took a while and I also completely switched tech stacks in the middle of the development process and wasn't sure how to transfer things over. There is a lack of robust data on PCOS or PCOS symptoms, so the dataset I used was on the smaller side (542 rows) and was unbalanced. For one feature, I was running into problems with deploying semantic analysis with good accuracy. I also was working on image classification to detect PCOS in python using ultrasound images, but there were time constraints and unfortunately, I could not fully implement it, although I was most excited about that part."},{"heading":"Accomplishments that I'm proud of","content":"I decided to work on something that strays away from what I normally do, which meant spending a lot of time learning and experimenting. I am proud that I ended this with a working model that can predict PCOS and I am walking away with new skillsets."},{"heading":"What I learned","content":"I am excited that I had the opportunity to learn a different way of database management. I learned how to train models using Intersystems integrated ML and also how to use flask. I strengthened my SQL and python skills."},{"heading":"What's next for PCOS Pal","content":"There are several other endpoints I would like to continue developing, such as daily mood check-ins and journal entries that could be analyzed with NLP. I also want to have a platform where people with PCOS can review birth control along with other common methods of treatment. To tie it all together, I want to have a better UX/UI design. I have a lot of visions for this product and hope to continue developing it to help other people like me."},{"heading":"Built With","content":"express.js flask intersystems mongodb node.js python react sqlalchemy"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"ForeStall","project_url":"https://devpost.com/software/forestall","tagline":"Forestall predicts a patient's risk level to medication at a macro (across all patient data) and micro scale (across subset of patient data specific to practitioner) to mitigate medical errors.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/518/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of InterSystems IntegratedML: $2000 (1st Place) & $1500 (2nd Place) & $1000 (3rd Place)"}],"team_members":[],"built_with":[{"name":"figma","url":null},{"name":"integratedml","url":null},{"name":"intersystems","url":null},{"name":"openfda","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react.js","url":null},{"name":"sql","url":"https://devpost.com/software/built-with/sql"}],"external_links":[{"label":"github.com","url":"https://github.com/nellapark/forestall-treehacks23"}],"description_sections":[{"heading":"Inspiration","content":"On average, every patient in the United States will experience one significant diagnostic error in their lifetime, incurring potentially devastating effects on the patient, their loved ones, and healthcare professionals. [1] Diagnostic errors are a common issue in healthcare and can lead to significant medical, legal, and financial consequences. [2]\n\nEvery year, nearly 400,000 hospitalized patients suffer from medical harm that could have been avoided. [3] Errors in medical practice contribute to approximately $20 billion in costs each year. [4] Medical errors in hospitals and clinics contribute to approximately 100,000 deaths each year. [5]\n\nAs a result, there remains an urgent need for research to identify the predictors of diagnostic errors in order to develop effective interventions that can improve diagnostic accuracy, preventing these errors from occurring in the first place."},{"heading":"What it does","content":"ForeStall works to predict potential diagnosis errors through analyzing a patient‚Äôs risk level to a certain medication at both a macro and micro scale. The interface provides a searchable macro dashboard that identifies high risk patients across entire hospitals, while its micro dashboard identifies high risk patients for individual practitioners.\n\nForeStall finds mappings of allergies to medication as well as mappings of medications that are incompatible, then uses a function that takes in the allergies of patients as parameters and outputs non-compatible medications. Given a patient‚Äôs profile (age, weight, sex) and a medication that they are taking. ForeStall uses InterSystems Integrated ML to output a patient‚Äôs risk level and other high risk medications (that are not definitively known as incompatible). High risk is identified by calculating potential combinations of allergies that have overlapping drug instances, which could potentially lead to fatal results for patients.\n\nMedical errors commonly occur through patient misidentification, wrong dosage regimen, and wrong medication administration; ForeStall mitigates these issues through clear, clickable profiles that identify each patient with multiple factors (photo, age, sex, demographic) and provide detailed, easy-to-understand medication information for practitioners. Each patient profile includes a thread of patient notes so that practitioners can remain on the same page when a patient is passed down.\n\nForeStall also introduces an anonymous error reporting feature, addressing the stigma of not reporting medical errors due to fear of backlash. This function will mitigate future medical errors, as multiple studies have identified that if error-prone situations are reported and managed by a modification of the system, a decrease in the frequency of the error and concomitant errors will ensue."},{"heading":"How we built it","content":"Our team built an innovative machine learning model that predicts the risk of severity of drug adverse effects. We started by querying 100,000 patient drug adverse effect profiles from the openFDA database, and then extracted and used patient demographic information, medications, and reported symptoms. We created a scale from 1 to 5 to assess the severity of adverse effects, ranging from low severity to death. Using Intersystems Integrated ML, we trained an optimized model with the top 50 most common symptoms and the top 50 most commonly prescribed drugs in the dataset. Our team spent considerable time fine-tuning the model and trying various configurations, which ultimately paid off. We achieved a remarkable predictive power of 73% of the variance. Overall, we built a refined model that will help healthcare professionals assess the risk of drug adverse effects, which could have a significant impact on patient care and safety. In addition to building the backend machine learning model, our team also implemented the frontend. To begin, we used Figma to create wireframes that allowed us to visualize the layout and design of the website. We then used React.js to develop the frontend, which included a user-friendly interface for healthcare professionals to input patient information and receive predictions about the severity of potential drug adverse effects. One of the key features of the website was the use of generative AI to create patient medical profiles. This allowed us to generate realistic and detailed profiles that could be used to demonstrate the functionality of the website. Throughout the development process, we focused on creating a clean and intuitive design that would be easy to use for healthcare professionals of all levels of technical expertise."},{"heading":"Challenges we ran into","content":"The first and foremost challenge we encountered was wrangling the data set, which involved querying the openFDA API, understanding the JSON elements, and extracting essential calls for the machine learning (ML) model. The difficulty was that we had to represent adverse drug effects quantitatively in a way that could be incorporated effectively into an ML model. Additionally, determining the most common drugs and reactions, as well as deciding on the optimal number of drugs and reactions to include in the model, was a complex undertaking due to the large number of unique drugs (3176 unique drugs and 2286 different adverse reactions across the dataset)/\n\nMoreover, we had to learn SQL on the fly and become proficient in InterSystem's API. Learning InterSystem was particularly challenging because we had to iteratively conform the data preprocessing to the environment and data formatting requirements of InterSystem. Finally, after trying multiple different models with varying combinations of reactions, drugs, and model configurations, we had to figure out the optimal model to increase predictive power from 2% to 73% of the variance. The biggest challenge we faced was connecting the different components of our project, as each aspect required different technical skills and expertise. Despite these challenges, we adapted to the pressure of the tight timeline and completed our project through perseverance and collaboration."},{"heading":"Accomplishments that we're proud of","content":"We're proud of creating an app with the potential to save lives through harnessing ML. It was a crazy challenge learning how to apply ML in less than 2 days, but it was amazing that it pulled through. We're also proud of the clean and logical site UI, which makes practitioners‚Äô harried lives easier through its intuitive design."},{"heading":"What we learned","content":"Developed skills in SQL and InterSystemsML for creating an optimal model with high predictive power Learned effective feature extraction and data processing techniques and importantly how to iteratively improve them alongside what is most predictive for the ML model Gained experience utilizing advanced hooks and state management techniques in React to implement complex UI/UX design across multiple pages Learned how to adapt & problem-solve quickly in the face of a tight deadline! (fueled by lots of Pocari Sweat)"},{"heading":"What's next for ForeStall","content":"We feel very passionate about exploring this project in more depth by applying more complex ML models to create more accurate predictions and increase mitigation of medical errors. We would also like to deploy this service in real hospitals to test our technology with the collection of actual data and test the effectiveness of its ability to make real-life medication predictions. In response to this testing, we would like to flesh out front end and add polish ML predictive features. Our end goal is to open source ForeStall for doctors and medical workers to use free of charge to access guidance and resources that will assist them in making the best possible medication decisions.\n\nCitations\n\nCommittee on Diagnostic Error in Health Care, Board on Health Care Services, Institute of Medicine, The National Academies of Sciences, Engineering, and Medicine. Improving diagnosis in health care. In: Balogh, EP, Miller, BT, Ball, JR, editors. Improving diagnosis in health care [Internet]. Washington, D.C.: National Academies Press; 2015. http://www.nap.edu/catalog/21794 . Brown, TW, McCarthy, ML, Kelen, GD, Levy, F. An epidemiologic study of closed emergency department malpractice claims in a national database of physician malpractice insurers. Acad Emerg Med 2010;17:553‚Äì60. https://doi.org/10.1111/j.1553-2712.2010.00729.x . James, J. T. A new, evidence-based estimate of patient harms associated with hospital care. J Patient Saf. 2013 Sep;9(3):122-8. Henriksen, K., Battles, J. B., Keyes, M. A., & Grady, M. L. (Eds.). (2008). Chapter 2: The need for a national focus on patient safety. In Advances in patient safety: New directions and alternative approaches (Vol. 1: Assessment). Agency for Healthcare Research and Quality (US). https://www.ncbi.nlm.nih.gov/books/NBK499956/ . Singh H, Schiff GD, Graber ML, Onakpoya I, Thompson MJ. The global burden of diagnostic errors in primary care. BMJ Qual Saf. 2017 Jun;26(6):484-494."},{"heading":"Built With","content":"figma integratedml intersystems openfda python react.js sql"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Condensis","project_url":"https://devpost.com/software/condensis","tagline":"Condensis offers AI-generated notes to students who struggle with note-taking, helping promote accessible education. Our multimodal language model can synthesize notes from any lecture video.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/391/940/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Natural Language Hack by Mem: 4 x AirPods Max (1st Place) & 4 x JBL Flip 6 (2nd Place) & 4 x Mini Projectors (3rd Place)"}],"team_members":[],"built_with":[{"name":"chatgpt","url":null},{"name":"checkbook.io","url":null},{"name":"figma","url":null},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"google-text-to-speech","url":null},{"name":"gpt-3","url":null},{"name":"openai","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"retool","url":null},{"name":"whisper","url":null}],"external_links":[{"label":"condensis.xyz","url":"http://condensis.xyz"},{"label":"github.com","url":"https://github.com/arjvik/Condensis"}],"description_sections":[{"heading":"Built With","content":"chatgpt checkbook.io figma google-cloud google-text-to-speech gpt-3 openai opencv python react retool whisper"},{"heading":"Try it out","content":"condensis.xyz github.com"}]},{"project_title":"Whisker Workshop","project_url":"https://devpost.com/software/whisker-workshop","tagline":"A fun and cute cat-themed playground for students to explore machine learning and data science concepts!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/087/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of InterSystems IntegratedML: $2000 (1st Place) & $1500 (2nd Place) & $1000 (3rd Place)"}],"team_members":[],"built_with":[{"name":"adobe-illustrator","url":"https://devpost.com/software/built-with/adobe-illustrator"},{"name":"intersystems-integratedml","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react.js","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/2022tgoel/TreeHacks2023"}],"description_sections":[{"heading":"Inspiration","content":"Most students don‚Äôt encounter machine learning until college. However, this typical track of Calculus 2 > Machine Learning may be outdated. With the development of powerful machine learning tools like IntersystemsML, complex mathematics is no longer necessary for a conceptual understanding of machine learning.\n\nWe make the bold claim that kids ‚Äì even middle schoolers ‚Äì can and should be exposed to machine learning concepts. With this goal, Whisker Workshops sets out to preserve precious machine learning insights while replacing formidable blocks of code and equations with cute hand-drawn graphics and games."},{"heading":"What it does","content":"Whisker Workshops consists of two main playground sections: one allows students to interactively build a neural network to represent the nonlinear exclusive or (XOR) gate while the other allows users to explore various dimensionality reduction levels for principal component analysis (PCA). We designed the UI to be cute and hand-drew graphics down to the buttons, aiming to foster a friendly and welcoming environment for beginners.\n\nFor the XOR gate playground, the truth table for the logic gate is given (no prior experience is assumed) ‚Äî the goal is then to create a network to reproduce XOR. The playground is very visual: the user can see the entire neural network in real-time while updating neurons and edges. Edge weights can be updated by clicking on them, and the thickness of an edge visualizes its corresponding weight; the number of neurons is adjustable through a slider. Then, the player can run the network on different inputs and see how well they do: the task is essentially presented as a game of sorts!\n\nThe PCA playground (also known as ‚ÄúMore Isn‚Äôt Always Better‚Äù) follows a similar visual philosophy: users can change the dimensionality of input data (Fashion MNIST dataset, images of clothes and accessories) and visualize how well the model performs through an interactive chart. Our friendly cat mentor also guides us through the entire process and explains why we observe the results we do!"},{"heading":"How we built it","content":"All of the graphics and artwork in the final product were drawn by our team and incorporated into the website frontend built in React.JS and CSS.\n\nThe PCA playground was built by first conducting principal component analysis in Python on the Fashion MNIST dataset for a variety of output dimensionalities. We then used InterSystems IntegratedML to train a machine learning model for each of the resulting datasets. Through this process, we were delightfully surprised by the versatility of InterSystems IntegratedML‚Äôs capabilities. Not only was the model able to predict the 2-way XOR task, a classic non-linearity test, but it was also able to perform quite well on classifying MNIST fashion pieces, with no knowledge of what the input was.\n\nThe resulting accuracy data was then visualized through Chart.JS, a data visualization library in Javascript. The cat animations and dialogue were all created in CSS.\n\nThe XOR gate playground was designed primarily in React.JS, using a lot of different state logic and hooks to create the interactive neural network editor and interface for running the model. Due to the highly custom nature of the project, we manually implemented forward propagation for the network. All styling was done in CSS."},{"heading":"Challenges we ran into","content":"It was often difficult to create certain visual designs, effects and features with CSS: for example, the slider that demonstrates the results of Principal Component Analysis for different output dimensions. This was especially the case for importing our custom graphics and artwork into our project. This improved our debugging skills significantly and also taught us how to better utilize documentation to learn.\n\nAnother challenge we faced was navigating and running models on IntegratedML. We are very grateful for Thomas from Intersystems for his exceedingly helpful advice, allowing us to successfully train and validate the models we needed."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre proud of having built a functional application with real-world value during this hackathon. As a team, we believe that Whisker Workshop isn‚Äôt just a toy project but a starting point for future AI education initiatives aimed at a younger audience. Our team is also proud to have explored and combined skills from a lot of different fields including machine learning, web development, data analysis, and graphic design.\n\nAnother accomplishment that we feel proud of is the fact that we incorporated the InterSystems IntegratedML framework into our project as this took us a lot of effort and research."},{"heading":"What we learned","content":"We learned how to make a stylish and customized UI and utilize CSS to its fullest extent; along with incorporating custom graphic design, we learned to create a product that would appeal to our target audience: children without technical knowledge interested in exploring machine learning. Thinking about our target audience was a skill we improved a lot throughout TreeHacks as we continually aimed to look at our product from users‚Äô perspective.\n\nUsing InterSystems IntegratedML also taught us how to effectively use external tools to help build our product. Through the process, we had to read a lot of documentation and learn to understand the new paradigm presented by this specific system ‚Äî this is a skill that is essential as programmers always use different tools and technologies to assist them.\n\nWe were also puzzled as to how to efficiently run the machine learning algorithm in real time after each update made by the user without taking a toll on the user‚Äôs computer or taking too long. We learned how to custom-build a machine learning algorithm without the conventional tools such as Tensorflow or Pytorch, which would be too inefficient to run each time. We eventually accomplished this by extracting only the features essential to the differentiation task with principal component analysis, and then coding up our own dense network."},{"heading":"What's next for Whisker Workshop","content":"We plan to expand this concept of abstractified ML to middle school and high school students who don‚Äôt have access to machine learning education. We hope to promote Whisker Workshop to elementary and middle school teachers, who can encourage their students to explore machine learning in their free time.\n\nOne extension is a playground for kids to create a multi-layer deep learning model that will perform image classification. For each layer, they will have options to input a dense or convolutional layer and sliders to tune hyperparameters ‚Äî observing how different settings impact accuracy in this gamified and interactive environment will allow students to develop intuition about deep learning concepts (e.g. network architecture, activations, etc.)."},{"heading":"Built With","content":"adobe-illustrator intersystems-integratedml python react.js"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"MediBot","project_url":"https://devpost.com/software/medibot-iq8lf0","tagline":"Help us help you get the health care you deserve!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/341/datas/medium.jpeg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of InterSystems IntegratedML: $2000 (1st Place) & $1500 (2nd Place) & $1000 (3rd Place)"}],"team_members":[],"built_with":[{"name":"chatbot","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"healthcare","url":null},{"name":"intersystems","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"natural-language-processing","url":"https://devpost.com/software/built-with/natural-language-processing"},{"name":"nltk","url":"https://devpost.com/software/built-with/nltk"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"github.com","url":"https://github.com/IamWafula/MediBot"}],"description_sections":[{"heading":"Inspiration:","content":"Our team went into the ideation phase of Treehacks 2023 with the rising relevance and apparency of conversational AI as a ‚Äúfresh‚Äù topic occupying our minds. We wondered if and how we can apply conversational AI technology such as chatbots to benefit people, especially those who may be underprivileged or underserviced in several areas that are within the potential influence of this technology. We were brooding over the six tracks and various sponsor rewards when inspiration struck. We wanted to make a chatbot within healthcare, specifically patient safety. Being international students, we recognize some of the difficulties that arise when living in a foreign country in terms of language and the ability to communicate with others. Through this empathetic process, we arrived at a group that we defined as the target audience of MediBot; children and non-native English speakers who face language barriers and interpretive difficulties in their communication with healthcare professionals. We realized very early on that we do not want to replace the doctor in diagnosis but rather equip our target audience with the ability to express their symptoms clearly and accurately. After some deliberation, we decided that the optimal method to accomplish that using conversational AI was through implementing a chatbot that asks clarifying questions to help label the symptoms for the users."},{"heading":"What it does:","content":"Medibot initially prompts users to describe their symptoms as best as they can. The description is then evaluated to compare to a list of proper medical terms (symptoms) in terms of similarity. Suppose those symptom descriptions are rather vague (do not match very well with the list of official symptoms or are blanket terms). In that case, Medibot asks the patients clarifying questions to identify the symptoms with the user‚Äôs added input. For example, when told, ‚ÄúMy head hurts,‚Äù Medibot will ask them to distinguish between headaches, migraines, or potentially blunt force trauma. But if the descriptions of a symptom are specific and relatable to official medical terms, Medibot asks them questions regarding associated symptoms. This means Medibot presents questions inquiring about symptoms that are known probabilistically to appear with the ones the user has already listed. The bot is designed to avoid making an initial diagnosis using a double-blind inquiry process to control for potential confirmation biases. This means the bot will not tell the doctor its predictions regarding what the user has, and it will not nudge the users into confessing or agreeing to a symptom they do not experience. Instead, the doctor will be given a list of what the user was likely describing at the end of the conversation between the bot and the user. The predictions from the inquiring process are a product of the consideration of associative relationships among symptoms. Medibot keeps track of the associative relationship through Cosine Similarity and weight distribution after the Vectorization Encoding Process. Over time, Medibot zones in on a specific condition (determined by the highest possible similarity score). The process also helps in maintaining context throughout the chat conversations. Finally, the conversation between the patient and Medibot ends in the following cases: the user needs to leave, the associative symptoms process suspects one condition much more than the others, and the user finishes discussing all symptoms they experienced."},{"heading":"How we built it","content":"We constructed the MediBot web application in two different and interconnected stages, frontend and backend. The front end is a mix of ReactJS and HTML. There is only one page accessible to the user which is a chat page between the user and the bot. The page was made reactive through several styling options and the usage of states in the messages. The back end was constructed using Python, Flask, and machine learning models such as OpenAI and Hugging Face. The Flask was used in communicating between the varying python scripts holding the MediBot response model and the chat page in the front end. Python was the language used to process the data, encode the NLP models and their calls, and store and export responses. We used prompt engineering through OpenAI to train a model to ask clarifying questions and perform sentiment analysis on user responses. Hugging Face was used to create an NLP model that runs a similarity check between the user input of symptoms and the official list of symptoms."},{"heading":"Challenges we ran into","content":"Our first challenge was familiarizing ourselves with virtual environments and solving dependency errors when pushing and pulling from GitHub. Each of us initially had different versions of Python and operating systems. We quickly realized that this will hinder our progress greatly after fixing the first series of dependency issues and started coding in virtual environments as solutions. The second great challenge we ran into was integrating the three separate NLP models into one application. This is because they are all resource intensive in terms of ram and we only had computers with around 12GB free for coding. To circumvent this we had to employ intermediate steps when feeding the result from one model into the other and so on. Finally, the third major challenge was resting and sleeping well."},{"heading":"Accomplishments we are proud of","content":"First and foremost we are proud of the fact that we have a functioning chatbot that accomplishes what we originally set out to do. In this group 3 of us have never coded an NLP model and the last has only coded smaller scale ones. Thus the integration of 3 of them into one chatbot with front end and back end is something that we are proud to have accomplished in the timespan of the hackathon. Second, we are happy to have a relatively small error rate in our model. We informally tested it with varied prompts and performed within expectations every time."},{"heading":"What we learned:","content":"This was the first hackathon for half of the team, and for 3/4, it was the first time working with virtual environments and collaborating using Git. We learned quickly how to push and pull and how to commit changes. Before the hackathon, only one of us had worked on an ML model, but we learned together to create NLP models and use OpenAI and prompt engineering (credits to OpenAI Mem workshop). This project's scale helped us understand these ML models' intrinsic moldability. Working on Medibot also helped us become much more familiar with the idiosyncrasies of ReactJS and its application in tandem with Flask for dynamically changing webpages. As mostly beginners, we experienced our first true taste of product ideation, project management, and collaborative coding environments."},{"heading":"What‚Äôs next for MediBot","content":"The next immediate steps for MediBot involve making the application more robust and capable. In more detail, first we will encode the ability for MediBot to detect and define more complex language in simpler terms. Second, we will improve upon the initial response to allow for more substantial multi-symptom functionality.Third, we will expand upon the processing of qualitative answers from users to include information like length of pain, the intensity of pain, and so on. Finally, after this more robust system is implemented, we will begin the training phase by speaking to healthcare providers and testing it out on volunteers."},{"heading":"Ethics:","content":"Our design aims to improve patients‚Äô healthcare experience towards the better and bridge the gap between a condition and getting the desired treatment. We believe expression barriers and technical knowledge should not be missing stones in that bridge. The ethics of our design therefore hinges around providing quality healthcare for all. We intentionally stopped short of providing a diagnosis with Medibot because of the following ethical considerations:\n\nBias Mitigation: Whatever diagnosis we provide might induce unconscious biases like confirmation or availability bias, affecting the medical provider‚Äôs ability to give proper diagnosis. It must be noted however, that Medibot is capable of producing diagnosis. Perhaps, Medibot can be used in further research to ensure the credibility of AI diagnosis by checking its prediction against the doctor‚Äôs after diagnosis has been made. Patient trust and safety: We‚Äôre not yet at the point in our civilization‚Äôs history where patients are comfortable getting diagnosis from AIs. Medibot‚Äôs intent is to help nudge us a step down that path, by seamlessly, safely, and without negative consequence integrating AI within the more physical, intimate environments of healthcare. We envision Medibot in these hospital spaces, helping users articulate their symptoms better without fear of getting a wrong diagnosis. We‚Äôre humans, we like when someone gets us, even if that someone is artificial.\n\nHowever, the implementation of AI for pre-diagnoses still raises many ethical questions and considerations:\n\nFairness: Use of Medibot requires a working knowledge of the English language. This automatically disproportionates its accessibility. There are still many immigrants for whom the questions, as simple as we have tried to make them, might be too much for. This is a severe limitation to our ethics of assisting these people. A next step might include introducing further explanation of troublesome terms in their language (Note: the process of pre-diagnosis will remain in English, only troublesome terms that the user cannot understand in English may be explained in a more familiar language. This way we further build patients‚Äô vocabulary and help their familiarity with English ). There are also accessibility concerns as hospitals in certain regions or economic stratas may not have the resources to incorporate this technology. Bias: We put severe thought into bias mitigation both on the side of the doctor and the patient. It is important to ensure that Medibot does not lead the patient into reporting symptoms they don‚Äôt necessarily have or induce availability bias. We aimed to circumvent this by asking questions seemingly randomly from a list of symptoms generated based on our Sentence Similarity model. This avoids leading the user in just one direction. However, this does not eradicate all biases as associative symptoms are hard to mask from the patient (i.e a patient may think chills if you ask about cold) so this remains a consideration. Accountability: Errors in symptom identification can be tricky to detect making it very hard for the medical practitioner to know when the symptoms are a true reflection of the actual patient‚Äôs state. Who is responsible for the consequences of wrong pre-diagnoses? It is important to establish these clear systems of accountability and checks for detecting and improving errors in MediBot. Privacy: MediBot will be trained on patient data and patient-doctor diagnoses in future operations. There remains concerns about privacy and data protection. This information, especially identifying information, must be kept confidential and secure. One method of handling this is asking users at the very beginning whether they want their data to be used for diagnostics and training or not."},{"heading":"Built With","content":"chatbot flask healthcare intersystems javascript natural-language-processing nltk openai python react"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Amanuensis","project_url":"https://devpost.com/software/amanuensis","tagline":"AI-enabled physician assistant for automated clinical summarization and question generation. Empowering physicians to achieve accurate diagnoses and effective treatments.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/391/613/datas/medium.jpg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Big Idea - Best Technology-Enabled Patient Safety Solution: $2000"}],"team_members":[],"built_with":[{"name":"biogpt","url":null},{"name":"chakraui","url":null},{"name":"chatgpt","url":null},{"name":"graphql","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"postgresql","url":"https://devpost.com/software/built-with/postgresql"},{"name":"prisma","url":null},{"name":"r","url":"https://devpost.com/software/built-with/r"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"redwood","url":null},{"name":"synthea","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/ayushnoori/amanuensis"}],"description_sections":[{"heading":"Problem Statement üí°","content":"The modern electronic health record (EHR) encompasses a treasure trove of information across patient demographics, medical history, clinical data, and other health system interactions (Jensen et al. ). Although the EHR represents a valuable resource to track clinical care and retrospectively evaluate clinical decision-making, the data deluge of the EHR often obfuscates key pieces of information necessary for the physician to make an accurate diagnosis and devise an effective treatment plan (Noori and Magdamo et al. ). Physicians may struggle to rapidly synthesize the lengthy medical histories of their patients; in the absence of data-driven strategies to extract relevant insights from the EHR, they are often forced to rely on intuition alone to generate patient questions. Further, the EHR search interface is rarely optimized for the physician search workflow, and manual search can be both time-consuming and error-prone.\n\nThe volume and complexity of the EHR can lead to missed opportunities for physicians to gather critical information pertinent to patient health, leading to medical errors or poor health outcomes. It is imperative to design tools and services to reduce the burden of manual EHR search on physicians and help them elicit the most relevant information from their patients."},{"heading":"About Amanuensis üìù","content":"Amanuensis is an AI-enabled physician assistant for automated clinical summarization and question generation. By arming physicians with relevant insights collected from the EHR as well as with patient responses to NLP-generated questions, we empower physicians to achieve more accurate diagnoses and effective treatment plans. The Amanuensis pipeline is as follows:\n\nClinical Summarization: Through our web application, physicians can access medical records of each of their patients, where they are first presented with a clinical summary: a concise, high-level overview of the patient's medical history, including key information such as diagnoses, medications, and allergies. This clinical summary is automatically generated by Amanuensis using Generative Pre-Trained Transformer 3 (GPT-3), an autoregressive language model with a 2048-token-long context and 175 billion parameters. The clinical summary may be reviewed by the physician to ensure that the summary is accurate and relevant to the patient's health. Question Generation: Next, Amanuensis uses GPT-3 to automatically generate a list of questions that the physician can ask their patient to elicit more information and identify relevant information in the EHR that the physician may not have considered. The NLP-generated questions are automatically sent to the patient prior to their appointment ( e.g. , once the appointment is scheduled); then, the physician can review the patient's responses and use them to inform their clinical decision-making during the subsequent encounter. Importantly, we have tested Amanuensis on a large cohort of high-quality simulated EHRs generated by Synthea TM .\n\nBy guiding doctors to elicit the most relevant information from their patients, Amanuensis can help physicians improve patient outcomes and reduce the incidences of all five types of medical errors: medication errors, patient care complications, procedure/surgery complications, infections, and diagnostic/treatment errors."},{"heading":"Building Process üèó","content":"To both construct and validate Amanuensis, we used the Synthea TM library to generate synthetic patients and associated EHRs (Walonoski et al. ). Synthea TM is an open-source software package that simulates the lifespans of synthetic patients using realistic models of disease progression and corresponding standards of care. These models rely on a diverse set of real-world data sources, including the United States Census Bureau demographics, Centers for Disease Control and Prevention (CDC) prevalence and incidence rates, and National Institutes of Health (NIH) reports. The Synthea TM package was developed by an international research collaboration involving the MITRE Corporation and the HIKER Group, and is in turn based on the Publicly Available Data Approach to the Realistic Synthetic EHR framework (Dube and Gallagher). We customized the Synthea TM synthetic data generation workflow to produce the following 18 data tables (see also the Synthea TM data dictionary ):\n\nTable Description Allergies Patient allergy data. CarePlans Patient care plan data, including goals. Claims Patient claim data. ClaimsTransactions Transactions per line item per claim. Conditions Patient conditions or diagnoses. Devices Patient-affixed permanent and semi-permanent devices. Encounters Patient encounter data. ImagingStudies Patient imaging metadata. Immunizations Patient immunization data. Medications Patient medication data. Observations Patient observations including vital signs and lab reports. Organizations Provider organizations including hospitals. Patients Patient demographic data. PayerTransitions Payer transition data ( i.e. , changes in health insurance). Payers Payer organization data. Procedures Patient procedure data including surgeries. Providers Clinicians that provide patient care. Supplies Supplies used in the provision of care.\n\nTo simulate an EHR system, we pre-processed all synthetic data (see code/construct_database.Rmd ) and standardized all fields. Next, we constructed a PostgreSQL database and keyed relevant tables together using primary and foreign keys constructed by hand. In total, our database contains 199,717 records from 20 patients across 262 different fields . However, it is important to note that our data generation pipeline is scalable to tens of thousands of patients (and we have tested this synthetic data generation capacity).\n\nFinally, we coupled the PostgreSQL database with the RedwoodJS full stack web development framework to build a web application that allows:\n\nPhysicians: Physicians to access the clinical summaries and questions generated by Amanuensis for each of their patients. Patients: Patients to access the questions generated by Amanuensis and respond to them via a web form.\n\nTo generate both clinical summaries and questions for each patient, we used the OpenAI GPT-3 API . In both cases, GPT-3 was prompted with a subset of the EHR record for a given patient inserted into a prompt template for GPT-readability. Other key features of our web application include:\n\nAuthentication: Users can log in with their email addresses; physicians are automatically redirected to their dashboard upon login, while patients are redirected to a page where they can respond to the questions generated by Amanuensis. EHR Access: Physicians can also access the full synthetic EHR for each patient as well as view autogenerated graphs and data visualizations, which they can use to review the accuracy of the clinical summaries and questions generated by Amanuensis. Patient Response Collection: Prior to an appointment, Amanuensis will automatically collect the patient's responses to the NLP-generated questions and send them to the physician. During an appointment, physicians will be informed by these responses which will facilitate better clinical decision-making."},{"heading":"Future Directions üöÄ","content":"In the future, we hope to integrate Amanuensis into existing EHR systems ( e.g. , Epic, Cerner, etc.), providing physicians with a seamless, AI-powered assistant to help them make more informed clinical decisions. We also plan to enrich our NLP pipeline with real patient data rather than synthetic EHR records. In concert with gold-standard annotations generated by physicians, we intend to fine-tune our question generation and clinical summarization models on real-world data to improve the sophistication and fidelity of the generated text and enable more robust clinical reasoning capabilities.\n\nDevelopment Team üßë‚Äçüíª\n\nAyush Noori I√±aki Arango Addea Gupta Smriti Somasundaram\n\nThis project was completed during the TreeHacks 2023 hackathon at Stanford University.\n\nAward Descriptions üèÜ\n\nBelow, we provide descriptions of specific prizes at TreeHacks 2023 which we believe Amanuensis is a strong candidate for. Please note that this list is non-exhaustive. We thank the sponsors and judges for their consideration.\n\nPatient Safety Technology Challenge\n\nBy guiding physicians to make more informed clinical decisions, Amanuensis will help reduce medical errors and improve patient safety. We anticipate that Amanuensis is well poised to avert patient harm and reduce the indidence of medical across the continuum of care, including:\n\nMedication errors: Through AI-based summarization of the medication history and identification of key risk factors for adverse drug events, potential drug-drug interactions, drug-allergy reactions, and drug-disease contraindications, Amanuensis will help physicians prescribe safer medications. Procedural/surgical errors: With access to patient responses to relevant AI-generated questions, physicians will be more prepared for procedures and surgeries, and will be able to identify potential complications and risks. Diagnostic errors: By providing physicians with a summary of the patient's medical history, relevant clinical findings, and most salient symptoms, Amanuensis will help physicians make more accurate diagnoses and avoid treatment errors.\n\nWe thank Dr. Paul Tang for his time and guidance throughout the hackathon.\n\nBest Startup and Most Likely to Become a Business\n\nThe EHR industry is ripe for disruption. Among hospitals with over 500 beds, the two dominant EHR systems, Epic and Cerner, hold 85% market share: Epic‚Äôs market share is 58%, and Cerner‚Äôs market share is 27%. Yet, physicians consistently express frustration with antiquated and inefficient interface. By contrast, Amanuensis offers a unique value proposition to physicians: a seamless, AI-powered assistant that may integrate with or supplant existing EHR systems. We believe that Amanuensis will be well positioned to disrupt the EHR industry and become a leading provider of AI-powered clinical decision support tools.\n\nBest Use of Data\n\nAmanuensis is undergirded by careful and nuanced analysis of large electronic medical datasets. To construct and validate Amanuensis, we generated a dataset with 199,717 records from 20 patients across 262 different fields; further, our synthetic EHR data generation pipeline can scale to tens of thousands of patients. Our deep understanding of the data enabled us to construct a large relational database with explicit foreign and primary keys; we later exploit these relations to efficiently query the database in JavaScript. Finally, informed by our high-quality dataset, we used leading large language models like GPT-3 from OpenAI to generate clinical summaries and questions for each patient, and designed a user interface for clinicians to both access and validate this information.\n\nBest Hack for a Real World Use Case\n\nWe carefully designed our solution to address a real-world problem: the need for more efficient and effective clinical decision support tools. Further, we iterated on our solution throughout the hackathon, incorporating feedback from physicians such as Dr. Paul Tang and other stakeholders to ensure that our solution is both feasible, impactful, and closely aligned with physician needs.\n\nMost Ethically Engaged Hack\n\nPatient privacy and safety are at the core of our hack. Thus, we invested significant effort in generating synthetic data records, which we provided to downstream language models in our web application. We also designed our web application to leave the database unexposed, and we plan to integrate Amanuensis into existing EHR systems to ensure that patient data is stored securely and is only accessible to authorized users."},{"heading":"References üìö","content":"Noori, A. et al. Development and Evaluation of a Natural Language Processing Annotation Tool to Facilitate Phenotyping of Cognitive Status in Electronic Health Records: Diagnostic Study. Journal of Medical Internet Research 24 , e40384 (2022). Jensen, P. B., Jensen, L. J. & Brunak, S. Mining electronic health records: towards better research applications and clinical care. Nat Rev Genet 13 , 395‚Äì405 (2012). Walonoski, J. et al. Synthea: An approach, method, and software mechanism for generating synthetic patients and the synthetic electronic health care record. Journal of the American Medical Informatics Association 25 , 230‚Äì238 (2018). Dube, K. & Gallagher, T. Approach and Method for Generating Realistic Synthetic Electronic Healthcare Records for Secondary Use. in Foundations of Health Information Engineering and Systems (eds. Gibbons, J. & MacCaull, W.) 69‚Äì86 (Springer, 2014). doi:10.1007/978-3-642-53956-5_6."},{"heading":"Built With","content":"biogpt chakraui chatgpt graphql node.js postgresql prisma r react redwood synthea typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"A.L.D.I. ‚Äî Automaton Language-based Dynamic Interpretor","project_url":"https://devpost.com/software/a-l-d-i-automaton-language-based-dynamic-interpretor","tagline":"Using LLMs for easy access interfaces for robotic applications. With minimal code, allow LLMs to construct your API calls for complex systems and custom tasks.","preview_image_url":"https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Drone Hack: Skydio 2+"}],"team_members":[],"built_with":[{"name":"gpt-3","url":null},{"name":"skydio","url":null},{"name":"whispr","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/punwai/aldi"}],"description_sections":[{"heading":"Inspiration","content":"LLMs are already revolutionizing software, but how can we use them for hardware ü§ñ?\n\nConsider a drone ‚Äî we can manually control it pretty easily via a joystick üïπÔ∏è.\n\nBut how can we leverage LLMs to teach it to perform tasks that we want automatically, especially without a dedicated API?\n\nAPIs are the way to interact with code, but natural language is how people think. User use-cases can be complex, and it‚Äôs practically impossible to design a Python wrapper for everything and anything a user might do.\n\nCan we do better than static APIs for robotic applications?"},{"heading":"What it does","content":"A developer tool for translating natural language üìñ into automata routines ‚öôÔ∏è.\n\nWe want to be able to conduct long-horizon automaton tasks based off natural language, even in the absense of formal APIs and documentation. Imagine a search-and-rescue team telling the drone to \"search for a person wearing red, and around 1.6m in the 100 meters paramter\" and the drone being able to search immediately without code!\n\nTo do so, we can define a couple basic function primitives, and task LLMs with decomposing our more complex tasks into a series of primitive function calls.\n\nWhy?\n\nDevelopers are happier, less functions to write! Users are happier, they can perform more complex tasks, without having to write code to automate the drone."},{"heading":"How we built it","content":"We use a Skydio Drone as our initial use case, using:\n\nSkydio Drone Custom-Built Drone SDK Networking + Ethernet local network AI Text Completion (e.g. OpenAI GPT3) AI Voice Recognition (e.g. OpenAI Whisper)"},{"heading":"Challenges we ran into","content":"The Skydio Drone SDK had not been updated in over 4 years and contained many hidden endpoints, so we had to write our own scaffolding to be able to communicate with the drone."},{"heading":"Accomplishments that we're proud of","content":"Getting the drone to listen to our voice commands and handle non-trivial tasks that it had not been programmed to enact (e.g. \"move in a 1 m square without turning\")."},{"heading":"What we learned","content":"Hardware is hard, but we can use LLMs to abstract away a lot of the complexity."},{"heading":"What's next for A.L.D.I. ‚Äî Automaton Language-based Dynamic Interpretor","content":"Add more functionality to the drone by finetuning an instruction-following language model to handle even more complex tasks, such as \"pick up my package at Tressider\", \"follow me while I ride my bike and take pictures\", \"explore a 100m radius and find my bike\"."},{"heading":"Built With","content":"gpt-3 skydio whispr"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Lav√ú","project_url":"https://devpost.com/software/lavu","tagline":"An eHealth device consisting of a wearable electromyogram (EMG) sensor that monitors muscle tension and sends haptic feedback. It includes an app that guides you towards managing your stress levels.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/391/271/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best VALUENEX Radar Hack: 4 x $250 Amazon Card & 1 year VALUENEX Radar Membership"},{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Cyberpunk Hardware Hack by Arduino: 4 x Arduino Machine Vision Bundle Kits"}],"team_members":[],"built_with":[{"name":"3d-printing","url":null},{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"c++","url":"https://devpost.com/software/built-with/c--3"},{"name":"emg","url":null},{"name":"figma","url":null},{"name":"haptic","url":null}],"external_links":[{"label":"www.figma.com","url":"https://www.figma.com/proto/uk6XDGN2MiQnWQybqksYnJ/Lav%C3%9C?page-id=0%3A1&node-id=1%3A5&viewport=493%2C548%2C0.29&scaling=scale-down&starting-point-node-id=1%3A5"},{"label":"github.com","url":"https://github.com/mehulrao/Lav-U"},{"label":"youtu.be","url":"https://youtu.be/D1cZ__7crLs"},{"label":"www.canva.com","url":"https://www.canva.com/design/DAFbABx3kSo/LyxyAOvE6nVvUxlXr3KcPQ/view?utm_content=DAFbABx3kSo&utm_campaign=designshare&utm_medium=link&utm_source=publishsharelink"}],"description_sections":[{"heading":"Intro","content":"Have an upcoming exam? Planning a wedding? Or have a tight deadline?\n\n\"I'm really stressed right now! Help!\"\n\nWell, with Lav√ú, we've gotchyou!"},{"heading":"Inspiration","content":"After experiencing stressors in everyday life and speaking with members of the community, we found that many people experience stress physically‚Äîparticularly, through tightness in the neck and shoulders. Research backs this up. A study by Jacqueline Wijsman et al. published in Wireless Health found \"significantly higher amplitudes of the EMG signals [from the Trapezius muscles] during stress compared to rest and fewer gaps (periods of relaxation) during stress,\" making it a useful indicator of stress in real time."},{"heading":"What it does","content":"Lav√ú Device : A wearable electromyogram (EMG) sensor that monitors muscle tension and sends haptic feedback . By analyzing trends in muscle tension over time, Lav√ú detects changes in stress levels. Using this data, we can notify users through a gentle tap if it's time to do haptic-assisted breathing exercises or take a break.\n\nLav√ú App : In addition, the Lav√ú App, displays a chart of your stress levels over time throughout the day. The app provides features to take care of your mental health reducing your stress levels such as providing journal entries, nutritional values, breathing exercises, and more."},{"heading":"How we built it","content":"Lav√ú is powered by the Nicla Sense ME microcontroller and a LiPo battery, while a Gravity EMG Sensor takes measurements of muscle tension. A DRV2605 Haptic Driver assists in generating gentle vibrations.\n\nThe device itself is enclosed in a flexible 3D printed chassis, which is sewn into clothes for comfort."},{"heading":"Challenges we ran into","content":"Creating a hardware project results in many practical challenges.\n\nPowering the device (working with multiple power sources) Mounting the device - ensuring that proper contact is made between the sensor and the body Writing code to interpret data from the EMG Developing haptic breathing sequences"},{"heading":"Accomplishments that we're proud of","content":"We are extremely proud of the ability to record data that can be converted into stress levels in real time. Additionally, we were able to design an interactive prototype of our envisioned app that goes hand-in-hand with the device."},{"heading":"What we learned","content":"Working on a project that requires both technical aspects of both hardware and software requires a strong understanding of how we can integrate the data together. Coming from different backgrounds, we learnt how to collaborate cohesively and efficiently to build this project. We also have a better understanding of the users we design for and the various forms of stress relieving exercises. We have thoroughly enjoyed this project as it has given us multiple perspectives of technology."},{"heading":"What's next for Lav√ú","content":"Create greater awareness of points system that can provide positive reinforcement ML model that can learn stress patterns from each individual for personalized detection and feedback Include better accessibility software on different mobile applications\n\nTry out Lav√ú for a better you!"},{"heading":"Built With","content":"3d-printing arduino c++ emg figma haptic"},{"heading":"Try it out","content":"www.figma.com github.com youtu.be www.canva.com"}]},{"project_title":"yumma","project_url":"https://devpost.com/software/yumma","tagline":"‚ÄúYumma‚Äù (a play on words, ‚Äúyum‚Äù + ‚Äúumma‚Äù [Mom in Korean]) forms bonds between Asian American Gen Z and our cultural roots via the sharing of traditional recipes by our immigrant parents.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/390/375/datas/medium.JPG","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Hack to Connect with Others Through Food by Otsuka VALUENEX: 4 x $500 DoorDash Card & $250 Spa Card"}],"team_members":[],"built_with":[{"name":"convex","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"figma","url":null},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"materialui","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"www.figma.com","url":"https://www.figma.com/file/oNXTXlHaBCuhat4kYOhl02/yumma?node-id=53295%3A27471&t=8FwAzztoXkZ1jnUc-1"},{"label":"github.com","url":"https://github.com/erinkwon01/yumma"}],"description_sections":[{"heading":"Inspiration","content":"When we heard about using food as a means of love and connection from Otsuka x VALUENEX‚Äôs Opening Ceremony presentation, our team was instantly inspired to create something that would connect Asian American Gen Z with our cultural roots and immigrant parents. Recently, there has been a surge of instant Asian food in American grocery stores. However, the love that exudes out of our mother‚Äôs piping hot dishes is irreplaceable, which is why it‚Äôs important for us, the loneliest demographic in the U.S., to cherish our immigrant parents‚Äô traditional recipes. As Asian American Gen Z ourselves, we often fear losing out on beloved cultural dishes, as our parents have recipes ingrained in them out of years of repetition and thus, neglected documenting these precious recipes. As a result, many of us don‚Äôt have access to recreating these traditional dishes, so we wanted to create a web application that encourages sharing of traditional, cultural recipes from our immigrant parents to Asian American Gen Z. We hope that this will reinforce cross-generational relationships, alleviate feelings of disconnect and loneliness (especially in immigrant families), and preserve memories and traditions."},{"heading":"What it does","content":"Through this web application, users have the option to browse through previews of traditional Asian recipes, posted by Asian or Asian American parents, featured on the landing page. If choosing to browse through, users can filter (by culture) through recipes to get closer to finding their perfect dish that reminds them of home. In the previews of the dishes, users will find the difficulty of the dish (via the number of knives ‚Äì greater is more difficult), the cultural type of dish, and will also have the option to favorite/save a dish. Once they click on the preview of a dish, they will be greeted by an expanded version of the recipe, featuring the name and image of the dish, ingredients, and instructions on how to prepare and cook this dish. For users that want to add recipes to yumma , they can utilize a modal box and input various details about the dish. Additionally, users can also supplement their recipes with stories about the meaning behind each dish, sparking warm memories that will last forever."},{"heading":"How we built it","content":"We built yumma using ReactJS as our frontend, Convex as our backend (made easy!), Material UI for the modal component, CSS for styling, GitHub to manage our version set, a lot of helpful tips and guidance from mentors and sponsors (‚ô°), a lot of hydration from Pocari Sweat (‚ô°), and a lot of love from puppies (‚ô°)."},{"heading":"Challenges we ran into","content":"Since we were all relatively beginners in programming, we initially struggled with simply being able to bring our ideas to life through successful, bug-free implementation. We turned to a lot of experienced React mentors and sponsors (shoutout to Convex) for assistance in debugging. We truly believe that learning from such experienced and friendly individuals was one of the biggest and most valuable takeaways from this hackathon. We additionally struggled with styling because we were incredibly ambitious with our design and wanted to create a high-fidelity functioning app, however HTML/CSS styling can take large amounts of time when you barely know what a flex box is. Additionally, we also struggled heavily with getting our app to function due to one of its main features being in a popup menu (Modal from material UI). We worked around this by creating an extra button in order for us to accomplish the functionality we needed."},{"heading":"Accomplishments that we're proud of","content":"This is all of our first hackathon! All of us also only recently started getting into app development, and each has around a year or less of experience‚Äìso this was kind of a big deal to each of us. We were excitedly anticipating the challenge of starting something new from the ground up. While we were not expecting to even be able to submit a working app, we ended up accomplishing some of our key functionality and creating high fidelity designs. Not only that, but each and every one of us got to explore interests we didn‚Äôt even know we had. We are not only proud of our hard work in actually making this app come to fruition, but that we were all so open to putting ourselves out of our comfort zone and realizing our passions for these new endeavors. We tried new tools, practiced new skills, and pushed our necks to the most physical strain they could handle. Another accomplishment that we were proud of is simply the fact that we never gave up. It could have been very easy to shut our laptops and run around the Main Quadrangle, but our personal ties and passion for this project kept us going."},{"heading":"What we learned","content":"On the technical side, Erin and Kaylee learned how to use Convex for the first time (woo!) and learned how to work with components they never knew could exist, while Megan tried her hand for the first time at React and CSS while coming up with some stellar wireframes. Galen was a double threat, going back to her roots as a designer while helping us develop our display component. Beyond those skills, our team was able to connect with some of the company sponsors and reinvigorate our passions on why we chose to go down the path of technology and development in the first place. We also learned more about ourselves‚Äìour interests, our strengths, and our ability to connect with each other through this unique struggle."},{"heading":"What's next for yumma","content":"Adding the option to upload private recipes that can only be visible to you and any other user you invite to view it (so that your Ba Ngoai‚Äìgrandma‚Äôs‚Äîrecipes stay a family secret!)\n\nAdding more dropdown features to the input fields so that some will be easier and quicker to use\n\nA messaging feature where you can talk to other users and connect with them, so that cooking meetups can happen and you can share this part of your identity with others\n\nAllowing users to upload photos of what they make from recipes they make and post them, where the most recent of photos for each recipe will be displayed as part of a carousel on each recipe component.\n\nAn ingredients list that users can edit to keep track of things they want to grocery shop for while browsing"},{"heading":"Built With","content":"convex css figma github html materialui node.js react"},{"heading":"Try it out","content":"www.figma.com github.com"}]},{"project_title":"Semantic Near","project_url":"https://devpost.com/software/semantic-near","tagline":"Perform Semantic Search over all the posts of any user on the decentralized Near Social network.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/389/407/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Uses of NEAR Social: $1000 (1st & 2nd & 3rd Place)"}],"team_members":[],"built_with":[{"name":"docker","url":"https://devpost.com/software/built-with/docker"},{"name":"faiss","url":null},{"name":"near","url":null},{"name":"nearsocial","url":null},{"name":"nextjs","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"www.semanticnear.xyz","url":"https://www.semanticnear.xyz/"}],"description_sections":[{"heading":"Background & Architecture","content":"The Near Social Network is a fully decentralized social network that lives entirely on the NEAR blockchain. As usage of the platform grows and becomes a more prominent source of news and media consumption in the future, tools such as Semantic Search are required to help parse this information.\n\nBecause all data is stored on-chain, the contracts are optimized to minimize storage. Thus, although a user may have made hundreds of posts over time, only a single post is stored in the smart contract state at any given time. When a new post is made, the old post is deleted to free storage and the new post replaces it. Thus, recreating the entire chain of user posts requires traversing the blockchain history to analyze each block and fetch the current post for the user at that block. Building an indexer would be the best solution for this problem, but due to resource & time constraints, we opt for a different solution.\n\nA user inputs a Near Social account id along with a semantic search query. We use the Pagoda Enchanced API to then grab all the blocks that the account ID of interest has had any interaction in. We then query the SocialDB Contract (which contains all the state of Near Social) to reconstruct the chain of posts the user has made.\n\nThese posts are then passed into our backend server, which is written in python & uses FastAPI as the web framework. With the posts in hand, we use NLTK to slice up the text into smaller chunks composed of complete sentences. This will allow us to identify the most relevant chunks of text. We calculate the word embeddings for each of our chunks ‚Äì the embeddings come from OpenAI's Embedding Model . With embeddings in hand, we compute a similarity search using Facebook Research's FAISS library against the user-inputted semantic search query. In order to capture surrounding context, we also retrieve neighboring textual chunks (the +/- 1 chunks that surround the relevant chunks we have found). We then return these results to the user.\n\nFor deployment, we deploy a docker container on AWS ECS using Fargate as our compute engine to autoscale compute resources depending on website load. Our container fleet sits behind an Elastic Load Balancer that provides SSL termination."},{"heading":"Build","content":"Backend\n\nFor our backend code we use a Makefile for our build process and Poetry as our dependency manager for Python. Install poetry, change directories into the server folder, and then run poetry install to install all dependencies. Note that we require python 3.9.13 and that the Rust Compiler must be installed on your machine in order to build certain dependencies. An OpenAI API Key is required for the project, and must be available in the environment as OPENAI_API_KEY . You can run export OPENAI_API_KEY=<your key> in your current shell or add the key to your .zshenv file.\n\nAfterwards, run make setup to configure your environment to run our application. To run the server run make server . To build a docker image for the server run make docker-build-local . To create a docker container based on the image run make docker-run-local .\n\nFrontend\n\nOur frontend is built using React , Next.js , and Tailwind CSS . To run our web app locally, change directories into the frontend directory and run yarn install to install all dependencies. Then run yarn dev ."},{"heading":"Improvements","content":"This is an early prototype and there are many improvements to be made. A cleaner integration with Near Social would allow a user to login into their account and select multiple users to conduct a semantic search on. In it's final form, this may look like a Near Social Widget that allows a user to effectively parse information through their feed via blazing-fast semantic search. The word embeddings of a user's feed can be computed & caches before hand, and websockets can be used to allow for real-time search results."},{"heading":"Acknowledgement & Disclaimer","content":"This is a prototype and has not been thoroughly battle-tested."},{"heading":"Built With","content":"docker faiss near nearsocial nextjs openai python react tailwind typescript vercel"},{"heading":"Try it out","content":"www.semanticnear.xyz"}]},{"project_title":"Vapor Protocol","project_url":"https://devpost.com/software/vapor-protocol","tagline":"Vapor Protocol helps users exchange tokens or fiat for gas on different chains without needing to go through a centralized party.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/243/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Real-World Crypto Hack by Zetachain: 4 x Ledger Nano x"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"solidity","url":"https://devpost.com/software/built-with/solidity"},{"name":"webflow","url":"https://devpost.com/software/built-with/webflow"}],"external_links":[{"label":"vapor-protocol.webflow.io","url":"https://vapor-protocol.webflow.io/"},{"label":"github.com","url":"https://github.com/jeremyzhang1/vapor-protocol"}],"description_sections":[{"heading":"Critical notes:","content":"Website MUST be viewed between 67% and 75% on any Mac or Windows laptop Website"},{"heading":"What inspired you?","content":"We were inspired to build this project to solve one of the most core problems experienced by native and non-native Crypto users. Needing native gas to process transactions on a new chain is a nightmare to acquire and necessitates a centralized exchange that the user can interact with (with all the pain points of CEXs like KYC and delays). We‚Äôve figured out a way to use Zetachain‚Äôs cross-chain swaps to be able to send gas to any chain as long as you have some tokens on one chain. This way, users don‚Äôt have to route through CEX and acquire gas without touching a custodial actor."},{"heading":"If we had more time","content":"One of the best ways to improve our product would be to incorporate fiat onramps so users don‚Äôt have to have any existing tokens on any chain to split gas across chains. Integrating Stripe or Ramp Network would be simple to do but we ran out of time to look into it. This feature would make our product fully abstracted for the Web3 newbie, allowing them to start with gas on any chain they wanted using the fiat money they already possess."},{"heading":"How we built our project","content":"On the backend, we implemented a Solidity smart contract that conducted cross-chain swaps. This contract would first take the native token on the first chain and use the Uniswap quoter and router to swap it into ZETA tokens on the first chain. Then, we would use Zetachain‚Äôs cross chain messaging Connector API to send the ZETA tokens to a second chain. On receiving these tokens on the second chain, the smart contract would deconstruct the message, then use the Uniswap quoter and router again to swap the ZETA tokens back into the desired native token on the second chain. On the frontend, we used a combination of Webflow and React. We used Webflow to make a landing page that described many of the features of our project as well as a sample user flow. For the actual smart contract interaction, we linked the Webflow landing page to a React page that uses web3.js to interact with the smart contracts. Setting up the smart contracts was quite involved. First, we had to deploy this contract onto every single chain that we wanted to potentially swap tokens into. Then, we had to call the setInteractorByChainId function so that each contract would know where its counterparts on other chains lived. After all of this was set up, swaps were ready to be made by the user."},{"heading":"Challenges we faced","content":"This was the first time any of us had dealt with programming on the blockchain across chains. Thinking in terms of sending messages across chains was quite challenging but also very rewarding once we understood the programming paradigms. Our biggest difficulty was the transaction not succeeding on the other side of the bridge. While we have a few guesses as to why that may be, we had difficulty navigating the block explorer and the documentation, so we were unable to understand exactly why transactions were failing."},{"heading":"Built With","content":"css html react solidity webflow"},{"heading":"Try it out","content":"vapor-protocol.webflow.io github.com"}]},{"project_title":"YouCare","project_url":"https://devpost.com/software/youcare-sjaovm","tagline":"Introducing YouCare, the health app that helps women identify their PCOS symptoms based on their personal data. Simply search on You.com to receive customized results and take control of your health.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/387/624/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of the You.com Open Platform: $2000"}],"team_members":[],"built_with":[{"name":"checkbook.io","url":null},{"name":"you.com","url":null}],"external_links":[{"label":"tinyurl.com","url":"https://tinyurl.com/2j88tjae"},{"label":"github.com","url":"https://github.com/nbalamur03/treeHacks.git"},{"label":"github.com","url":"https://github.com/brookebols/symptoms-api"}],"description_sections":[{"heading":"Inspiration","content":"Polycystic Ovary Syndrome (PCOS) is a disorder that affects 5-10% of the female population due to an imbalance of hormones. Women that experience PCOS have an increased risk of type 2 diabetes, high blood pressure, high cholesterol, anxiety, and depression. Like a lot of women's disorders, it‚Äôs common for PCOS to receive a delayed or no diagnosis at all due to lack of awareness of PCOS symptoms and the wide-range of symptoms. As a consequence, many women unknowingly suffer from the health risks without proper treatment.\n\nWe have developed an application for the You.com search engine that compares your health data with information about women's health from your searches, allowing you to monitor your health status and identify potential indicators of PCOS."},{"heading":"What it does","content":"When you search anything related to women‚Äôs sexual and reproductive health, our application pops up with 3 key features: (1) providing comprehensive information on PCOS by web scrapping, (2) comparing these symptoms with information from your health app, (3) donation feature that allows you to contribute to organizations dedicated to providing resources to women with the condition."},{"heading":"How we built it","content":"Using You.com's Developer Dashboard, we utilized their editor to design the user interface, incorporating two APIs for personalized health data and generalized PCOS information. Furthermore, we integrated checkbook.io to enable donations directly to community organizations just with payee info!"},{"heading":"Challenges we ran into","content":"We encountered challenges while incorporating the API into the You.com codebase, primarily due to the limitations of the \"Form\" components and difficulties placing components precisely as desired. Additionally, the integration of Checkbook.io was challenging due to the steps involved with user authentication and bank account creation."},{"heading":"Accomplishments that we're proud of","content":"The donation app tile is fully functional and we can track the donations given by the user through email and the Sandbox environment."},{"heading":"What we learned","content":"We learned about how to create and integrate APIs, front-end development using You.com, and functionality of HTTP POST and GET methods while deepening our knowledge of PCOS and its impact on women's health."},{"heading":"What's next for YouCare","content":"We aim to expand this tool to include more topics in women's health like STDs, pregnancy and sex education, each with their unique features to improve awareness. It‚Äôs capabilities can further develop to address all queries that deal with women‚Äôs health like providing advice on topics related to women's health, like periods or menstrual products. For instance, it can show you a summary of your cycle and suggest products that might be useful for you, and physicians you should consider etc."},{"heading":"Built With","content":"checkbook.io you.com"},{"heading":"Try it out","content":"tinyurl.com github.com github.com"}]},{"project_title":"Talk to History","project_url":"https://devpost.com/software/living-history","tagline":"Talk to History: Step into your textbook. Read about history and then talk to the people in the passage, just like the magical portraits in Harry Potter.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/389/536/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Chat App by You.com: $2000"}],"team_members":[],"built_with":[{"name":"chakra","url":null},{"name":"gpt","url":null},{"name":"next.js","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null},{"name":"wav2lip","url":null}],"external_links":[{"label":"treehacks-2023.vercel.app","url":"https://treehacks-2023.vercel.app"},{"label":"github.com","url":"https://github.com/Scott-Hickmann/TreeHacks-2023"},{"label":"github.com","url":"https://github.com/Scott-Hickmann/TreeHacks-2023-GPT-Agent"},{"label":"github.com","url":"https://github.com/Scott-Hickmann/TreeHacks-Wav2Lip"}],"description_sections":[{"heading":"Inspiration","content":"Textbooks have not fundamentally changed since their invention in the 16th century. Although there are now digital textbooks (ePubs and the like), they're still just pictures and text. From educational literature, we know that discussion and interactivity is crucial for improving student outcomes (and, particularly, those of marginalized students). But we still do the majority of our learning with static words and images on a page."},{"heading":"What it does","content":"How do we keep students engaged? Introducing Talk To History . This is a living textbook, where students can read about a historical figure, click on their face on the side of the page, and have an immersive conversation with them. Or, read a primary text and then directly engage to ask questions about the writing. This enables a richer, multimodal interaction. It makes history more immersive. It creates more places to engage and retain knowledge. Most importantly, it makes the textbook fun. If Civ5 can make history fun, why can‚Äôt textbooks?"},{"heading":"How we built it","content":"Talk To History was built using TypeScript, React, Next.js, Vercel, Chakra, Python, Google Text-To-Speech, Wav2Lip, GPT, and lots of caffeine :) The platform has several components, including a frontend for students and a backend to handle user data and text analysis. We also used Google's Text-To-Speech (TTS) API to generate high-quality speech output, which we then fed into Wav2Lip, a deep generative adversarial network, to produce realistic lip movements for the characters. For accelerated inference, we deployed Wav2Lip on an NVIDIA A40 GPU server."},{"heading":"Challenges we ran into","content":"Dealing with CUDA memory leaks when performing inference using the Wav2Lip model Finetuning hyperparameters of the Wav2Lip model and optimizing PyTorch loading to reduce latency Connecting and deploying all of the different services (TTS, GPT, Wav2Lip) into a unified product"},{"heading":"Accomplishments we're proud of","content":"We're most proud of building a platform that makes learning fun and engaging for students. On the technical side, we're proud of seamlessly integrating several cutting-edge technologies, such as Wav2Lip and GPT, to create a more immersive experience; this project required advanced techniques in full-stack engineering, multi-processing, and latency optimization. The end result was more than worth the effort, as we successfully created a platform that makes education more engaging and immersive. With Talk To History , we hope to transform the way students learn history."},{"heading":"What we learned","content":"We learned how to integrate multiple services and optimize our code to handle large amounts of data, but perhaps more importantly, we gained a deep appreciation for the importance of creating an exciting experience for students."},{"heading":"What's next","content":"Scalability and speed improvements for Wav2Lip GPU instances for more realtime chats Improved robustness against adversarial prompts Broader selection of articles and speakers organized into different domains, such as \"Pioneers in Environmental Sustainability\", \"Female Heroes in Science\", and \"Diverse Voices in Literature\" Talk to History as a platform: ability for any educational content author to add their own character (subject to content approval) given some context and voice and integrate it on their website or e-reader"},{"heading":"Built With","content":"chakra gpt next.js python react typescript vercel wav2lip"},{"heading":"Try it out","content":"treehacks-2023.vercel.app github.com github.com github.com"}]},{"project_title":"Apto-Check","project_url":"https://devpost.com/software/apto-check","tagline":"The first blockchain-backed legit check","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/183/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Aptos: $1000"}],"team_members":[],"built_with":[{"name":"aptos","url":null},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"firestore","url":null},{"name":"gimp","url":"https://devpost.com/software/built-with/gimp"},{"name":"next.js","url":null},{"name":"next.js-backend:-typescript-+-aptos-api","url":null},{"name":"petra","url":null},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"}],"external_links":[{"label":"github.com","url":"https://github.com/rydelopez/treehacks2023"}],"description_sections":[{"heading":"Inspiration","content":"The biggest question asked in the resale of any item of value used to be about condition, functionality, and other tangibles. But now, in a world where counterfeits are so hard to spot and brand value reigns supreme, the single most important question has become ‚Äúis it real?‚Äù As unfortunate as it is, with the explosion of e-commerce, counterfeits have become an increasingly prominent concern in the purchase of any item, from consumer electronics to even fields as critical as prescription medication. However, no sector of business has been hit harder by counterfeiting than that of luxury apparel and accessories.\n\nThe rise of counterfeiting has spawned a $118 billion anti-counterfeiting industry, with advanced QR codes and printing techniques employed to make it more difficult for bad actors to manufacture fakes and third-party validation companies like StockX protecting the resale market from fakes. Ironically, anti-counterfeiting measures have inspired many counterfeiters to also manufacture fake anti-counterfeiting features, including copied QR codes, forged certificates of authenticity, and even fake StockX tags. As a result it is absolutely impossible to say with 100% certainty that anything sold by anybody but the manufacturer itself is real, a plight that has plagued the secondhand market for years.\n\nIn a survey of several sneakerheads across the nation with varying stakes in the sneaker resale market, the unanimous single largest concern when buying goods, even with seemingly proper documentation, is that the product is counterfeit, and the process of verifying/proving authenticity takes an average of nearly half the time spent on a transaction (over ten minutes!).\n\nWe seek to provide a solution to this problem by leveraging the immutability of the blockchain, transparent transaction history of digital assets, and the unforgeability of digital signatures to INSTANTLY certify with 100% certainty that a physical asset is real using an NFT."},{"heading":"What it does","content":"Apto-check is a protocol built on the Aptos blockchain that backs verifiably legitimate physical assets with NFTs. The protocol works as such:\n\nWhen the admin receives the asset‚Äôs serial number and substantial evidence that an asset is legitimate (what qualifies as ‚Äúsubstantial‚Äù is either proof of recent purchase directly from the manufacturer or verification by trusted third parties like StockX or GOAT), the admin mints an NFT for the asset using the admin account‚Äôs private key and sends it to the address of the user requesting the NFT. It is important to note that the protocol is structured such that new NFTs can only be minted by ONE ADDRESS, the admin account. This is done deliberately, as it allows for every NFT minted for Apto-check to be traced back to the exact same minting address, making Apto-check NFTs absolutely impossible to counterfeit. Even if a criminal were able to mint an NFT with the exact same picture, serial number, and internal smart contract data, because they don‚Äôt have the admin‚Äôs private key, the fake NFT would trace back to the criminal‚Äôs address, rather than the admin‚Äôs, making it painfully obvious that the NFT is fake. Although this is certainly enough to invalidate attempts to counterfeit Apto-check NFTs, Apto-check actually has an additional safeguard in place in that it is impossible to send, receive, or even view NFTs not minted by the admin address, meaning that even if a counterfeit Apto-check NFT were to make it into an Aptos wallet, it would be impossible to use in the Apto-check dApp.\n\nApto-check syncs with a user‚Äôs Petra Aptos wallet, and shows a detailed overview of the user‚Äôs current Apto-check NFTs on the homepage. Because Apto-check is meant to be used as a tool for the sneaker resale industry, let us consider how the dApp performs in the case of a sneaker sale. The idea is that a sale between buyer Alice and seller Bob will go as follows:\n\nAlice takes a look at an Apto-check backed pair of Jordans and decides that she is interested in purchasing it. Alice asks the ultimate question in requesting proof that those Jordans are real. Bob shows Alice the corresponding Apto-check NFT on the homepage of the Apto-check dApp, and demonstrates that the NFT‚Äôs serial number field matches the physical serial number on the pair of Jordans. Alice is assured without any doubt that the pair of Jordans are real, and decides to buy the shoes. Bob transfers the corresponding NFT to Alice‚Äôs Aptos address through the Apto-check dApp. Upon receiving the pending transfer of the shoes‚Äô NFT in her Aptos wallet, Alice pays Bob for the shoes and accepts the transaction. The NFT is transferred to her wallet, and Alice is now able to prove to anybody that her Jordans are undeniably real.\n\nThe hope is that in the sneaker resale market, Apto-check NFTs will be used as an undeniable standard of authenticity."},{"heading":"How we built it","content":"Frontend: React, Typescript, Tailwind, Next.js Backend: Typescript + Aptos API, Firebase Blockchain: Aptos Accounts DB: Firestore Aptos Wallet: Petra Design: GIMP & MS Paint"},{"heading":"Challenges we ran into","content":"Learning how to use the Aptos API to interact with the Aptos blockchain was difficult to pick up, as it was both of our first times ever being exposed to the Aptos blockchain. We encountered some difficulty with using the Aptos incrementer to access an account‚Äôs tokens for the frontend, and accidentally became rate-limited. Many thanks to the Aptos team for their incredible support in helping us through the process of building in the Aptos ecosystem, answering any and all questions we had, and for solving the rate-limiting fiasco :)"},{"heading":"Accomplishments that we're proud of","content":"We took a big risk by deciding to take an idea we had planned to implement on another blockchain and building it on Aptos, a blockchain we hadn‚Äôt heard of until Treehacks. We are especially proud of how we were still able to leverage some unique aspects of Aptos to implement additional security features (such as preventing non-admin-minted NFTs from appearing in the dApp) to make Apto-check as airtight as possible, and we‚Äôve certainly learned the unique benefits of building of Aptos, especially for a project like ours. In addition, we‚Äôre very happy with the user-friendly user experience we‚Äôve created, as we believe that especially with blockchain projects, it is of utmost importance to make it easy enough for a user with no blockchain background at all to use properly."},{"heading":"Features Coming Soon to Apto-Check","content":"Our intentions from the start were to subsidize all gas fees as to prevent overcomplicating the user experience by requiring all users to have APT in their wallets. The means to implement this feature are soon to come in an upcoming Aptos update. We also intend on vastly simplifying the barriers of entry for blockchain users by utilizing QR codes to communicate public keys, and by removing the necessity of a user to set up their own Petra wallets. We plan to allow users to sign up and sign in with just their email addresses and passwords by setting up wallets for them when they sign up to remove the overcomplication of needing to deal with multiple platforms."},{"heading":"Apto-Check‚Äôs growth strategy","content":"Apto-Check has been segmented for the sneakerhead market first for several reasons, with the most obvious being the importance of proving genuinity quickly and with complete certainty, and with the most important being that the sneakerhead community has a generally bullish outlook on NFTs and has a substantial amount of overlap with the NFT community. We hope to establish Apto-Check as the new golden standard for authenticity in the sneakerhead market, just like how StockX did with their verification tags before they started getting faked, and use this to expand into the very adjacent broader market for luxury apparel.\n\nGiven Apto-check‚Äôs potential to disrupt the $1.7 - 4.5 trillion market for counterfeit goods, the market potential for Apto-check, especially if it becomes integrated in the luxury goods supply chain (e.g. partnering with manufacturers to mint NFTs for all goods produced), is incredible. Furthermore, because it costs fractions of a penny for each transaction, monetization via charging a flat fee for each NFT minted will be infinitely scalable due to the negligible cost of maintaining the Apto-check network."},{"heading":"Built With","content":"aptos firebase firestore gimp next.js next.js-backend:-typescript-+-aptos-api petra react tailwind typescript"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Saga","project_url":"https://devpost.com/software/saga-7fivyd","tagline":"Custom, user driven bedtime stories for children using generative AI -- Saga makes reading more fun and educational","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/391/957/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Chat App by You.com: $2000"}],"team_members":[],"built_with":[{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"flutter","url":"https://devpost.com/software/built-with/flutter"},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"openai","url":null}],"external_links":[{"label":"www.sagaverse.app","url":"http://www.sagaverse.app"},{"label":"github.com","url":"https://github.com/davisgcii/codeontap"}],"description_sections":[{"heading":"Inspiration","content":"There are few better feelings in the world than reading together with a child that you care about. ‚ÄúJust one more story!‚Äù ‚Äî ‚ÄúI promise I‚Äôll go to bed after the next one‚Äù ‚Äî or even simply ‚ÄúZzzzzzz‚Äù ‚Äî these moments forge lasting memories and provide important educational development during bedtime routines. We wanted to make sure that our loved ones never run out of good stories. Even more, we wanted to create a unique, dynamic reading experience for kids that makes reading even more fun.\n\nAfter helping to build the components of the story, kids are able to help the character make decisions along the way. ‚ÄúShould Balthazar the bear search near the park for his lost friend? or should he look in the desert?‚Äù These decisions help children learn and develop key skills like decisiveness and action. The story updates in real time, ensuring an engaging experience for kids and parents.\n\nThrough copious amounts of delirious research, we learned that children can actually learn better and retain more when reading with parents on a tablet. After talking to 8 users (parents and kiddos) over the course of the weekend, we defined our problem space and set out to create a truly ‚ÄúNeverending Story.‚Äù"},{"heading":"What it does","content":"Each day, Saga creates a new, illustrated bedtime story for children aged 0-7. Using OpenAI technology, the app generates and then illustrates an age and interest-appropriate story based on what they want to hear and what will help them learn. Along the way, our application keeps kids engaged by prompting decisions; like a real-time choose-your-own-adventure story.\n\nWe‚Äôre helping parents broaden the stories available for their children ‚Äî imprinting values of diversity, inclusion, community, and a strong moral compass. With Saga , parents and children can create a universe of stories, with their specific interests at the center."},{"heading":"How we built it","content":"We took an intentional approach to developing a working MVP\n\nNeeds finding: We began with a desire to uncover a need and build a solution based on user input. We interviewed 8 users over the weekend (parents and kids) and used their insights to develop our application. Defined MVP: A deployable application that generates a unique story and illustrations while allowing for dynamic reader inputs using OpenAI. We indexed on story, picture, and educational quality over reproducibility. Tech Stack: We used the latest LLM models (GPT-3 and DALLE-2), Flutter for the client, a Node/Express backend, and MongoDB for data management Prompt Engineering: Finding the limitations of the underlying LLM technology and instead using Guess and check until we narrowed down the prompt to produce to more consistent results. We explored borderline use cases to learn where the model breaks. Final Touches: Quality control and lots of tweaking of the image prompting functionality"},{"heading":"Challenges we ran into","content":"Our biggest challenges revolved around fully understanding the power of, and the difficulties stemming from prompt generation for OpenAI. This struggle hit us on several different fronts:\n\nText generation - Early on, we asked for specific stories and prompts resembling ‚Äúwrite me a 500-word story.‚Äù Unsurprisingly, the API completely disregarded the constraints, and the outputs were similar regardless of how we bounded by word count. We eventually became more familiar with the structure of quality prompts, but we hit our heads against this particular problem for a long time. Illustration generation - We weren‚Äôt able to predictably write OpenAI illustration prompts that provided consistently quality images. This was a particularly difficult problem for us since we had planned on having a consistent character illustration throughout the story. Eventually, we found style modifiers to help bound the problem. Child-safe content - We wanted to be completely certain that we only presented safe and age-appropriate information back to the users. With this in mind, we built several layers of passive and active protection to ensure all content is family friendly."},{"heading":"What we learned","content":"So many things about OpenAI!\n\nCreating consistent images using OpenAI generation is super hard, especially when focusing on one primary protagonist. We addressed this by specifically using art styles to decrease the variability between images. GPT-3's input / output length limitations are much more stringent than ChatGPT's -- this meant we had to be pretty innovative with how we maintained the context over the course of 10+ page stories. How to reduce overall response time while using OpenAI's API, which was really important when generating so many images and using GPT-3 to describe and summarize so many things. Simply instructing GPT to not do something doesn‚Äôt seem to work as well as carefully crafting a prompt of behavior you would like it to model. You need to trick it into thinking it is someone or something -- from there, it will behave."},{"heading":"Accomplishments that we're proud of","content":"We‚Äôre super excited about what we were able to create given that this is the first hackathon for 3 of our team members! Specifically, we‚Äôre proud of:\n\nDeveloping a fun solution to help make learning engaging for future generations Solving a real need for people in our lives Delivering a well-scoped and functional MVP based on multiple user interviews Integrating varied team member skill sets from barely technical to full-stack"},{"heading":"What's next for Saga","content":"Test and Iterate\n\nWe‚Äôre excited to get our prototype project in the hands of users and see what real-world feedback looks like. Using this customer feedback, we‚Äôll quickly iterate and make sure that our application is really solving a user need. We hope to get this on the App Store ASAP!!\n\nAdd functionality\n\nBased on the feedback that we‚Äôll receive from our initial MVP, we will prioritize additional functionality:\n\nReading level that grows with the child ‚Äî adding more complex vocabulary and situations for a story and character that the child knows and loves.\n\nAllow for ongoing universe creation ‚Äî saving favorite characters, settings, and situations to create a rich, ongoing world.\n\nUnbounded story attributes ‚Äî rather than prompting parents with fixed attributes, give an open-ended prompt for more control of the story, increasing child engagement\n\nReal-time user feedback on a story to refine the prompts ‚Äî at the end of each story, capture user feedback to help personalize future prompts and stories.\n\nMonetize\n\nEvaluate unit economics and determine the best path to market. Current possible ideas:\n\nSaaS subscription based on one book per day or unlimited access Audible tokens model to access a fixed amount of stories per month Identify and partner with mid-market publishers to license IP and leverage existing fan bases Whitelabel the solution on a services level to publishers who don‚Äôt have a robust engineering team"},{"heading":"References","content":"https://www.frontiersin.org/articles/10.3389/fpsyg.2017.00677/full"},{"heading":"Built With","content":"express.js flutter mongodb node.js openai"},{"heading":"Try it out","content":"www.sagaverse.app github.com"}]},{"project_title":"Carb0 - Empower your carbon journey","project_url":"https://devpost.com/software/carb0","tagline":"Our mission is to establish \"consumer-driven ESG\" by creating a personal carbon tracker that incentivizes customers to adopt low-carbon lifestyles and democratizes carbon footprint data.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/100/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Retool Hack Ninjas (Tentative): 4 x Ducky One 3 SF Pure White 65% Hotswap RGB Mechanical Keyboard"}],"team_members":[],"built_with":[{"name":"convex","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"retool","url":null},{"name":"tableau","url":"https://devpost.com/software/built-with/tableau"}],"external_links":[{"label":"carb0.retool.com","url":"https://carb0.retool.com/apps/57a70378-aff5-11ed-a02d-6fc45d0cf27b/Carb0_HOME"},{"label":"github.com","url":"https://github.com/cynliuys/carb0"}],"description_sections":[{"heading":"Inspiration","content":"At Carb0, we're committed to empowering individuals to take control of their carbon footprint and contribute to a more sustainable future. Our inspiration comes from the fact that 72% of CO2 emissions could be reduced by changes in consumer behavior, yet many companies lack the motivation to conduct ESG reports if not required by investors or the government. We believe that establishing consumer-driven ESG can drive companies to be accountable and take action to provide more sustainable products and services."},{"heading":"What it does","content":"We created a personal carbon tracker that incentivizes customers to adopt low-carbon lifestyles and democratizes carbon footprint data , making it easier for everyone to contribute to a sustainable future. Our platform provides information to influence consumers' purchase decisions and provides alternatives to help them make sustainable decisions. This way, we can encourage companies, investors, and the government to take responsibility and be more sustainable."},{"heading":"How we built it","content":"We began by identifying the problem and then went through an intense ideation process to converge on our consumer-driven ESG idea. We defined the user journey and pain points to create a convenient, incentivizing, and user-centric platform. Our reward system easily links to digital payment details and helps track CO2 emissions with data visualization and cashback based on monthly summaries. We also make product carbon footprint data easily accessible and searchable."},{"heading":"Challenges we ran into","content":"Our biggest challenge was integrating front-end and back-end and defining scope. We faced technical assumptions since the accurate database was not available due to time constraints."},{"heading":"Accomplishments that we're proud of","content":"Despite these challenges, we are proud of our self-sustaining system to establish consumer-driven ESG, successful integration of front-end and back-end with a user-friendly interface, and the intense ideation process we went through."},{"heading":"What we learned","content":"During this project, we learned how to rapidly prototype a digital app in limited time and resources, gained a deeper understanding of ESG, its current challenges, and potential solutions."},{"heading":"What's next for Carb0 - Empower your carbon journey","content":"Our next steps are to conduct user testing and iterations for a higher-fidelity prototype, enrich carbon footprint database coverage and accuracy. We also plan to potentially add Carb0 as an add-on for digital wallets to reach a broader audience and engage more people in a more sustainable lifestyle.\n\nOur vision is that consumer-driven ESG will incentivize governments, investors, and companies to take more initiatives in creating a more sustainable world. Join us on our journey to a sustainable future with Carb0!"},{"heading":"Built With","content":"convex javascript retool tableau"},{"heading":"Try it out","content":"carb0.retool.com github.com"}]},{"project_title":"Express Drone Care","project_url":"https://devpost.com/software/express-drone-care","tagline":"Delivering physician-ordered medical prescriptions and lab tests in minutes from any medical record.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/388/649/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Use of Drone Technology by Parrot: Anafi AI Drone"}],"team_members":[],"built_with":[{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"autodesk-fusion-360","url":"https://devpost.com/software/built-with/autodesk-fusion-360"},{"name":"electronics","url":null},{"name":"microcontroller","url":null},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"servo","url":"https://devpost.com/software/built-with/servo"}],"external_links":[{"label":"github.com","url":"https://github.com/dliud/express-drone-care"}],"description_sections":[{"heading":"Inspiration","content":"The inspiration for Express Drone Care came from the growing need for safe and efficient delivery of medical prescriptions and lab tests to patients, especially during the COVID-19 pandemic. We recognized the growing use of telehealth and digital clinics providing both synchronous and asynchronous interactions to interact with patients. We also realize the potential of drones to address the full stack delivery of telehealth services for providers and set out to create a solution that would provide fast and reliable delivery to patients' homes without increasing physician responsibilities."},{"heading":"What it does","content":"Express Drone Care can take in a general medical record from a provider, understand and extract the relevant patient, prescription/lab test, and delivery information from the medical record, and surface this information to a drone operator who would be at a central location to fill the prescription and send the drone out for autonomous flight.\n\nUser journey:\n\nPhysician uploads medical record to our drag and drop portal We send the medical record to our server We use our custom ChatGPT script to extract the relevant information about the patient Prescription/lab test, and delivery We send the information back to the portal to surface to the drone operator (in the future) to program the autonomous drone flight Drone operator loads prescription/lab test into our custom payload Drone delivers payload to patient‚Äôs delivery address."},{"heading":"How we built it","content":"Hardware: We used the ANAFI Ai drone from Parrot. We custom laser cut the payload ‚Äúclaw‚Äù out of acrylic and connected an Arduino Nano to the drone to control the claw‚Äôs I/O and mechanism. We discovered the ANAFI drone runs linux and can give and receive serial commands. Because we can control external peripherals (microcontrollers, etc), we created a small peripheral device out of a microcontroller, LEDs, buttons, and servo motor controller on a custom proto board to use in a mechanical assembly later.\n\nMechanical assembly: due to tight time constraints (3D printing is too slow), we were only left with laser cutting which led to design challenges (constrained to 2D objects). With this, we used compliant mechanisms to retrofit onto the drone‚Äôs curvature and body, accommodating numerous constraints (space, weight, air flow, staying clear of propellers, reliability, diverse set of payloads). We also wrote small calibration software to make sure motors go into correct positions and firmware to communicate with drone.\n\nSoftware: We built our frontend using React/Typescript and Ant Design. We set up a Node JS server on the backend to handle local API requests. We used custom prompt schemes in ChatGPT from OpenAI to extract the relevant information from the medical record for prescription/lab test delivery.\n\nWe send a POST request from our frontend to our primary endpoint ‚Äò/upload‚Äô to process the medical record. We had a custom prompt sequence that included setting initial context, querying the name, prescriptions/lab tests, and addresses to extract across a general set of medical records. We then sent the extracted and formatted data to our Node server to re-surface back to the client for a drone operator to program the drone‚Äôs autonomous flight and know which prescription/lab tests to include in the payload."},{"heading":"Challenges we ran into","content":"Due to safety constraints with regards to flying drones outside of Treehacks' drone cage, we were not able to show a test flight of sending the drone to a patient's home. Therefore, we decided to split the project into two halves:\n\nCreate a provider portal to upload a medical record, then use NLP to extract relevant patient, prescription, and delivery information from the medical record to surface to a drone operator. Build a native drone attachment to carry the medical prescription/lab test and directly integrate with the drone's firmware to drop the test at a specified time (e.g., when the drone reaches the patient's home).\n\nWe also ran into several rate limit and inconsistent response challenges with ChatGPT. To resolve the rate limit issues, we added an error checking mechanism to flag if we need to re-log in to ChatGPT or start a VPN. To improve response accuracy, we created a custom function to check for valid answers (e.g., delivery address should start with an integer).\n\nHardware is always hard, but especially more difficult with drones, including:\n\nANAFI simulator package hardware dependent on having an NVIDIA graphics card which no one on our team had. Building hardware (design, fabrication, assembly) in this small of a time frame is difficult (ie. resort to laser cutting). This also led us to only have essentially one shot at getting the hardware right. Drone payload: ensure it was light and customized enough to minimize impact on drone flight."},{"heading":"Accomplishments that we're proud of","content":"Added additional system to existing drone and figured out a way to mount the payload mechanism without mounting points prebuilt on to the drone. Improving ChatGPT‚Äôs reliability for our use case through prompt engineering Full stack software design to integrate across client, server, and drone Working on a complex drone application within the time and space constraints"},{"heading":"What we learned","content":"Mechanical design was a great exercise in thinking about what is actually necessary and minimally viable in this very tight time span vs. over-engineering Learned a ton about Parrot‚Äôs simulation software was created and the nuances of building a drone company (TLDR: it‚Äôs hard) which was super interesting to hear about Nuances of ChatGPT and prompt engineering"},{"heading":"What's next for Express Drone Care","content":"Because each drone and battery pack are independent parts, we can load up each drone with a different type of payload in the future. We also intend on creating an API to directly integrate into other EHRs and health systems. No physician upload necessary ‚Üí automatically screen after visit summaries Automatically program full flight path for drone (no manual work for drone operator)"},{"heading":"Built With","content":"arduino autodesk-fusion-360 electronics microcontroller openai python react servo"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Locl","project_url":"https://devpost.com/software/locl-lf734n","tagline":"Locl offers a platform that supports EBT card purchases to allow SNAP benefit users to purchase healthy food options from local markets","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/381/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Implementation of Checkbook API: 4 x AirPod Pros"}],"team_members":[],"built_with":[{"name":"checkbook","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"jinja","url":"https://devpost.com/software/built-with/jinja"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"supabase","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/jonathanshu87/locl"}],"description_sections":[{"heading":"EBT Support","content":"Shoppers can convert their EBT balance into Locl credits. From there, they can spend their credits buying produce from our set of carefully curated suppliers. To prevent fraud, each vendor is carefully evaluated to ensure they sell ethically sourced produce. Thus, shoppers can only spend their Locl credits on produce, adhering to government regulation on SNAP benefits."},{"heading":"Bank-less payment","content":"Because low-income shoppers may not have access to a bank account, we've used Checkbook.io's virtual credit cards and direct deposit to facilitate payments between shoppers and vendors."},{"heading":"Producer accessibility","content":"By listing multiple vendors on one platform, Locl is able to circumvent the initial problems of scale. Rather than each vendor being its own store, we consolidate them all into one large store, thereby increasing accessibility for consumers to purchase products from smaller vendors."},{"heading":"Recognizable marketplace","content":"To improve the ease of use, Locl's interface is carefully crafted to emulate other popular marketplace applications such as Facebook Marketplace and Craigslist. Because shoppers will already be accustomed to our app, it'll far improve the overall user experience.\n\nHow we built it\n\nLocl revolves around a web app interface to allow shoppers and vendors to buy and sell produce."},{"heading":"Flask","content":"The crux of Locl centers on our Flask server. From there, we use requests and render_templates() to populate our website with GET and POST requests."},{"heading":"Supabase","content":"We use Supabase and PostgreSQL to store our product, market, virtual credit card, and user information. Because Flask is a Python library, we use Supabase's community managed Python library to insert and update data."},{"heading":"Checkbook.io","content":"We use Checkbook.io's Payfac API to create transactions between shoppers and vendors. When people create an account on Locl, they are automatically added as a user in Checkbook with the POST /v3/user endpoint. Meanwhile, to onboard both local farmers and shoppers painlessly, we offer a bankless solution with Checkbook‚Äôs virtual credit card using the POST /v3/account/vcc endpoint.\n\nFirst, shoppers deposit credits into their Locl account from the EBT card. The EBT funds are later redeemed with the state government by Locl. Whenever a user buys an item, we use the POST /v3/check/digital endpoint to create a transaction between them and the stores to pay for the goods. From there, vendors can also spend their funds as if it were a prepaid debit card. By using Checkbook‚Äôs API, we‚Äôre able to break down the financial barrier of having a bank account for low-income shoppers to buy fresh produce from local suppliers, when they otherwise wouldn‚Äôt have been able to.\n\nChallenges we encountered\n\nBecause we were all new to using these APIs, we were initially unclear about what actions they could support. For example, we wanted to use You.com API to build our marketplace. However, it soon became apparent that we couldn't embed their API into our static HTML page as we'd assume. Thus, we had to pivot to creating our own cards with Jinja.\n\nLooking forward\n\nIn the future, we hope to advance our API services to provide a wider breadth of services which would include more than just produce from local farmers markets. Given a longer timeframe, a few features we'd like to implement include:\n\na search and filtering system to show shoppers their preferred goods. an automated redemption system with the state government for EBT. improved security and encryption for all API calls and database queries.\n\nEthics\n\nSNAP (Supplemental Nutrition Assistance Program), otherwise known as food stamps, is a government program that aids low-income families and individuals to purchase food. The inaccessibility of healthy foods is a pressing problem because there is a small number of grocery stores that accept food stamps, which are often limited to large, chain grocery stores that are not always accessible. Beyond this, these grocery stores often lack healthy food options in favor of highly-processed goods.\n\nWhen doing further research into this issue, we were fortunate to have a team member who has knowledge about SNAP benefits through firsthand experience in classroom settings and at food banks. Through this, we learned about EBT (Electronic Benefit Transfer) cards, as well as their limitations. The only stores that can support EBT payments must offer a selection for each of the staple food categories, which prevents local markets and farmers from accepting food stamps as payment.\n\nTo tackle this issue of the limited accessibility of healthy foods for SNAP benefit users, we came up with Locl, an online platform that allows local markets and farmers to list fresh produce for EBT cardholders to purchase with food stamps. When creating Locl, we adhered to our goal of connecting food stamp users with healthy, ethically sourced foods in a sustainable manner. However, there are still many ethical challenges that must be explored further.\n\nFirst, to use Locl, users would require a portable electronic device and an internet connection due to it being an online platform. The Pew Research center states that 29% of adults with incomes below $30,000/year do not have access to a smartphone and 44% do not have portable internet access. This would greatly lessen the range of individuals that we aim to serve.\n\nSecond, though Locl aims to serve SNAP beneficiaries, we also hope to aid local markets and farmers by increasing the number of potential customers. However, Locl runs the risk of displaying certain produce items or marketplaces disproportionately in comparison to others, which could create imbalances and inequities between all stakeholders involved. Furthermore, this display imbalance could limit user knowledge about certain marketplaces.\n\nThird, Locl aims to increase ethical consumerism by connecting its users with sustainable markets and farmers. However, there arises the issue of selecting which markets and farmers to support on our platform. While considering baselines that we would expect marketplaces to meet to be displayed on Locl, we recognized that sustainability can be measured through a wide number of factors- labor, resources used, pollution levels, and began wondering whether we prioritize sustainability of items we market or the health of users. One example of this is meat, a popular food product which is known for its high health benefits, but similarly high water consumption and greenhouse gas levels. Narrowing these down could greatly limit the display of certain products.\n\nFourth, Locl does not have an option for users to filter the results that are displayed to them. Many EBT cardholders say that they do not use their benefits to make online purchases due to the difficulty of finding items on online store pages that qualify for their benefits as well as their dietary needs. Thus, our lack of a filter option would cause certain users to have increased difficulty in finding food options for themselves.\n\nOur next step for Locl is to address the ethical concerns above, as well as explore ways to make it more accessible and well-known. However, there are still many components to consider from a sociotechnical lens. Currently, only 4% of SNAP beneficiaries make online purchases with their EBT cards. This small percentage may stem from reasons that range from lack of internet access, to not being aware that online options are available. We hope that with Locl, food stamp users will have increased access to healthy food options and local markets and farmers will have an increased customer-base.\n\nReferences\n\nhttps://ajph.aphapublications.org/doi/full/10.2105/AJPH.2019.305325 https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-019-6546-2 https://www.ibisworld.com/industry-statistics/number-of-businesses/supermarkets-grocery-stores-united-states/ https://www.masslive.com/food/2022/01/these-are-the-top-10-unhealthiest-grocery-items-you-can-buy-in-the-united-states-according-to-moneywise.html https://farmersmarketcoalition.org/education/qanda/ https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-019-6546-2 https://news.climate.columbia.edu/2019/08/09/farmers-market-week-2019/"},{"heading":"Built With","content":"checkbook flask jinja python supabase"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"First Plate","project_url":"https://devpost.com/software/first-plate","tagline":"Choose a plate, go on a date! Swipe through restaurant options that align with your preferences and match with potential partners who share your taste in food. The stomach is the way to the heart!","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/391/713/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Likely to Become a Business by Neo: Airfare + Accommodations for Summer Retreat with Neo"}],"team_members":[],"built_with":[{"name":"canva","url":null},{"name":"checkbook","url":null},{"name":"expo.io","url":"https://devpost.com/software/built-with/expo-io"},{"name":"figma","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"react-native","url":"https://devpost.com/software/built-with/react-native"},{"name":"supabase","url":null},{"name":"vscode","url":null},{"name":"xcode","url":"https://devpost.com/software/built-with/xcode"}],"external_links":[{"label":"github.com","url":"https://github.com/jduan22/firstplate"}],"description_sections":[{"heading":"Meet Our Team :)","content":"Lucia Langaney, first-time React Native user, first in-person hackathon, messages magician, snack dealer Tracy Wei, first-time React Native user, first in-person hackathon, payments pro, puppy petter :) Jenny Duan, first in-person hackathon, sign-up specialist, honorary DJ"},{"heading":"Inspiration","content":"First Plate was inspired by the idea that food can bring people together. Many people struggle with finding the perfect restaurant for a first date, which can cause stress and anxiety. By matching users with restaurants, First Plate eliminates the guesswork and allows users to focus on connecting with their potential partner over a shared culinary experience. In addition, food is a topic that many people are passionate about, so a food-based dating app can help users form deeper connections and potentially find a long-lasting relationship. After all- the stomach is the way to the heart."},{"heading":"What it does","content":"Introducing First Plate, a new dating app that will change the way you connect with potential partners - by matching you with restaurants! Our app takes into account your preferences for cuisine location, along with your dating preferences such as age, interests, and more.\n\nWith our app, you'll be able to swipe through restaurant options that align with your preferences and match with potential partners who share your taste in food and atmosphere. Imagine being able to impress your date with a reservation at a restaurant that you both love, or discovering new culinary experiences together.\n\nNot only does our app provide a fun and innovative way to connect with people, but it also takes the stress out of planning a first date by automatically placing reservations at a compatible restaurant. No more agonizing over where to go or what to eat - our app does the work for you.\n\nSo if you're tired of the same old dating apps and want to spice things up, try our new dating app that matches people with restaurants. Who knows, you might just find your perfect match over a plate of delicious food!"},{"heading":"How we built it","content":"Figma mockup Built React Native front-end Added Supabase back-end Implemented Checkbook API for pay-it-forward feature Connecting navigation screens & debugging Adding additional features\n\nWhen developing a new app, it's important to have a clear plan and process in place to ensure its success. The first step we took was having a brainstorming session, where we defined the app's purpose, features, and goals. This helped everyone involved get on the same page and create a shared vision for the project. After that, we moved on to creating a Figma mockup, where we made visual prototypes of the app's user interface. This is a critical step in the development process as it allows the team to get a clear idea of how the app will look and feel. Once the mockup was completed, we commenced the React Native implementation. This step can be quite involved and requires careful planning and attention to detail. Finally, once we completed the app, we moved on to debugging and making final touches. This is a critical step in the process, as it ensures that the app is functioning as intended and any last-minute bugs or issues are resolved before submission. By following these steps, developers can create a successful app that meets the needs of its users and exceeds their expectations."},{"heading":"Challenges we ran into","content":"The app development using React Native was extremely difficult, as it was our first time coding in this language. The initial learning curve was steep, and the vast amount of information required to build the app, coupled with the time constraint, made the process even more challenging. Debugging the code also posed a significant obstacle, as we often struggled to identify and rectify errors in the codebase. Despite these difficulties, we persisted and learned a great deal about the React Native framework, as well as how to debug code more efficiently. The experience taught us valuable skills that will be useful for future projects."},{"heading":"Accomplishments that we're proud of","content":"We feel extremely proud of having coded First Plate as React Native beginners. Building this app meant learning a new programming language, developing a deep understanding of software development principles, and having a clear understanding of what the app is intended to do. We were able to translate an initial Figma design into a React Native app, creating a user-friendly, colorful, and bright interface. Beyond the frontend design, we learned how to create a login and sign-up page, securely connected to the Supabase backend, and integrated the Checkbook API for the \"pay it forward\" feature. Both of these features were also new to our team. Along the way, we encountered many React Native bugs, which were challenging and time-consuming to debug as a beginner team. We implemented front-end design features such as scroll view, flexbox, tab and stack navigation, a unique animation transition, and linking pages using a navigator, to create a seamless and intuitive user experience in our app. We are proud of our teamwork, determination, and hard work that culminated in a successful project."},{"heading":"What we learned","content":"In the course of developing First Plate, we learned many valuable lessons about app development. One of the most important things we learned was how to implement different views, and navigation bars, to create a seamless and intuitive user experience. These features are critical components of modern apps and can help to keep users engaged and increase their likelihood of returning to the app.\n\nAnother significant learning experience was our introduction to React Native, a powerful and versatile framework that allows developers to build high-quality cross-platform mobile apps. As previous Swift users, we had to learn the basics of this language, including how to use the terminal and Expo to write code efficiently and effectively.\n\nIn addition to learning how to code in React Native, we also gained valuable experience in backend development using Supabase, a platform that provides a range of powerful tools and features for building, scaling, and managing app infrastructure. We learned how to use Supabase to create a real-time database, manage authentication and authorization, and integrate with other popular services like Stripe, Slack, and GitHub.\n\nFinally, we used the Checkbook API to allow the user to create digital payments and send digital checks within the app using only another user's name, email, and the amount the user wants to send. By leveraging these powerful tools and frameworks, we were able to build an app that was not only robust and scalable but also met the needs of our users. Overall, the experience of building First Plate taught us many valuable lessons about app development, and we look forward to applying these skills to future projects."},{"heading":"What's next for First Plate","content":"First Plate has exciting plans for the future, with the main focus being on fully implementing the front-end and back-end of the app. The aim is to create a seamless user experience that is efficient, secure, and easy to navigate. Along with this, our team is enthusiastic about implementing new features that will provide even more value to users. One such feature is expanding the \"Pay It Forward\" functionality to suggest who to send money to based on past matches, creating a streamlined and personalized experience for users. Another exciting feature is a feed where users can share their dining experiences and snaps of their dinner plates, or leave reviews on the restaurants they visited with their matches. These features will create a dynamic community where users can connect and share their love for food in new and exciting ways. In terms of security, our team is working on implementing end-to-end encryption on the app's chat feature to provide an extra layer of security for users' conversations. The app will also have a reporting feature that allows users to report any disrespectful or inappropriate behavior, ensuring that First Plate is a safe and respectful community for all. We believe that First Plate is a promising startup idea implementable on a larger scale."},{"heading":"Built With","content":"canva checkbook expo.io figma javascript react-native supabase vscode xcode"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"FreshBuddy","project_url":"https://devpost.com/software/tba-l3dy1j","tagline":"11.5 BILLION tons of homegrown produce are wasted in the US each year. Solution: FreshBuddy. The platform where you can grow share and enjoy fresh local produce, from the comfort of your backyard.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/387/363/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Payments Hack by Checkbook: $500"}],"team_members":[],"built_with":[{"name":"checkbook.io","url":null},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"retool","url":null}],"external_links":[{"label":"treehacksfood1.retool.com","url":"https://treehacksfood1.retool.com/apps/c706b8e4-aff0-11ed-9642-37b708985b49/treehacks%20project%20-%20home"}],"description_sections":[{"heading":"What it does","content":"Fresh Buddy allows users to search for local farmers and find fresh produce nearby."},{"heading":"How we built it","content":"Our web development application is powered by sponsors Retool and Checkbook."},{"heading":"Challenges we ran into","content":"We ran into various challenges such as handling and working with the Checkbook API's, figuring out how to power and host our idea. With much diligence (and a good amount of reading the api docs) we found out how to use API's and were delighted at the ease Retool provided us for creating our web application!"},{"heading":"Accomplishments that we're proud of","content":"Completing our first ever hackathon and having a product to show for! (:"},{"heading":"What we learned","content":"We learned how to use Checkbook.io and Retool."},{"heading":"What's next for Fresh Buddy","content":"Expand and conquer homegrown produce waste! We plan to advertise and connect others to fresh produce and find their fresh buddy!"},{"heading":"Built With","content":"checkbook.io html javascript retool"},{"heading":"Try it out","content":"treehacksfood1.retool.com"}]},{"project_title":"Cognito","project_url":"https://devpost.com/software/cognito-uf3rs1","tagline":"Ask any question about your users","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/064/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Startup by YCombinator: Real Interview for Y Combinator (No Expiration) & Dinner on Sunday with YC team"}],"team_members":[],"built_with":[{"name":"fastapi","url":null},{"name":"gcp","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"openai","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"vercel","url":null}],"external_links":[{"label":"joincognito.com","url":"https://joincognito.com/"}],"description_sections":[{"heading":"Inspiration","content":"Companies lack insight into their users, audiences, and marketing funnel.\n\nThis is an issue I've run into on many separate occasions. Specifically,\n\nwhile doing cold marketing outbound, need better insight onto key variables of successful outreach while writing a blog, I have no idea who reads it while triaging inbound, which users do I prioritize\n\nGiven a list of user emails, Cognito scrapes the internet finding public information about users and the companies they work at. With this corpus of unstructured data, Cognito allows you to extract any relevant piece of information across users. An unordered collection of text and images becomes structured data relevant to you."},{"heading":"A Few Example Use Cases","content":"Startups going to market need to identify where their power users are and their defining attributes. We allow them to ask questions about their users, helping them define their niche and better focus outbound marketing. SaaS platforms such as Modal have trouble with abuse. They want to ensure people joining are not going to abuse it. We provide more data points to make better judgments such as taking into account how senior of a developer a user is and the types of companies they used to work at. VCs such as YC have emails from a bunch of prospective founders and highly talented individuals. Cognito would allow them to ask key questions such as what companies are people flocking to work at and who are the highest potential people in my network. Content creators such as authors on Substack looking to monetize their work have a much more compelling case when coming to advertisers with a good grasp on who their audience is."},{"heading":"What it does","content":"Given a list of user emails, we crawl the web, gather a corpus of relevant text data, and allow companies/creators/influencers/marketers to ask any question about their users/audience.\n\nWe store these data points and allow for advanced querying in natural language.\n\nvideo demo"},{"heading":"How we built it","content":"we orchestrated 3 ML models across 7 different tasks in 30 hours\n\nsearch results person info extraction custom field generation from scraped data company website details extraction facial recognition for age and gender NoSQL query generation from natural language crunchbase company summary extraction email extraction\n\nThis culminated in a full-stack web app with batch processing via async pubsub messaging. Deployed on GCP using Cloud Run, Cloud Functions, Cloud Storage, PubSub, Programmable Search, and Cloud Build."},{"heading":"What we learned","content":"how to be really creative about scraping batch processing paradigms prompt engineering techniques"},{"heading":"What's next for Cognito","content":"predictive modeling and classification using scraped data points scrape more data more advanced queries proactive alerts\n\nvideo demo"},{"heading":"Built With","content":"fastapi gcp javascript openai python react vercel"},{"heading":"Try it out","content":"joincognito.com"}]},{"project_title":"Origin","project_url":"https://devpost.com/software/pathfinder-em2qjb","tagline":"Building the future of personalized browsers with LLMs.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/594/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Hack Using Frontier Tech by Pear: $1000 & upto $100000 uncapped SAFE"}],"team_members":[],"built_with":[{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"huggingface","url":null},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"scikit-learn","url":"https://devpost.com/software/built-with/scikit-learn"}],"external_links":[{"label":"drive.google.com","url":"https://drive.google.com/file/d/1gKcsXFkupt4CVtn2qgXfZ7xkzSKayQ5A/view?usp=sharing"},{"label":"github.com","url":"https://github.com/pgasawa/origin"}],"description_sections":[{"heading":"Inspiration","content":"Has your browser ever looked like this?\n\n... or this?\n\nOurs have, all the time.\n\nRegardless of who you are, you'll often find yourself working in a browser on not just one task but a variety of tasks. Whether its classes, projects, financials, research, personal hobbies -- there are many different, yet predictable, ways in which we open an endless amount of tabs for fear of forgetting a chunk of information that may someday be relevant.\n\nOrigin aims to revolutionize your personal browsing experience -- one workspace at a time."},{"heading":"What it does","content":"In a nutshell, Origin uses state-of-the-art natural language processing to identify personalized, smart workspaces . Each workspace is centered around a topic comprised of related tabs from your browsing history, and Origin provides your most recently visited tabs pertaining to that workspace and related future ones, a generated textual summary of those websites from all their text, and a fine-tuned ChatBot trained on data about that topic and ready to answer specific user questions with citations and maintaining history of a conversation. The ChatBot not only answers general factual questions (given its a foundation model), but also answers/recalls specific facts found in the URLs/files that the user visits (e.g. linking to a course syllabus).\n\nOrigin also provides a semantic search on resources, as well as monitors what URLs other people in an organization visit and recommend pertinent ones to the user via a recommendation system .\n\nFor example, a college student taking a History class and performing ML research on the side would have sets of tabs that would be related to both topics individually. Through its clustering algorithms, Origin would identify the workspaces of \"European History\" and \"Computer Vision\", with a dynamic view of pertinent URLs and widgets like semantic search and a chatbot. Upon continuing to browse in either workspace, the workspace itself is dynamically updated to reflect the most recently visited sites and data.\n\nTarget Audience : Students to significantly improve the education experience and industry workers to improve productivity."},{"heading":"How we built it","content":"Languages : Python ‚àô JavaScript ‚àô HTML ‚àô CSS\n\nFrameworks and Tools : Firebase ‚àô React.js ‚àô Flask ‚àô LangChain ‚àô OpenAI ‚àô HuggingFace\n\nThere are a couple of different key engineering modules that this project can be broken down into.\n\n1(a). Ingesting Browser Information and Computing Embeddings\n\nWe begin by developing a Chrome Extension that automatically scrapes browsing data in a periodic manner (every 3 days) using the Chrome Developer API. From the information we glean, we extract titles of webpages. Then, the webpage titles are passed into a pre-trained Large Language Model (LLM) from Huggingface, from which latent embeddings are generated and persisted through a Firebase database.\n\n1(b). Topical Clustering Algorithms and Automatic Cluster Name Inference\n\nGiven the URL embeddings, we run K-Means Clustering to identify key topical/activity-related clusters in browsing data and the associated URLs.\n\nWe automatically find a description for each cluster by prompt engineering an OpenAI LLM, specifically by providing it the titles of all webpages in the cluster and requesting it to output a simple title describing that cluster (e.g. \"Algorithms Course\" or \"Machine Learning Research\").\n\n2. Web/Knowledge Scraping\n\nAfter pulling the user's URLs from the database, we asynchronously scrape through the text on each webpage via Beautiful Soup. This text provides richer context for each page beyond the title and is temporarily cached for use in later algorithms.\n\n3. Text Summarization\n\nWe split the incoming text of all the web pages using a CharacterTextSplitter to create smaller documents, and then attempt a summarization in a map reduce fashion over these smaller documents using a LangChain summarization chain that increases the ability to maintain broader context while parallelizing workload.\n\n4. Fine Tuning a GPT-3 Based ChatBot\n\nThe infrastructure for this was built on a recently-made popular open-source Python package called LangChain (see https://github.com/hwchase17/langchain ), a package with the intention of making it easier to build more powerful Language Models by connecting them to external knowledge sources.\n\nWe first deal with data ingestion and chunking, before embedding the vectors using OpenAI Embeddings and storing them in a vector store.\n\nTo provide the best chat bot possible, we keep track of a history of a user's conversation and inject it into the chatbot during each user interaction while simultaneously looking up relevant information that can be quickly queries from the vector store. The generated prompt is then put into an OpenAI LLM to interact with the user in a knowledge-aware context.\n\n5. Collaborative Filtering-Based Recommendation\n\nProvided that a user does not turn privacy settings on, our collaborative filtering-based recommendation system recommends URLs that other users in the organization have seen that are related to the user's current workspace.\n\n6. Flask REST API\n\nWe expose all of our LLM capabilities, recommendation system, and other data queries for the frontend through a REST API served by Flask. This provides an easy interface between the external vendors (like LangChain, OpenAI, and HuggingFace), our Firebase database, the browser extension, and our React web app.\n\n7. A Fantastic Frontend\n\nOur frontend is built using the React.js framework. We use axios to interact with our backend server and display the relevant information for each workspace."},{"heading":"Challenges we ran into","content":"We had to deal with our K-Means Clustering algorithm outputting changing cluster means over time as new data is ingested, since the URLs that a user visits changes over time. We had to anchor previous data to the new clusters in a smart way and come up with a clever updating algorithm. We had to employ caching of responses from the external LLMs (like OpenAI/LangChain) to operate under the rate limit. This was challenging, as it required revamping our database infrastructure for caching. Enabling the Chrome extension to speak with our backend server was a challenge, as we had to periodically poll the user's browser history and deal with CORS (Cross-Origin Resource Sharing) errors. We worked modularly which was great for parallelization/efficiency, but it slowed us down when integrating things together for e2e testing."},{"heading":"Accomplishments that we're proud of","content":"The scope of ways in which we were able to utilize Large Language Models to redefine the antiquated browsing experience and provide knowledge centralization.\n\nThis idea was a byproduct of our own experiences in college and high school -- we found ourselves spending significant amounts of time attempting to organize tab clutter systematically."},{"heading":"What we learned","content":"This project was an incredible learning experience for our team as we took on multiple technically complex challenges to reach our ending solution -- something we all thought that we had a potential to use ourselves."},{"heading":"What's next for Origin","content":"We believe Origin will become even more powerful at scale, since many users/organizations using the product would improve the ChatBot's ability to answer commonly asked questions, and the recommender system would perform better in aiding user's education or productivity experiences."},{"heading":"Built With","content":"firebase flask huggingface pytorch react scikit-learn"},{"heading":"Try it out","content":"drive.google.com github.com"}]},{"project_title":"Theia","project_url":"https://devpost.com/software/thiea","tagline":"A simple interfaced supervised model to build and filter Labeled Image Data Sets","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/390/951/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Startup by YCombinator: Real Interview for Y Combinator (No Expiration) & Dinner on Sunday with YC team"}],"team_members":[],"built_with":[{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"ddg","url":null},{"name":"fastai","url":null},{"name":"flask","url":"https://devpost.com/software/built-with/flask"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"requests","url":"https://devpost.com/software/built-with/requests"},{"name":"selenium","url":"https://devpost.com/software/built-with/selenium"}],"external_links":[{"label":"github.com","url":"https://github.com/shzcuber/TreeHacks"},{"label":"theia-ten.vercel.app","url":"https://theia-ten.vercel.app/"}],"description_sections":[{"heading":"Inspiration","content":"Every Core Innovation in ML comes from a better architecture, more compute or more and better Data. While Architectures are freely published on the web and Compute, though expensive, is still accessible by anyone on the planet, the moat of most ML companies lies in Accessing Data.\n\nEven though most data is freely available on the web, most indie Researchers and Data Scientist have to drop the project, until the Dataset becomes publicly available on the internet. But What if Accessing Data was easier?"},{"heading":"What it does","content":"Introducing Theia: A simple interfaced supervised model to build and filter Labeled Image Data Sets.\n\nThe easiest dev tool to Download and Filter Image datasets in Minutes not days!"},{"heading":"How we built it","content":"The front end is built using React. First the user simply inputs the keywords for the dataset, just like one would simply do in Google or any Search Engine\n\nNext, the user can adjust various parameters for the images, including colour, size, NSFW/NON-NSFW, Image Licences. We use Selenium, DDG and Request, to scrape the best matching images across the web.\n\nAfter that, the user selects the images he likes and dislikes and we use that as Input for the supervised learning Image Classifier built using transfer learning on top of ResNet34.\n\nNow the scraping bot built with Selenium, DDG and Requests, download the images and pass it through the and the supervised model built using transfer learning on top of ResNet34. And the user gets the images that classifies as the liked images (as selected by the user in previous step).\n\nThat's it! Building Datasets has never been easier! Theia cuts out image filtering tasks by upto 90%! Download and Filter Image datasets in Minutes not days!"},{"heading":"Challenges we ran into","content":"CORS Issues are the worst Aligning Divs Web Dev is annoying as hell Next time we are building LLM guided frontend builder"},{"heading":"Accomplishments that we're proud of","content":"Coming up with an idea, that solves a very real problem and will be used by hundreds, if not thousands of people Integrating ResNet34 to apply Transfer Learning to filter image datasets Shipping the project on Time"},{"heading":"What we learned","content":"Having a clear roadmap and an idea of where you are heading is very important Simple Ideas, with high usability are perfect hackathon builds TL on ResNet34 work surprisingly well on a small batch size of 50-100 images"},{"heading":"What's next for Theia","content":"Adding more efficient image filtering options, better UI, and adding more image manipulation options from OpenCV2 Image manipulation capabilities"},{"heading":"Built With","content":"css ddg fastai flask pytorch react requests selenium"},{"heading":"Try it out","content":"github.com theia-ten.vercel.app"}]},{"project_title":"CashFlow","project_url":"https://devpost.com/software/cashflow-7xqoc4","tagline":"International money transfer made easy.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/391/403/datas/medium.gif","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Replit's Choice Award: 3000 Replit Cycles + 3 mo of Hacker Subscription (1st Place) & 2000 Replit Cycles + 2 mo of Hacker Subscription (2nd Place) & 1000 Replit Cycles + 1 mo of Hacker Subscription (3rd Place)"}],"team_members":[],"built_with":[{"name":"checkbook-nyc","url":"https://devpost.com/software/built-with/checkbook-nyc"},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"exchange-rate","url":"https://devpost.com/software/built-with/exchange-rate"},{"name":"html5","url":"https://devpost.com/software/built-with/html5"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"}],"external_links":[{"label":"github.com","url":"https://github.com/aadya7104/cashflow-treehacks23.git"},{"label":"cashflow.aadya7104.repl.co","url":"https://cashflow.aadya7104.repl.co/"}],"description_sections":[{"heading":"Inspiration","content":"As international students, we often have to navigate around a lot of roadblocks when it comes to receiving money from back home for our tuition. Cross-border payments are gaining momentum with so many emerging markets. In 2021, the top five recipient countries for remittance inflows in current USD were India (89 billion), Mexico (54 billion), China (53 billion), the Philippines (37 billion), and Egypt (32 billion). The United States was the largest source country for remittances in 2020, followed by the United Arab Emirates, Saudi Arabia, and Switzerland.\n\nHowever, Cross-border payments face 5 main challenges: cost, security, time, liquidity & transparency.\n\nCost: Cross-border payments are typically costly due to costs involved such as currency exchange costs, intermediary charges, and regulatory costs. -Time: most international payments take anything between 2-5 days. -Security: The rate of fraud in cross-border payments is comparatively higher than in domestic payments because it's much more difficult to track once it crosses the border. Standardization: Different countries tend to follow a different set of rules & formats which make cross-border payments even more difficult & complicated at times. Liquidity: Most cross-border payments work on the pre-funding of accounts to settle payments; hence it becomes important to ensure adequate liquidity in correspondent bank accounts to meet payment obligations within cut-off deadlines."},{"heading":"What it does","content":"Cashflow is a solution to all of the problems above. It provides a secure method to transfer money overseas. It uses the checkbook.io API to verify users' bank information, and check for liquidity, and with features such as KYC, it ensures security in enabling instant payments. Further, it uses another API to convert the currencies using accurate, non-inflated rates.\n\nSending money: Our system requests a few pieces of information from you, which pertain to the recipient. After having added your bank details to your profile, you will be able to send money through the platform. The recipient will receive an email message, through which they can deposit into their account in multiple ways.\n\nRequesting money: By requesting money from a sender, an invoice is generated to them. They can choose to send money back through multiple methods, which include credit and debit card payments."},{"heading":"How we built it","content":"We built it using HTML, CSS, and JavaScript. We also used the Checkbook.io API and exchange rate API."},{"heading":"Challenges we ran into","content":"Neither of us is familiar with backend technologies or react. Mihir has never worked with JS before and I haven't worked on many web dev projects in the last 2 years, so we had to engage in a lot of learning and refreshing of knowledge as we built the project which took a lot of time."},{"heading":"Accomplishments that we're proud of","content":"We learned a lot and built the whole web app as we were continuously learning. Mihir learned JavaScript from scratch and coded in it for the whole project all under 36 hours."},{"heading":"What we learned","content":"We learned how to integrate APIs in building web apps, JavaScript, and a lot of web dev."},{"heading":"What's next for CashFlow","content":"We were having a couple of bugs that we couldn't fix, we plan to work on those in the near future."},{"heading":"Built With","content":"checkbook-nyc css exchange-rate html5 javascript"},{"heading":"Try it out","content":"github.com cashflow.aadya7104.repl.co"}]},{"project_title":"Transit Tracker","project_url":"https://devpost.com/software/test-wqgj3x","tagline":"A data management tool for both transit riders and system operators","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/392/179/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best use of Palantir Foundry: $2000"}],"team_members":[],"built_with":[{"name":"foundry","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"palantir","url":null},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sql","url":"https://devpost.com/software/built-with/sql"}],"external_links":[{"label":"youtu.be","url":"https://youtu.be/M3oJR87kcjk"},{"label":"github.com","url":"https://github.com/petern03/Treehacks-2023"}],"description_sections":[{"heading":"Inspiration","content":"We wanted to find a way to make transit data more accessible to the public as well as provide fun insights into their transit activity. As we've seen in Spotify Wrapped, people love seeing data about themselves. In addition, we wanted to develop a tool to help city organizers make data-driven decisions on how they operate their networks."},{"heading":"What it does","content":"Transit Tracker is simultaneously a tool for operators to analyze their network as well as an app for users to learn about their own activities and how it lessens their impact on the environment. For network operators, Transit Tracker allows them to manage data for a system of riders and individual trips. We developed a visual map that shows the activity of specific sections between train stations. For individuals, we created an app that shows data from their own transit activities. This includes gallons of gas saved, time spent riding, and their most visited stops."},{"heading":"How we built it","content":"We primarily used Palantir Foundry to provide a platform for our back-end data management. Used objects within Foundry to facilitate dataset transformation using SQL and python. Utilized Foundry Workshop to create user interface to display information."},{"heading":"Challenges we ran into","content":"Working with the geoJSON file format proved to be particularly challenging, because it is semi-structured data and not easily compatible with the datasets we were working with. Another large challenge we ran into was learning how to use Foundry. This was our first time using the software, we had to first learn the basics before we could even begin tackling our problem."},{"heading":"Accomplishments that we're proud of","content":"With Treehacks being all of our first hackathons, we're proud of making it to the finish line and building something that is both functional and practical. Additionally, we're proud of the skills we've gained from learning to deal with large data as well as our ability to learn and use foundry in the short time frame we had."},{"heading":"What we learned","content":"We learned just how much we take everyday data analysis for granted. The amount of information being processed everyday in regards to data is unreal. We only tackled a small level of data analysis and even we had a multitude of difficult issues that had to be dealt with. The understanding we‚Äôve learned from dealing with data is so valuable and the skills we‚Äôve gained in using a completely foreign application to build something in such a short amount of time has been truly insightful."},{"heading":"What's next for Transit Tracker","content":"The next step for Transit Tracker would be to be able to translate our data (that is being generated through objects) onto a visual map where the routes would constantly be changing in regards to the data being collected. Being able to visually represent the change onto a graph would be such a valuable step to achieve as it would mean we are working our way towards a functional application."},{"heading":"Built With","content":"foundry javascript palantir python sql"},{"heading":"Try it out","content":"youtu.be github.com"}]},{"project_title":"Surge Protector","project_url":"https://devpost.com/software/surge-protector","tagline":"Using drone technology and artificial intelligence to actively predict crowd surges and get rapid assistance for those who need it.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/389/111/datas/medium.jpeg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Hack using AI/ML by Pear: $1000 & up to $100000 uncapped SAFE"}],"team_members":[],"built_with":[{"name":"cuda","url":"https://devpost.com/software/built-with/cuda"},{"name":"matplotlib","url":null},{"name":"opencv","url":"https://devpost.com/software/built-with/opencv"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react","url":"https://devpost.com/software/built-with/react"}],"external_links":[{"label":"github.com","url":"https://github.com/Anirudh171202/CrowdSafe"}],"description_sections":[{"heading":"Inspiration","content":"Two of our teammates, Archna and Anirudh, had witnessed serious accidents at previous concerts and noticed how delayed the medical response was.\n\nOn discussing this with teammates, we were appalled to find out the number of deaths and injuries at concerts each year due to crowd surges and stampedes, which can be easily prevented."},{"heading":"What it does","content":"Surge Protector uses drone technology to monitor crowded locations like music concerts and public protests.\n\nUsing a Dilated Convolutional Neural Network (CNN) model, we find the areas with the highest densities in the crowd, and alert organizers or authorities in a timely manner to prevent events such as stampedes. On Surge Protector's dashboard you can view these problematic regions with bounding rectangles and a density heat map, and with that information quickly send the necessary personnel to where they're needed most.\n\nWith statistics such as population in certain areas and time-series of population groups in the crowd, Surge Protector can be the key to a future of safer and more accessible concerts for all."},{"heading":"How we built it","content":"Drone Infrastructure (provided by TreeHack Sponsors) - Use drone camera footage, with plans to add object detection and autonomous flying to navigate the venue, and streaming video footage and location data live time using a live-streaming API.\n\nBackend: Uses Pytorch and CNNs for marking heads in a crowd Generate heatmaps using Matplotlib and OpenCV with custom thresholds. Used open sourced algorithms for training crowd counting model link\n\nWrote custom heatmap algorithms with Matplotlib and opencv to mark crowd, and temporal averaging for stabilizing bounding boxes generated by the model in Python3.\n\nFrontend was designed in ReactJS with bootstrap."},{"heading":"Challenges we ran into","content":"Our biggest issue was in the image processing side, trying to efficiently process video frames at a reasonable speed. Additionally, conversion between different intermediate formats such as numpy arrays, Python Images and Matplotlib plots was surprisingly painful. In one instance, converting a pyplot to a cv2 image without a margin became a technical issue which caused an immense amount of frustration .\n\nOther problems would be incorporating the torch model, which was originally written in Python 2.7, and transforming it to Python 3.10 and running it in our Conda environment.\n\nWe also faced hardware issues while getting the drone feed, and even learning to fly a drone as none of our team members had used one before."},{"heading":"Accomplishments that we're proud of","content":"We are incredibly grateful for TreeHacks for giving us the opportunity to meet amazing people and collaborate on ideas. As a team, we are proud that we met as diverse individuals from each of the four corners of the US, to hack on a project we felt passionate about.\n\nWe were also really happy that after almost 24 hours of continous hacking, we were able to get a real demo ready for our app, despite facing problems with conversions and cloud computing. All the pain and bugs we had to debug to get to the demo was worth it immediately after seeing the demo coming to light."},{"heading":"What we learned","content":"We learned a lot about the potential of drone technology after speaking with some of the sponsors of the hackathon. We got to know about some incredible innovations happening in the autonomous aviation space and got to implement a tiny use case of the same for our project! Additionally, we had to research and use some interesting techniques for detecting the most dangerous areas of crowds, specifically keeping the bounded rectangles in consistent positions that made sense based on the density heat maps the the CNN produced."},{"heading":"What's next for Surge Protector","content":"Surge Protector is just a proof of concept, and has a huge potential to grow as an project.\n\nFully autonomous drones from TreeHacks sponsors can be used to automate concert scans, and technologies such as infrared imagery and LIDAR can be used to ensure better safety of citizens by drones at night-time. Additionally, there is existing software which can fly towards a selected target, which we believe can help guide emergency personnel to those who need it most by shining a lot on dense spots in a crowd.\n\nIn the future, the Surge Protector dashboard can be expanded to include real time graphs and analytics in addition to a drone's live feed, allowing organizers to keep track of a constantly changing complex situations."},{"heading":"Built With","content":"cuda matplotlib opencv python pytorch react"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Picture Pathway","project_url":"https://devpost.com/software/picture-pathway","tagline":"A memorization-aid learning tool. Generate a story to help learn and watch difficult concepts come to life.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/386/904/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Replit's Choice Award: 3000 Replit Cycles + 3 mo of Hacker Subscription (1st Place) & 2000 Replit Cycles + 2 mo of Hacker Subscription (2nd Place) & 1000 Replit Cycles + 1 mo of Hacker Subscription (3rd Place)"}],"team_members":[],"built_with":[{"name":"dall-e","url":null},{"name":"django","url":"https://devpost.com/software/built-with/django"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"sqlite","url":"https://devpost.com/software/built-with/sqlite"}],"external_links":[{"label":"github.com","url":"https://github.com/aj-avendano/Tree_hacks_23"}],"description_sections":[{"heading":"Inspiration","content":"Memory athletes retain large amounts of information using mnemonics, story-telling, and visualizations. Picture Pathway aims to emulate this studying methodology and bring it into the classroom!"},{"heading":"What it does","content":"Picture Pathway is a student-teacher platform. Teachers submit the problem they would like their class to visualize and/or convert into a story. From there, the student describes a scene to DALL-E and then receives a generated image to add to their story on solving their assigned problems\n\nIn our example, a teacher is looking to solidify the process of Integration for her students; thus, they have assigned a series of steps to 'storify'. The text contained in yellow represents what a student user's responses might look like (and our last slide demonstrates what the corresponding image output may be)."},{"heading":"How we built it","content":"-Front-End: Repl.it - HTML, Javascript -Back-End: Python (Jango), SQLite"},{"heading":"Challenges we ran into","content":"-Most of our members are just beginning their coding journey so there was certainly a learning curve! -The integration of Dall-E API was especially uncharted territory for our team and required much research to implement -DebuggingÔºàœÄ„ÉºœÄÔºâ"},{"heading":"Accomplishments that we're proud of","content":"Our team is most proud of our ability to riff off each other--- most of us met for the first time just Friday, yet we trusted one another to perform our assigned roles and successfully worked our way from 0 to a working prototype"},{"heading":"What we learned","content":"-3/4 members learned Django + SQL for the first time! -APIs can interact on the backend (what enabled us to pull images from Dall-E to embed into our project!)"},{"heading":"What's next for Picture Pathway","content":"-All our members are passionate about accessibility in STEM education"},{"heading":"Built With","content":"dall-e django python sqlite"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"OrangeBanana","project_url":"https://devpost.com/software/name-8v3fdx","tagline":"Using the Arduino IOT API, OrangeBanana provide features of monitoring, analysis and remote control of sensor devices. The workflow is provided for a few sample sensors.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/507/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best use of Arduino Cloud/API: 4 x Arduino Make Your UNO Kit"}],"team_members":[],"built_with":[{"name":"arduino","url":"https://devpost.com/software/built-with/arduino"},{"name":"bootstrap","url":"https://devpost.com/software/built-with/bootstrap"},{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"iot","url":null},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"mongodb","url":"https://devpost.com/software/built-with/mongodb"},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"}],"external_links":[{"label":"github.com","url":"https://github.com/hithaaaa/treehacks-arduino"}],"description_sections":[{"heading":"Inspiration","content":"The Arduino community provides a full eco-system of developing systems, and I saw the potential in using hardware, IOT and cloud-integration to provide a unique solution for streamlining processes for business."},{"heading":"What it does","content":"The web-app provides the workflow for a one-stop place to manage hundreds of different sensors by incorporating intelligence to each utility provided by the Arduino REST API. Imagine a health-care company that would need to manage all its heart-rate sensors and derive insights quickly and continuously on patient data. Or picture a way for a business to manage customer device location parameters by inputting customized conditions on the data or parameters. Or a way for a child to control her robot-controlled coffee machine from school. This app provides many different possibilities for use-cases."},{"heading":"How we built it","content":"I connected iPhones to the Arduino cloud, and built a web-app with NodeJS that uses the Arduino IOT API to connect to the cloud, and connected MongoDB to make the app more efficient and scalable. I followed the CRM architecture to build the app, and implemented the best practices to keep scalability in mind, since it is the main focus of the app."},{"heading":"Challenges we ran into","content":"A lot of the problems faced were naturally in the web application, and it required a lot of time."},{"heading":"Accomplishments that we're proud of","content":"I are proud of the app and its usefulness in different contexts. This is a creative solution that could have real world uses if the intelligence is implemented carefully."},{"heading":"What we learned","content":"I learned a LOT about web development, database management and API integration."},{"heading":"What's next for OrangeBanana","content":"Provided we have more time, we would implement more sensors and more use-cases for handling each of these."},{"heading":"Built With","content":"arduino bootstrap express.js html iot javascript mongodb node.js"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"GrazePro","project_url":"https://devpost.com/software/grazepro","tagline":"Enabling farmers to sustainably optimize resources.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/388/810/datas/medium.jpg","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Cotopaxi's Choice Award: 4 x Cotopaxi Allpa 28L Backpack with Dopp Kit & Cotopaxi Hat & MiiR x Cotopaxi Camping Mug"}],"team_members":[],"built_with":[{"name":"convex","url":null},{"name":"css","url":"https://devpost.com/software/built-with/css"},{"name":"figma","url":null},{"name":"html","url":"https://devpost.com/software/built-with/html"},{"name":"netlogo","url":null},{"name":"next.js","url":null},{"name":"npm","url":"https://devpost.com/software/built-with/npm"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"tailwind","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"graze-pro.vercel.app","url":"http://graze-pro.vercel.app"},{"label":"github.com","url":"https://github.com/sarah-gu/graze-pro"}],"description_sections":[{"heading":"Inspiration","content":"When tackling the issue of sustainability, we looked first at the major sources of emissions. One thing that caught our eye was agriculture ‚Äì Particularly, livestock production (especially cattle) which is the largest contributor for carbon emissions. Annually, each cow produces 220 pounds of methane and in totality accounts for 14.5% of global greenhouse gas emissions. Agriculture continues to be one of the most important industries that technology overlooks. As a team, we are driven to build in communities and industries that are underserved by existing technologies and from this, GrazePro was born .\n\nWe decided to focus on rotational grazing, a popular farming technique that involves moving livestock between paddocks so that only one or some paddocks are grazed at any given time. On the contrary, continuous grazing involves only one paddock, and the forage is not allowed to fallow. We realized that there was an efficiency maximization problem related to when farmers should switch paddocks to maximize cattle health and ability for grass to regrow. We decided to model this using a simulation."},{"heading":"What it does","content":"GrazePro is a virtual simulation intended to enable farmers to accurately predict and forecast the optimal approach to rotational grazing. This means that we can take real data points provided by farmers, input them into the algorithm that we‚Äôve created and generate actionable suggestions to improve cattle health, sustainable practices and cost efficiency.\n\nOur algorithm can help answer questions such as: How many segments farmers should divide their paddock into? What is the optimal time that cattle should stay within one area to ensure that the grass has time to regrow?\n\nThe prediction algorithm is built on a cellular automata model, which is a collection of cells on a grid that evolves over discrete time steps according to a set of preferences and rules. In this case, we modeled how fast grass grew back based on various factors, including number of cattle, amount of water used, fertilizers used, previous cover crops and more.\n\nUsers have the ability to change certain inputs, such as number of paddocks, number of cows, growth rate of grass and rotation time. When the simulation is played, the dashboard also displays the health of the grass and the cattle and how they change over time according to the feeding patterns of the cattle. Farmers can then use this data to inform their farming practices."},{"heading":"How we built it","content":"We used a combination of coding languages, including Typescript, React, Netlogo. A number of technologies, frameworks and packages were used, including Next.js, Convex, Vercel, Tailwind. We designed and built our wireframe in Figma."},{"heading":"Challenges we ran into","content":"On our journey to TreeHacks this year, our car was broken into and our laptops, belongings and personal items were stolen. While this unfortunately has severely impacted our ability to hack, as we were unable to begin until 12 hours into the hackathon, there is nothing that builds stronger bonds than trauma . Thankfully, we were still able to build GrazePro with the limited resources we had, and were able to find some hacky solutions (i.e, figuring out a way to locally install Node.js on Stanford's admin protected computers). A huge shout-out to the TreeHacks organizers!"},{"heading":"Accomplishments that we're proud of","content":"This was our team's first major in-person hackathon since the pandemic began, and it presented a significant learning opportunity. While we encountered some initial challenges, we are proud of the progress we were able to achieve as a team without any laptops or personal devices (explained above) AND the additional time constraint of 24 hours instead of 36."},{"heading":"What we learned","content":"We learned to never leave our suitcases unattended‚Ä¶kind of a hard thing to do at a hackathon. In all seriousness, as the first hackathon that we have participated in as a team, one of the most important lessons that we learned is how to work together. This was integral in dividing the workload of this huge project into manageable and sizable chunks that we could delegate effectively to maximize the use of our time.\n\nOn a technical level, we were able to use, learn, and implement some really interesting frameworks and packages from the TreeHacks sponsors (shoutout to Convex and Vercel!). We also had the chance to participate in a mock interview with YC which really taught us how to navigate the business-side of a startup alongside a technically-refined product."},{"heading":"What's next for GrazePro","content":"Where to even begin? Firstly, incorporating satellite and drone imaging technology into our platform and setting up a method to scan the uploaded image to determine the existing health of the grass would help streamline the onboarding of new users. Secondly, using more data to train our simulation would make it more realistic and improve scientific accuracy and predictability. Thirdly, we would introduce features that would complicate our simulation, such as changing the shape of each paddock, reproduction and death of cattle, incorporating weather patterns and forecasts into the model to determine crop growth, use of rivers and riparian buffers to prevent waste contamination from cattle feces, nitrogen fixation mechanisms and their effect on soil quality."},{"heading":"Works Cited","content":"https://www.ucdavis.edu/food/news/making-cattle-more-sustainable"},{"heading":"Built With","content":"convex css figma html netlogo next.js npm react tailwind typescript vercel"},{"heading":"Try it out","content":"graze-pro.vercel.app github.com"}]},{"project_title":"Mixingjays","project_url":"https://devpost.com/software/mixingjays","tagline":"live music visualization generation and editing tools -- industry-grade and AI-powered","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/939/datas/medium.gif","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Peak Modal: $1000/mo For Life in Modal Credits"}],"team_members":[],"built_with":[{"name":"express.js","url":"https://devpost.com/software/built-with/express-js"},{"name":"fair","url":null},{"name":"firebase","url":"https://devpost.com/software/built-with/firebase"},{"name":"github","url":"https://devpost.com/software/built-with/github"},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"huggingface","url":null},{"name":"mantine","url":null},{"name":"modal","url":null},{"name":"next.js","url":null},{"name":"node.js","url":"https://devpost.com/software/built-with/node-js"},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"openai","url":null},{"name":"pytorch","url":"https://devpost.com/software/built-with/pytorch"},{"name":"react.js","url":null},{"name":"render","url":null},{"name":"scipy","url":"https://devpost.com/software/built-with/scipy"},{"name":"tailwind","url":null},{"name":"tensorflow","url":null},{"name":"typescript","url":"https://devpost.com/software/built-with/typescript"},{"name":"vercel","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/jameszhou02/hackathon"}],"description_sections":[{"heading":"Inspiration","content":"Some of our team members are hobbyist DJs, playing shows for college parties and other local events. As smaller-size DJs we've always dreamed of having amazing live visuals for our sets, at the same quality as the largest EDM festivals; however, the cost, effort, and skillset was clearly infeasible for us, and infeasible for any musicians but the higher-profile ones who have the budget to commission lengthy visualizations and animations from third-party digital artists. That was a few years ago; recently, since generative vision models in ML have reached such a high quality of output, and open-source models (namely, stable diffusion) allow for intricate, transformative engineering at the level of model internals, we've realized our music live visuals dream has become possible.\n\nWe've come up with an app that takes a song and a prompt, and generates a music video in real-time that's perfectly synced to the music. The app will allow DJs and other musicians to have professional-level visuals for their live shows without the need for expensive commissions or complex technical setups. With our app, any musician can have access to stunning visuals that will take their performances to the next level."},{"heading":"What it does","content":"Mixingjays is an innovative video editing tool powered by machine learning that's designed specifically for creating stunning visual accompaniments to music. Our app allows clients to upload their music tracks and specify various parameters such as textures, patterns, objects, colors, and effects for different sections of the song.\n\nOur system then takes these specifications and translates them into prompts for our advanced ML stable diffusion model, which generates a unique video tailored to the uploaded music track. Once the video is generated, the user can easily edit it using our intuitive and user-friendly interface. Our app provides users with a range of editing options, from basic graphical edits (similar to popular photo editing apps like Instagram and VSCO) to advanced generative edits that are handled by our ML pipeline.\n\nThe user experience of Mixingjays is similar to that of well-known video editing software like Adobe Premiere or Final Cut, but with the added power of our machine learning technology driving the video outputs. Our app provides users with the ability to create professional-quality music videos with ease and without the need for extensive technical knowledge. Whether you're a professional musician or an amateur DJ, Mixingjays can help you create stunning visuals that will take your music to the next level while giving the musicians full creative control over the video."},{"heading":"How we built it","content":"One of our baseline innovations is generating video from stable diffusion and engineering on the model internals of stable diffusion. As a standalone, stable diffusion outputs static images based on natural language prompts. Given a list of images that stable diffusion outputs from several prompts, we're able to generate video between the images by interpolating between images in CLIP latent space. A detail of stable diffusion is that it actually computes its output on a latent space, a compressed coordinate system the the model abstractly uses to represent images and text; the latent vector in latent space is then decoded into the image we see. This latent space is well-behaved in Euclidean space, so we can generate new image outputs and smooth transitions between images, strung into a video, by linearly interpolating between the latent vectors of two different images before decoding every interpolated vector. If the two images we interpolate between are from two different prompts from the same seed of stable diffusion, or the same prompt across two different seeds of stable diffusion, the resulting interpolations and video end up being semantically coherent and appealing.[1] A nice augmentation to our interpolation technique is perturbing the latent vector in coordinate space, making a new latent vector anywhere in a small Lp-norm ball surrounding the original vector. (This resembles the setting of adversarial robustness in computer vision research, although our application is not adversarial.) As a result, given a list of stable diffusion images and their underlying latent vectors, we can generate video by latent-space-interpolating between the images in order.\n\nWe generate videos directly from the music, which relies on a suite of algorithms for music analysis. The demucs model from Facebook AI Research (FAIR) performs \"stem separation,\" or isolation of certain individual instruments/elements in a music track; we pass our music track into the model and generate four new music tracks of the same length, containing only the vocals, drums, bass, and melodic/harmonic instruments of the track, respectively. With OpenAI Whisper, we're able to extract all lyrics from the isolated vocal track, as well as bucket lyrics into corresponding timestamps at regular intervals. With more classical music analysis algorithms, we're able to:\n\nconvert our drum track and bass track into timestamps for the rhythm/groove of the track and convert our melody/harmony track into a timestamped chord progression, essentially the formal musical notation of harmonic information in the track.\n\nThese aspects of music analysis directly interface into our stable diffusion and latent-space-interpolation pipeline. In practice, the natural language prompts into stable diffusion usually consist of long lists of keywords specifying:\n\nobjects, textures, themes, backgrounds physical details adjectives influencing tone of the picture photographic specs: lighting, shadows, colors, saturation/intensity, image quality (\"hd\", \"4k\", etc) artistic styles Many of these keywords are exposed to the client at the UI level of our application, as small text inputs, sliders, knobs, dropdown menus, and more. As a result, the client retains many options for influencing the video output, independently of the music. These keywords are concatenated with natural language encapsulations of musical aspects: Lyrics are directly added to the prompts. Melodic/harmonic information and chord progressions map to different colors and themes, based on different chords' \"feel\" in music theory. Rhythm and groove is added to the interpolation system! We speed up, slow down, and alter our trajectory of movement though latent space in time with the rhythm. The result is a high-quality visualizer that incorporates both the user's specifications/edits and the diverse analyzed aspects of the music track.\n\nTheoretically, with good engineering, we'd be able to run our video generation and editing pipelines very fast, essentially in real time! Because interpolation occurs at the very last layer of the stable diffusion model internals, and video output from it depends only on a simple decoder instead of the entire stable diffusion model, video generation from interpolation is very fast and the runtime bottleneck depends only on stable diffusion. We generate one or two dozen videos from stable diffusion per video, so by generating each image in parallel on a wide GPU array, as well as incorporating stable diffusion speedups, we're able to generate the entire video for a music track in a few seconds!"},{"heading":"Challenges we ran into","content":"Prompt generation: Generating good quality prompts is hard. We tried different ways of prompting the model to see its affect on the quality of generated images and output video and discovered we needed more description of the song in addition to the manually inputted prompt. This motivated us to look into music analysis.\n\nMusic Analysis: Our music analysis required pulling together a lot of disparate libraries and systems for digital signal processing that aren't typically used together, or popular enough to be highly supported. The challenge here was wrangling these libraries into a single system without the pipeline crumbling to obscure bugs.\n\nStable Diffusion: The main challenge in using stable diffusion for multiple image generation is the overhead cost, compute and time. Primitive implementations of stable diffusion took 30s to generate an image which made things hard for us since we need to generate multiple images against each song and prompt pair. Modal workshop at Treehacks was very helpful for us to navigate this issue. We used modal containers and stubs to bake our functions into the images such that they are run only when the functions are called and free the GPUs otherwise for other functions to run. It also helped us parallelise our code which made things faster. However, since it is new, it was difficult to get it to recognise other files, adding data types to function methods etc.\n\nInterpolation: This was by far the hardest part. Interpolation is not only slow but also hard to implement or reproduce. After extensive research and trials with different libraries, we used Google Research‚Äôs Frame-interpolation method. It is implemented in tensorflow, in contrary to the other code which was more PyTorch heavy. In addition to that it is slow and scales exponentially with the number of images. A 1 minute video took 10 minutes to generate. Given the 36 hour time limitation, we had to generate the videos in advance for our app but there is tons of scope to make it faster.\n\nIntegration: The biggest bottlenecks came about when trying to generate visuals for arbitrary input mp3 files. Because of this, we had to reduce our expectation of on-the-fly, real-time rendering of any input file, to a set of input files that we generated offline. Render times ranged anywhere from 20 seconds to many minutes, which means that we‚Äôre still a little bit removed from bringing this forward as a real-application for users around the world to toy with. Real-time video editing capabilities also proved difficult to implement given the lack of time for building substantial infrastructure, but we see this as a next step in building out a fully functional product that anyone can use!"},{"heading":"Accomplishments that we're proud of","content":"We believe we've made significant progress towards a finalized, professional-grade application for our purposes. We showed that the interpolation idea produces video output that is high-quality, semantically coherent, granularly editable, and closely linked to the concurrent musical aspects of rhythm, melody, harmony, and lyrics. This makes our video offerings genuinely usable in professional live performances. Our hackathon result is a more rudimentary proof-of-concept, but our results lead us to believe that continuing this project in a longer-term setting would lead to a robust, fully-featured offering that directly plugs into the creative workflow of hobbyist and professional DJs and other musical live performers."},{"heading":"What we learned","content":"We found ourselves learning a ton about the challenges of implementing cutting-edge AI/ML techniques in the context of a novel product. Given the diverse set of experiences that each of our team members have, we also learned a ton through cross-team collaboration between scientists, engineers, and designers."},{"heading":"What's next for Mixingjays","content":"Moving forward, we have several exciting plans for improving and expanding our app's capabilities. Here are a few of our top priorities:\n\nImproving speed and latency: We're committed to making our app as fast and responsive as possible. That means improving the speed and latency of our image-to-video interpolation process, as well as optimizing other parts of the app for speed and reliability.\n\nVideo editing: We want to give our users more control over their videos. To that end, we're developing an interactive video editing tool that will allow users to regenerate portions of their videos and choose which generation they want to keep. Additionally, we're exploring the use of computer vision to enable users to select, change, and modify objects in their generated videos.\n\nScript-based visualization: We see a lot of potential in using our app to create visualizations based on scripts, particularly for plays and music videos. By providing a script, our app could generate visualizations that offer guidance on stage direction, camera angles, lighting, and other creative elements. This would be a powerful tool for creators looking to visualize their ideas in a quick and efficient manner.\n\nOverall, we're excited to continue developing and refining our app to meet the needs of a wide range of creators and musicians. With our commitment to innovation and our focus on user experience, we're confident that we can create a truly powerful and unique tool for music video creation."},{"heading":"References","content":"Seth Forsgren and Hayk, Martiros, \"Riffusion - Stable diffusion for real-time music generation.\" 2022. https://riffusion.com/about"},{"heading":"Built With","content":"express.js fair firebase github google-cloud huggingface mantine modal next.js node.js numpy openai pytorch react.js render scipy tailwind tensorflow typescript vercel"},{"heading":"Try it out","content":"github.com"}]},{"project_title":"Dispatch","project_url":"https://devpost.com/software/dispatch-wedj2m","tagline":"No Borders. No limits. Just Remit.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/390/412/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Most Ethically Engaged Hack by Stanford Center for Ethics & Society: $1000"}],"team_members":[],"built_with":[{"name":"api","url":null},{"name":"checkbook","url":null},{"name":"google-cloud","url":"https://devpost.com/software/built-with/google-cloud"},{"name":"javascript","url":"https://devpost.com/software/built-with/javascript"},{"name":"php","url":"https://devpost.com/software/built-with/php"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"retool","url":null},{"name":"sql","url":"https://devpost.com/software/built-with/sql"}],"external_links":[{"label":"www.canva.com","url":"https://www.canva.com/design/DAFa-v8EdCc/wT__PIobO1BkE07cX_hG5Q/view?utm_content=DAFa-v8EdCc&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton"},{"label":"restarauntradar.retool.com","url":"https://restarauntradar.retool.com/apps/f5736d60-af43-11ed-9692-63e73c9c8fc9/Onboarding%20Page"},{"label":"shorturl.at","url":"http://shorturl.at/fJTX2"}],"description_sections":[{"heading":"Inspiration","content":"One of the biggest challenges faced by families in war effected countries was receiving financial support from their family members abroad. High transaction fees, lack of alternatives and a lack of transparency all contributed to this problem, leaving families struggling to make ends meet.\n\nAccording to the World Bank, the average cost of sending remittances to low income countries is a striking 7% of the amount sent . For conflict affected families, a 7% transaction fee means the difference between putting food on the table or going hungry for days. The truth is that the livelihoods of those left behind vitally depend on remittance transfers. Remittances are of central importance for restoring stability for families in post-conflict countries. At Dispatch, we are committed to changing the lives of war stricken communities. Our novel app allows families to receive money from their loved ones, without having to worry about the financial barriers that had previously stood in their area.\n\nHowever, the problem is far larger. Economically, over $20 billion has been sent back and forth in the United States this year, and we are barely even two months in. There are more than 89 million migrants in the United States itself. In a hugely untapped market that cares little about its customers and is dominated by exploitative financial institutions, we provide the go-to technology-empowered alternative that lets users help their families and friends around the world. We provide a globalized, one-stop shop for sending money across the world.\n\nSimply put, we are the iPhone of a remittance industry that uses landlines."},{"heading":"What problems exist","content":"High cost, mistrust and inefficiency : Traditional remittance services often charge high fees for their services, which significantly reduces the amount of money that the recipient receives. A report by the International Fund for Agricultural Development (IFAD) found that high costs of remittance lead to a loss of $25 billion every year for developing countries . Additionally, they don‚Äôt provide clear information on exchange rate and fees, which leads to mistrust among users. Remittance services tend to have an upper limit on how much one can send per transaction, and they end up leading to security issues once money has been sent over. Lastly, these agencies take days to acknowledge, process, and implement a certain transaction, making immediate transfers intractable. Zero alternatives = exploitation : It‚Äôs also important to note that very few traditional remittance services are offered in countries affected by war. Remittance services tend not to operate in these regions. With extremely limited options, families are left with no option but to accept the high fees and poor exchange rates by these agencies. This isn‚Äôt unique to war stricken countries. This is a huge problem in developing countries. Due to the high fees associated with traditional remittance services, many families in developing countries are unable to fully rely on remittance alone to support themselves. As a result, they may turn to alternative financial options that can be exploitative and dangerous. One such alternative is the use of loan sharks, who offer quick loans with exorbitant interest rates, often trapping borrowers in a cycle of debt."},{"heading":"How we improve the status quo","content":"We are a mobile application that provides a low-cost, transparent and safe way to remit money. With every transaction made through Dispatch, our users are making a tangible difference in the lives of their loved ones.\n\nZERO Transaction fees : Instead of charging a percentage-based commission fee, we charge a subscription fee per month. This has a number of advantages. Foremost, it offers a cost effective solution for families because it remains the same regardless of the transfer amount. This also makes the process transparent and simpler as the total cost of the transaction is clear upfront. Simplifying the process : Due to the complexity of the current remittance process, migrants may find themselves vulnerable to exploitative offers from alternative providers. This is because they don‚Äôt understand the details and risks associated with these alternatives. On our app, we provide clear and concise information that guides users through the entire process. A big way of simplifying the process is to provide multilingual support. This not only removes barriers for immigrants, but also allows them to fully understand what‚Äôs happening without being taken advantage of. Transparency & Security Clearly stated and understood fees and exchange rates - no hidden fees Real-time exchange rate updates Remittance tracker Detailed transaction receipts Secure user data (Users can only pay when requested to) Instant notifications and Auto-Payment Reminders for bill payments and insurance renewals Can auto-pay bills (will require confirmation each time before its done) so the user remains worry- free and does not require an external calendar to manage finances Notifications for when new requests have been made by the remitter"},{"heading":"How we built it","content":"Backend Our backend is built on an intricate relational database between users, their transactions and the 170 currencies and their exchange rates We use the robust Checkbook API as the framework to make payments and keep track of the invoices of all payments run through Dispatch Frontend We used the handy and intuitive Retool environment to develop a rudimentary app prototype, as demonstrated in our video demo It implements most of the core functionality of our app and makes use of our functional MySQL database to create a working app The Figma designs represent our vision of what the end product UI would look like"},{"heading":"Challenges we ran into","content":"International money transfer regulations Government restrictions on currencies /embargos Losing money initially with our business model"},{"heading":"Accomplishments that we're proud of","content":"Develop an idea with immense social potential Integrating different APIs into one comprehensive user interface Coming from a grand total of no hackathon experience, we were able to build a functioning prototype of our application. Team bonding ‚Äì jamming to Bollywood music"},{"heading":"What we learned","content":"How to use Retool and Checkbook APIs How to deploy a full fledged mobile application How to use MySQL Understanding the challenges faced by migrants Gained insight into how fintech can solve social issues"},{"heading":"What's next for Dispatch","content":"The primary goal of Dispatch is to empower war-affected families by providing them with a cost-effective and reliable way to receive funds from their loved ones living abroad. However, our vision extends beyond this demographic, as we believe that everyone should have access to an affordable, safe, and simple way to send money abroad.\n\nWe hope to continuously innovate and improve our app. We hope to utilize blockchain technology to make transactions more secure by providing a decentralized and tamper proof ledger. By leveraging emerging technologies such as blockchain, we aim to create a cutting-edge platform that offers the highest level of security, transparency and efficiency.\n\nUltimately, our goal is to create a world where sending money abroad is simple, affordable, and accessible to everyone. Through our commitment to innovation, transparency, and customer-centricity, we believe that we can achieve this vision and make a positive impact on the lives of millions of people worldwide."},{"heading":"Ethics","content":"Banks are structurally disincentivized to help make payments seamless for migrants. We read through various research reports, with Global Migration Group‚Äôs 2013 Report on the ‚ÄúExploitation and abuse of international migrants, particularly those in an irregular situation: a human rights approach‚Äù to further understand the violation of present ethical constructs. As an example, consider how bad a 3% transaction fees (using any traditional banking service) can be for an Indian student whose parents pay Stanford tuition - 3 % of $ 82, 162 = $ 2464.86 (USD) = 204,005.37 (INR) [1 USD = 82.07 INR] That is, it costs an extra 200,000 Indian rupees for a family that pays Stanford students via a traditional banking service. Consider the fact that, out of 1.4 billion Indians, this is greater than the average annual income for an Indian. Just the transaction fees alone can devastate a home. Clearly, we don‚Äôt destroy homes, hearts, or families. We build them, for everyone without exception.\n\nWe considered the current ethical issues that arise with traditional banking or online payment systems. The following ethical issues arise with creating exclusive, expensive, and exploitative payment services for international transfers:\n\nBanks earn significant revenue from remittance payments, and any effort to make the process more seamless could potentially reduce their profits. Banks may view migrant populations as a high-risk group for financial fraud, leading them to prioritize security over convenience in remittance payments Remittance payments are often made to developing countries with less developed financial infrastructure, making it more difficult and costly for banks to facilitate these transactions Many banks are large, bureaucratic organizations that may not be agile enough to implement new technologies or processes that could streamline remittance payments. Banks may be more focused on attracting higher-value customers with more complex financial needs, rather than catering to the needs of lower-income migrants. The regulatory environment surrounding remittance payments can be complex and burdensome, discouraging banks from investing in this area. Banks do not have a strong incentive to compete on price in the remittance market, since many migrants are willing to pay high fees to ensure their money reaches its intended recipient. Banks may not have sufficient data on the needs and preferences of migrant populations, making it difficult for them to design effective remittance products and services. Banks may not see remittance payments as a strategic priority, given that they are only a small part of their overall business. Banks may face cultural and linguistic barriers in effectively communicating with migrant populations, which could make it difficult for them to understand and respond to their needs.\n\nCollectively, as remittances lower, we lose out on the effects of trickle-down economics in developing countries, detrimentally harming how they operate and even stunting their growth in some cases. For the above reasons, our app could not be a traditional online banking system. We feel there is an ethical responsibility to help other countries benefit from remittances. Crucially, we feel there is an ethical responsibility to help socioeconomically marginalized communities help their loved ones. Hence, we wanted to use technology as a means to include, not exclude and built an app that we hope could be versatile and inclusive to the needs of our user. We needed our app design to be helpful towards our user - allowing the user to gain all the necessary information and make bill payments easier to do across the world. We carefully chose product design elements that were not wordy but simple and clear and provided clear action items that indicated what needed to be done. However, we anticipated the following ethical issues arising from our implementation :\n\nData privacy: Remittance payment apps collect a significant amount of personal data from users. It is essential to ensure that the data is used ethically and is adequately protected. Security: Security is paramount in remittance payment apps. Vulnerabilities or data breaches could lead to significant financial losses or even identity theft. Fast transfers can often lead to mismanagement in accounting. Accessibility: Migrants who may be unfamiliar with technology or may not have access to smartphones or internet may be left out of such services. This raises ethical questions around fairness and equity. Transparency: It is important to provide transparent information to users about the costs and fees associated with remittance payment apps, including exchange rates, transfer fees, and any other charges. We even provide currency optimization features, that allows users to leverage low/high exchange rates so that users can save money whenever possible. Inclusivity: Remittance payment apps should be designed to be accessible to all users, regardless of their level of education, language, or ability. This raises ethical questions around inclusivity and fairness. Financial education: Remittance payment apps could provide opportunities for financial education for migrants. It is important to ensure that the app provides the necessary education and resources to enable users to make informed financial decisions.\n\nConscious of these ethical issues, we came up with the following solutions to provide a more principally robust app:\n\nData privacy: We collect minimal user data. The only information we care about is who sends and gets the money. No extra information is ever asked for. For undocumented immigrants this often becomes a concern and they cannot benefit from remittances. The fact that you can store the money within the app itself means that you don‚Äôt need to go through the bank's red-tape just to sustain yourself. Security: We only send user data once the user posts a request from the sender. We prevent spam by only allowing contacts to send those requests to you. This prevents the user from sending large amounts of money to the wrong person. We made fast payments only possible in highly urgent queries, allowing for a priority based execution of transactions. Accessibility: Beyond simple button clicks, we don‚Äôt require migrants to have a detailed or nuanced knowledge of how these applications work. We simplify the user interface with helpful widgets and useful cautionary warnings so the user gets questions answered even before asking them. Transparency: With live exchange rate updates, simple reminders about what to pay when and to who, we make sure there is no secret we keep. For migrants, the assurance that they aren‚Äôt being ‚Äúcheated‚Äù is crucial to build a trusted user base and they deserve to have full and clearly presented information about where their money is going. Inclusivity: We provide multilingual preferences for our users, which means that they always end up with the clearest presentation of their finances and can understand what needs to be done without getting tangled up within complex and unnecessarily complicated ‚Äúterms and conditions‚Äù. Financial education: We provide accessible support resources sponsored by our local partners on how to best get accustomed to a new financial system and understand complex things like insurance and healthcare.\n\nBefore further implementation, we need to robustly test how secure and spam-free our payment system could be. Having a secure payment system is a high ethical priority for us.\n\nOverall, we felt there were a number of huge ethical concerns that we needed to solve as part of our product and design implementation. We felt we were able to mitigate a considerable percentage of these concerns to provide a more inclusive, trustworthy, and accessible product to marginalized communities and immigrants across the world."},{"heading":"Built With","content":"api checkbook google-cloud javascript php python retool sql"},{"heading":"Try it out","content":"www.canva.com restarauntradar.retool.com shorturl.at"}]},{"project_title":"Pocket Plots","project_url":"https://devpost.com/software/pocket-plots","tagline":"Making land ownership accessible and affordable to all","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/386/319/datas/medium.gif","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Startup by YC, Runner-Ups"}],"team_members":[],"built_with":[{"name":"checkbook","url":null},{"name":"convex","url":null},{"name":"gradio","url":null},{"name":"huggingface","url":null},{"name":"materialui","url":null},{"name":"natural-language-processing","url":"https://devpost.com/software/built-with/natural-language-processing"},{"name":"netlify","url":null},{"name":"nltk","url":"https://devpost.com/software/built-with/nltk"},{"name":"numpy","url":"https://devpost.com/software/built-with/numpy"},{"name":"pandas","url":"https://devpost.com/software/built-with/pandas"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"react","url":"https://devpost.com/software/built-with/react"},{"name":"scikit-learn","url":"https://devpost.com/software/built-with/scikit-learn"},{"name":"tailwind","url":null},{"name":"transformer","url":null}],"external_links":[{"label":"github.com","url":"https://github.com/crasgaitis/TreeHacks-23-deployment"},{"label":"warm-cendol-1db56b.netlify.app","url":"https://warm-cendol-1db56b.netlify.app/"},{"label":"colab.research.google.com","url":"https://colab.research.google.com/drive/1NH8jJWesyJmiUALU_JdPAiHiSCwNtkne?usp=sharing"}],"description_sections":[{"heading":"üí° Inspiration","content":"Generation Z is all about renting - buying land is simply out of our budgets. But the tides are changing: with Pocket Plots, an entirely new generation can unlock the power of land ownership without a budget.\n\nTraditional land ownership goes like this: you find a property, spend weeks negotiating a price, and secure a loan. Then, you have to pay out agents, contractors, utilities, and more. Next, you have to go through legal documents, processing, and more. All while you are shelling out tens to hundreds of thousands of dollars.\n\nYuck.\n\nPocket Plots handles all of that for you.\n\nWe, as a future LLC, buy up large parcels of land, stacking over 10 acres per purchase. Under the company name, we automatically generate internal contracts that outline a customer's rights to a certain portion of the land, defined by 4 coordinate points on a map.\n\nEach parcel is now divided into individual plots ranging from 1,000 to 10,000 sq ft, and only one person can own a contract to each plot to the plot.\n\nThis is what makes us fundamentally novel: we simulate land ownership without needing to physically create deeds for every person. This skips all the costs and legal details of creating deeds and gives everyone the opportunity to land ownership.\n\nThese contracts are 99 years and infinitely renewable, so when it's time to sell, you'll have buyers flocking to buy from you first.\n\nYou can try out our app here: https://warm-cendol-1db56b.netlify.app/ (AI features are available locally. Please check our Github repo for more.)"},{"heading":"‚öôÔ∏èWhat it does","content":"Buy land like it's ebay:\n\nWe aren't just a business: we're a platform. Our technology allows for fast transactions, instant legal document generation, and resale of properties like it's the world's first ebay land marketplace.\n\nWe've not just a business.\n\nWe've got what it takes to launch your next biggest investment.\n\nPocket as a new financial asset class...\n\nIn fintech, the last boom has been in blockchain. But after FTX and the bitcoin crash, cryptocurrency has been shaken up: blockchain is no longer the future of finance.\n\nInstead, the market is shifting into tangible assets, and at the forefront of this is land. However, land investments have been gatekept by the wealthy, leaving little opportunity for an entire generation\n\nThat's where pocket comes in. By following our novel perpetual-lease model, we sell contracts to tangible buildable plots of land on our properties for pennies on the dollar.\n\nWe buy the land, and you buy the contract.\n\nIt's that simple.\n\nWe take care of everything legal: the deeds, easements, taxes, logistics, and costs. No more expensive real estate agents, commissions, and hefty fees.\n\nWith the power of Pocket, we give you land for just $99, no strings attached.\n\nWith our resell marketplace, you can sell your land the exact same way we sell ours: on our very own website.\n\nWe handle all logistics, from the legal forms to the system data - and give you 100% of the sell value, with no seller fees at all.\n\nWe even will run ads for you, giving your investment free attention.\n\nSo how much return does a Pocket Plot bring?\n\nWell, once a parcel sells out its plots, it's gone - whoever wants to buy land from that parcel has to buy from you.\n\nWe've seen plots sell for 3x the original investment value in under one week. Now how insane is that? The tides are shifting, and Pocket is leading the way.\n\n...powered by artificial intelligence\n\nCaption generation\n\nPocket Plots scrapes data from sites like Landwatch to find plots of land available for purchase. Most land postings lack insightful descriptions of their plots, making it hard for users to find the exact type of land they want. With Pocket Plots , we transformed links into images, into helpful captions.\n\nCaptions ‚Üí Personalized recommendations\n\nThese captions also inform the user's recommended plots and what parcels they might buy. Along with inputting preferences like desired price range or size of land, the user can submit a text description of what kind of land they want. For example, do they want a flat terrain or a lot of mountains? Do they want to be near a body of water? This description is compared with the generated captions to help pick the user's best match!\n\nChatbot\n\nMinute Land can be confusing. All the legal confusion, the way we work, and how we make land so affordable makes our operations a mystery to many. That is why we developed a supplemental AI chatbot that has learned our system and can answer questions about how we operate.\n\nPocket Plots offers a built-in chatbot service to automate question-answering for clients with questions about how the application works. Powered by openAI, our chat bot reads our community forums and uses previous questions to best help you."},{"heading":"üõ†Ô∏è How we built it","content":"Our AI focused products (chatbot, caption generation, and recommendation system) run on Python, OpenAI products, and Huggingface transformers. We also used a conglomerate of other related libraries as needed.\n\nOur front-end was primarily built with Tailwind, MaterialUI, and React. For AI focused tasks, we also used Streamlit to speed up deployment.\n\nWe run on Convex\n\nWe spent a long time mastering Convex, and it was worth it. With Convex's powerful backend services, we did not need to spend infinite amounts of time developing it out, and instead, we could focus on making the most aesthetically pleasing UI possible.\n\nCheckbook makes payments easy and fast\n\nWe are an e-commerce site for land and rely heavily on payments. While stripe and other platforms offer that capability, nothing compares to what Checkbook has allowed us to do: send invoices with just an email. Utilizing Checkbook's powerful API, we were able to integrate Checkbook into our system for safe and fast transactions, and down the line, we will use it to pay out our sellers without needing them to jump through stripe's 10 different hoops."},{"heading":"ü§î Challenges we ran into","content":"Our biggest challenge was synthesizing all of our individual features together into one cohesive project, with compatible front and back-end. Building a project that relied on so many different technologies was also pretty difficult, especially with regards to AI-based features. For example, we built a downstream task, where we had to both generate captions from images, and use those outputs to create a recommendation algorithm."},{"heading":"üòé Accomplishments that we're proud of","content":"We are proud of building several completely functional features for Pocket Plots . We're especially excited about our applications of AI, and how they make users' Pocket Plots experience more customizable and unique."},{"heading":"üß† What we learned","content":"We learned a lot about combining different technologies and fusing our diverse skillsets with each other. We also learned a lot about using some of the hackathon's sponsor products, like Convex and OpenAI."},{"heading":"üîé What's next for Pocket Plots","content":"We hope to expand Pocket Plots to have a real user base. We think our idea has real potential commercially. Supplemental AI features also provide a strong technological advantage."},{"heading":"Built With","content":"checkbook convex gradio huggingface materialui natural-language-processing netlify nltk numpy pandas python react scikit-learn tailwind transformer"},{"heading":"Try it out","content":"github.com warm-cendol-1db56b.netlify.app colab.research.google.com"}]},{"project_title":"NazAR","project_url":"https://devpost.com/software/nazar","tagline":"Scan a homework problem and instantly generate a novel, interactive learning environment from it in AR. No QR codes. No pre-curated problems. And all you need is an iPhone or iPad.","preview_image_url":"https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/838/datas/medium.png","prizes":[{"hackathon_name":"TreeHacks 2023","hackathon_url":"https://treehacks-2023.devpost.com/","prize_name":"Best Startup by YC, Runner-Ups"}],"team_members":[],"built_with":[{"name":"apple-vision-framework","url":null},{"name":"augmented-reality","url":"https://devpost.com/software/built-with/augmented-reality"},{"name":"natural-language-processing","url":"https://devpost.com/software/built-with/natural-language-processing"},{"name":"python","url":"https://devpost.com/software/built-with/python"},{"name":"reality-kit","url":null},{"name":"swift","url":"https://devpost.com/software/built-with/swift"}],"external_links":[{"label":"github.com","url":"https://github.com/devstep2/Treehacks_Proj.git"}],"description_sections":[{"heading":"About the Project","content":"NazAR is an educational tool that automatically creates interactive visualizations of math word problems in AR, requiring nothing more than an iPhone."},{"heading":"Behind the Name","content":"Nazar means ‚Äúvision‚Äù in Arabic, which symbolizes the driving goal behind our app ‚Äì not only do we visualize math problems for students, but we also strive to represent a vision for a more inclusive, accessible and tech-friendly future for education. And, it ends with AR, hence NazAR :)"},{"heading":"Inspiration","content":"The inspiration for this project came from each of our own unique experiences with interactive learning. As an example, we want to showcase two of the team members‚Äô experiences, Mohamed and Rayan‚Äôs. Mohamed Musa moved to the US when he was 12, coming from a village in Sudan where he grew up and received his primary education. He did not speak English and struggled until he had an experience with a teacher that transformed his entire learning experience through experiential and interactive learning. From then on, applying those principles, Mohamed was able to pick up English fluently within a few months and reached the top of his class in both science and mathematics. Rayan Ansari had worked with many Syrian refugee students on a catch-up curriculum. One of his students, a 15 year-old named Jamal, had not received schooling since Kindergarten and did not understand arithmetic and the abstractions used to represent it. Intuitively, the only means Rayan felt he could effectively teach Jamal and bridge the connection would be through physical examples that Jamal could envision or interact with. From the diverse experiences of the team members, it was glaringly clear that creating an accessible and flexible interactive learning software would be invaluable in bringing this sort of transformative experience to any student‚Äôs work. We were determined to develop a platform that could achieve this goal without having its questions pre-curated or requiring the aid of a teacher, tutor, or parent to help provide this sort of time-intensive education experience to them."},{"heading":"What it does","content":"Upon opening the app, the student is presented with a camera view, and can press the snapshot button on the screen to scan a homework problem. Our computer vision model then uses neural network-based text detection to process the scanned question, and passes the extracted text to our NLP model.\n\nOur NLP text processing model runs fully integrated into Swift as a Python script, and extracts from the question a set of characters to create in AR, along with objects and their quantities, that represent the initial problem setup. For example, for the question ‚ÄúSally has twelve apples and John has three. If Sally gives five of her apples to John, how many apples does John have now?‚Äù, our model identifies that two characters should be drawn: Sally and John, and the setup should show them with twelve and three apples, respectively.\n\nThe app then draws this setup using the Apple RealityKit development space, with the characters and objects described in the problem overlayed. The setup is interactive, and the user is able to move the objects around the screen, reassigning them between characters. When the position of the environment reflects the correct answer, the app verifies it, congratulates the student, and moves onto the next question. Additionally, the characters are dynamic and expressive, displaying idle movement and reactions rather than appearing frozen in the AR environment."},{"heading":"How we built it","content":"Our app relies on three main components, each of which we built from the ground up to best tackle the task at hand: a computer vision (CV) component that processes the camera feed into text: an NLP model that extracts and organizes information about the initial problem setup; and an augmented-reality (AR) component that creates an interactive, immersive environment for the student to solve the problem.\n\nWe implemented the computer vision component to perform image-to-text conversion using the Apple‚Äôs Vision framework model, trained on a convolutional neural network with hundreds of thousands of data points. We customize user experience with a snapshot button that allows the student to position their in front of a question and press it to capture an image, which is then converted to a string, and passed off to the NLP model.\n\nOur NLP model, which we developed completely from scratch for this app, runs as a Python script, and is integrated into Swift using a version of PythonKit we custom-modified to configure for iOS. It works by first tokenizing and lemmatizing the text using spaCy, and then using numeric terms as pivot points for a prioritized search relying on English grammatical rules to match each numeric term to a character, an object and a verb (action). The model is able to successfully match objects to characters even when they aren‚Äôt explicitly specified (e.g. for Sally in ‚ÄúRalph has four melons, and Sally has six‚Äù) and, by using the proximate preceding verb of each numeric term as the basis for an inclusion-exclusion criteria, is also able to successfully account for extraneous information such as statements about characters receiving or giving objects, which shouldn‚Äôt be included in the initial setup. Our model also accounts for characters that do not possess any objects to begin with, but who should be drawn in the display environment as they may receive objects as part of the solution to the question. It directly returns filenames that should be executed by the AR code.\n\nOur AR model functions from the moment a homework problem is read. Using Apple‚Äôs RealityKit environment, the software determines the plane of the paper in which we will anchor our interactive learning space. The NLP model passes objects of interest which correspond to particular USDZ assets in our library, as well as a vibrant background terrain. In our testing, we used multiple models for hand tracking and gesture classification, including a CoreML model, a custom SDK for gesture classification, a Tensorflow model, and our own gesture processing class paired with Apple‚Äôs hand pose detection library. For the purposes of Treehacks, we figured it would be most reasonable to stick with touchscreen manipulation, especially for our demo that utilizes the iPhone device itself without being worn with a separate accessory. We found this to also provide better ease of use when interacting with the environment and to be most accessible, given hardware constraints (we did not have a HoloKit Apple accessory nor the upcoming Apple AR glasses)."},{"heading":"Challenges we ran into","content":"We ran into several challenges while implementing our project, which was somewhat expected given the considerable number of components we had, as well as the novelty of our implementation.\n\nOne of the first challenges we had was a lack of access to wearable hardware, such as HoloKits or HoloLenses. We decided based on this, as well as a desire to make our app as accessible and scalable as possible without requiring the purchase of expensive equipment by the user, to be able to reach as many people who need it as possible.\n\nAnother issue we ran into was with hand gesture classification. Very little work has been done on this in Swift environments, and there was little to no documentation on hand tracking available to us. As a result, we wrote and experimented with several different models, including training our own deep learning model that can identify gestures, but it took a toll on our laptop‚Äôs resources. At the end we got it working, but are not using it for our demo as it currently experiences some lag. In the future, we aim to run our own gesture tracking model on the cloud, which we will train on over 24,000 images, in order to provide lag-free hand tracking.\n\nThe final major issue we encountered was the lack of interoperability between Apple‚Äôs iOS development environment and other systems, for example with running our NLP code, which requires input from the computer vision model, and has to pass the extracted data on to the AR algorithm. We have been continually working to overcome this challenge, including by modifying the PythonKit package to bundle a Python interpreter alongside the other application assets, so that Python scripts can be successfully run on the end machine. We also used input and output to text files to allow our Python NLP script to more easily interact with the Swift code."},{"heading":"Accomplishments we're proud of","content":"We built our computer vision and NLP models completely from the ground up during the Hackathon, and also developed multiple hand-tracking models on our own, overcoming the lack of documentation for hand detection in Swift.\n\nAdditionally, we‚Äôre proud of the novelty of our design. Existing models that provide interactive problem visualization all rely on custom QR codes embedded with the questions that load pre-written environments, or rely on a set of pre-curated models; and Photomath, the only major app that takes a real-time image-to-text approach, lacks support for word problems. In contrast, our app integrates directly with existing math problems, and doesn‚Äôt require any additional work on the part of students, teachers or textbook writers in order to function.\n\nAdditionally, by relying only on an iPhone and an optional HoloKit accessory for hand-tracking which is not vital to the application (which at a retail price of $129 is far more scalable than VR sets that typically cost thousands of dollars), we maximize accessibility to our platform not only in the US, but around the world, where it has the potential to complement instructional efforts in developing countries where educational systems lack sufficient resources to provide enough one-on-one support to students. We‚Äôre eager to have NazAR make a global impact on improving students‚Äô comfortability and experience with math in coming years."},{"heading":"What we learned","content":"We learnt a lot from building the tracking models, which haven‚Äôt really been done for iOS and there‚Äôs practically no Swift documentation available for. We are truly operating on a new frontier as there is little to no work done in the field we are looking at We will have to manually build a lot of different architectures as a lot of technologies related to our project are not open source yet. We‚Äôve already been making progress on this front, and plan to do far more in the coming weeks as we work towards a stable release of our app."},{"heading":"What's next for NazAR","content":"Having the app animate the correct answer (e.g. Bob handing apples one at a time to Sally) Animating algorithmic approaches and code solutions for data structures and algorithms classes Being able to automatically produce additional practice problems similar to those provided by the user Using cosine similarity to automatically make terrains mirror the problem description (e.g. show an orchard if the question is about apple picking, or a savannah if giraffes are involved) And more!"},{"heading":"Built With","content":"apple-vision-framework augmented-reality natural-language-processing python reality-kit swift"},{"heading":"Try it out","content":"github.com"}]}],"generated_at":"2026-02-18T16:40:22.763538Z"}}